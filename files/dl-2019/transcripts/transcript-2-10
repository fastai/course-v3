welcome to lesson 10 which I've rather enthusiastically titled wrapping up our CNN but looking at how many things we want to cover redditor nearly to the end and I'm not actually sure how nearly we'll get there we'll see we'll probably have a few more things to cover next week as well I just want to remind you after hearing from a few folks during the week who are very sad that they're not quite keeping up with everything that's totally ok don't worry as I mentioned in lesson 1 I'm trying to give you enough here to keep you busy until the next part to next year so you can dive into the bits you're interested in and go back and look over stuff and yeah don't feel like you have to understand everything within within a week of first hearing it and also if you're not putting in the time during the homework or you didn't put in the time during the homework in the last part you know the expect to have to go back and recover things particularly because a lot of the stuff we covered in part 1 I'm kind of assuming that you're deeply comfortable with at this point not because you're stupid if you're not but just because it gives you the opportunity to go back and re study it and practice and experiment until you are deeply comfortable so yeah it's if you're finding it whizzing along at a pace that is because it is with you along at a pace also it's covering a lot of more software engineering kind of stuff which for the soft people who are practicing software engineers you'll be thinking this is all pretty straightforward and for those of you that are not you'll be thinking wow there's a lot here part of that is because I think data scientists need to be good software engineers so I'm trying to show you some of these things but you know it's stuff which people can spend years learning and so hopefully this is the start of a long process for you that haven't done software engineering before of becoming better software engineers and there are some useful tips hopefully so to remind you where we're trying to recreate faster and much of much of pi torch from these foundations and and starting to make things even better and today you'll actually see some some bits well in fact you've already seen some bits that are going to be even better I think the next version of fast AI all have this new callback system which i think is better than the old one and today we're going to be showing you some new previously unpublished research which will be finding its way into fast AI and maybe other libraries as well also so we're going to try and stick to and we will stick to using nothing but these foundations and we're working through developing a modern CNN model and we've got to the point where we've done our training loop at this point we've got a nice flexible training loop so from here the rest of it when I say we're going to finish out a modern CNN model it's not just going to be some basic getting by model but we're actually going to endeavour to get something that is approximately state-of-the-art on imagenet in the next week or two so that's that's the goal and in our testing at this point we're feeling pretty good about showing you some stuff that maybe hasn't been seen before on image net results so that's that's where we're going to try and head as a group and so these are some of the things that we're going to be covering to get there one of the things you might not have seen before in the section code optimization is lamb the reason for this is that this was going to be some of the unpublished research we were going to show you which is a new optimization algorithm that we've been developing the framework is still going to be new but actually the particular approach to using it was published by Google two days ago so we've kind of been scooped there so this is the core paper really great and they introduced a new optimization algorithm called lamb which will be showing you how to implement it very easily and if you're wondering how we're able to do that so fast it's because we've kind of been working the same thing ourselves through a few weeks now so then from next week we'll start also developing a completely new fast ayo module called faster I audio so you'll be seeing how to actually create modules and how to write Jupiter documentation and tests and we're going to be learning about audio such as complex numbers and Fourier transforms which if you're like me at this point you're going oh what no because I managed to spend my life avoiding complex numbers and Fourier transforms on the whole but don't worry it'll be okay it's it's not it's actually not at all bad or at least the bits we need to learn about not at all bad and you'll totally get it even if you've never ever touched these before I will be learning about audio formats and spectrograms doing a data augmentation and things that aren't images and some particular kinds of loss functions and architectures for audio and you know as much as anything it'll just be a great kind of exercise in okay I've got some different data types it's not in fast day I had away build up all the bits I need to make it work then we'll be looking at neural translation as a way to learn about sequence to sequence with attention models and then we'll be going deeper and deeper into attention models looking at transformer and it's even more fantastic descendant transformer excel and then we'll wrap up our Python adventures with a deep dive into some really interesting vision topics which is going to require building some bigger models so we'll talk about how to build your own deep learning box how to run big experiments on AWS with a new library we've developed board first ec2 and then we're going to see exactly what happened last course when we did that unit super-resolution image generation what are some of the pieces there and we've actually got some really exciting new results to show you which have been done in collaboration with some really cool partners so I'm looking forward to showing you that to give you a tip generative video models is what we're going to be looking at and then we'll be looking at some interesting different applications devise cycle gain and object detection and then Swift of course so and the Swift lessons are coming together nicely really excited about them and we'll be covering as much of the same territory as we can but obviously it'll be in Swift and it'll be in only two lessons so it won't be everything but we'll try to give you enough of a taste that you'll feel like you understand why Swift is important and how to get started with building something similar in Swift and maybe building out the whole thing in Swift we'll take the next 12 months who knows we'll see so we're going to start today on zero 5a foundations and what we're going to do is we're going to recover some of the software engineering and math basics that we were relying on last week and going into a little bit more detail specifically we'll be looking at callbacks and variants and a couple of other Python concepts like add under special methods if you're familiar with those things feel free to skip ahead if you're watching the video till we get to the new material about callbacks as I'm sure you've seen a super important for fast AI and in general they're a really useful technique for software engineering and great for researchers because they allow you to build things that you can quickly adjust and add things in and pull them out again so really great for research as well so what is a callback let's look at an example so here's a function called F which prints out hi and I'm going to create a button and I'm going to create this button using I pi widgets which is a framework for creating GUI widgets in Python so if I run if I say W then it shows me a button which says click me and I can click on it and nothing happens so how do I get something to happen well what I need to do is I need to pass some I need to pass a function to the I PI widgets framework to say please run this function when you click on this button so I PI widget doc says there's a unclick method which can register a function to be called when the button is clicked so let's try running that method passing at F my function okay so now nothing happened alright didn't run anything but now if I click on here oh hi hi so what happened is I told W that when a click occurs you should call back to my F function and run it right so anybody who's done GUI programming will be extremely comfortable with this idea and if you haven't this will be kind of mind-bending right so f is a callback it's not a particular class it doesn't have a particular signature it's not a particular library it's a concept it's a function that we treat as an object so look we're not calling the function right we don't have any parentheses after F we're passing the function itself to this method and it says please call back to me when something happens in this case it's when I click okay so there's our starting point and these kinds of functions these kinds of call backs that are used in a GUI in particular framework when some event happens often called events so if you've heard of events they're kind of call back and then callbacks are kind of what we would call a function pointer I mean it can be much more general than that as you'll see but it's basically a way of passing in something to say call back to this when something happens now by the way these widgets are really worth looking at if you're interested in building some analytical gooeys here's a great example from the plotly documentation of the kinds of things you can create with with widgets and it's not just for creating applications for others to use but if you want to experiment with with different types of function or hyper parameters or you know explore some data you've collected widgets are a great way to do that and as you can see they're very very easy-to-use in part one you saw the image labeling stuff that was built with with widgets like this so that's how you can use somebody else's call back how do we create our own call back so let's create a call back and the event that it's going to call back on is after a calculation is complete so let's create a function a function called slow calculation and it's going to do five calculations it's going to add I squared to a result and then it's going to take a second to do it because we're going to add a sleep there so this is kind of something like a an epoch of deep learning at some calculation that takes a while so if we call slow calculation then it's going to take five seconds to calculate the sum of I squared and there it's done it so I'd really like to know how's it going you know get some progress so we could take that and we could add something that you pass in a callback and we just add one line of code that says if there's a callback then call it and pass in the ePub number so then we could create a function called show progress that prints out awesome we finished epoch number epoch and look it takes a parameter and we're passing a parameter so therefore we could now call slow calculation and passing show progress and it will call back to our function after each epoch so this our starting point for our callback now what will tend to happen you'll notice with stuff that we do in faster and faster I will start somewhere like this that's like for many of you is trivially easy and at some point during the next you know hour or two you might reach a point where you're feeling totally lost and the trick is to go back if you're watching the video to the point where it was trivially easy and figure out the bit way you suddenly noticed you were totally lost and find the bit in the middle where you kind of missed a bit because we're going to just keep building up from trivially easy stuff just like we did with that matrix multiplication all right so we're going to gradually build up from here and look at more more interesting callbacks but we're starting with this wonderfully short and simple line of code so rather than defining a function just for the purpose of using it once we can actually define the function at the point we use it using lambda notation so lambda notation is just another way of creating a function so rather than saying def we say lambda and then rather than putting in parenthesis the arguments we put them before a colon and then we miss the thing you're going to do so this is identical to the previous one it's just a convenience for times where you want to define the callback at the same time that you use it can make your code a little bit more concise what if you wanted to have something where you could define what explanation exclamation to use in the string as well so we've now got two things we can't pass this show progress to shut slow calculation let's try it right it tries to call back and it calls remember CB is now show progress so it's casting show progress and it's passing epoch as exclamation and then epoch is missing so that's an error we've called a function with two arguments with only one so we have to convert this into a function with only one argument so lambda o is a function with only one argument and this function calls show progress with a particular exclamation okay so we've converted something with two arguments into something with one argument we might want to make it really easy to allow people to create different progress indicators with different exclamations so we could create a function called make show progress that returns that lambda okay so now we could say make show progress so we could do that here make show Pro okay and that's the same thing all right this is a little bit awkward so generally you might see it done like this instead you see this in fast AI all the time we define the function inside it okay but this is basically just the same as our lambda and then we return that function so this is kind of interesting because you might think of defining a function as being like a declarative thing that as soon as you define it that now it's part of the thing that's like compiled if you see your C++ that's how they work in Python that's not how they work when you define a function you're actually saying the same basically the same as this which is there's a variable with this name which is a function right and that's how come then we can actually take something that's passed to this function and use it inside here right so this is actually every time we call make show progress it's going to create a new function underscore inner internally with a different exclamation and so it'll work the same as before okay so this thing where you create a function that actually stores some information from the external context and like it can be different every time that's called a closure okay so it's a concept you'll come across a lot particularly if you're a JavaScript programmer so we could say F 2 equals make sure progress terrific right and so that now contains that closure so it's it actually remembers what exclamation you passed it okay there's because it's so often that you want to take a function that takes two parameters and turn it into a function that takes one parameter Python and most languages have a way to do that which is called partial function application standard library funk tools has this incredible so if you take rock or partial and you pass it a function and then you pass in some arguments for that function it returns a new function that now just takes which which that parameter is always a given so let's check it out so we could run it like that or we could say F 2 equals this partial function application and so if I say f 2 shift-tab then you can see this is now a function that just takes a clock it just takes a park because show progress took two front two parameters we've already passed it one so this node takes one parameter which is what we need so that's why we could pass that to as our callback okay so we've seen a lot of those techniques already last week most of what we saw last week though did not use a function as a callback that used a class as a callback so we could do exactly the same thing but pretty much any place you can use a closure you can also use a class instead of storing it away inside the closure some state we can store our state in this case the explanation inside self passing it into in it all right so here's exactly the same thing as we saw before but as a class dunder call is a special magic name which will be called if you take a an object so in this case a progress showing callback object and call it with parentheses so if I go see B hi you see I'm taking that object and I'm treating as if it's a function and that will call dunder call if you've used other languages like in C++ this is called a func tour in more generally it's a quarter callable in python so it's a kind of something that a lot of languages have alright so now we can use that as a callback just like before all right next thing to look at is for our core backers we're going to use star args and star star kW args or otherwise known as kwargs for those of you that don't know what these mean let's create a function that takes togs and star star kW eggs and prints out eggs and kW eggs so if I call that function I could pass it three a thing one equals hello and you'll see that all the things that are passed as positional arguments end up in a you know tuple called arcs and all the things passed as keyword arguments end up as a dictionary called Quags that's literally all these things do right and so pi torch uses that for example when you create an n n dot sequential it's you it takes what you pass in as a star uggs right you just pass them directly and it turns it into a tuple so why do we use this there's a few reasons we use it but one of the common ways to use it is if you kind of want to wrap some other class or object then you can take a bunch of stuff as star star Quags and pass it off to some other functional object for we're getting better at this and we're removing a lot of the usages but in the early days of fast AI version 1 we actually were overusing kwargs so quite often we would kind of there would be a lot of stuff that wasn't obviously in the parameter list of a function that ace ended up in Quags and then we would pass it down to I don't know the PI torch data loader initializer or something and so we've been gradually removing those usages because like it's mainly most helpful for kind of quick and dirty throwing things together in in are they actually use an ellipsis for the same thing they kind of overuse it quite often it's hard to see what's going on you might have noticed in matplotlib a lot of times the thing you're trying to pass the matplotlib isn't there in the shift tab when you hit shift tab it's the same thing that using Quags so there are some downsides to using it but there are some places you really want to use it for example take a look at this let's take rewrite slow calculation but this time we're going to create allow the user to create a callback that is called before the calculation occurs and after the calculation that occurs and the after calculation one's a bit tricky because it's going to take two parameters now it's going to take both the epoch number and also what if we calculated so far all right so we can't just call CB parentheses I we actually now have to assume that it's got some particular methods so here is for example a print step callback right which before calculation just says I'm about to start and after calculation it says I'm done and there it's running so in this case this core back didn't actually care about the epoch number or about the value right and so it just has star star star kwargs in both places it doesn't have to worry about exactly what's being passed in because it's not using them so this is quite a good kind of use of this is to basically create a a function that's going to be used somewhere else and you don't care about one or more of the parameters or you want to make things more flexible so in this case we don't get an error saying because if we if we remove this like which looks like we should be able to do because we don't use anything but here's a problem it tried to call before calc I and before calc doesn't take an eye alright so if you put in both positional and keyword arguments it'll always work everywhere and so here we can actually use them so let's actually use epoch and value to print out those details so now you can see there it is printing them out and in this case I've put star star Quags at the end because maybe you know in the future there'll be some other things that a pasty and we want to make sure this doesn't break so it kind of makes it more resilient the next thing we might want to do with callbacks is to actually change something so a couple of things that we did last week one was we wanted to be able to cancel out of a loop to stop early the other thing we might want to do is actually change the value of something so in order to stop early we could check and also the other thing we might want to do is say well what if you don't want to define before calc or after calc we wouldn't want everything to break so we can actually check whether our callbacks defined and only call it if it is and we could actually check the return value and then do something based on the return value so here's something which will cancel out of our loop if the value that's been calculated so far is over 10 so here we stopped okay what if you actually want to change the way the calculations being done so we could even change the way the calculations being done by taking our calculation function putting it into a class and so now the value that it's calculated is a attribute of the class and so now we could actually do something a callback that reaches back inside the calculator and changes it right so this is going to double the result if it's less than 3 so if we run this right we now actually have to call this because it's a it's a class but you can see it's giving a different different value and so we're also taking advantage of this in the callbacks that we're using so this is kind of the ultimately flexible callback system and so you'll see in this case we actually have to pass the calculator object to the callback so the way we do that is we've defined a callback method here we're checks to see whether it's defined and if it is it grabs it and then it calls it passing in the calculator object itself so it's now available and so what we actually did in it last week is we didn't call this callback we called this dunder call which means we were able to do it like this okay now you know which do you prefer it's kind of up to you right I mean we had so many callbacks being called that I felt the extra noise of giving it a name was a bit messy on the other hand you might feel that calling a callback isn't something you expect them to call to do in which case you can do it that way so there's pros and there's pros and cons neither is right or wrong okay so that's that's callbacks we've been using dunder thingies a lot dunder thingies look like this and in Python a dunder thingy is special somehow most languages kind of let you define special behaviors for example in C++ there's an operator keyword where if you define a function that says operator something like plus you're defining the plus operator so most languages tend to have like special magic names you can give things that make something a constructor or a destructor or operator I like in Python that all of the magic names actually look magic they all look like that which i think is actually a really good way to do it so the Python Docs have a data model reference where they tell you about all these special method davis and you can go through and you can see what are all the special things you can get your method to do like you can override how it behaves with less than or equal to or etc etc there's a particular list ICG you know and this is the list okay so you can go to those Doc's and see what these things do because we use all of these in this course so here's an example here's a sloppy adder plus you pass in some number that you're gonna add up and then when you add two things together it will give you the result of adding them up but it will be wrong by 0.01 and that is called done to add because that's what happens when you see Plus this is called dunder init because this is what happens when an object gets constructed and this is called dunder repre because this is what gets called when you print it out so now I can create a one adder and a two adder and I can plus them together and I can see the result okay so that's kind of an example of how these special dunder methods work okay so that's a bit of that pice and stuff there's another bit of code stuff that I wanted to show you which you'll need to be doing a lot of which is you need to be really good at browsing source code if you're going to be contributing stuff too fast AI or too fast AI for Swift for tensorflow or just building your own more complex projects you need to be able to jump around source code or even just to find out how high torch does something if you're doing some research you need to really understand what's going on under the hood this is a list of things you should know how to do in your editor of choice any editor that can't do all of these things is worth replacing with one that can most editors can do these things Emacs can visual studio code can sublime can and the editor I use most of the time vim can as well I'll show you what these things are in vim on the forums there are already some topics saying how to do these things in other editors if you don't find one that seems any good your Creed free to create your own topic if you've got some tips about how to do these things or other useful things and your editor of choice so I'm going to show you in vim for no particular reason just because I use vim so here's my editor it's called vim one of the things I like about VM is I can use it in a terminal which I find super helpful because I'm working on remote machines all the time and I would like to be as at least as productive in a terminal as I am on my local computer and so the first thing you should be able to do is to jump to a symbol a symbol would be like a class or a function or something like that so for example I might want to be able to I might want to be able to jump straight to the definition of create CNN but I can't quite remember the name of the function create CNN so I would go colon tag create I'm pretty sure it's create underscore something it's and then I press tab a few times and it would loop through there it is create CNN and then I hit enter so that's the first thing that your editor should do is it should make it easy to jump to a tag even if you can't remember exactly what it is the second thing it should do is that you should be able to click on something like CNN learner and hit a button which in VIMS case is control right square bracket and it should take you to the definition of that thing so okay let's create this you know learner what's this thing called a data bunch red square bracket okay now there's data bunch you'll also see that my VM is folding out folding things classes and functions to make it easier for me to see exactly what's in this file in some editors this is called outlining in some it's called folding most editors should do this then this there should be a way to go back to where you were before in VM that's ctrl T for going back up the tag stack so here's my CNN learner is my create CNN and so you can see in this way it makes it nice and easy to kind of jump around a little bit something I find super helpful is to also be able to jump into the source code of libraries I'm using so for example here's climbing normal so I've got my VM configured so if I hit ctrl right square bracket on that it takes me to the definition of climbing normal in the pipe or source code and I find docstrings kind of annoying so I have mine folded up by default but I can always open them up if you use vim the way to do that is to add a additional tags for any packages you want to be able to jump to I'm sure most editors will do something pretty similar now that I've seen how climbing normal works I can use a saying ctrl T to jump back to where I was in my first AI source code then the only other thing that's particularly important to know how to do is to just do more general searches so let's say I wanted to find all the places that I've used lambda since we talked about lambda today I have a particular thing I use called AK I can say act lambda and here's a list of all of the places I've used lambda and I could click on one and it will jump to the code where it's used again most editors should do something like that for you so I find with that basic set of stuff you should be to get around pretty well if you're a professional software engineer I know you know all this if you're not hopefully you're feeling pretty excited right now to discover that editors can do more than you realized and so sometimes people will jump on our github and say I don't know how to find out what a function is that you're calling because you don't list all your imports of imports at the top of the screen that this is a great place where you should be using your editor to tell you and in fact one place that GUI editors can be pretty good is often if you actually just point at something they will pop up something saying exactly where is that symbol coming from I don't have that set up in vim so I just have to hit the right square bracket to see where something's coming from okay so that's some tips about stuff that you should be able to do when you're browsing source code and if you don't know how to do it yet please Google or look at the forums and practice something else we were looking at a lot last week and you need to know pretty well is variance so just a quick refresher on what variance is or for those of you who haven't studied it before here's what variance is variance is the average of how far away each data point is from the mean so here's some data right and here's the mean of that data and so the average distance for each data point from the mean is T the data points minus M that mean oh that's zero I didn't work well of course it didn't work the mean is to find as the thing which is in the middle all right so of course that's always zero so we need to do something else that doesn't have the positives and negatives counsel well so there's two main ways we fix it one is by squaring each thing before we take the main like so the other is taking the absolute value of each thing so turning all the negatives and positives before we take them in so they're both common fixes for this problem you can see though the first is now in a totally different scale right the numbers were like 1 2 4 80 and this is 47 so we need to undo that squaring so after we squared we then take the square root at the end so here are two numbers that represent how far things are away from the mean or in other words how much do they vary if everything is pretty close to similar to each other those two numbers will be small if they're wildly different to each other those two numbers will be big this one here is called the standard deviation and it's defined as the square root of this one here which is called the variance and this one here is called the mean absolute deviation you could replace this M main with various other things like median for example so in the we have one outlier here 18 right so in the case of the one where we took a square in the middle of it this number is higher right because the square it takes that 18 and makes it much bigger so in other words standard deviation is more sensitive to outliers than mean absolute deviation so for that reason the mean absolute deviation is very often the thing you want to be using because in machine learning outliers are more of a problem than to help a lot of the time but mathematicians and statisticians tend to work with standard deviation rather than mean absolute deviation because it makes their math proofs easier and that's the only reason they'll tell you otherwise but it that's the only reason so the the main absolute deviation is really underused and it actually is a it's a really great measure to use and you should yet definitely get used to it there's a lot of places where I kind of noticed that replacing things involving Squared's with things involving absolute values the absolute value things just often work better it's a good tip to remember that there's this kind of long-held assumption we have to use the squared thing everywhere but it actually often doesn't work for you it doesn't work as well this is our definition of variance notice that this is the same so this is written in math this written in math looks like this and it's another way of writing the variance it's important because it's super handy and it's super handy because in this one here we have to go through the whole data set once once to calculate the mean of the data and then a second time to get the Squared's of the differences this is really nice because in this case we only have to keep track of two numbers the Squared's of the data and the summer for data and as you'll see shortly this kind of way of doing things is generally therefore just easier to work with so even though this is kind of the definition of the variance that makes intuitive sense this is the definition of variance that you normally want to implement and so there it is in myth the other thing we see quite a bit is covariance and correlation so if we take our same data set let's now create a second data set which is TT times a little bit of random noise okay so here's that plotted let's now look at the difference between H item of T and its mean and multiply it by H item of you and it's mean so there's those values and let's look at the mean of that so what's this number so it's the average of the difference of how far away the x value is from the mean of the x value is of the X's multiplied by each difference between the Y value and how far away from the Y mean it is let's compare this number to the same number calculated with this data set where else this where this data set is just some random numbers compared to V and let's now calculate the exact same product the exact same mean this numbers much smaller than this number why is this number much smaller so if you think about it if these are kind of all lined up nicely then every time it's higher than the average on the x axis it's also higher than the x of the average on the y axis so you have two big positive numbers and vice versa two big negative numbers so in either case you end up with when you multiply them together as big positive number so this is adding up a whole bunch of big positive numbers so in other words this number tells you how much these two things vary in the same way kind of how lined up are they on this graph and so this one when one is big the other is not necessarily big when one is small the other is not necessarily very small okay so this is the covariance and you can also calculate it in this way which might look somewhat similar to what we saw before with our different variance calculation and again this is kind of the easier way to use it so as I say here from now on I don't want you to ever look at an equation or type an equation in late equi thout typing it in Python calculating some values and plotting them now because this is the only way we get a sense in here of what these things mean okay and so in this case we're going to take our covariance and we're going to divide it by the product of the standard deviations and this gives us a new number and this is called correlation or more specifically Pearson correlation coefficient yeah so we don't cover covariance and Pearson correlation coefficient too much in the course but it is one of these things which it's often nice to see how things vary but remember it's telling you really about how things vary linearly right so if you want to know how things vary none in ially you have to create something called a neural network and check the loss and the metrics but it's you know it's kind of interesting to see also how variance and covariance you can see they're much the same thing you know where else one of them in fact basically you can think of it this way right one of them is e of x squared in other words X and X are kind of the same thing it's V of x times X or else this is two different things they have x times y but and so rather than having here we had if x squared here and E of x squared here if you replace the second X for the Y you get that and you get that so they're like literally the same thing and then again here if X and X are the same and this is just Sigma squared right so the last thing I want to quickly talk about a little bit more as softmax this was our final log softmax definition from the other day and this was this is the formula the same thing as a equation and this is our cross entropy loss remember so these are all important concepts we're going to be using a lot so I just wanted to kind of clarify something that a lot of researchers that are published in big-name conferences get wrong which is when you should you and shouldn't you use softmax so this is our softmax page from our entropy example spreadsheet where we were looking at cat dog plain fish building and so we had various outputs this is just the activations that we might have gotten out of the last layer of our model and this is just e to the power of each of those activations and this is just the sum of all of those e to the power of x' and then this is e to the power of divided by the sum which is soft mix and of course they all add up to 1 this is like some image number one that gave these activations here's some other image number two which gave these activations which are very different to these right but the soft maxes are identical that and that are identical so that's weird how has that happened well it's happened because in every case they e to the power of this divided by the sum of the e to the power of ended up in the same ratio so in other words even although fish is only 0.63 here but it's true here one needs once you take e to the power of it's the same percentage of the sum right and so we end up with the same soft mix why does that matter well in this model it seems like being a fish is associated with having an activation if maybe like two ish alright and this is only like 0.6 ish so maybe this there's no fish in this but what's actually happened is there's no cats or dogs or planes or fishes or buildings so in the end then so in the end then because we softmax has to add to one it has to pick something so it's fish that comes through and what's more is because we do this e to the power of the thing that's a little bit higher it pushes much higher because it's exponential right so it softmax likes to pick one thing and make it big and they have to add up to one so the problem here is that I would guess that maybe image two doesn't have any of these things in it and we had to pick something so it said oh I'm pretty sure there's a fish or maybe the problem actually is that this image had a cat and a fish and a building but begin because softmax they have to add two one and one and and and one of them is going to be much bigger than the others so you know I don't know exactly which of these happened but it's definitely not true that they both have an equal probability of having a fish in them so to put this another way softmax is a terrible idea unless you know that every one of your as you're doing image recognition every one of your images or if you're doing audio or tabular whatever every one of your items has one no more than one and definitely at least one example of the thing you care about in it because if it doesn't have any of cat dog plain fish you're building it's still going to tell you with high probability that it has one of those things even if it has more than just one of cat dog playing official building it'll pick one of them and tell you it's pretty sure it's got that one so what do you do if there could be no thing or there could be more than one of these things well instead you use binomial regular old binomial which is a to the X divided by one plus a to the X it's exactly the same as softmax if you're two categories are has the thing and doesn't have the thing because they're like P and 1 minus B so you can convince yourself of that during the week so in this case let's take image 1 and let's go 1.0 2 divided by 1 plus 1.0 - right and ditto for each of our different ones and then let's do the same thing for image 2 and you can see now the numbers are different that's we would hope and so for image 1 it's kind of saying oh it looks like them might be a cat in it if we see in point 5 as a cutoff there's probably a fish in it and it seems likely that there's a building in it all right where else for image 2 it's saying I don't think there's anything in there but maybe a fish and this is what we want right and so when you think about it like 4 for image recognition probably most of the time you don't want softmax so why do we always use softmax because we all grew up with image net an image net was specifically curated so it only has one of the classes in image net in it and it always has one of those classes in it an alternative if you want to be able to handle there what if none of these classes are in a case as you could create another category called background or or doesn't exist or null or missing so let's say you created this missing category so there's no there's 6 cat dog plain fish building or missing nothing a lot of researchers have tried that but it's actually a terrible idea and it doesn't work and the reason it doesn't work is because to to be able to successfully predict missing the penultimate layer activations have to have the features in it that is what a not cat dog plain fish fish or building looks like so how do you describe a not cat dog playing Fisher Building what are the things that would activate hi is that shininess is it fur is it sunshine is it edges no it's none of those things there is no set of features that when they're all high is clearly a not cat dog playing official building so that's just not a kind of object so a neural net can kind of try to hack its way around it by creating a negative model of every other single type and create a kind of not one of any of those other things but that's very hard for it where else creating simply a binomial does it or doesn't it have this for every one of the classes is really easy for it right because it just doesn't have a cat yes or no does it have a dog yes or no and so forth so lots and lots of well-regarded academic papers make this mistake so look out for it and if you do come across an academic paper that's using softmax and you think does that actually work with softmax and you think maybe the answer's no try replicating it without softmax and you may just find you get a better result an example of somewhere where softmax is obviously a good idea or something like softmax is obviously a good idea language modeling what's the next word it's definitely at least one word it's definitely not more than one word right so you want softmax that's all nothing softmax is always a dumb idea but it's often a dumb idea so that's something to look out for okay next thing I want to do is I want to build a learning rate finder and to build a learning rate finder we need to use this test callback kind of idea this ability to stop somewhere problem is as you may have noticed this I want to stop somewhere call back wasn't working in our new refactoring where we created this runner class and the reason it wasn't working is because we returning true to mean cancel but even after we do that it still goes on to do the next batch and even if we set self dot stop even after we do that it'll go on to the next epoch so like actually stop it you would have to return false from every single callback that's checked to make sure it like really stops or you would have to add something that checks for self dot stop in lots of places be a real pain right it's also not as flexible as we would like so what I want to show you today is something which i think is really interesting which is using the idea of exceptions as a kind of control flow stay a statement you may have think of exceptions it's just being a way of handling errors that actually exceptions are a very versatile way of writing very neat code that will be very helpful for your users let me show you what I mean so let's start by just grabbing our M&S data set us before and creating your data bunches before and here's our callback as before and our Train eval callback as before but there's a couple of things I'm going to do differently the first is this is a bit unrelated but I think it's a useful refactoring is previously inside runner in dunder call we went through each call back in order and we checked to see whether existed in the weather that that particular method exists in that callback and if it was we called it and check whether it returns true or false it actually makes more sense for this to be inside the callback plus not inside the runner class because by putting it into the callback class the callback class is now taking a has a dunder core which takes a callback name and it can do this stuff and what it means is that now you're your users who want to create their own callbacks let's say they wanted to create a callback that printed out the callback name for every callback every time it was run well let's say they wanted to add a breakpoint as like a set trace that happened every time the callback was run well they could now create their own inherit from callback and actually replace dunder call itself with something that added this behavior they want right or they could like add something that looks at like three or four different core back names and attaches to all of them so this is like a nice little extra piece of flexibility it's not the key thing I wanted to show you but it's like an example of a nice little refactoring the key thing I wanted to show you is that I've created three new types of exception so an exception in Python is just a class that inherits from exception and most of the time you don't have to give it any other behavior so to create a class that's just like its parent but it just has a new name and no more behavior you just say pass so pass means this has all the same attributes and everything as the parent but it's got a different name so why do we do that well you might get a sense from the names cancel train exception cancel epoch exception cancel batch exception the idea is that we're going to let people's callbacks cancel anything you know cancel at one of these levels so if they cancel a batch it will keep going with the next batch but not finish this one if they cancel an epoch it'll keep going at the next epoch that will cancel this one cancel train will stop the training or together so how would cancel train exception work well here's the same runaway you had before but now fit we already had try finally to make sure that our after fit and remove learner happened even if there's an exception I've added one line of code except cancel train exception and if that happens then optionally it could call some after cancel train call back but most importantly no error occurs but it just keeps it just keeps on going to the finally block and well elegantly you know elegantly and happily finish up so we can cancel training so now our test callback can after step you'll just print out what step are up to and if it's greater than or equal to ten will raise cancel train exception and so now when we say run dot fit it just prints out up to ten and stops there's no stack trace there's no error this is using an exception as a control flow technique not as an error handling technique so another example inside all batches I go through all my batches in a try block except if there's a cancel epoch exception in which case I optionally call and after cancer or epoch callback and then continue to the next epoch or inside one batch I try to do all the stuff for a batch except if there's a cancel batch exception I will up tional eke all the after canceled batch callback and then continue to the next batch so this is like a super neat way that we've allowed any callback writer to stop any one of these three levels of things happening okay so it's so in this case we're using cancel train exception to stop training so we can now use that and to create a learning rate finder so the basic approach of the learning rate finder is that there's something in begin batch which just like our parameter scheduler is using exponential an exponential curve to set the learning rate so this is identical to program scheduler and then after each step it checks to see whether we've done more than the maximum number of iterations which is d40 to 100 or whether the loss is much worse than the best we've had so far and if either of those happens we will raise cancel train exception so to be clear this neat exception based approach to control flow isn't being used in the first day I vision one at the moment that it's very likely that first day I 1.1 or two will switch to this approach because it's just so much more convenient and flexible and then assuming we haven't cancelled just see if the loss is better than our best loss and if it is then set best loss to the loss so now we can create a learner we can add the ELA find we can fit and you can see that it only does less than 100 epochs before it stops because the loss got a lot worse and so now we know that we want something about there through our learning rate okay so now we have a learning rate finder so let's go ahead and create a CNN and specifically a scooter CNN so we'll keep doing the same stuff we've been doing get our amnesty to normalize it here's a nice little refactoring because we very often want to normalize with the fist data set and normalize both data sets using this data sets mean a standard deviation let's create a function called normalized to which does that and returns the normalized training set and the normalized validation set so we can now use that make sure that it's behaves properly that looks good create our data bunch and so now we're going to create a CNN model and the CNN is just a sequential model that contains a bunch of tried to convolutions and remember the inputs 28 by 28 so after the first it'll be 14 by 14 then 7 by 7 and 4 by 4 then 2 by 2 then we'll do our average pooling flat inert and a linear layer and that's then we're done now remember our original data is vectors of length 768 they're not 28 by 28 so we need to do a next view one channel by 28 by 28 because that's what NN comm 2d expects and then -1 the batch size remains whatever it was before so we need to somehow include this function in our and n dot sequential pipe torch doesn't support that by default we could write our own class with a forward function but not sequential is convenient for lots of ways it has a nice representation you can do all kinds of customizations with it so instead we create a layer a layer called lambda and n n module quote lambda you just pass it a function and the forward is simply to call that function and so now we can say lambda M ministry size and that will call that calls that function to be called and here lambda flatten simply calls this function to be called which removes that 1 comma 1 axis at the end after the adaptive average pooling so now we've got to CNN model we can grab our callback functions and our optimizer and our runner and we can run it and 6 seconds later we get back 1 epochs result so that's a at this point now getting a bit slow so let's make it faster so let's use CUDA let's pop it on the GPU so we need to do two things we need to put the model on the GPU it specifically means the models parameters on the GPU so remember a model contains two kinds of numbers parameters they're the things that your you're updating the things that it stores and there's the activations there's the things that it's calculating so it's the parameters that we need to actually put on the GPU and the inputs to the model and the loss function so in other words the things that come out of the data loader we need to put those on the GPU how do we do that with a callback of course so here's a CUDA callback when you initialize it you pass it a device and then when you begin fitting you move the model to that device so model 2.2 is part of play torch it moves something with parameters or a tensor to a device and you can create a device by calling torch dot device pass it the string CUDA and whatever GPU number you want to use if you only have one GPU its device 0 then when we begin a batch let's go back and look at our runner when we begin a batch we've put X patch and Y batch inside self dot X B and self dot Y B so that means we can change them so let's set the runners X B and the runners Y B to whatever they were before but move to the device so that's it that's that's going to run everything on CUDA that's all we need this is kind of flexible because we can put things on any device we want maybe more easily is just to call this once which is torch Kudarat set device and you don't even need to do this if you've only got one GPU and then everything by default will now be sent to that device and then instead of saying dot 2 device we can just say doc CUDA and so since we're doing pretty much everything with just one GPU for this course this is the one we're going to export so just model CUDA X speed up here to wavy doctor so that's how CUDA callback so let's add that to our callback functions grab our model and our runner and fit and now we can do three epochs in five seconds versus one epoch in six seconds so that's a lot better and for a much deeper model it'll be dozens of times faster so this is literally all we need to use CUDA so that was nice and easy now we want to make it easy to create different kinds of architectures make things a bit easier so the first thing we should do is recognize that we go confer Lu a lot so let's pop that into a function called calm 2d that just goes con value since we use a kernel size of three in Australia of two in this emili´s model a lot let's make those defaults also this this model we can't reuse for anything except em nest because it has a em ministry size at the start so we need to remove that so if we were to remove that something else is going to have to do the resizing and of course the answer to that is a call back so here's a call back which transforms the independent variable the X for a batch and so you pass it some transformation function which it stores away and then begin batch simply replaces the batch with the result of that transformation function so now we can simply append another callback which is the partial function application of that callback with this function and this function is just to view something at one by 28 by 28 and you can see here we've used the trick we saw earlier of using underscore inner to define a function and then return it so this is something which creates a new view function that views it in this size so for those of you that aren't that comfortable with closures and partial function application this is a great piece of code to study experiment make sure that you feel comfortable with it so using this approach we now have the the amnesty you resizing as a callback which means we can remove it from the model so now we can create a generic get CNN model function that returns a sequential model containing some arbitrary set of layers containing some arbitrary set of filters so we're going to say okay this is the number of filters I have per layer 8 16 32 32 okay and so here is my get CNN layers and at the end the last few layers is the average pooling flattening and the linear layer the first few layers is for every one of those filters length of the filters it's a calm 2d from that filter to the next one and then what's the kernel size the kernel size depends it's a kernel size of five for the first layer or three otherwise why is that well the number of filters we had for the first layer was eight and that's a pretty reasonable starting point for a small model to start with eight filters and remember our image had a single channel and we were like imagine if we had a single channel and we were using 3x3 filters all right so as that convolution kernel Scrolls through the image at each point in time it's looking at a 3x3 window and it's just one channel right so in total there's nine input activations that is looking at and then it spits those into a dot product with so it spits us into eight dot products so I'm matrix multiplication I should say 8 by 9 and out of that will come a vector of length 8 okay because we said we wanted eight filters so that's what a convolution does right and this seems pretty pointless because we started with nine numbers and we ended it with eight numbers so all we're really doing is just reordering them but it's not really doing any useful computation so there's no point making your first layer basically just shuffle the numbers into a different order so what you'll find happens in for example most imagenet models all right most imagenet models they're a little bit different because they have three channels so it's actually three by three by three right which is 27 but it's still kind of like you know quite often with imagenet models the first layer will be like 32 channels so like going from 27 to 32 is literally losing information so most image net models they actually make the first layer seven by seven not three by three and so for a similar reason we're going to make our first layer five by five so we have 25 inputs for our 8 outputs so this is the kind of things that you want to be thinking about when you're designing or reviewing an architecture is like how many numbers are actually going into that little dot product that happens inside you'll see an end kernel okay so that's something which can give us a CNN model so let's pop it all together into a little function that just grabs an optimization function grabs an optimizer grabs a learner grabs a runner and at this point if you can't remember what any of these things does remember we've built them all by hand from scratch so go back and see what we wrote okay there's no magic here and so let's look if we say get CNN model passing in 8 16 32 32 here you can see 8 16 32 32 here's our 5 by 5 the rest of 3 by 3 they all have a straight of 2 and then a linear layer and then trade ok so at this point we've got a fairly general simple CNN Creator that we can fit and so let's try to find out what's going on inside how do we make this number higher how do we make it train more stable how do we make a train more quickly well we really want to see what's going on inside we know already that different ways of initializing changes the variance of different layers how do we find out if it's saturating somewhere if it's too small if it's too big what's going on so what if we replace n n dot sequential with our own sequential model class all right and if you remember back we've already built our own sequential model class before and it just had these two lines of code plus return so let's keep the same two lines of code but also add two more lines of code that grabs the mean of the outputs and the standard deviation of the outputs and saves them away inside a bunch of lists all right so here's a list for every layer four means and a list for every layer four standard deviations so let's calculate the mean and standard deviations pop them inside those two lists right and so now it's a sequential model that also keeps track of what's going on the telemetry of the model so we can now create it in the same way as usual fit it in the same way as usual that now our model has two extra things in it it has an act means and acts standard deviations so let's plot the ACT means for every one of those lists what we had and here it is right here's all of the different means and you can see it looks absolutely awful what happens early in training is every layer the means get exponentially bigger until they suddenly collapse and then it happens again it suddenly collapses and it happens again and it suddenly collapses until eventually oh it kind of starts training so you might think well it's it's eventually training so isn't this okay but my concern would be this thing where it kind of falls off a cliff there's lots of vector there's lots of parameters in our model right are we sure that all of them are getting back into reasonable places or is it just that a few of them have got back into a reasonable place like maybe the vast majority of them have like zero gradients at this point I don't know it seems very likely that this awful training profile early in training is leaving our model in a really sad state that's my guess and we're going to check it to see later but for now okay it's going to say let's try to make this not happen and let's also look at the standard deviations and you see exactly same thing this just looks really that so let's look at just the first 10 means and they all look okay they're all pretty close ish to zero which is about what we want but more importantly let's look at the standard deviations for the first ten batches and this is a problem the first layer has a variance not too fast and deviation not too far away from one but they're not surprisingly the next layer is lower the next layer is lower as we would expect because the first layer is less than one the following layers are getting exponentially further away from one until the last layer is really close to zero so now we can kind of see what was going on here is that is that our final layers were getting basically no activations they were basically getting no gradients so gradually it was moving into spaces where they actually at least had some gradient but by the time they kind of got there the the gradient was so fast that they were kind of falling off a cliff and having to start again so this is the thing we're going to try and fix and we think we already know how to we can use some initialization yes Rachel did you say that if we went from 27 numbers to 32 that we were losing information could you say more about what that means yeah I guess we're not losing information where that was Pauly said we're we're we're wasting information I guess we're like that if you start with 27 numbers and you do some matrix multiplication and number 32 numbers you're you're you are now taking more space for the same information you started with and the whole point of a neural network layer is to pull out some interesting features so you know you would expect to have you know less total activations going on because you're trying to say oh you know in this area I've kind of pulled this this set of pixels down into something that says how fairy this is or how much of a diagonal line does this have or or whatever so increasing the the the number of actually you know the actual number of activations we have for a particular position is it's a total waste of time we're not doing any useful you know where we're wasting a lot of calculation yeah that's we can talk more about that on the forum if that's still not clear okay so this is so this idea of creating telemetry for your model is really vital this approach to doing it where you actually write a whole new class that only can do one kind of telemetry is clearly stupid and so we clearly need a better way to do it and what's the better way to do it it's callbacks of course except we can't use our callbacks because we don't have a callback that says when you calculate this layer callback to our code we have no way to do that right so we actually need to use a feature inside PI torch that can call back into our code when a layer is calculated either the forward pass or the backward pass and for reasons I can't begin to imagine play torch doesn't call them callbacks they're called hooks right but it's the same thing it's a callback okay and so we can say for any module we can say register forward hook and pass in a function this is a callback this is a callback that will be called when this modules forward pass is calculated or you could say register backward hook and that will cause call this function when this modules backward pass is calculated so to replace that previous thing with hooks we can simply create a couple of global variables to store our means and standard deviations for every layer we can create create a function to call back to to calculate the mean and standard deviation and if you google for the documentation for register forward hook you will find that it will tell you that the callback will be called with three things the module that's doing the callback the input to the module and the output of that module either the forward or the backward pass is appropriate in our case it's the output we want and then we've got a fourth thing here because this is the layer number we're looking at and we used partial to connect the appropriate closure with each layer so once we've done that we can call fit and we can do exactly the same thing okay so this is the same thing just much more convenient and because this is such a handy thing to be able to do first day a has a hook class so we can create our own hook class now which allows us to rather than having this kind of messy global state we can instead put this date inside the hook so let's create a class called hook that when you initialize is that it registers a forward hook on some function alright and what it's going to do is it's going to record back to this object so we pass himself with the partial and so that way we can get access to the hook we can pop inside it our two empty lists when we first call this to store away our means and standard deviations and then we can just append our means and standard deviations so now we just go Hawks equals pork for layer in children of my model and we'll just grab the first two layers because I don't care so much about the linear layers it's really the conflicts are the most interesting and so now this does exactly the same thing since we do this a lot let's put that into a class to cord hooks so here's our hooks class which simply calls hook for every module in some list of modules now something to notice is that when you're done using a hooked module you should call hooked up remove because otherwise if you keep registering more hooks on the same module they're all going to get cold and eventually you're going to run out of memory so one thing I did when our Hawk class was I created a dunder del this is called automatically when Python clears cleans up some memory so when it's done with your hook it will automatically call remove which in turn will remove the hook so I then have a similar thing in hooks so when hooks is done it calls self dot remove which in turn goes through every one of my registered hooks and removes them you'll see that somehow I'm able to go 4-h in self but I haven't registered any kind of iterator here and the trick is I've created something called a list container just above which is super handy it basically defines all the things you would expect to see in a list using all of the various special dunder methods and then some it actually has some of the behavior of num play as well we're not allowed to use numpy in our foundations so we use this instead and this is actually also works a bit better than um play for this stuff because numpy does some weird casting and weird edge cases so for example with this list container it's got done to get item so that's the thing that gets called when you call something with square brackets right so if you call if you index into it with an int then we just pass it off to the enclosed list because we go over to list to enclose if you send it off to send it a list of balls like false false false false false true false then it will return all of the things where that's true or you can index it into it with a list in which case it will return all of the index the things that are indexed by that list for instance and it's got a length which just passes off to length and an iterator that passes off - iterator and so forth and then we also define the representation for it such that if you print it out it just prints out the contents unless there's more than ten things in it in which case it shows dot dot dot so with a nice little base class like this so you can create like really useful little base classes in much less than a screen full of code and then we can use them and we will use them everywhere from now on so now we've created our own list e class that has hooks in it and week and and so now we can just use it like this we can just say hooks equals books everything in our model with that function we had before the pen stats we can print it out to see all the hooks we can grab a batch of data so now we've got one batch of data and check its mean and standard deviation is about zero one as you'd expect we can pass it through the first layer of our model model zero was the first layer of our model which is the first convolution and our mean is not quite zero and our standard deviation is quite a lot less than one as we kind of know what's going to happen so now we're just go ahead and initialize it with chi-ming and after that variance is quite close to one and our standard deviation sorry and I mean as expected is quite close to 0.5 because of the rel u so now we can go ahead and create our hooks and do a fit and we can plot the first 10 means and standard deviations and then we can plot all the means and standard deviations and they're all is and this time we're doing it after we've initialized all the layers of our model and as you can see we don't have that awful exponential crashed exponential crashed exponential crash looking much better and you can see early on in training our sterian sirs all look of standard deviations all look much closer to one so this is looking super hopeful I've used a width block a RIF block is something that will create this object give it this name and when it's finished it will do something there's something it does is to call your dunder exit method here which will not remove so here's a nice way to ensure that things are cleaned up for example your hooks are removed so that's why we have a dunder enter that's what happens when you start the with block dunder excerpt when you finish the with block so this is looking very hopeful but it's not quite what we wanted to know really the concern was is does this actually do something bad right is it is it actually you know or does it just train fine afterwards so something bad really is more about how many of the activations are really really small you know how well is it actually getting everything activated nicely so what we could do is we could adjust our append stats so not only does it have a mean and a standard deviation but it's also got a histogram so we could create a histogram of the activations pop them into 40 bins between zero between 0 and 10 now we don't need to go under this theorem because we have a rail u so we know that there's none unbelief zero so let's again run this we will use our claiming initialization and what we find is that even with that if we make our learning rate really high 0.9 we can still get this same behavior and so here's plotting the entire histogram and I should say thank you to our Stefano for the original code here from our San Francisco study group to plot these nicely so you can see this kind of grow collapse grow collapse grow collapse thing the biggest concern for me though is this yellow line at the bottom the the yellow line yellow is is where most of the histogram is I actually what I really care about is how much yellow is there so let's instead let's say the first two histogram bins are zero or nearly zero so let's get the sum of how much is in those two bins and divide by the sum of all of the bins and so that's going to tell us what percentage of the activations are zero or nearly zero now let's plot that for each of the first four layers and you can see that in the last layer it's just as we suspected over 90% of the activations are actually zero so if you would training your model like this right it could eventually look like it's training nicely without you realizing that 90% of your activations who have totally wasted and so you're never going to get great results by wasting 90% of your activations so let's try and fix it let's try and be able to train it a nice high learning rate and not have this happen and so the trick is is we're going to try a few things but the main one is we're going to use our better value and so we've created a generalized value class where now we can pass in things like an amount to subtract from the earlier because remember we thought subtracting half from the real you might be a good idea we can also use leekie earlier and maybe things that are too big also a problem so let's also optionally have a maximum value so in this generalized value if you passed a leakiness then we'll use leekie earlier otherwise we use normal value you could have you know very easily write these leekie earlier by hand but I'm just trying to make the make it run a little faster by taking advantage of player to watch if you said I want to subtract something from it then go ahead and subtract that from it if I said there's some maximum value go ahead and clamp it at that maximum value so here's our generalized value and so now let's have our con flare and get CNN layers both take a star star Quags and just pass them on through so that eventually they end up pass to our generalised value and so that way we're going to be able to create a CNN and say what value characteristics do we want nice and easily and even get CNN model or passed down clogs as well so now that our rail you can go negative because it's leaky and because it's subtracting stuff we'll need to change our histogram so it goes from minus seven to seven rather than from zero to ten so we'll also need to change our definition of get min so that the middle few bits of the histogram of zero rather than the first two and now we can just go ahead and train this model just like before and plot just like before and this is looking pretty hopeful let's keep looking at the rest so here's the first one two three four layers so compared to that which was expand to die expand I expand I we're now seeing this is looking much better it's straight away it's using the full richness of their possible activations there's no death going on but a real question is how much is in this yellow line there's a question and let's see in the final layer look at that less than 20% right so we're now using nearly all of our activations by being careful about our our initialization and value and then we're still training at a nice high learning rate so this is looking great could you explain again how to read the histograms sure so the for history let's go back to the earlier one so the four histograms are simply the four layers so layer the first and after the first Kampf second third fourth and the x-axis is the iteration so each each one is just one more iteration as most of our plots show the y-axis is how many activations are the highest they can be or the lowest they can be so what this one here is showing us for example is that there are some activations that are at the max and some activations are in the middle and some activations at the bottom where else this one here is showing us that all of the activations are basically zero so what this shows us in this histogram is that now we're going all the way from plus seven to minus 7 because we can have negatives this is 0 it's showing us that most of them are 0 because yellow is the most is the most energy but there are activations throughout everything from the bottom to the top and a few less than 0 as we would expect because we have a link here Lu and we also have that - we're not doing minus 0.5 we're doing minus 0.4 because Li key value means that we don't need to subtract half anymore we subtract a bit less than half and so then this this line is telling us what percentage of them are 0 or nearly zero and so you know this is a one of those things which is good to brand lots of experiments in the notebook yourself to get a sense of what what's actually in these histograms so you can just go ahead and have a look at H hooks stats and the third thing in it will be the histograms so you can see what shape is and how is it calculated and so forth ok so now that we've done that this is looking this is looking really good so what what what actually happens if we train like this so let's do a one cycle training so use that combine sheds we built last week fifty-fifty two phases cosign scheduling cosign annealing so gradual warm-up gradual cooldown and then run it for 80 pucks and there we go we're doing really well we're getting up to 98% alright so this is kind of we hardly were really training in a thing we were just trying to get something that looked little that looked good and once we had something that looked good in terms of the telemetry it's really training really well one option I added by the way in in at CNN was I added a uniform bullion which will set the initialization function to timing normal if it's false which is what we've been using so far or climbing uniform if it's true coming uniform so now I've just trained the same model with uniform equals true a lot of people think that uniform is better than normal because a uniform random number is less often close to zero and so the thinking is that maybe uniform random uniform initialization might cause it to kind of have a better richness of activations I haven't studied this closely I'm not sure I've seen a careful analysis in a paper in this case nine eight to two versus 1982 six they're looking pretty similar but that's just something else that it's there to play with so at this point like we've got a pretty nice bunch of things you can look at now and so like you can see as you're kind of problem to play with during the week is like how accurate can you make a model you know just using the layers we've created so far and and and for the ones that a great accuracy what is the telemetry look like how can you tell whether it's going to be good and then what insights can you gain from that to make it even better alright so in the end try to beat me right try to beat 98% you'll find you can beat it pretty easily with some playing around but do some experiments all right so that's what that's kind of about what we can do with initialization you can go further with as we discussed with with cell you or with fix-up like there are these really finely tuned initialization methods that you can do a thousand layers deep but they're super fiddly so generally I would use something like the layer wise sequential unit variance LS UV thing that we saw earlier in also we haven't done the way yet okay we didn't do the next ok so again I said that so that's kind of about as far as we can get with with basic initialization to go further we really need to use normalization of which the most commonly known approach to normalization in the model is batch normalization so let's look at better normalization so batch normalization has been around since I think about 2005 this is the paper and the first of all describe a bit about why they thought batch normalization was a good idea and by about page three they provide the algorithm so it's one of those things that if you don't read a lot of math it might look a bit scary but then when you look at it for a little bit longer you suddenly notice that this is literally just the main sum divided by the count and this is the main of the difference to the the difference to the main square dance the main of that oh that's just what we looked at that's variance and this is just subtract the main divided by at the standard deviation oh that's just normalization so like once you look at it a second time you realize we've done all this we just done it with code not with math and so then the only thing they do is after they've normalized it in the usual way is that they then multiply it by gamma and they add beta what a gamma and beta they are parameters to be learned what does that mean this is the most important line here remember that there are two types of numbers in a neural network parameters and activations activations of things we calculate parameters of things we learn so these are just numbers that we learn so that's all the information we need to implement batch norm so let's go ahead and do it so first of all we'll grab our data as before create a callback sirs before here's our pre batch norm version ninety six and a half percent and the highest I could get was a point for learning rate this way and so now let's try better norm so here's batch norm so let's look at the forward first we're going to get the mean and the variance and the way we do that is we call update stats and the mean is just the mean and the variance is just the variance and then we subtract the mean and we divide by the square root of the variance and then we multiply by and then I didn't call them gamma and beta because why use Greek letters when Kristen who remembers which ones gamma and which ones beta let's use English the thing we multiply will call the Maltz there are things we add or other ads and so malts and ads are parameters we multiply by a parameter that initially is just a bunch of ones so does nothing and we add a parameter which is initially just a bunch of zeros so it does nothing but their parameters so they can learn just like our remember our original linear layer we created by hand it just looked like this in fact if you think about it ads is just bias but it's identical to our to the bias we created earlier so then there's a few extra little things we have to think about one is why happens at inference time all right so during training we we normalize but the problem is that if we normalize in the same way at inference time if we get like a totally different kind of image we might kind of remove all of the things that are interesting about it so what we do is well we're training we keep a exponentially weighted moving average of the means and the variances I'll talk more about what that means in a moment but basically we've got they're kind of running average of the last few batches means and a running average of the last two batches variances and so then when we're not training in other words an inference time we don't use the mean and variance of this mini-batch we use that running average mean and variance that we've been keeping track of okay so how do we calculate that running average well we don't just create something called self dot bars we go self dot register buffer fuzz now that creates something called stealth self dot buzz so why didn't we just say self dot far as equals torch dot one's why do we say self dot register buffer it's almost exactly the same as saying self dot vars equals torch dot ones but it does a couple of nice things the first is that if we move the model to the GPU anything that's registered as a buffer will be moved to the GPU as well all right and if we didn't do that then it's going to try and do this calculation down here and if the VARs and means aren't on the GPU but everything else is on the GPU we'll get an error it'll say oh you're trying to add this thing on the CPU to this thing on the GPU and it'll fail so that's one nice thing about register buffer the other nice thing is that the variances and the means these running averages they're part of the model right they they when we do inference in order to calculate our predictions we actually need to know what those numbers are so if we save the model we have to save those variances and means so the register buffer also causes them to be saved along with everything else in the model so that's what register buffer does so the variances we start them out at once the means we start them out at zeros we then calculate the mean and variance of the mini - and we average out the axes 0 2 & 3 so in other words we average over all the batches and we average over all of the x and y-coordinates so all we're left with is a mean for each channel or a mean for each filter okay keep dem equals true means that it's going to leave an empty unit access in position 0 2 & 3 so it'll still broadcast nicely so now we want to take a running average so normally if we want to take a moving average right if we've got like a bunch of data points right we want a moving average we would kind of like grab five at a time and we would like to take their moving average they take the average of those five and they would take the next five and would like take their average and we keep doing that like you know a few at a time we don't want to do that here though because this these batch norm statistics every single activation has one so it's giant right like an you know models can have hundreds of millions of activations we don't want to have to save a whole history if every single one of those just so that we can calculate an average so there's a handy trick for this which is instead to use an exponentially weighted moving average and basically what we do is we start out with this first point and we say okay our first our first average is just the first point okay so let's say I don't know that's three okay and then the second point is five and what we do is we to take an exponentially weighted moving average we first of all need some number which we call momentum let's say it's 0.9 so for the second value so for the first value our exponentially weighted moving average which we'll call mu equals 3 and then for the second one we take new one we multiply it by our momentum and then we add our second value 5 and we multiply it by 1 minus our momentum so in other words it's mainly whatever it used to be before plus a little bit of the new thing and then mu 2 is it's only 3 equals mu 2 times 0.9 plus and maybe this one here is for the new one times 0.1 so we're basically continuing to say oh it's mainly the thing before plus a little bit of the new one and so what you end up with is something where it like by the time we get to here the amount of influence of each of the previous data points once you calculate it out it turns out to be exponentially decayed so it's a moving average with an exponential decay with a benefit that we only ever have to keep a track of one value so that's what an exponentially weighted moving averages this this thing we do here where we basically say we've got some function where we say it's some previous value times 0.9 say plus some other value times 1 minus that thing this is called a linear interpolation that's a bit of this and a bit of this other thing and the two together make one linear interpolation in pi torch is built look so we take the means and then we work with our new mean using this amount of momentum unfortunately lerp uses the exact opposite of the normal sense of momentum so momentum of 0.1 in batch norm actually means for mentum of 0.9 in normal person speak right so this is actually how a tender batch norm works as well so when you see so batch norm momentum is the opposite of what you would expect I wish they'd given it a different name they didn't sadly so this is what we're stuck with so this is the running average means and standard deviations so now we can go ahead and use that so now we can create a new con flower which you can optionally say whether you want batch norm if you do we append a batch norm layer if we do append a batch norm layer we remove the bias layer because remember I said that the the the adds in batch norm just is a bias right so there's no point having a bias layer anymore so we'll remove the unnecessary bias layer and so now we can go ahead and initialize our CNN this is a slightly more convenient initialization now that's actually going to go in and recursively initialize every module inside our module the weights and the standard deviations and then we will train it with our hooks and you can see our mean is starts at 0 exactly and our standard deviation starts at 1 exactly so our training has entirely gotten rid of all of the exponential growth and sudden crash stuff that we had before there's something interesting going on at the very end of training which I don't quite know what that is I mean when I say the end of training we've already done one epoch but you know this is looking a lot better than anything we've seen before I mean that's that's just a very nice looking curve and so we're now able to get up to you know learning rates up to one we've got 97% accuracy after just three epochs this is looking very encouraging so now that we've built our own batch norm we're allowed to use play torches batch norm and we get pretty much the same results sometimes it's 97 sometimes it's 98 this is just random variation so now that we've got that let's try going crazy let's try using our little one cycle learning scheduler we had and let's try and go all the way up to a learning rate of two and look at that we totally can right and we're now up towards nearly 99% accuracy so betch norm really is quite fantastic batch norm has a bit of a problem though which is that you can't apply it to what we call online learning tasks in other words if you have a batch size of 1 right so you're just effort you're getting a single item at a time and learning from that item what's the variance of that batch the variance of a batch of one is infinite right so we can't use batch norm in that case well what if we're doing like a segmentation task where we can only have a batch size of two or four which we've seen plenty of times in part one that's going to be a problem right because across all of our layers of course all of our training across all of the channels are the batch size of two at some point those two values are going to be the same or nearly the same and so we then divide by that variance which is about 0 we have infinity alright so we we have this problem where anytime you have a small batch size you're going to get unstable or impossible training it's also going to be really hard for our own ends because for our own ends remember it looks something like this right we have this hidden state and we use the same weight matrix again and again and again right remember we can unroll it and it looks like this if you've gotten go back to lesson 7 and then we can even stack them together into to our own ends one hour a 10 feeds to another RNN and if we unroll that it looks like this and remember these state just you know time state two time step transitions if we're doing IMDB with a movie review with two thousand words there's two thousand of these and this is the same weight matrix each time and the number of these circles will vary it's the number of time steps will vary from document a document so how would you do batch none right how would you say what's the what's the moving what's the running average of means and variances because you can't put a different one between each of these unrolled layers because like this is a for loop remember so we can't have different values every time so it's not at all clear how you would insert batch norm into an aryl in so batch norm has these two deficiencies how do we handle very small batch sizes or way down to about size of one how do we handle our own ends so this paper called layer normalization suggests a solution to this and the layer normalization paper from Geneva and Chios and Geoffrey Hinton who just won the Turing award with yoshua bengio and Jana Kuhn now it's kind of the Nobel Prize of computer science they created this paper which like many papers when you read it it's looks reasonably terrifying particularly once you start looking at all this stuff but actually when we take this paper and we convert it to code it's this now we just have to say the papers garbage is just that the paper has lots of explanation about what's going on and what do we find out and what does that mean right but the extra what Slayer norm it's the same as batch norm but rather than saying X dot means 0 comma 2 comma 3 you say X dot mean 1 comma 2 comma 3 and you remove all the running averages so this is Leonor all right with none of that running average stuff and the reason we don't need to running averages anymore is because we're not taking the mean across all the items in the batch every image has its own mean every image has its own standard deviation so there's no concept of having to average across things in a batch right and so that's all Leonor is it's this we also averaged over the channels so we average over the channels and the X and the y for each image individually so we don't have to keep track of any running averages the problem is that when we do that and we train even at a lower learning rate of 0.8 it doesn't work all right layin norms not as good so it's it's it's a workaround we can use but because we don't have the running average is at at inference time and more importantly because we don't have a different a different normalization for each channel we're just throwing them all together and pretending they're the same and they're not all right so land norm helps but it's nowhere near as good as batching on okay but for our own ends it's kind of what you have to use is something like this so here's the thought experiment what if you are using Leonor on the very first on the actual input data and you're trying to distinguish between foggy days and sunny days so foggy days will have less activations on average because they're less bright and they will have less contrast in other words they have lower variance so layin norm would cause the variances to normalised to be the same and the means to be normalized to be the same so now the sunny day picture and the hazy day picture would have the same overall kind of activations and amount of contrast and so the answer to this question is no you couldn't with layer norm you would literally not be able to tell the difference between pictures of sunny days and pictures of foggy days now it's not only if if you put the layer norm on the input data which you wouldn't do but any everywhere in the middle layers it's the same right anywhere where the overall level of activation or the amount of difference of activation is something that is part of what you care about it can't it throws it away it's designed to throw it away furthermore if your inference time is using things from kind of a different distribution where that different distribution is important it throws that away and soul and norms a partial hacky workaround for some very genuine problems there's also something called instance norm and instance norm is basically the same thing as layer norm it's that it's a bit easier to read in the paper because they actually lay out all the indexes so a particular output for a particular batch for a particular channel for a particular extra particular way is their call to the input for that batch and channel in x and y minus the mean for the batch and the channel so in other words it's the same as layer norm but now it's mean 2 comma 3 rather than mean 1 comma 2 comma 3 so you can see how all these different papers when you turn them into code they're tiny variations right instance norm even at a learning rate of point one doesn't learn anything at all why can it classify anything because we're now taking the mean removing the difference in means and the difference in activations for every channel and for every image which means we've literally thrown away all the things that allow us to classify does that mean that instance norm is stupid no certainly not it wasn't designed for classification it designed for style transfer where the authors guessed that these differences in contrast and overall amount were not important or something they should remove from trying to create things that were like look like different types of pictures it turned out to work really well but you've got to be careful right you can't just go in and say oh here's another normalization thing I'll try it you've got to actually know what it's for to know where it's going to work so then finally there's a paper called group norm which has this wonderful picture and it shows the differences batch norm is averaging over is averaging over the batch and the height and the width and is different for each channel layer norm if it's averaging for each channel for each height for each width and is different for each element of the batch instance norm is averaging over height and width and is different for each channel and each batch and then group norm is the same as instance norm but they arbitrarily group a few channels together and and do that so group norm is kind of a more general way to do it and in the PI torch Docs they point out that you can actually turn group norm into instance norm or group norm into layer norm depending on how you group things up so so there's all kinds of attempts to work around the problem that we can't use small batch sizes and we can't use Iranians with with batch norm but none of them are as good as batch norm so what do we do well I don't know how to fix the Aaron end problem but I think I know how to fix the batch size problem so let's start by taking a look at the batch size problem in practice let's create a new data bus with a batch size of two okay and so here's our chrome flare as before with a batch norm and let's use a learning rate of point four and fit that and the first thing you'll notice is that it takes a long time but small batch sizes take a long time because it's just lots and lots of kernel launches on the GPU is just a lot of overhead right but something like this might even run faster on the CPU and then you'll notice that it's only 26 percent accurate which is awful why is it awful because of what I said these small batch size is causing a huge problem because quite often there's a one channel in one layer where the variance is really small because those two numbers just happen to be really close and so it blows out the activations out to a billion and everything falls apart there is one thing we could try to do to fix this really easily which is to use epsilon what's epsilon let's go take a look at our code here's our batch norm look we don't divide by the square root of variance we divide by the square root of variance plus epsilon where epsilon is 1 a neg 5 epsilon the number that computer scientists and mathematicians like they use this this Greek letter very frequently to mean some very small number and in computer science it's normally a small number that you add to avoid like floating-point rounding problems and stuff like that so it's very common to see it on the bottom of a division to avoid dividing by such small numbers that you kind of can't calculate things and floating-point properly but our view is that epsilon is actually a fantastic hyper parameter that you should be using to train things better and here's a great example with batch norm what if we didn't set epsilon to 1 in egg 5 but what if we set it to 0.1 if we set Absalon to 0.1 then that basically would cause this to never make the the overall activations not be multiplied by anything more than ten right now sorry I don't that'd be point O one because we're taking the square root so if you set it to 0.01 right because we're because saying let's say the variance was zero it would be zero plus 0.01 square root right so it ends up dividing by 0.1 which is ends up multiplying by 10 so even in the worst case it's not going to blow out I mean it's still not great because like there actually are huge differences in variance between different channels and different layers but at least this would cause it to not fall apart so option number one would be use a much higher epsilon value and we'll keep coming back to this idea that epsilon appears in lots of places and deep learning and we should use it as a hyper parameter we control and take advantage of but we have a better idea we think we have a better idea which is we've built a new algorithm called running batch norm and running batch norm I think is the first true solution to the small batch size batch norm problem and like everything we do at first AI it's ridiculously simple and I don't know why no one's done it before maybe they have and I've missed it and a ridiculously simple thing is this in the forward function for running batch norm don't divide by the batch standard deviation don't subtract the batch mean but instead use the moving average statistics at training time as well not just at inference time why does this help because let's say you're using a batch size of two okay then from time to time you know in this particular layer in this particular channel you happen to get two values that are really close together and they have a variance really close to zero but that's fine right because you're only taking point one of that and point mine of whatever you had before like that's how running averages work right so if previously the variance was one and now it's not one a neg five it's just Oh point nine all right so in this way as long as you don't get really unlucky and have the very first batch be be dreadful because you're using this this this moving average you never have this problem so let's take a look but look at the code in a moment but let's do the same thing zero point four we're going to use our running batch norm we trained it for one a park and instead of twenty-six percent accuracy its ninety-one percent accuracy all right so it totally nails it in in in one epoch just a two batch size and a pretty high learning rate there's quite a few details we have to get right to make this work but they're all details that are that we're gonna see in lots of other places in this course we're just kind of seeing them here for the first time so I've got to show you all the details but don't get overwhelmed we'll keep coming back to them the first detail is something very simple which is a normal batch norm we take the running average of variance but you can't take the running average of areas it doesn't make sense to take the running average of areas it's a variance you know you can't just average a bunch of variances in particularly because they might even be different batch sizes right because batch size isn't necessarily constant right instead as we learned earlier in the class the way that we want to calculate variance is like this sum of expected value of a mean of x squared minus mean of x squared so let's do that let's just as I mentioned we can do let's keep track of the Squared's and the sums so we register a buffer called sums and we register a buffer called squares and we just go X dot sum over zero to three dimensions and x times X dot sum so squared all right and then we'll take the the lerp the exponentially weighted moving average of the sums and the Squared's and then for the variance we will do Squared's divided by count minus squared mean all right so it's it's that formula okay so that's detail number one that we have to be careful of detail number two is that the batch size could vary from from any batch to mini batch so we should also register a buffer for count and take an exponentially weighted moving average of the counts of the batch sizes all right so that basically tells us so what do we need to divide by each time the amount we need to divide by each time is the total number of elements in the in the mini batch divided by the number of channels right that's basically grid x times grid Y times batch size so let's take a exponentially exponentially weighted moving average of the count and then that's what we will divide by for both their means and variances that's detail number two detail number three is that we need to do something called D biasing so deep I are seeing is this we want to make sure that at every point and we're going to look at this more detail when we look at optimizers we want to make sure that every point that no observation is weighted too highly right and the problem is that the the normal way of doing moving averages the very first point gets far too much weight because it appears in the first moving average and the second and the third and the fourth right so there's a really simple way to fix this which is that you initialize both sums and Squared's to zeroes right and then you do a work in the usual way right and let's see what happens when we do this so let's say our values are 10 and then 20 these are the first two values we get so actually are you ready to talk with the first value so the value so actually that's let's say the value is 10 okay so we initialize our mean to 0 at the very start of training ok and then the value that comes in is 10 all right so we would expect the moving average to be 10 but our our loop formula says it's equal to our previous value which is 0 times 0.9 plus our new value times 0.1 equals 0 plus 1 equals 1 it's ten times too small okay but that's very easy to correct for because we know it's always going to be wrong by that amount so we then divide it by 0.1 but that fixes it and then the second value has exactly the same problem it's got too much 0 in it but this time it's actually going to be divided by let's still call it point one let's call it 1 minus 0.9 because when you work through the math you'll see the second one it's going to be divided by 1 minus 0.9 squared and so forth okay so this thing here where we divide by that that's called D biasing now it's going to appear again when we look at optimization so you can see what we do is we have a exponentially weighted D biasing amount where we simply keep multiplying momentum times the previous D biasing amount so initially it's just equal to momentum and then mentum squared and then momentum cubed and so forth so then we do what I just said we divide by the D biasing amount okay and then there's just one more thing we do which is we remember how I said you might get really unlucky that your first mini batch is just really close to zero and we don't want that to destroy everything so I just say if you haven't seen more than a total of 20 items yet just plant the variance to be no smaller than 0.01 just to avoid blowing out of the water and then the last two lines are the same okay so that's that's it right it's it's it's all pretty straightforward arithmetic it's a very straightforward idea but when we put it all together it's shockingly effective and so then we can try an interesting thought experiment so here's another thing to try doing the week what's the best accuracy you can get in a single ipok so say run dot fit one and with this convolutional with running batch norm layer and a batch size of 32 and linear scheduled from one to point two I got ninety seven and a half percent I only tried a couple of things so I haven't you know this is definitely something that I hope you can beat me at but like it's really good to kind of create like interesting little day to play in in research we call them toy problems but almost everything in research is basically toy problems come up with to a problems and try and try to find good solutions to them so the auditory problem another toy problem for this week is what's the best you can get using yeah whatever kind of normalization you like whatever kind of architecture you like as long as it only uses concepts we've used up to less than seven to get the best accuracy you can in one a pug so yeah that's that's basically it so what's the future of running batch norm I mean it's it's kind of early days right we we haven't published this research yet we haven't done all the kind of ablation studies and stuff we need to do yet at this stage though I'm really excited about this every time I've tried it on something it's been working really well I you know the last time that we had something in a lesson that we said this is unpublished research that we're excited about it turned into you LM fit which is now you know really widely used algorithm and was published at the ACM so yeah at the ACL so you know fingers crossed that this turns out to be something really terrific as well but either way you've kind of got to see the process because like literally building these notebooks was the process I used to create this algorithm so you've seen the exact process that I use to to build up this idea and do some initial testing of it so hopefully that's been fun for you and see you next week [Applause]