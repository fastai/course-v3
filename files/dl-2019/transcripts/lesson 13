welcome everybody to lesson 13 also known as lesson 6 or part 2 also known as lesson 1 of devilment the lesson in which we start talking about Swift before we do I wanted to mention a couple of cool things during the week because lots of people doing lots of cool things and in part 2 I haven't done as much highlighting of these things but I thought it'd be nice to look at a couple of cool examples from this week big congrats to rob g who said that 14 months ago he had never done any machine learning or deep learning or Python or maths beyond high school and he just competed in one of the top academic challenges for computer vision machine learning and came first and second in the to of the true challenge tracks he entered so congrats Rob and I thought this is a great example of like you know the kind of interesting things you can do because if you do an academic challenge like this and if you do well like Rob you actually get the opportunity as he mentions here to to write a paper and so if you've never done an academic paper before this is a great way to get an introduction you kind of have a certain publishing venue and you get a bit of an insight to the academic world and I certainly found the same thing that that Rob points out here which is that when you actually submit a paper for the first time you suddenly realized why so many academic papers aren't that useful because they focus on weird things so anyway I thought this is a great result congratulations to Rob I also feel like I have a kind of a regular gig in promoting the amazing work Elena Haley does because she does so much great work but this is yet another great piece of work that she's done you're a member from the part-1 genomic stuff and this is nice because it's an example of looking at text data for the purpose of looking at genomic information and I just love this example and Elena has got a great walk through that you can find describing I mean look how familiar this looks it's the exact steps that we've just taken and one the things I love is she's actually using whatever this version of fast AI is that we have in our expert older so it's not even faster I version one it's the stuff that we've built from scratch and so it's nice to see that used in practice and not just used but not bad for a quick throw to get the baseline it hits 15th out of three hundred and fifty-seven teams on this leaderboard which he describes is not a bad starting point so not a bad starting point at all so that's very cool so rewind start of less than eight we said we're going to try and recreate fast AI and much of Pi torch from the foundations and 26 days ago silver and I started the same thing for Swift except we actually had no ability to cheat because when we started we really we're starting with from the foundations we know three of data science modules basic but there is stuff as you'll see in for creating tensors and random number generators and you will actually see we've been able to use matplotlib which might surprise you will show you why and how so so this is like what we're going to do over the next two lessons is is revisit this now obviously we're not going to go through every step in excruciating detail because as you'll see the vast majority of it is hey this is almost identical to what we did in Python so what we're going to do is dig in to the bits that show us something interesting or different of which there will be many but in the end we're going to get here which is this is x ResNet is the res block from SP x ResNet and this believe it or not is the swift version like you you you almost can't tell us different so we're going to end up in this beautiful situation this is the res block here's the x ResNet itself it's it's so concise it's so familiar hopefully it's going to make you feel pretty comfortable that this is where we're going and what about how we go again all the data in there have to deal with all that tensorflow data API s and learn all this stuff as well well know here is the data approach that we going to use data blocks API so actually going to show you how to build the data blocks API in Swift or tensorflow so you know three weeks ago when we started digging into this none of us knew if this would be possible and I'm really thrilled to find that it not only is it possible but we end up with code that looks you know wonderfully familiar and has all the nice features that we've hopefully grown to love so to get to here there's a lot of people I want to thank in particular in particular Chris Latner who I still don't understand why he put his trust in us in this way it seems like you know he has very strange judgment or something yeah but given that he did we felt that we had to make sure we don't screw it up so he's been fantastic and then the whole suite for tensorflow team has actually made this project their number one priority and this totally wouldn't have happened without everybody pulling together also in terms of bad judgment Silva has you know obviously we all know made the mistake of spending deciding to spend his time working with me on fast AI stuff and a few weeks ago I said guess what we're going to rebuild everything from scratch in Swift and rather than running away screaming he said okay when do we start so thank you for survey and he has built you know nearly all of these notebooks in three weeks and one Swift which is not bad thanks Alexis for the value types discussion you'll see next week super helpful Pedro has built something which makes the Swift packaging system suck slightly less than it otherwise does which is a lot and also the whole San Francisco Fastow a study group who's given us lots of valuable feedback over the last few weeks so what does this mean for day I there is a blog post we will link to about which many of you I'm sure I've read about why we're doing this crazy harebrained Swift thing but I was particularly wanted to mention like two things the first is we actually don't really have a choice right we we used to work with tensorflow and care us and we had to stop because we couldn't build for you and with you the things that we wanted to build together so luckily paid watch had just come out and we actually first started using paid watch in this course I think was two weeks after the first pre release of play torch so doing ridiculous things ridiculously early is definitely part of our DNA right we were lucky that happened but then when we came to get to you know the next part one because we started using plier torch in in an earlier part two just like we're doing for Swift then we got to this the next part one and we thought well pipe torch is great we want to use it all the time but there's no way we can teach pi torch to new practitioners so we created a whole new library board first day I because we had to and now we've hit the same point we were with with when we first which the PI torch which is we can't build with you the stuff we want to build together right we're just we're hitting the boundaries we want to create nice regular eyes Darren ends for example we want to create batch norm layers which skip computing the statistics from time to time for example we want to create highly flexible on GPU orientation systems and we can do all these things in play torch but they're slow enough that we kind of tend to choose not to so we're hitting the limits so we actually need to do something else so we need to start building the next thing and we were very lucky again that rift for tensorflow appeared at just the right time the second thing I mention is that not only will this not hurt fast AI for pi torch but I'm confident it will make it better I find that when I work with new programming languages and in new environments I learn new things and I become a better developer and we're already coming up with ideas that's going to help us to actually make faster a Python better you have a question yes how why is faster I chosen Swift over Julia well because it's impractical deep learning for coders and Julia is far too immature for such a thing I mean that they were both be great choices but I mean a lot of it is just for me personally I'm really interested in getting involved in something that has a huge amount of potential but a little bit earlier so I can help guide it I feel like I can be more part of it I would have to create something for our student community and our practitioner community where we could all kind of help be part of that that guiding and development process so that's one reason the second reason is it's not just about the language but it's about who's using it and Julia doesn't quite have that big customer that really makes sure that it goes from quite good to huge where else Swift for tensorflow has as Google and so Google needs it to work Google needs it to be hugely successful so I feel that that's really good I also feel like the stuff that I've talked to Chris Latner about as to what's next for Swift goes beyond the stuff I've talked to the Julia core team about what they're doing and so to be clear I've sat down with many of the Julia founding team members and I think they're amazing and I hope I get to spend to have time hacking stuff with them too but I feel like the place we're heading with Swift is like another level again as you'll see but I definitely would not say to anybody don't touch Julia I've actually sent invites to the forum to number of the Julia developers at their request to say why don't you build faster a with us but earlier too and so I hope that happens perhaps another question is why not Python because it it's it's and for most people the answer to the question of like what do we do next is given we're using Python we fix the problems in certain ways so for example in the tensorflow world they're creating things like TF dot function which is kind of like allows them to connect up Python to the whole xla environment which we'll learn about in PI torch they're using JIT to kind of turn Python into C++ why aren't we doing this why aren't we just you know do the best with what we have because PI seem to be clear has a fantastic ecosystem and we already all know it and it kind of seems crazy to throw that all away I think you'll see the answer to this question in the next two weeks but basically it turns out I'm pretty sure that it's easier to pick the right language and compilation environment and write everything else on top of it from scratch than it is to write everything else on top of something that was not written for that in the first place and then try and madly patch up the thing underneath to make it work so you know things like the global interpreter lock you know we're everything we're doing has to be massively parallel but python is written so that no two things can happen at the same time so it's these are things that are just incredibly incredibly hard to work around or else with Swift as you'll see it's like the things we want is how it's designed so why not Python because you know we think that we can't keep going with Python we were not the first people to think the existing languages are not good enough there's actually somebody else you had that thought a few years ago and he's so OCD that he actually decided to write his own language and he stole on a CD that before that he wrote his own compiler because they weren't good enough either and so whilst it may be difficult to be around such an OCD person we're over a thankful that these people exist because they create the things we have oh and here's one now haha Chris tell us about why you did this crazy thing thanks Jeremy I'm not the only crazy one as you know so let's talk about what Swift is and and then we'll kind of go very high level and then we'll get down in the bits so Swift is a lot of different things it's a programming language if you go ask the marketing people what it is it says they say things like Swift defines away large classes of errors and programs it talks about how fast it is and it's optimized to get the most out of modern hardware I think another aspect of it is that Swift is really ambitious and that is something that I think you'll see over the next two lessons where Swift isn't just about solving a niche problem it was not about like let's make iOS a little bit better Swift was conceived as a full-stack programming language that goes all the way from scripting down to low-level systems programming so you can write bootloaders in it now this is this is crazy I'm not aware of any other language it's actually set out from the start to do that but that's one of the reasons why it becomes really interesting and really good for this demand because you want very high level programming obstructions and a very nice and easy to use way of working with the language but you also want the ability to go down to the metal in the rare cases you need to so there's a there's some random guy in the internet the wrote a blog post about this I highly recommend that one of the things that he says is that it's the the interesting thing about Swift is it you get expressivity flexibility tight code you get safety ease-of-use and speed and it pulls it together in a unique way that's a very insightful quote Chris I'd like to read more of that person's work yeah he does some good things too he's a little bit crazy himself too so like getting out the marketing stuff what is really swift about so if does a really young language this is something I don't think that people realize Jeremy you like to point out that Python is 25 years old yep many of the systems were working on or 30 years old yeah I think Python might be 30 javascript might be 25 Java is about 25 I mean it for me I've never spent time writing such a length young language before I also don't really remember I'm not quite sure I guess I guess I go just like JavaScript have developed quickly but it's really unusual to have such a young language be so widely used so there's definitely a feeling for me often really like oh I'm using a language which lots of people use yet somehow it still feels like not everything is probably baked yet yeah yeah well it's kind of interesting because you have millions of programmers using it but on the other hand it can be changed and so that's one of the things that in this project we'll talk about being able to do language integrated Auto DIF as an example the kind of thing that you can only do if on a reasonable time scale you can innovate and make new language features get them merged in and evolve quickly and that's one of the things that's made this whole project possible Swift from its roots was designed for usability and so it's designed for IDE s and user experience and code completion and inline errors and things like that it has a ref acting engine a bunch of stuff that modern languages have the other aspect of Swift that I think is really important is Swift is designed to be not weird and so when you look at Swift code over the course of lessons it will look pretty familiar if you've used JavaScript you use lots of other language you've used Python it'll look pretty similar in a lot of ways and that's by design a lot of languages start out being trying to prove a point about something and Swift was really designed to be you know there's lots of good ideas in the world let's take them together and through a hardcore intense design process actually apply taste and try to come up with something that is well considered and fits well together it reminds me of Perl which Larry wall its developer described as a Swiss Army chainsaw and I think like Swift it's kind of got a similar feel of like trying to get the bits of everything the best bits but it's much more curated and kind of carefully designed and something like Perl so it fits together and so as we'll talk about the whole team the built Swift was a team that built LLVM and clang and things like this and so many languages were designed you come from a perspective of will create a programming language and then figure out how to make it fast later a lot of Swift was built from the beginning to be something that compilers can use in humans too so what it's what for tensorflow so here we're here to rethink how deep learning systems work from the ground up and where a lot of the systems today are constrained by being you know as much as you can get done in a Python library here we're changing the language we're changing the compiler we're changing all the library stacks we're changing tensorflow which we'll talk about there's a tremendous amount of stuff involved in this and one of the things that's really cool about this and one of the focuses is that we want to make an open hackable platform where you can go and change anything you want in it and you can experiment and research explore do lots of new kinds of things because that's where science comes from oh yeah caveat it's all broken fair fair yeah nothing works you know which is important if you're going to be doing a impractical deep learning for coders you wouldn't want to work work with something that's beginner works so yeah Swift is not just very much much Estero of iOS programming it's incredibly powerful language and all these people that are writing iOS applications you know can much more quickly become AI expert yes suddenly they're they're working with the language which language which is super cool suddenly and they help propel the ecosystem as well so the things we'll be talking about across the lesson are the super intensive project has very big bricks that are part of it so part of it is the tensor API we'll touch on that a little bit today python integration is a really big deal this is what gives you direct access to the entire ecosystem the already no automatic differentiation hugely important for ml and Swift has a really cool industry-leading approach to it stolen from Fortran Jupiter you'll see a lot of that today so one of the things you'll notice is a lot of what you see as a high level programmer is very familiar and that's by design and so this is an example set an example layer built in Swift this is later built-in PI torch it looks basically the same I mean there's differences and we're working to reduce the difference even more we'd love all those floats to I mean some of some of the differences are very nice like the fact that you don't have to pass self all the time you know these there are things friend just like Oh finally yep so it's actually getting to the point where the the boilerplate in the Python code there's more boilerplate of like all this self calm and self dot Paul and self comma and get rid of a lot of that yeah so so we're gonna we're gonna start very deep and very low level so I just want to give you a high-level view of what things look like and where we'll end up and so this is a layer and so on swift this is implement with the struct we'll talk about those a little bit later and it says I'm defining my model and it's a layer we use layers just like you would normally right and so you have come to D max pool flatten things are callable and Swift and we use call instead of underbar number call you'll see a lot less under burst and otherwise it looks basically the same you just compose these things together one major difference is this differentiable thing and you may be wondering why do we have differentiable well this is just telling the compiler that it should be able to differentiate this and one of the cool things about compiler integration is that when you say hey compiler give me the gradient of some function you know in the happy path when everything is good it just does and that's what you'd expect but the unhappy path matters as well I don't know if you hear makes mistakes I do and so one of the cool things about having proper language supporters you can get an error message that says hey that function can't be differentiated let's that's useful but you go farther you say oh well it can't be differentiated because integers and this in cast you have can't be differentiated and then it says even part of their well it's actually this is several levels deep and function calls and this is exactly the path and this is exactly what went wrong and it's really cool to get this in your workbook without even having to run something right and so this is the kind of when you build things for IDs and you build things for usability you get really nice nice behavior that the compiler is helping you so what does Swift for dense flow and how does it stack up and how does it relate to tensor flow so tensor flow one way to think about classic tensor flow is that you have a tremendous amount of infrastructure intensive flow has this really mature distribution scale out end-to-end training inference with mobile devices like all this all this cool stuff in the ecosystem and then it has this thing called Python I call it Python for TF and Python for TF includes its Auto diff system and then it has a bunch of api's like kuro-san estimator and other things built on top and so what we've done is we built a parallel stack where we're using a lot of the same infrastructure underneath the covers and then we're building a new faster a framework on top now one of the things we'll talk about more later is that tensorflow itself is undergoing radical change in the internals and one example this is the excel a compiler and one of the things you'll find out is that tensorflow is compiler izing itself as new accelerators and your technologies and lots of things are coming into play and so tensorflow is the internals are undergoing major changes which is super exciting so let's dive into some code yeah what's the roadmap relationship between Swift for tensor flow and mainstream Swift will they eventually be the same thing or yeah that's a great question so right now the Swiffer intensiva project you can think of it as like a dev branch actually it is literally a dev branch on the Swift project and so what we do is we build things like automatic differentiation we bake them we get experience and then we propose them and merge them back in the mainland Swift language and a bunch of stuff has already been done that way so the Python integration is drove new language features in Swift we proposed them we got them integrated into the mainline compiler and now they're shipping and iOS developers can use cool things because of Swift for tensor flow yep so let's dive in now I I thought I would start with some really basic basic things to just introduce the language just so you understand you have some context of how things work and then we'll get into some more interesting stuff so this is a Jupiter notebook just like you'd expect this is Jeremy's window machine which I will struggle to use because I have not used Windows for a long time it will be fine it has a Mac keyboard on it so it's super weird scrolls the wrong direction but it'll all be great so a lot of a lot of what Swift does looks very familiar to Python so here I have some integer six you have some math I have print it all works exactly the same as you'd expect in Python one of the major differences in Swift is that you have this let in this bar thing and so let in Swift means constant var means variable and so it's super easy and as Jeremy I think loves to say in a workbook just to clear everything bar and then you don't have to worry about it and then you can change it however much you want but you can see if you declare a constant like pi because i should not change right it makes sense to use let if you try to change it change a constant you'll get this error message and this error message says something like you know cell 5 line 1 one of the cool things about jupiter is if you hit shift l you get line numbers in here and here you can see it's referring to cell 5 line 1 and it says hey if you go to cell 3 line 2 up here you can change this let into a bar and now your code will work and so it's trying to help you out here so that's something you'll see that's super awesome and and I'll just mention like the for people watching that have a background in Swift programming there's a tendency in that culture to kind of keep things closed keep things constant keep things private and there's lots of good reasons for that but when you're kind of getting into this deep learning mode we generally represent flipping everything upside down at least for the R&D and prototyping process because you want things to be 2 things to be infinitely hackable the way chris describes you want them to be VAR so you can change them you want to be public so that you can see inside them and so you'll actually find like there's been recent PRS to swift to tensorflow swift the tensor flow itself where we're starting to change ap is way to kind of like make it so that people can look inside the covers and change things more yep so you may notice that we're not using a lot of types here but Swift is a text language types are actually a very important way that the compiler can help you because you can detect errors early what Swift does is it has a thing called type inference and so when you say VAR x equals 4 it knows that 4 is an int and so it'll default it to an int or if you say var X is equal to 1 it'll say that that's a that's a float or a double and so types and swifter written with a colon here and so you can say okay well even though this would normally be an integer actually make it a float swift supports important things like emoji emojis totally better than Greek letters Jeremy yeah so actually Chris passed me last week he goes Jeremy yes Prince what it's like um how do you feel like emoji about emoji in the books in Swift code and I literally said to him Chris they're fine as long as it's the pile of poo emoji and it's next to a cow and Chris goes okay it's the pile of poo emoji but it's next to a dog is that okay so I yeah okay yeah we split the difference yeah yep so well you know this is great power and great responsibility if you name all of your variables pile of poo then your code is alright static on yes yes yes descriptive yes so how do so let's talk about a few other things so python uses indentation Swifty's is curly braces so I don't think that there's any I'm not gonna say one's better than the other curly braces are more commonly used and so that's why Swift uses them but they're basically the same thing just you'll figure it out how do functions work well in Python used F and so have to use func fun because it's a function and so what this is this is defining a function and you declare the inputs the signature x and y and returns a float and you implement it with thing you'd expect when you call it you pacify past keyword arguments swift is very opinionated about keyword arguments and so if you say that this thing has x and y is is arguments you have to pass x and y and so one of the funny things you'll see is you'll see this underbar thing going on right here and this is saying that ignore underbars ignore just like python ignore the keyword argument and so when you call it you don't pass it that's all I mean I've got to say I love almost everything about Swift except for three things this is one of the three things so like this this bit I find awkward because like these these positional parameters you can't even change the order of them even though they're positional you can't use them in a different order if you do have that underscore to say you don't have to name it then you're not allowed to name it like it's I don't know I I find this bit nasty but it's like everything almost everything else I love about Swift so I just put up with it this this is also not my opinion of the right thing but the argument for that is consistency of API is is important and and it works fine so two poles work pretty much the same way as they do in Python you can you can use them to return multiple values which is what we're doing here so here we're turning two floats and we're saying first one to sign and second cosine you get destructuring you get access to the two poles all the nice things that you'd expect one of the things that's different about Swift and Python so it has this thing called struct and the thing - the way to think about it to begin with is it's just like a class in Python structs are super powerful though they are more efficient there's a lot of good things about them they don't require memory allocation and we'll talk about why that matters if you've got a C programming background it's not much like that at all so I would say like think of it more like a Python class than a see straight yeah exactly and you know and we'll show you a lot about that so here I have a complex F struct and I've got a real and imaginary I stick it in there I can create one of these complex FS by specifying these things I print it out and I get it back and in Python there's this thing called data class yeah so we've used data class and it's interesting when I throw in a data class here it's it looks almost exactly the same there's some extra boilerplate we need in the Python version for example we have to put the two things on different lines we can't put them on the same line you know but overall like a lot of things between Swift and Python ends up looking extremely comfortable yep okay so now one of the bad things about this thing is you notice is to find with floats the complex numbers work with integers as well and they work with doubles and lots of other things so the way that Swift handles this is this thing called generics and we'll talk more about the details of generics later but basically what we can do is we can say let's define a complex type and complex works with any type T and anything that has assigned and that's a number and that's what the sign numeric thing says and so now what I can do is I can define the struct and I can use it down here with integers and with floating point and it just figures out that T is int or Tia's float depending on what you use it with and this is something that Python can't do right so with Python if we removed the data class we could certainly then remove the float and then we could have an untyped but we can't say in Python these two have to be of the same type but I don't know what type it is yet so this ability to use generics lets us do some pretty powerful stuff right out of the box yeah and we'll talk about some of the really cool things you can do that make it's super flexible and super I mean there's some really really powerful things you can do so we've got our complex here one of the things you can see we're doing is that just like in Python you have computed properties and stored properties and here we have a computed property we can define a getter just in line and so it's just a stored property but you provide a body it's quite simple here's a computed property doing a weird thing but here I just have a computed getter and a setter and it's pretty straightforward this is very similar to c-sharp when you've got one of these you can create some of these things you can use the computed property and it works just like a normal property it's all it's all very simple now one of the cool things about Swift is that after you define a type you can add methods to it and this this is something that might make you feel weird but you can add methods on anybody's type you can add it on your own like we're doing here or you can add it on standard library types or you can add it on anybody's I mean it doesn't make us feel we it doesn't make me feel weird Chris because like we do it in fast AI all the time it's called monkey patching but it's kind of something that we're told to avoid because monkey patching has weird dangerous undefined strange behavior and things combine in one place so is this monkey patching should we be innovating this in Swift so this is this works in a very highly principled way that actually composes and if you get a conflict the compiler will ask you which one you want it's this is not something you feel bad about now here I'm defining an ADD method and so I'm using this to add two complex numbers I feel bad about this because there's a way to spell add and that's yes it's a DD I guess but i would rather spell with plus and so you can call a method on this just like any other method but if you want to add an operator we do is you just define func plus and so instead of under barber and all that jazz you just find the operators you want and spell the way you expect and they're just functions like anything else and this like already is getting it something that would be really nice to be able to do in Python would be able to say like oh there's a whole bunch of different functions or operators with the same name and they behave differently depending on what type I pass to them now Python does have a standard library decorator you can use called single dispatch we almost never use it because like every time we've tried to use it it it reacts in weird ways with everything else but it's super nice that in in Swift as in many types languages like this it's very much designed for us to be able to say like oh here's lots of different types and they all have different meanings of what for example plus means no just works and so here we're implying Plus on complex in terms of plus of its elements and so we're just adding together the real and imaginary and these are different pluses one of the like mind-blowing things that's very different than Python is you can define your own operators and so some of us do lots of math us not including me but some of you all do a lot of math and or you're working in a domain where you're doing quaternions or other cool things like that and it's really nice to be able to use operators that are familiar to your domain and so if you wanted to find a square root operator then you can define a square root operator in these just work and now you can use a square root operator just like anything else and this is this is one of the examples of Swift being hackable like there's a standard library that has a bunch of stuff built in and provided with the in the box but the stuff the standard library does you can do too and so that we try very hard to not make the standard library be privileged so that that's like the super quick introduction to some random stuff and Swift there's this guided tour here which is really cool goes into other random stuff and so if you want just a high-level introduction like this you can you can go there but let's dive into some more relevant first two questions the first is the swift support any debugger with in Jupiter similar to I PDB for Python to set breakpoints so we don't have that yet we have all the mechanics under the covers so Jupiter is actually talking to a debugger we just haven't wired it up yet but that's one of the things we're interested in okay so that's probably coming I promised a guy in the front row that built it all is smiling so maybe and the Swift have something similar to pythons args and kW arcs yes in fact we'll talk about that when we get to the pythons great Thank You Olga so it works it works a little bit differently so let's talk about Python now because we love Python right well so flows Python too and as Jeremy helpfully pointed out Swift data science ecosystem is kind of pathetic so python is really important and beyond the data science ecosystem in Swift being pathetic you all know Python and so you all know important api's that are pervasively available there's no reason for you to relearn new ap is like if you know the API is in Python just use them so let's talk about how that works because I think it might blow your mind a little bit so to use Python in Swift you first import Python okay this is just a library and Swift called Python and then you use Python to import whatever Python libraries you want and there's no wrappers there's no build steps there's no generator wrapper of generator thingies you just literally import numpy aurere importing matplotlib ok what does this give you this gives you NP this gives you P LT just like you would do in Python and now you use it just like in Python and so here I'm calling NP array and this is except for the let this is literally what you write in Python okay so we can now use this to do some cool stuff and so here actually we're gonna use this load m-miss function and we'll see it a little bit later it's in the zero zero notebook this is firing up tensorflow and loading the Hemnes data set and plop it into a tensor for us once that comes back now we can use matplotlib and matplotlib we can use this magic incantation that's kind of like the matplotlib in line we can then load take the tensor the test flow gave us do all the numpy stuff with an umpire and dra reshape it and plot it out and this all just works the way you would normally use matplotlib and the cool thing about this is that Swift knows nothing about matplotlib it knows nothing about numpy it knows nothing about any of the particular libraries you're using we literally just imported some ran thing with strings and Swift doesn't know anything about what you imported here okay yeah so and and so you may be wondering how this works right because we're just using Python right from Swift and how does Swift know what Python is well the the way to think about this is that we think about Python as though it has no types but really python has one type and that type is Python object and Python has an eternal representation of objects and you can use dot on them and you can call them and so the way it works in Swift is that you have one type called Python object so here when we use the type of that's just like type in Python it says give me the type of NP or give me the type of NP or a or give me a type of the array that we got or or whatever what it actually shows you is the type is Python object and so Python values are Python object types and Swift and when you dot them when you call them as just using the interpreter and so it just works in Swift because you are literally using Python as dynamically as Python is designed to be used and you can actually go and look and one of the totally brain twisting things you can do is you can import Python into Swift import fasi eyes Python libraries into Swift and now go to town and just use all the standard fast AI cool stuff right from Swift and it all just works so thank you too OMA s F for trying this it's a crazy thing to try and like it's interesting how when you look at the resulting code it's it's the same code that we'd like at this point you can't you can't tell other than some slightly different syntax here and there but it's all the same it's like Python with Lautenberg one thing I'll say about this is this is a super cool feature that you should totally use to fill in the gaps that need to be filled in while this ecosystem doesn't exist but then as soon as possible fill in the gap right because like I don't want us you know as a switch for tensorflow community to use this as such a crutch that we never write our own even better data frames library because we're always using panda and we always used MATLAB so we never created an even better blooding library like we should use the crutch to allow us to get all our work done into end and then gradually replace it with bits that are more tea I mean one of the one of the awesome things about such is that it supports really well considered in beautiful api's and it was really designed for building api's but if particularly when you're new to swift don't worry about that stuff like that's a problem for a different day if you want to open a file open a file the way you know how just use the Python file i/o library that's fine you don't don't don't waste your brain cycles on that kind of stuff so let's now talk about the idea of Jeremy's course here which is building machine learning library from scratch and I think it's very quaint that Jeremy tried so hard to go down to the foundation and teach you how to build a Matt mole with a few loops and looping over an array and adding a multiplying floating point numbers and I think that it's very very nice how that he thinks that this is going down to the foundation Oh Chris it's Matt mole from scratch yes well so if that's mole from scratch then I think we should go down to the bedrock and actually talk about where float and arrays come from but before we do that I want to dive in and geek out just a little bit about compilers because I think you need to understand or it's useful to understand what LVM and Swift and things like this are so Chris what you're saying is that I cheated I used array without implementing exactly you just float without implementing float so so let's let's fix that okay I'm sorry so so what what what is a come yeah so what is a compiler so we can do bunk touchscreens Wow crazy okay so what is it what is a compiler anyways and what is the language so the way I think about this is that there's actually two unmovable obstacles in the universe there's humans which we're all kind of a pain to work with right highly opinionated sometimes and then there's computers and there's a pain because they are super opinionated and sort of what languages are is there a point in between and different languages are different points in between and you know some are optimized for working with humans better some were optimized for working with computers better but good languages were with both and so how do compilers work well the way that it used to work in the bad old days is that if somebody wanted to build a compiler for x86 they would build a parser the front-end part of a compiler they then build an optimizer and make the code go fast and they'd build a code generator for the Intel PC or whatever it is that they want to target somebody else will come along and say hey I want a different compiler I want a C++ compiler and they'd build a parser they'd build and optimize them they'd build back in for PowerPC somebody else would say hey APL was really cool let's build a parser for APL and optimizer for APL and then a back-end for arm and if you've noticed the trend here there's a lot of area of all the things going on and so what compilers have done is they've created funnel points LLVM is one of these funnel points where you can make it so that lots of different language people can implement lots of different front ends and lots of different hardware people can implement what's called the backend or the code generator and now they can share tremendous amount of code and now you can get all the permutations you want out of this and we should all thank Chris latinus master's thesis supervisor for forcing him to write his damn thesis and getting him to actually write LLVM version one in one and a half weeks of diet cook fueled fueled coding activity this is the way we get things done if people are ridiculous deadlines and yeah absolutely so yeah and so the the details of what LVM is is not really important but this this LVO is what powers julia and rust and swift and clang the does c and c++ it it's it's like a very common set of infrastructure the lots of things use these days and if you're not very familiar with compilers and what optimizations are there's a bunch of standard stuff that LVM does including constant folding removing dead code other things like the example I show here of taking an expression and pulling out of a loop this is something that in my torch for example if you do a multiply inside of a loop of two tensors it's gonna run that multiply every single time you go through the loop but you know reasonable more modern languages actually pull these things out for it so this like this is a fascinating example right because normally if we're writing Python and you see oh I'm doing this work inside the loop redundantly I can pull it out that's something that I as a programmer have to figure out right and the fact that LLVM can do for you and and other optimization systems in GCC or whatever it it certainly makes you realize that compilers as something different to at least what I thought they were I thought compilers were things that got in your way and complained until you did things the way they expected you to do them and took forever to run code that I would have finished yesterday if it was Python but actually working with Swift and particularly with sweet 4 tensorflow is made me realize that these optimizations actually allow us to write code in different ways and and actually be much more lazy about how we're at covered and this is this is you think about a point in the space between the human and the computer yeah so we're actually going to show you something really mind-blowing next week where this this is actually going to be used to basically make Auto diff work and it's it's like it blew my mind when I found out about it yep and so now if you think about languages and different points in the space there's a couple of different ways to look at this one of the ways I think about it ignoring the syntax pieces which the syntax is always the first thing people talk about is what are the atoms of the universe and how do they get composed and how do you build things out of them and so if you look at Python for example if you will boil everything down in Python boil a dictionary down it's a bunch of C functions and then what the interpreter does the Python interpreter does is it decides what C functions to call and what order and on what data and so the Python interpreter is slow and so the Python program ends up being slow even if the C pieces are fast C++ is another way which C++ is a little bit different C++ the atoms are built in things like integers and floats and arrays and pointers and things like that and then a C++ programmer can use structs and classes to build complex numbers or strings or it's variable sized array thing out of in the library right you can do this because C++ is a fast language it's also not a super well considered language but but but it's weird to me in C++ that array is hard-coded into the compiler but string is a library feature and why is that that doesn't really make sense to me because strings and arrays are so similar what Swift is is it says let's let's rethink all this and so the primitives the low-level atoms of the universe are now things that LVM the compiler knows about and then all the abstractions you build including floats arrays dictionaries of course the high-level stuff - like layers those are all defined in the library and so a float is not a magic built-in thing so if doesn't like magic built-in things Swift likes things that are hackable and if something is interesting for a library developer to do maybe you want to do in your workbook right and so having an open ecosystem is very powerful and so if you actually go look at the library that implements float float is just a struck just like the complex thing we were talking about before in the middle the inside of it is this built-in weird thing that's an LLVM thing and plus on floats isn't a magic thing that the compiler knows about plus is just an operator just like we were talking about before one redefined square root just this one happens to be named plus or plus equals and it's implemented at the LLVM magic so we're allowed to use float now Chris well let's go look at the let's go look at the implementation and so if you actually go look at this this is the standard library that comes with Swift here you can see it implements infinity it implements not a numbers it implements add PI like all the things that are in float is just a gigantic pile of Swift code and the cool thing about this is that this means that you can implement low-level stuff like this - and right in this right in the workbook and to be clear we don't expect you to implement float yes right yourself but the fact that you can is actually important to data for data scientists and so let me explain when when I was starting out and I was they did a lot of stuff with Delphi I guess twenty-something years ago which is like a very fast Pascal system and I was writing a lot of numeric code and I very often hit this floor where things weren't working the way I wanted them to so I had to use a similar which nobody should ever have to do but that that was the floor I had like I had some work that needed to be done and I couldn't do it in Delphi so I had to use assembler but at least I could you know and and over the last 25 years we've gradually kind of filled in more of the things that numeric programmers use but what I'm kind of finding is happening now is as numeric programming is becoming differentiable programming I'm hitting the bottom of the stack again and there aren't things that I want to do and or there are things I want to do a little bit differently so I feel like we're at this point in history you know and we might be for the next five or ten years or more where data scientists don't need to know how to write assembler but they do need a system where they can go under the surface and actually change things you know people don't normally change yeah well and again to me I think the goal here is an infinitely hackable platform it's like in the Box are all than that all the nice things you'd expect you don't have to write matte moles you don't have to write floats but if you want to go change it and do your own you can or if you want to take somebody else's you can drop it in your work book you don't have to recompile the whole stack now we talked about structure a little bit like like classes in Python the major difference is that these are actually fast so here's our square add that multiplies two things together and adds it if this was Python these would be allocating objects this would be doing lots of crazy stuff this thing I'm showing you now is called the compiler Explorer and you thought you came to learn machine learning here's some assembly language which we can't get away from as soon as possible but the point is like you're writing a reasonable Swift code and you're getting literally the same code you would get from clang if you wrote C++ like even though float is implement the standard library there's no tricks here you're getting the lowest level optimized fast code that's trying to multiply instruction and add instruction on on Intel and I'll go away from this very quickly because we're not here to learn about until assembly so now the thing about float again is not really about something you should want to do but you can poke at it if you want you can see what's inside of it one of the things we've at least so far chosen not to do is we don't export the built into workbooks and so you have to write a standalone file to use it we could change that if we wanted to but one of the really powerful things about this is because these types are defined in the library they're not magic well now all the other things we talked about or work with these and so we can add a method to int or to bool so here you know we add a little is odd method that's just saying is the little bit set or clear that's cool that's fine like this is not monkey-patching this is just super low-level int is a struct sure you can add a method to it no problem we can add a symbol that turns a boolean into an emoji because emojis are cool and so now you can just use these things and we can say hey for are you on a for are you are turning yourself into a symbol and we get true false we get thumbs-up thumbs-down and it just kind of works yeah I mean this this is particularly important for for all of us at this stage because as we discussed you know Swift hasn't been widely used for numeric programming so a lot of stuff doesn't exist and so when I started playing with it in December and I realized like oh I I'm missing stuff so yeah so I created this library court based math where I literally was defining things on float that I needed to exist and and not only did they then exist but they ran at say speed and then from then on I had all the stuff that I meth stuff that I wanted in the language and so if you're hacking around over the neck you know the coming months and you find things not quite the way you want you can and should change it right and it's really really really common in Swift code to add extensions two basic types it's not at all unusual or weird it's just part of how you write code and you can make it feel the way you want so we're not going to dive in too deep but there's there's lots of interesting things in the system so if you say well how does how does and and work and and only evaluates one side of itself if the other side is true well that's implements in our library it's three lines of code you can go dive in there's a couple of links let's talk about array because we need a raise to implement matmo before we talk about how array works let's look at how you use it as a swift programmer arrays and swift are super simple you just define them with square brackets like you'd expect Swift is type inferred and so what you'll end up seeing is there's two different syntaxes the types there's in square brackets which is the way you'd normally write it if it's not inferred but that is actually just sugar for this array okay and if you print out the types of these things you'll see that they're all just array event or a van or a event well arrays can be iterated over so you can have a for loop just goes over all the elements of the array pretty simple you can slice them swift has two ways to slice based on whether you want the endpoint or not if you want an inclusive range which includes that endpoint you use dot dot dot an exclusive range use dot lesson and the lesson says but not the last one swift supports functional programming things and so here what we do is we use this functional map algorithm and it's using a closure closures are the same thing as lambdas in Python with slightly nicer syntax and so here what we're doing is we're saying give me an array but run a function that takes all the elements and adds ten to them and it's very simple you can just do this right in line and it's nice and fast and so here we get our array where everything has ten added to it as filter and map filter and reduce as well so filter it just takes a predicate where you say filter and only include the things that are odd okay and we just added is odd and now we get an array that just has odd things in it it's super easy and one of the other things you'll notice is that Swift has lots of nice syntactic shortcuts and so instead of naming our argument like we did in map we just use the default name which is dollar sign zero so the top one is equivalent to lambda colon at plus ten right and so then we can get rid of both the lambda and the alcohol and by sticking it in curly brackets and just using dollar zero to refer to the first argument yep another super common thing is that often these closures end up being the last argument to a function if you have if there the last argument of function you can just put them outside the parentheses and if that's the only thing in the parentheses you can just get rid of the parentheses as well and so you get these really nice things that are kind of like list comprehensions or you can say map and multiply all the elements by three and then filter them and only keep the odd ones and you get very nice fluent things or here's a map where i'm saying you know pick get the odd like decide whether it's odd and then turn into assemble and I get very nice simple yeah so this so just come back and have a look at this map filter again at the end of the lesson because this is how you do list comprehensions in Swift you don't need special syntax for it because we the stuff that's already built in very elegantly gives us list comprehensions afraid yep and all these things are just library features reduces is a it's a reduction so you give it the first element and then in this case we're just adding all the elements of the array to zero and plus as a function we saw it already and so this just uses the plus function to do a reduction it's super simple now we're talking about array array is a type and that means you can do an extension on a type so you can add methods to arrays that's super easy so here we defined a double elements method that returns a new array and we just map so mm let's just multiplies all the elements by two and like the self thing we don't actually need oh thank you right Jerry too much self in Python yeah yeah and now one of the other things you may wonder about is like why do we need this where element is numeric and what this is talking about is it saying well we're taking all the elements out of this thing and multiplying it by two this is helping us catch errors so if I have an array of boolean's I get an error message that says hey I can't double all the elements of a boolean array because bool is not a number and so in Python what would end up happening is if you accidentally pass the wrong thing in you would pass in your bools and then they get multiplied by two and then sometime in a far-distant api call somewhere later you find out you have twos in your boolean like what just happened and so Swift helps catch these errors early and talking what just happened this is the point where if you've used a few languages before you're thinking Oh Swift is actually pretty different in a pretty interesting way because what we've just done we've just said here is some functionality which replies which applies to some type which has some particular properties to it right so we've like defined functionality in a way that's going to be going to be looked up in this really nuanced and interesting way and so we're not going to go into the details now but just like take a look at this after the eighth lesson and think like wow what's going on here because this is something really interesting and again one of the cool things about this is because it's all built on the library it's all open to you and you can do you can do the cool things like add methods or do other things so I'm not gonna go into the full details of arrey arrey is implemented right here and a raid on swift this is a standard library array is a struct it has a buffer inside of it the elements you can go through and you can see all the different gory details of things that go into array and instead of coding this and workbook I think that we'll just consider it that we implemented this is that okay with you Jeremy absolutely okay so now we can use arrays okay so let's move on to mammal okay so what I'm going to suggest is we might be good time to take a break so let's take a six minute break and we'll see you back here at 6:47 now that we've invented swift and float and array we will actually implement matrix multiplication so we'll see you back here at 7:47 okay any questions before we keep going yes we have two questions the first is that in keyword is very unintuitive for argh and argh plus tag enclosures oh can we point at that so yeah in keyword yeah peer in yep so that's the questions like why is it so weird why is argh in R plus ten yeah so we carefully considered the name of this keyword and we didn't have anything better to use so we got stuck with this and Python I guess that would be a : yeah so we there's no good answer it nobody knows what it means there's historical reasons but they're not good reasons so we just do it and it's so the answer is because Chris says so yeah thanks for your honest like why do we use : well that's what Python says and the second question can Swift LLVM implement instructions to execute on the GPU would this be a good idea yeah this is a really exciting direction this is one of the things we're investing a lot in tensorflow and the infrastructure pieces and we'll be talking about that a little bit next time yeah but I mean the short answer is that LLVM has a number of backends yes and one of the backends it has is a PTX back-end which is the lower level and video kind of instructions and so like right now you can compile stuff with LLVM and have it run as Goethe kernels yep so the answer is yes yeah and in fact like every pixel on the iPhone goes through a VM not there's Swift in a workbook all right not bad yeah it's so L Vanna is used for lots of cool stuff and using it for more cool stuff is fun so let's let's now that we have our bedrock of floats and arrays let's build something a little bit higher level let's talk about matrix multiplication so here what we've done what we're going to do is we're actually going to load up a few tensors and here we're playing by the same rules that we played with in Python where we could use the random number generation and things like this but we're not going to use the matrix multiplication operator quite yet so the so there's lots of ways there we go there's lots of ways to create tensors and Swifter tensorflow it has this tensor type the this little float thing we want to go away eventually and we hope but right now you say tensor a float to say that I want a tensor of floats you use the shape you can get zeros ones you can repeat a thing you can get random there's lots of different things you can play with I highly recommend you type tab and Jupiter and it will tell you all the things that you can do with completion so let's build a matrix multiply so here what we're doing is we're doing something kind of similar to what Jeremy did in the Python version of this but here we're starting a little bit lower level we only have one dimensional arrays that's how the software array works and so what we need to do is we need to pass in two arrays of floats and then we're doing a two dimensional matrix multiplication so we need to know the number of rows a number of columns for a and B so that's a definition of a tuple parameter Chris yep they're two ins yep so Adams is two int sand it be dims as two mints and so what we do is we create an array full of zeros and then we write the same three loops you saw before and because we have a one dimensional array we have to do manual arithmetic to get into it now one of the things that you'll see is like if you actually try this out and you run this oh I didn't actually run the cell this is way say don't do things I don't listen and then I make a fool out of myself okay so then you run you run this you get the the tensors here just using them in a Stata set because it's it's fun to use now we can run this and we can time it and one of the major differences you'll see is we just wrote three loops and it takes point one three two milliseconds the Python version of this took eight hundred and thirty five milliseconds just have a look so Chris I just wanted to compare so I mean the first thing wanna compare is to look at the code so that's a swift code and in Python here's the Python code so it's basically exactly the same code as you say here you have to do Cydia race which we'll get to and so yeah we kind of found with the Python version it took about a second to do a 5x7 84 matrix multiply with a 784 by 10 so we kind of did the math and said like we can't use this because it's just not fast enough but something very different going on here because this is about 9,000 times faster yeah so this is this is this is not super fast but this is pretty reasonable this is what you get from roughly see right and that's because again we talked about its primitives that are principled that are fast and when you build things out of principled fast primitives you get new things that are principled and fast okay so this is no big deal for you but for a pricing programmer this is like this was a whole mind shift change because this at this point the fact that you can write this and have it run this fast means like I can now write anything I can think of doing with numbers in the most obvious way possible and have a work pretty damn well so this is kind of like a superpower with the Python programmers don't have well and if you think about so one way to think about so for ten suppose we're trying to subtract c and c++ out of the picture right because if you think about working with python a lot of it ends up being if you care about performance working around the gill and how do you do that you go and deduce these stuff or working around writing oh I need a new kind of data structure what do I do I write a bunch of stuff and see because writing and Python wouldn't be fast enough and that's that's problematic for lots of reasons one of which is it's just really hard to do things in workbooks but here we're implementing basic stuff and workbooks and it goes fast yeah and I can like I can ship something that's like a my old program that I just ship it I don't have to figure out how to put the C library over here file it and put it together with this header so Jeremy what is this built-in called time oh that built-in language no well so Chris can you show me what that is absolutely so we're not using percent time because percent time is a magic and we under your new rules we shouldn't be allowed to use know things that are magic we should write them ourselves so so time is written ourselves and it's actually written in this notebook called zero zero so yeah so when when when we started out we started out with a blank slate and so we had to start out with things like how do i time itself right so the answer is it this is a nice thing about working with Swift is we can build everything from scratch right so here's the timing section right and the details don't matter but basically you can see we can grab some stuff from the Swift standard library for example a function that tells the time and we can run some function and see how long it takes and the nice thing is that we can end up with some very neat syntax right because the thing that we pass in the function we pass in is a closure right and this is how you say pass in some closure that takes no arguments and returns nothing at all and so for example we can give it a default value which means if we want to time something and just run it once we can just do that right so we can create syntax you know we can create api's that are really nice and elegant and simple to use and so this version of time actually is both time it and time together right so if you give it repeating it'll it'll do that right and actually this 0/0 notebook is is worth flicking through because it's the only notebook where there's no tensors in it there's no tensor flow in it there's no TF data in it so if you just want to see like just Swift right this is a good way to learn to Swift so for example you can see how we built this thing where you can go LS shell so we've actually added something to string that will run a task right and you can kind of see how to write these things in just nice neat little concise packages and now we can export this and now anytime you want to run a process through the shell you can just go blog shell you can see how to download a file and one of the nice things here is that you'll see that download a file we've actually using this path library that looks almost identical to path Lib and that's because there's a wonderful program a wonderful person called max Hal this is Max's user name on github and I mentioned he's actually an open source programmer who entirely relies on sponsorship for his work so if you like Max's work which I certainly do you should go to his patreon and give him a few dollars so thanks to max we have something that's really just like path live but actually even almost a bit better there's something that's almost exactly like requests it's called just right so in the Swift ecosystem thanks to the fact that you've got all these millions of iOS programmers that's been hoping using this language of five years to build pull stuff there's actually a nice non data science ecosystem and while we're talking about a non data science Python similar packages is there anything any web frameworks similar to flask or Django yeah actually the Swift on server community is a really vibrant community and there's the equivalent of Ruby on Rails and and a bunch of these different frameworks have sovereigns and that's actually one of the biggest non iOS communities that exist now one I've seen a lot of love for is vapor yeah vapor iBM is investing they have a framework called Couture and they're they're putting a lot of time and thought into that Apple has a low-level thing that's like Neddie Neddie library on Java and there's a swift version of that called Swift neo so there's a bunch of these fairly infrastructural things that exist that are part of the Swift ecosystem and Swift is really great on servers - ok so here you can see how we can download a file it's all pretty straightforward you've got try-catch blocks a lot like we used to but they're kind of do try catch the details are a bit different so in this case we want to download em list and load it up one thing to be aware of is that things can and we'll talk a lot more about this next week but things can get a little bit complicated when like for example for M NIST we've got a file containing labels and we've got a file containing images there different types labels are intz the images are floats so we kind of want two functions one that returns a tensor floats one that returns the tensor of images that's duplicate code I hate duplicate code right so here's a version where we actually tell it oh you could load up different types of M Nastasia and it's going to return a tensor of that type okay and unfortunately if I try to use this I get an error right and I really wanted to show you this error because for the first week as a Swift programmer I kind of fit I kind of I've never felt so stupid like I felt like everything I wanted to do Swift hated me and it told me these things like cannot invoke map weather data but what the hell is all this and I just gotta say that's totally fine right because the Swift type system is very new to somebody like me and probably most of the people watching this the messages are helpful for people who understand it pretty well and it's totally normal to think for what for a week or two it's a rift hates me to be stubbing your toe on every new thing and feeling like you'll never and particularly this generics data you know and and I would say look a couple of suggestions the first is just write the two separate versions so that you don't get frustrated and then come back and try again a few times yourself ask on the forum Stack Overflow screw ya there quite often quite often the kinds of errors you get from the site system are sometimes they're even like a long way away from really where the problem was it can be quite difficult because it's a powerful type system for it to really know where the problem is now in this case the issue basically is that we are trying to call they try to initialize either floats or or byte and so it basically needs to know that the type we're creating can initialize either floats or bytes so as you'll learn next week you could do that by creating something called a protocol you do it by saying that these things conform to that protocol you then use that protocol and so now this version of load M inist works totally fine right so this is a nice little package that you can look through the last piece that we had to build in 0/0 was the thing that makes slash / export works so it's kind of delightful writing the thing that makes slash / export work by typing slash slash export one of the things that I needed to do here was to check whether something matches a regular expression or not I found it extremely weird that the way to do that in Swift is called range of options regular expression so I created something called find in string so now I never have to worry about the weird and clunky Swift syntax most of the time I'm just looking to see whether something does exist or not so I just ran something called has match that checks whether something is ists or not so I make Swift work the way I wanted to yep and to give you a sense of like when I say clunky api's the in particular you'll see here we're using Max's beautiful path library before we realize that the path library does everything we wanted we use the thing that apple provides which is called the foundation library and that comes with swift these two lines also works great on Linux since it's a standard thing that's available yeah so so those two lines of code in Apple's foundation library looks like oh god it looks like this okay so to me a lot of Swift api's look like the leading pastor who ended up landing class component appending path extension all right I don't know why but a lot of script programmers seem to like writing this kind of code I like writing this kind of code but I think foundation is not necessarily your favorite API design Chris would that be fair to say I think it's fair to say that the thing that's great about foundation is it has a lot of interesting and useful stuff URLs and other stuff like that but its design is not all great it's great that it's there it's amazing that it's all been ported to Linux right so quite often you're fired romance malfunction I need something like you know the ability to tell the time is in dispatch or the ability to work with URLs and so it's know that foundation is there and generally speaking I always just imported first thing right because there's a lot of stuff you want will live there and if you forget to important it won't appear in your tab completion and you'll get errors but also when you find clunky foundation api's which is there's actually a better one out there or write your own little wrapper on top anyway so once you've done that now we've got our own you know Jason serialization thing we can grab our trip in a notebook we can find ourselves we can export them and now we can just do the same thing that we do in Python and we now have a nice little module exporter that we can use that's cool we have we have a question on the time function how do we know that calling F parentheses is not optimized away in this case because of a lack of side-effects detected by the compiler generally so that's actually a great question in the case of the workbook I don't think there's doing there's no cross workbook optimization going on so that's one thing I don't know if there's a really good right that's a good question what I recommend doing is put something that's not trivial inside the thing your timing and so if you're doing you know we'll show you later launching a CUDA kernel to do a matrix multiplication for example and that's not something that gets optimized to where you can also like get the value into the closure and then take the value back out so there's different things that you can do like that yeah sometimes when I was doing this stuff at base math I would just add a print inside the thing that I was hiding to force it to be calculated and one of the other things that will happen with GPUs is GPUs run asynchronously and so you need to force a GPU sync I'll show you how to do that in a minute in a minute so anyway so coming back to this so we showed you how to build Matt mole we showed you how to build time so this Matt moles working on arrays and this is pretty fast we talked about is point one three seconds but array and Swift is safe and so what's happening is every time you like index into an array it doesn't check to make sure that the index of your computing is in bounds and so this is actually doing a lot of work that you would not need to do if you're in C and so one of the other really cool things about Swift is that you can actually go all the way down to the bare metal and do things the unsafe nasty an awesome C way if you want to get even a little bit more performance and so here I forgot to change us back but we have a couple of arrays and so we have the exact same signature that we did before where we taken two arrays and we have our dimensions and so what we're going to do is and to optimize storing into that result array we're gonna say give me an unsafe mutable buffer or pointer into that array like and it's unsafe it's verbose it's has red warning signs all over because it's unsafe but with almost no code change now we're able to get something that runs twice as fast and so here's Matt Moll and now it runs at point zero seven milliseconds which is even faster which really is performance of C and this is this is pretty cool and something I found with with base math is like sometimes these differences are four or five times faster because making something a pointer allows it to use Cindy vector ization yep so it's like it's it's not a minor tweaks you can get super fast performance but the thing I want to emphasize at this point is that this is this is like a super low level geeky thing that ever not everybody should do right this is something that it exists because it's certain points in your career or your journey you may find that it's useful or you may find something that somebody else wrote and it going twice as fast as otherwise would is a pretty big deal because it makes you twice as productive but usually you're not working at this level like layers are a good thing if you want to go like super deep down the rabbit hole unsafe pointer and unsafe mutable buffer pointer and all these things are also Swift libraries and you can go see their implementations too and those are implemented in terms of the elevat-- just like FLOTUS so at this point d let's skip over more C stuff and jump down to working with tensor so we've got a matrix multiplication working on arrays and floats but we also have tensors and so when we talked about tensor and Matt mole in the PI torch context you started out by using the tensor abstraction as the thing that was the container for the Matt mole so let's talk a little bit about how tensor works because this is the first really soft retentive little piece of this tensor is a type and tensor can have multiple different elements in it like we talked about before you can create one of those zeros or or random numbers and the nice thing about tensors is that they carry a shape just like you'd expect and so you can get it with dot shape so here you can see we have a 5 by 7 84 just like you might expect and here we have a two dimensional tensor and you can print it out and it's a two dimensional tensor just like you would kind of expect python has the at operator to do mat moles of two tensors swift has the same thing but it uses the nice Unicode thing there's a easy way to type this if you're on a Mac or if you're using the compose key on Windows or if you don't like unicode that's also totally cool you can just use the map mole function and just spell it out and so you know this is an example of swift just wanting to work the way you work you want to work and if you like math then you can have math if you want to type things out you can do that too they're both great tensors do all the all the basic stuff you'd expect you can reshape them with the reshape function they support square root and all the other math stuff it all works the way it expect has elementwise operations like add and multiply and square root and POW we have a question from earlier Oh why was it unsafe what you did ah so what we did was we turned off bounds checking and so if I write code that if I have an array of ten numbers and in Swift if I access out the eleventh element it will explode and tell me that that's invalid if you use unsafe then it will let you do that and so whatever happens to be in memory beyond the end of your array you're now poking it and you know you should not do that but you're taking the guardrails off and so this is Swift is trying to be default by default safe and it's trying to help you start check things for you but if you want to you can just rip off all the guardrails and just like we showed you with Python like you can literally do things as dynamic as Python if that's what you'd like but you know that our faults are there to help you out yeah so Python program is a lot of them will be familiar with this idea but in things like C unsafe code is code where you're working with memory that hasn't been initialized or it's been frayed and it's a really big problem if you're using it like in production or something because that kind of thing is how people can like inject shell code into your server and secure dehorner and steal your users and whatever so you know you should I think it's fine and algae but in that book though yeah yeah so so coming back to tensor you know you can add them you can multiply them you can square root like all the normal stuff you'd expect is on tensor tensor else if I run the right so tensors also have a bunch of methods to do cool things like convolutions and other stuff like that that we'll talk about later one of the interesting things about Swift is that it like comparisons to return boolean's and so you'll see that if you compare two tensors it will see if it will give you an ordering of the two tensors but sometimes you want to get a tensor of boolean's back and so Swift calls these the point wise operators and so if you put a dot before the less than or the greater than or the equals or whatever it will do a tensor comparison yeah and I get bent by this all the time in numpy and PI torch that doesn't have this level of consistency so I think that this this design call is awesome this idea that boolean operations always return boolean z' and point wise operations return point wise billions it's good idea and then you have reductions like any and all that say hey if I have a tensor of boolean zai can check to see if they're all said or if any of them are set so basically then I mean the the next part of the notebook is just saying hey look all the stuff that you've seen before is looks exactly the same as what you've seen before sometimes the words changed like unscrews it's called expanding shape at which is rather swiftie way of saying things but there's in a lot of these notebooks you'll find that there's like lots of details where we've just basically copied the Python code and we're not going to show you all those details because they have the same yep now let's talk about Matt mall on tensor so what we've done here is we've defined the same Matt mole that we had before and before we took two arrays and we took two dimensions but tensor carries a shape and so here we implemented Matt mole on tensor I start by creating a zero tensor we loop over at all now we have our two-dimensional indexing just like you saw before with number when you run this what you'll see is this is a lot slower let's take seven seconds to do one Matt mole we're before was taking point through like one seven yeah milliseconds so yeah so so why is that Jeremy why is that well the first thing I want to say is that hopefully at this point you're thinking this is this is a problem because it's kind of like the exact opposite of everything that Chris has been telling us and I've been telling you about why this is good like what's the point is something that's infinitely hackable if there's this tensor flow layer we can't go beneath and that it's so slow that we can't really actually write things that run time in seven seconds for a small matrix multiplication extraordinary so so we would not we would not be running this course if this is where we were heading right this is where we are now and it's a temporary situation that we're fixing and so let me explain what's going on and how it's being fixed right so the first thing to point out is that when you work with high torch we have a similar issue right is like we don't write pi torch triply nested for-loops either right and the reason we don't is that we need pi torch to have a reasonable amount of work to do each time we get it to do something right so we kind of say here's a whole matrix a here's a whole matrix B there it all is multiply them together and then it says here's the whole thing multiplied together and and that's what we do so it's like if pi torch was an aero plane right and we want to send our stuff off to china we pack it all in a bag and we put the bag in the airplane and get sent off to China as opposed to the triply nested for loop version which is where I take a sock and I put it in an airplane and it flies to China and back and then I put in my next suck no flies there and back and it's going to take it that's a fast aeroplane right but it's just not an efficient way to use it okay so so we already have this issue which is you've got to give PI torch enough work to do to make this latency this overhead worthwhile now tensorflow is designed in a very different way to PI torch and for those of you that did the earliest courses with fast AI this will look very familiar right it's actually a really fascinating programming model you say there will be later on a float called X and later on I will want to multiply that float by two now set up a session where we're going to do some stuff and run this computation graph which could have lots of things going on in it and run it in these things right so I basically kind of set up this whole series of computations and then I pass in some data so this is a very different feel to PI torch right and because tensorflow was built this way tends to flow to me does not behave like a plane it behaves like a ship or actually a ship designed for shipping ships or actually a shipping ship design for shipping shipping ships which is this particular one the MV Blue Marlin so if you have a shipping ship shipping ships ship then you need to use it a different way which is if you want to get all of your socks all of the socks in America to China you send them all send all of your ships after all of the ports in America everybody dumps their socks on and they all get sent to China and we're all happy right now to take advantage of this extraordinary power you have to use it in a certain way and you have to have certain things that you need to be able to do so like if your Google and you want to run all the world's search engine queries this makes a hell of a lot of sense now TF eager is the kind of the new hot thing for tensorflow and it's designed to oh it does look like hi torch all right so this is what happens when you say TF dot a table eager execution that's becoming the default in intensive flow you can say here's my number I'm not saying there will be a number later I say this is my number and this is my matrix multiplication right and I can print it the thing about this is though is that this is kind of syntax sugar on top of the ship shipping ship shipping ship ship right or whatever the hell the thing is because we're still using the same a lot of the same kind of foundations and some of it's been optimized but only a bit right so as I say this today as of Twitter April 2019 like 5x5 matrix like a tiny matrix multiply on a GPU with TF eager takes 0.28 milliseconds which is ten times longer than play torture takes right and so we still just have a lot of overhead and so TF eager is is not a solution to writing the kind of low-level get down to the bottom stuff that Chris is saying you can do with Swift yeah but and also neither of GPUs um GP is not going to be fast at a 5x5 right right so I mean it's but it's not you know we want something we want something better yes right so so tensorflow has this big ecosystem of things to try and kind of fill in around this around this this issue of having this huge in kind of mechanism that works in a particular way to make sure that you know you can put it on mobile phones or that you can do it on web servers or whatever right but the good news is that what's happening at the moment and the reason we're seeing the reason we're seeing this speed right is that behind the scenes Swift for tensorflow is you zing TF ager and this is like a great choice because it lets us like do this course it lets us say like here's how you use it we can build things on top of it whilst the real stuff is being built behind the scenes and the real stuff which is to sit on top of this thing called Emily R which Chris can tell us a little bit about which has basically gets all of that compiler goodness that you've seen and allow that to work with the GPU and the CPU and different types of accelerators and let you write Swift right so the reason I mention this is that for probably as long as this course is relevant you know like the next year the the true potential of what we're talking about you kind of won't be able to see it right we're actually building for a future that's not yet here yet this is like a year away but when we get there all the stuff that Chris is showing you I don't we'll be able to write stuff that looks that that could even look like this yeah so if I were a different way to explain it well a year from now it's gonna be mind-blowing like the future you're gonna be able to do stuff you've never even thought that was possible and use these accelerators in ways that are just completely unthinkable unless you're writing low-level CUDA today like there there's certain humans in the world like Scott grey is one of these people who can who can make an accelerator do crazy things that nobody even thought was possible and that's what we're trying to do but in a workbook right and and the reason this matters is that is that there are vast areas of unexplored research territory because I mean most people can't write the CUDA code and even those that can it takes so long and it has so many errors you just don't write yes so so in a year's time we'll be able to do stuff that people just aren't even trying to do yet but one of the cool things about this is you don't have to wait a year so next next lesson will show you the excel a is here today Excel a is super awesome it's a really important part of the tensor flow ecosystem and it's way better than the tour right yeah so we want to like completely jump over the industry and do something that is this mind expanding right but even today a lot of power and Excel a allows you to express and build really cool things with super I perform exactly so Excel a is this really nice kind of intermediate thing where it's much more mature than the PI torch it it's been around for a couple of years you know it's a compiler that will turn your code into stuff that it's kind of similar ish performance to what you might see from play torch it probably a lot less rough edges doesn't generate blobs are C++ yeah try to compile them again yeah yeah it's a it's a principal compiler so it's a really neat path because it allows us to do this course now it allows you to start playing with this now in a couple of months that allows you to get a lot of performance for a lot of things that you might want to play with and and it means that by the time that mo IR comes we'll be all ready to hit the ground running and is there a way to make sure the matte mall or other functions are correctly using shared memory on the GPU for example using tiling to make sure you aren't constantly busting the cache of shared memory on the GPU yeah I've gotta talk about this next week so maybe we could well well so I think that the thing to the thing to know is that this is not something you would write in Swift retentive flow right you would not poke a tenser one float at a time it was just not designed for that and so you can go through all the steps this is very similar the Python workbook but what you end up wanting to write is let's see you just write this where you write something where you take two matrices and you multiply them together or you use the unicode one or the mattemore one it goes fast and it takes point zero two seconds which is faster than the Swift version because it's using the GPU it's properly tile blocked if you run CPU it uses all the threads on your computer and it goes really fast and so the way to think about tensor is that it's meant for these big operations it's not meant for one float at a time and we will say next week some really interesting stuff coming down the line which with yeah and with stuff where you can write kind of tiled algorithms in ways that are much more concise than the triply nested for-loops but much more flexible than the memo yeah Jon sorry another question just came in how do LLVM ml ir in excel a relate to each other would be better explained with slides which we'll go into on the next time I think but LVM the simple way to explain it is that it is really good at CPUs that's a little bit of an oversimplification because we do use it for some GPU stuff but LVM really helps you with the one float at a time kind of a thing if you're going to a simpler processor excellet is really good at tensors and so it's a tensor compiler and so it's really good at saying I have these big tensor operations I have convolutions to get maximum performance out of a CPU or GPU or a TPU for example you have to know about tiling you have to know about fusion you have to know about a lot of these low-level systems things before you then hand it off to LLVM that does the low-level stuff and so excellet talks to OEM for GPUs for example or and for CPUs and there's the way to think about is excellet does all the tensor stuff and LVM does all the float and small vector stuff MLR is like excellet in a certain way but it's tackling graph level optimizations and tensor flow and and kind of expanding excellet beyond just dense linear algebra because there's a lot of interesting sparse things and other things that are coming down the pipeline that are really exciting hmm so yes I mean basically I mean we won't look at the rest of this notebook other than to say that the broadcasting stuff that we saw is is all here so you can kind of see how that all looks at the moment if you can run apps on the CPU or the GPU I mean all that stuff is all here and it's don't worry about the performance it's really slow at the moment for the reason we mentioned but it totally won't be and you can also see matrix multiplications at different sizes and how to add a tickets timing and so forth so did you want to go to roar no well do you want to do this would you want to go to 11 do we have time now we have time to do this now okay it's a 10-minute five minutes okay cool so one of the really cool things about the stack is that tensorflow is a really mature ecosystem it has hundreds of different operators available available there's pros and cons of this so tense flow kind of grew organically over time a little bit and so it has a lot of things in its toolbox what Swift for tests does it tries to curate that and has tensor and the way tensor works is it's the struct and the struct is implemented in terms of those low level tensor operations and so if you look inside tensor and here there's a link so you can go click on it and see the implementation tensor has this thing called tensor handle that is under the covers basically the tensor flow low-level thing the Iger mode uses and if you look at plus what plus does on two tensors is it calls this raw add operation and the way that this works is this is just directly talking to the add op in tensor flow and the add op is implement with ku DNN or it's implemented with excel a or simple in different ways for different pieces of hardware but this is just a simple syntactic sugar thing where we're saying hey plus turns into tenths flow ad now again since well has tons of cool stuff and it has stuff that I barely understand with lots of math you things and triangular Lu decomposition all things and like Bayesian propagation of things that I we have an excellent course about trying to let decomposition if you awesome right I'm gonna try to survive next week and then I'll take it the N so we haven't curated all of the things that are potentially interesting and so what you can do is you can actually add new things to tensor and so one example of that right here is so you can get like zeros like if you go into here and see if this is so with with tab-completion you can see all of the all of the interesting things add many sparse to tensor map add and adjust contrast a sign like it's got lots and lots and lots and lots and lots and lots and lots and lots of lots of and this is just a cool particularly if you're watching this between like about April and about September like in the proton the period where maybe the excel a staff isn't as fully fleshed out this is you probably care about this because there's lots and lots and lots and lots and lots and lots and we haven't necessarily surfaced yet so for example today was saying how do I can switch from RGB to BG our format and somebody said oh there's something in tensor flow called reversed and so here's the answer or dot reversed and so one is knowing about this yeah and so one of the things we'll use 4x resna and other image models in this course is hey we need to be able to load a file and you can do that with Python that's fine tensile has great stuff for doing this and so here we just use raw read file and so all we're doing is we're adding a method to string tensor and we're saying hey if you want to create a string tensor from a file we can have read tensor we can we can just use read file and now I can say string give me a string tensor read file foo and I added a decode JPEG method on here too so now I can say decode JPEG JPEG and I got my file right and so this is one of the cool things about this platform is that tentacle has all this functionality we're not trying to hide it we're just trying to cure it a little bit but again you can just go add whatever you need yeah so one of the people is a study group today was building a audio library with Swift or tensorflow and we haven't served it surfaced any of that so they were grabbing a you know raw dot d code where for something and yep they had it all up and running yeah and it's super cool and again so it gives you nice ways to build these things as API is default arguments and all this nice stuff and so you get a lot of design space to do things that work the wave like um war cool so the way we're gonna do this is we've kind of gone like super super bottom-up I must admit I thought we had done bottom up before but this is another level of bottom-up then he brought a compiler yeah yeah you know it's always good at making me feel small and insignificant and so but now let's jump back up to the top again to see where we're going to end up and then next week we're going to kind of flesh out all the stuff between the middle right so I'm going to jump to notebook 11 and notebook 11 is interesting because this is the one where we train an X ResNet on imagenet all right so this is where we're heading so so every time we import the previous notebook just like we do in Python the previous notebooks however aren't just numbered but they also have the name that's the only difference and then this is this the equivalent of percent matplotlib in line in in this environment so here load data we've will show you how we built something that downloads imaginet but it basically looks almost exactly like the very similar to the download emulous thing you've already seen and we've created an item list which has extensions and we've created a split data which takes an item list now one of the nice things here is that we don't really need something like funk tools partial in Swift because now we can just pass in a trailing closure which has Chris described if the last thing is is in the last parameter is a closure then you can just whack it in curly brackets you don't even need a return or anything and you don't even have to give it an argument name because you can use the default ones so we're saying split this item list by grandparent this is the file name that you're going to get this is basically like the equivalent of doing partial right and it's going to be some different validation set and so now we can create our labeled data and we need a processor so we have again a category processor so you can see we've got a whole data blocks API here one of the things that I guess you're going to talk about next week chris is and and mutation and stuff yeah okay so so basically in in Swift as Chris mentioned most of the time we use struts and as Chris will describe to you structured things that normally don't change but you can create something that kind of feels a lot like a C++ reference or a C pointer but it's much cooler by adding an episode because remember processes actually change their state because we get like a vocabulary for example the first time we use a processor on the training set so now we've got a split label data set and then we've added a to date a bunch and we can pass in all the normal stuff including a batch size so next thing we can do is we can do transformations and again here we can use a trailing closure to basically do a partial to say that we're going to do resize in their transformations so then we'll grab a batch something that I think Chris will probably talk about next week more is this thing but basically in Swift very often you want to be able to say hey this is going to return either a batch of data or maybe it we're going to return nothing at all right which in Python we use the optional type for that that is called the same thing in Swift right and no none yes so so if basically what happens is if you if you have something that might not return anything so one batch might not return anything because there might be nothing to return it can return nothing and then exclamation mark just says assume that it's something okay so we can look at the shapes of that batch and look we've even got show batch so it's it's it's it's been really fun this process of you know in the last couple of weeks of basically saying what does fast AI look like on on Swift and one thing I'll say is like a lot of these notebooks have been written by by silver in particular and by me a little bit and we don't know Swift at all well so any good Swift program is looking through those notebooks thinking oh this is nice but it'd be even more swifty if you did blah please let us know in the forum because we're super interested to learn how to write better Swift and I've been super interested to learn all the amount that's been great I mean it's it's it's you know and since it's a good sign that you're learning fast AI for Swift from the people who start at the first AI in scripture projects but on another sense I know nothing about Swift and Chris doesn't know much about deep learning so maybe it's the worst of all possible worlds I don't know no I think this we're all learning together yeah so anyway yeah it's been super fun and so as you can see we've got a data blocks API that's now working the other thing I mentioned as you'll see next week is the way we've got this working is it's using a tensorflow API called TF data which is actually a lot better than a lot of data API s but it's still not nearly as good as I would like and I would love to as a community start building out the the next version that uses like Swift's Lib dispatch to do the threading and maybe open CV to do the transformations and stuff like that like we can build I think a data blocks something like the Python data blocks API but that is like native it's not talking to anything else yep anyway so now we've got batches of data we can train a model as soon as we have one so let's create a X ResNet model and as you've already seen in the slides it ends up looking very very familiar so here's our con flyer just one thing to mention at the moment and this will probably only be true for a couple more weeks there are kind of two versions of all the layers there's the versions in the FASTA a repo which all start with FA and there are versions from the Swift repo that don't so just ignore these FAS so a cone flower has a batch norm and it has a convolution another thing that's slightly awkward at the moment is that we so you'll see in right now some of our code looks weird because auto diff in Swift doesn't support flow control so if or Follett's that'll change soon enough right so when you see something like no bias convolution that's because we can't write a convolution layer that has an if statement saying if you if the person Tobias use it otherwise don't write so this don't worry too much about those workarounds either they'll go away soon enough so we've got a batch normally we've got a comp layer and we can go through them and the 0 BN is the stuff that you're used to and as Chris said under call is built without the dunder but otherwise everything looks the same as usual because we don't have the ability right now this will change soon to use if in differentiable tip code that needs to be differentiated we've basically added something called a switchable layer which is something you can turn on or off so the details don't matter Chris will describe next week however how we actually wrote our own kind of custom gradients for this kind of layer and that'll be fun to learn about so then we used that to basically have something where because remember an X ResNet in the identity path it's not always an identity path sometimes you downsampling that path sometimes you change the number of channels in that path if you downsample then you maybe add an average called hoody so because again we don't have the ability to have if we just use this switchable layer and maybe you change the number of channels by adding a 1x1 con that's all that is so most of this stuff if you're watching this you know much lighter than in kind of July or something so probably all have gone away and been replaced by some if statements but you know once we've got all that the res block is there's really nothing to mention is there I mean it's it's basically identical if you look back at the version in 11 on in the Python versions and kind of switch between them you almost need like a strobe light thing to see that they're different like it's it's the same layers equals coneflower way as you can come to equal scrambler to know why we change the name got this ternary here this question mark and colon is identical to if and else as an operator in Python comes from C and then yeah and then finally in the call that and that look exactly the same pure selves yeah thank heavens thank you make layer looks basically the same this is the make layer we had before this is the make layer we have now and so it's interesting to see how some Swift things kind of coming up quite neatly right so this use of map so this is generating this is the same as range and blocks in place on so this is basically saying map range and blocks and then passing in this closure which generates the res block right so I think it's kind of I don't know I find it more clear the Swift way but very very similar and the idea of socialists to have simpler primitives that compose yeah having selectional cases for the important things yeah so now we've got all that the the X ResNet looks very similar to what we would expect we've still got our number of filters thing going on the stem so now we've got that array map thing you kind of get a start to get a feel for these kind of idioms in Swift so kind of range dot map is a useful kind of idiom to be aware of you can also use a for loop you can say for or I and 0.3 that's also fine too mmm just depends on how you wanna write the code there's an enumerator but rather than enumerate brackets something it's not enumerated but it works the same way when you map to what you get back an index and an object just like in Python so very familiar so in this case because we've gone dot map and then dot reduce with plus on a list this is a list comprehension now right because this is spitting out a bunch of lists that we're joining all together so those special cases there this is one of those case is where you're asking for the last element of a list list could be empty so there might be nothing in it so exclamation marks says just assume that there is something there and we've written a little compose so we can compose this list of layers on our input so again we've got that of similar similar concepts expressed in similar ways so we can now put all that together and we've got our all our different resinates so now we create the various functions that we need to pass in to our murder so one is a function that's going to create the model so it's going to be something that creates an x ResNet and that's the function that it's going to create a model we're going to have a function that creates our optimizer which as you'll see we have a stateful optimizer just like we had in python we have a learner just like we had in python and it has very very similar yeah book to it and again next time we'll talk about how all these are built and so atom optimizer of course is just a thing that's hackable yep you can change it exactly we have recorder callbacks just like we're familiar with we have one cycle training just like we're familiar with this add one cycle delegates and make default delegates is probably going to go away pretty soon and we'll have some slightly neater ways to do this so by the time you see this notebook this might have changed a bit and then we train it with a resonant 18 for a few minutes and we're at point eight one a couple of things to mention as I go through this end of a crawl right now this uses about twice as much memory as play torch and it's about three to four times slower than pi torch no fundamental reason why did this need to be the case is just we've just started and so the fact that within it's not bad for three weeks it's not bad for three weeks I mean and all that will come nothing and all the guy at work that you guys did to build the auto different the first nights ago didn't it really didn't work yes so it's pretty cool that we're at a point where we can actually train proper models like this from scratch in like not to slow and not to memory-intensive and if you're interested in kind of getting into the weeds we would certainly love help with fixing the performance and fixing the amount of memory so that's a there's a related question what would be the best way to contribute to this with four tensorflow ecosystem is someone who's now using swift for the first time yeah that's that's a great question so the the best place to go is github.com slash tensorflow slash swift that's our landing page there's also a buncha toriel's there it explains how to get and build things one of the things that we're doing is we're building everything in the open and so we do our development in the open we use github we have our discussions on a mailing list so you'll find linked out for a github page and so we try to have a really inclusive and welcoming community and there's a ton of resources available and a lot to do yeah and I would that's one way to do it I would like to suggest another way which is to come to the hairbrained forum your faster your forums because I think for a lot of people the right way the best way to contribute the way that you'll get the most out of them it'll be most relevant to you right now is to pick something that you've already been using in Python and doesn't exist yet and create the Swift version and you may think you have no idea how to do that and perhaps you don't but like create a really crappy slimmed-down Swift version and build from there that's hell that's the only way any of this stuff gets done asked for help on the forum offer help to others and so I like pick picks more bit so I'll find some piece that hasn't been documented yet we haven't really figured out yet where to put things yeah we're fast day.i lives and we're Swift for tensorflow lives and we're different repos will be but you know in the end between the you know fast AI and swift potential flow repos there'll be a kind of an ecosystem that covers the same kind of ground that pi torch plus fast AI covers and has just as much room for you to well much more room actually for you to build things on top of that because you've got like the entirety of scikit-learn and that plot live and pandas and all this stuff to it as another thing is if you go on the feci a you'll see these workbooks and we skipped from 1 to 11 and so next time we'll go back through and talk about 2 & 3 & 4 & 5 like but but these are all there for you now and so if you'd like to look you can go do that and they'll get a little bit better by next week I bet yeah and one thing to mention is where else with the normal fast AI notebooks we we nearly freeze them once we do the course we we just fix errors and that's about it these notebooks is going to be very different we're going to keep them very very up to date so but only by the time you watch this they may look very different because we want to always have for you showing you like this is how we suggest you write Swift or tensorflow code now and even over the last week we've been if you look at the github history you'll see we've been discovering new things like differentiable arrays and such a bowl ayres and it allows us to delete lots of previous work arounds and the next weeks and the next couple months will be similar to do it more question drawer all right is swift thread safe yes Swift is well thread safe and has a really great threading abstraction called dispatch and so you can fire up lots of concurrent work items set up work work work queues has a really vibrant and good API for doing that with quality of service and like all these all these advanced things that are available there yeah I've never used such a nice kind of reading that's it's like it's a framework it feels more like more than just a language so like on the Apple side they call it Grand Central Dispatch no but they pour that the whole thing over to Linux yep and you have this whole kind of threading library framework which is super easy to use and extensible and this is one one of the reasons the swift on server community really like Swift is that it's efficient yes but they're also supports threading and other things really well and very naturally well are there any scikit-learn for Swift projects and the works I have no idea there should be yeah I haven't seen anything much I have a random forest implementation I would love to convert over to Swift which is a pretty nice one but we'd definitely be nice if you could build a gradient boosting machine or even simple things like K nearest neighbors and stuff like that I think that um I think though that the opportunity here is to go beyond just reinventing what's already there like psychic learn is called that it exists but it's it could be a lot better particularly in Swift so if you do decide I want to build bits of SK learn or bits of pandas you know jump on the forum and talk to us about about it and let's try and build something that's vastly better than what's been before not just a copy of it I wouldn't suggest that being a starter project like if you want to start a project pick one of the one of the lessons and the one through seven class and implements some of those algorithms I think in terms of this framework I think that'd be a really great place to start but as you get more experienced and you get more familiar with then tackling something like building a big library it can be a lot of fun is there any plan to build tensor shapes into the Swift type system so we have a tensor shape type it's a struct literally right now and that's what when you when you pass in shapes to create a tensor of zeros you get that I think what they're probably asking is will we get dimensions in the types or will we get names in the dimensions so this is something we're super interested in we think there's a lot of opportunities there both in terms of like shape checking for example the whole stack we're building with the compiler integration and the good air the locations and stuff like that we think there's a ton of potential we haven't tapped into that yet the names on dimensions is tricky and there's lots of space and we haven't exactly figured out how the best way to do that is because there's trade-offs but that's exactly all the kind of like second step things we want to do probably starting this fall ish when the basic Auto diff base performance like scale out and a bunch of other things are all settled and we feel good about all those basics I'm gonna try to stay focused on making sure that things are really good and build the basics and get them right and then move out any more questions no I mean that's fine we're good and how is ampersand referencing different from struct oh well talk more about that next time so Swift has a this comes back to safety in the language Swift has a completely different approach to references like classes and Struck's and values and so I'm gonna save that mind-blowing piece for next time it's really cool it is it underlies a ton of I mean it it's a very foundational thing that makes a lot of stuff possible and how a swift for probabilistic programming whoo so I this is one of the areas I'm both completely incapable of talking intelligently about but also very excited about because this is one of those things that I think is really underutilized one of the things that I think is really interesting about Swift as a platform for machine learning is that you often so with Python you end up in this weird situation where you build a machine learning model and then you have an application that you eventually want to use it in and these are two different things training your model and deploying your model are different worlds and we can start started raising some those boundaries because so if can be put in a mobile app believe it or not we're putting the server button other things you're actually deploying and probabilistic programming and many of these other applications I think would be great to build and integrate with the application so I think the answer is it'll be a great fit there's there's I haven't seen anything here yet but basically with things like probabilistic programming or things like kind of graph based systems they're not a great fit for PI torch and that's not a controversial thing to say because so mithran Chola who created fly torch said that on Twitter himself last week you said if you want to do this kind of work at the moment you might want to look at julia which is another great option for this kind of programming because what happens is you you have these kind of deep connections you know computational graphs of lots of things crawling lots of other things and so you need and they're often kind of small so you need those things to happen super quickly so things like julier and swift work really well for that kind of thing particularly when you kind of had all the threading stuff on top as well so if you're interested in that area that would certainly be one that I think you could start getting into straight away like one of the nice things about that is you can do a lot on the CPU like a lot of these girls don't even make sense on the GPU so you can probably you know take advantage of it right now and for that actually we'll add it to the forum post but I actually have a post already about how to access a variety of random number distributions from Swift C++ ran a number distributions so you can actually get started with this right away yeah yeah also the tenth folio system has a big mature framework called tense flow probability and so I personally don't know very much about it but I expect that all the atoms you need are all there and we just need somebody who knows the space really well to build a Swift library that can can expose all the primitives that intz Laurie has and how could you deploy Swift models on Android well so I think there's two options you have there so one is Swift again builds on the entire tensor flow ecosystem and so tense flow ecosystem includes graphs and graphs are part of what Swift talks to so you can explore the graph you can send it through TF light and so the whole mobile deployment situation there works I feel like that's kind of the model we're trying to get away from a little bit certainly so the other option is like Swift actually runs violent Android people ship Android app straight and Swift so you can do that too Swift on Android isn't really awesome as far as I know I'm not exactly an Android programmer I don't really know that but the issue there is that Android you have a dual world between the Java stuff and the native stuff and so Swift fits into the native stuff is my understanding but I know the people are building and shipping Android apps right and Swift and so that's a totally reasonable thing to do the other thing to mention in terms of platforms is that Swift on Windows is starting to come together as well so I don't know where it'll be by the time you're watching this at home that Swift is definitely making its way to do worlds outside the iOS world pretty rapidly and Windows is one of them yeah it's super exciting any people writing what's the windows MBC mmm FC NFC absence swift which is brain twisting to me so what we're going to close with now is a little taste of where we're heading next week and this is actually something that Rachel shows in her computational linear algebra course and it comes from a really amazing programming language called halide and how it is is one of these like dramatic steps in terms of like completely rethinking how we program computers and I want to show it to you because it gives you a sense of the kinds of problems that Swift has to solve in order to like that the goal here is to be able to get the goal here is to be able to get this performance because remember that the C speed triply nested for loop was 0.07 but tensorflow is point-o true right how do we get this level of performance but you being able to write it yourself in Swift now here's why it's hard right and so this video actually comes from the halide project which is a programming language that has kind of invented an amazing way to think about this and so I'm going to use it to describe the problems that we're going to solve so in order to write something fast we have to think about how everything is going to get put together and so the algorithm we're going to write here that they wrote in this halide video is one where they're doing a simple blur a 3x3 blur right so we take each group of three by three pixels and we take their average that's how you do a three by three blur now how what are some of the things we could do right so how and what order for example do i compute the values in my 3x3 blur and one way is just go through each x12 time and then within that go through each y one at a time that would be one choice a second choice I could make would be to do the exact opposite which is to go through each column one at a time now these aren't going to have very different characteristics maybe the latter might be a bit slower because we're jumping further through memory but what we could do is we could do something called vectorization and vectorization is super important because what happens with vectorization is we actually take four or sometimes even eight numbers at a time and throw them all at the CPU or GPU at once and say calculate them all together and so we have these things called vector units in our computers nowadays it can do that you can even have multiple vectorize things happening at the same time because you have multiple cause that in fact in the GPUs is what happens all the time or in order to think about kind of better memory access we could kind of do a little block at a time like this so there's like lots of choices about how I compute my values that are going to change the performance characteristics of my in this case a blur another question is when should I compute my inputs so here's my input and see how it's going through three at a time right so because I'm doing I'm trying to calculate three at a time and that gives me my blood in X now I have to go through all of those three at a time and so you can see this is super slow it's recalculating things again and again and it's not able to really use the cache well instead I could do a whole set of nine at a time and that would then allow me to create a whole blood output at a time or I could go through it like this exactly like before but actually save what I had before and that means when I then do the next row I don't need to recompute because it's already there okay just add a clarification that the left the left panels input the middle is the intermediate values and the right is the final output thank you we could vectorize that so we can do vectorized input and then vectorized on the intermediate values and then calculate those to create our vectorized output with parallel processing here's another way that we could combine vectorization and parallel processing there's all these things you can do and you can see they're going to have very different performance characteristics Dick's right so it halide they have this neat idea which is hey let's not write nested nested nested for-loops and tiles and looping through the memory like that let's instead describe for each value X comma Y in my blurred output here is how it's calculated in this kind of declarative way right this is like literally the definition of a blur algorithm and so you first do that and then after you've done that you can then say to halide what are different schedules for calculating that so how what's the kind of order in which things are done and for these different schedules that are written here they have all the different behaviors you just saw all right now here's the thing right when expert cuda programmers and expert cpu programmers write code to do things like this they're using the world's best knowledge available across all of those things to create special versions for every architecture for every difficult not every but lots of different matrix sizes tensors of different numbers of dimensions so much assembly code right and so we can't write that right so how are we going to be able to write the stuff that's in our head but have it right but have it run reasonably quickly and so what what we're moving towards with stuff like mo ir is the ability to have kind of have like the main specific languages where you could write like his the tiling domain-specific language and here's the you know and and the for example halide directly for example halide directly right and so that that's the hope of where we're going to be going here is is that Chris's team is going to be putting these kinds of tools in your hands by a swift yeah is that a reasonable summary well and so one of the bad things about Helen so in this space we have tensorflow today tensorflow today we have Excel a excel a is an important part dense flow right now it's just not really wired into the Swift part of tintin flow yet excellet does all this stuff right now and Axl is really good because you don't have to hand tune it like that whole writing out schedules excellet does a good job of using the hardware as it is today the thing we're going further with mor is to say well instead of you having to put all this blood sweat and tears into tuna and know the hardware and do all this stuff we can do other things like search and in fact there are research systems available now which will use genetic algorithms to auto search for there an optimal schedule so you're starting to see the kind of the ideas that come out of the database query optimizer world coming into the CUDA kernel world and like this is gonna be so great for us in the sentences exactly search can be influence of different ways brute force reinforcement learning like lots of different genetic algorithms there's lots of cool things that can be done here and so what we're going to do over time is crack open the compiler and make the internal algorithms all learned and I think that's going to be super cool so this is why you have a compiler guy and a DL guy standing next to each other right because it we like each other it's yeah you're okay wait because we're not gonna get this kind of great outcome unless people like us are working together with amazing teams like the folks that they have in tensorflow and X LA and so forth so next week come back and we will dig even deeper thank you very much Chris [Applause]w