{
  "00:00": "okay so welcome practical deep learning",
  "00:07": "for coders less than one it's kind of",
  "00:10": "lesson two because there's a lesson zero",
  "00:13": "in less than zero is is why do you need",
  "00:15": "a GPU and how do you get it set up so if",
  "00:17": "you haven't got the GPU running yet then",
  "00:21": "go back and do that make sure that you",
  "00:24": "can access a jupiter notebook and and",
  "00:28": "then you're ready to start the real",
  "00:30": "lesson one so if you're ready you will",
  "00:33": "be able to see something like this and",
  "00:37": "in particular hopefully you have gone to",
  "00:40": "notebook tutorial it's at the top that's",
  "00:42": "right with zero zero here as this grows",
  "00:44": "you'll see more and more files but will",
  "00:46": "keep a notebook tutorial at the top and",
  "00:48": "you will have used your jupiter notebook",
  "00:52": "to add one and one together getting the",
  "00:55": "expected result bigger and hopefully",
  "01:04": "you've learned these four keyboard",
  "01:05": "shortcuts so the basic idea is that your",
  "01:11": "jupiter notebook has pros in it it can",
  "01:16": "have pictures you know it can have",
  "01:20": "charts in it and most importantly it can",
  "01:24": "have code in it okay so the code is in",
  "01:29": "python how many people have used Python",
  "01:32": "before so nearly all of you that's great",
  "01:36": "um if you haven't used Python that's",
  "01:39": "totally okay okay it's a pretty easy",
  "01:42": "language to pick up but if you haven't",
  "01:44": "used Python this will feel a little bit",
  "01:47": "more intimidating because the code that",
  "01:49": "you're seeing will be unfamiliar to you",
  "01:51": "yes Rachel oh yeah no because I'm trying",
  "02:00": "to keep them up separate yeah yeah okay",
  "02:02": "we're not the way here so as I say there",
  "02:06": "are things like this where people in the",
  "02:09": "room in person",
  "02:10": "and this is one of those bits just like",
  "02:12": "this is really for the book audience not",
  "02:14": "for you that's I think this will be the",
  "02:17": "only time like this in the in the lesson",
  "02:19": "where we've assumed you've got this set",
  "02:21": "up thanks to a mother okay",
  "02:25": "all right so yeah this is you're in the",
  "02:28": "room or on foreign faster you're alive",
  "02:30": "you can go back after this and make sure",
  "02:32": "that you can get this running using the",
  "02:34": "information in course III go faster do",
  "02:40": "okay okay okay so a Jupiter notebook is",
  "02:49": "a really interesting device for our data",
  "02:55": "scientists because it kind of lets you",
  "02:57": "run interactive experiments and it lets",
  "03:01": "us give you not just a static piece of",
  "03:05": "information but it let it lets ask you",
  "03:07": "something that you can actually",
  "03:10": "interactively experiment with so let me",
  "03:15": "explain how we think works well to use",
  "03:19": "these notebooks and to use this material",
  "03:21": "and this is based on the kind of last",
  "03:23": "three years of experience we've had with",
  "03:24": "the students who have gone through this",
  "03:26": "course first of all it works pretty well",
  "03:31": "just to watch a lesson end to end okay",
  "03:35": "don't try and follow along because it's",
  "03:38": "not really designed to go to speed where",
  "03:40": "you can follow along it's designed to be",
  "03:41": "something where you just take in the",
  "03:43": "information you get a general sense of",
  "03:45": "all of the pieces how it all fits",
  "03:46": "together right and then you can do it",
  "03:49": "back and go through it more slowly",
  "03:52": "pausing on in the video and trying",
  "03:56": "things out making sure that you can do",
  "03:58": "the things that I'm doing and that you",
  "04:02": "can try and extend them to do it things",
  "04:04": "in your own way okay so don't worry if",
  "04:07": "things are zipping along faster then you",
  "04:11": "can do them that's normal and also don't",
  "04:13": "try and stop and understand everything",
  "04:15": "the first time if you do understand",
  "04:18": "everything the first time good for you",
  "04:21": "but most people don't particularly as",
  "04:23": "the lessons go on they get faster and",
  "04:25": "they get more difficult okay so at this",
  "04:31": "point we've got our notebooks going",
  "04:33": "we're ready to start doing deep learning",
  "04:35": "and so the main thing that hopefully",
  "04:38": "you're going to agree at the end of this",
  "04:39": "is that you can do deep learning",
  "04:42": "regardless of who you are now I don't",
  "04:45": "just mean do we mean do at a very high",
  "04:47": "level",
  "04:48": "I mean world-class practitioner level",
  "04:50": "deep learning okay so your main place to",
  "04:56": "be looking for things is course b3 to",
  "04:58": "fast",
  "04:59": "AI where you can find out how to get a",
  "05:03": "GPU other information and you can also",
  "05:07": "access our forums you can also access",
  "05:12": "our forums and on our forums you'll find",
  "05:14": "things like how do you build a deep",
  "05:21": "learning box yourself and that's",
  "05:22": "something that you can do after you",
  "05:23": "don't later on once you've kind of got",
  "05:25": "going Who am I so why should you listen",
  "05:31": "to me well maybe you shouldn't but I'll",
  "05:34": "try and justify why you should listen to",
  "05:36": "me I've been doing stuff with machine",
  "05:40": "learning for over 25 years I started out",
  "05:43": "in management consulting where actually",
  "05:45": "initially I was I think Mackenzie and",
  "05:47": "company's first analytical specialist",
  "05:49": "and went into a general consulting ran",
  "05:52": "number of startups for a long time",
  "05:53": "eventually became the president of",
  "05:56": "cattle but actually the thing I'm",
  "05:58": "probably most proud of in my life is",
  "06:00": "that I got to be the number one ranked",
  "06:02": "contestant in travel competitions",
  "06:04": "globally so I think that's a good fact",
  "06:10": "to call why can you actually train a",
  "06:11": "predictive model that predicts things",
  "06:12": "pretty important aspect of data science",
  "06:16": "I didn't found a company called analytic",
  "06:18": "which was the first kind of medical deep",
  "06:21": "learning company nowadays I'm on the",
  "06:25": "faculty at University of San Francisco",
  "06:26": "and also co-founder with Rachel of fast",
  "06:30": "AI so I",
  "06:32": "used machine learning throughout that",
  "06:36": "time and I guess I'm not really although",
  "06:38": "I am at usf for the University",
  "06:40": "I'm not really an academic type I'm much",
  "06:42": "more interested in in using this tool to",
  "06:45": "do useful things specifically through",
  "06:49": "fast AI we are trying to help people use",
  "06:52": "deep learning to do useful things",
  "06:54": "through creating software to make deep",
  "06:58": "learning easier to use at a very high",
  "07:00": "level through education such as the",
  "07:02": "thing you are watching now through",
  "07:04": "research which is where we spend a very",
  "07:06": "large amount of our time which is",
  "07:07": "researching to figure out how can you",
  "07:10": "make deep learning easier to use at a",
  "07:12": "very high level which ends up in as",
  "07:14": "you'll see in the software and the",
  "07:15": "education and by helping to build a",
  "07:17": "community which has made me through the",
  "07:19": "forums so that practitioners can find",
  "07:22": "each other and work together so that's",
  "07:24": "what we're doing so this lesson",
  "07:27": "practical deep learning for coders is",
  "07:29": "kind of the starting point in this",
  "07:30": "journey it contains seven lessons each",
  "07:33": "one's about two hours long we're then",
  "07:36": "expecting you to do about eight to ten",
  "07:37": "hours of homework during the week so",
  "07:40": "it'll end up being something around 70",
  "07:42": "or 80 hours of work I will say there is",
  "07:46": "a lot as to how much people put into",
  "07:47": "this I know a lot of people who work",
  "07:50": "full time on fast AI some folks whose do",
  "07:54": "the two parts can spend a whole year",
  "07:56": "doing it really intensively I know some",
  "07:59": "folks watch the videos on double-speed",
  "08:01": "and never do any homework and come at",
  "08:03": "the end of it with you know a general",
  "08:04": "sense of what's going on so there's lots",
  "08:06": "of different ways you can do this but if",
  "08:08": "you follow along with this kind of ten",
  "08:10": "hours a week or so approach for the",
  "08:12": "seven weeks by the end you will be able",
  "08:15": "to build an image classification model",
  "08:17": "on pictures that you choose that will",
  "08:20": "work at a world class level you'll be",
  "08:22": "able to classify text again using",
  "08:26": "whatever datasets you're interested in",
  "08:28": "you'll be able to make predictions of",
  "08:30": "kind of commercial applications like",
  "08:32": "sales you'll be able to build",
  "08:34": "recommendation systems such as the one",
  "08:37": "used by Netflix not Tory examples of any",
  "08:40": "of these but actually things that can",
  "08:42": "come top ten and capital competitions",
  "08:45": "that",
  "08:45": "be everything that's in the academic",
  "08:47": "community very very high-level versions",
  "08:49": "of these things so that might surprise",
  "08:51": "you that's slightly over the the",
  "08:53": "prerequisite here is literally one year",
  "08:57": "of coding and high school math but we",
  "09:00": "have thousands of students now who have",
  "09:02": "done this and shown it to be true you",
  "09:06": "will probably hear a lot of naysayers",
  "09:08": "less now than a couple of years ago than",
  "09:11": "we started but a lot of naysayers",
  "09:12": "telling you that you can't do it or that",
  "09:15": "you shouldn't be doing it or the deep",
  "09:17": "learnings got all these problems it's",
  "09:19": "not perfect but these are all things",
  "09:21": "that people claim about deep learning",
  "09:24": "which are either pointless or untrue",
  "09:27": "it's not a black box as you'll see it's",
  "09:30": "really great for interpretive",
  "09:32": "interpreting what's going on it does not",
  "09:35": "need much data for most practical",
  "09:37": "applications you certainly don't need a",
  "09:39": "PhD rate from house one so it doesn't",
  "09:42": "actually stop you from doing deep",
  "09:43": "learning if you have a PhD I certainly",
  "09:45": "don't I have a philosophy degree and",
  "09:47": "nothing else it can be used very widely",
  "09:50": "for lots of different applications not",
  "09:52": "just for vision which is where it's most",
  "09:54": "well-known you don't need lots of",
  "09:57": "hardware you know that thirty-six cent",
  "09:59": "and our server is more than enough to",
  "10:01": "get world-class results for most",
  "10:03": "problems it's true that maybe this is",
  "10:07": "not going to help you to build a",
  "10:08": "sentient brain but that's not our focus",
  "10:11": "okay so for all the people who say deep",
  "10:14": "learning is not interesting because it's",
  "10:15": "not really AI not really a conversation",
  "10:18": "that I'm interested in we're focused on",
  "10:20": "solving interesting real-world problems",
  "10:24": "what are you going to be able to do by",
  "10:26": "the end of lesson one well this was an",
  "10:28": "example from Nikhil who's actually in",
  "10:29": "the audience now cuz he was in last",
  "10:31": "year's course as well this is an example",
  "10:35": "of something he did which is he",
  "10:36": "downloaded 30 images of people playing",
  "10:39": "cricket and people playing baseball and",
  "10:41": "around the coach will see you today and",
  "10:43": "build a nearly perfect classifier of",
  "10:46": "riches which so this kind of its kind of",
  "10:49": "stuff that you can build with some fun",
  "10:51": "hobby examples like this or you can try",
  "10:53": "stuff as we'll see in the workplace that",
  "10:56": "could be of direct commercial value so",
  "10:59": "this is the idea",
  "10:59": "we're going to get to by the end of",
  "11:00": "lesson one we're going to start by",
  "11:05": "looking at code which is very different",
  "11:08": "to many of the academic courses so for",
  "11:12": "those of you who haven't kind of an",
  "11:13": "engineering or math or computer science",
  "11:15": "background this is very different to the",
  "11:16": "approach where you start with lots and",
  "11:18": "lots of theory and then eventually you",
  "11:21": "get to a postgraduate degree and you're",
  "11:22": "finally at the point where you can build",
  "11:23": "something useful we're gonna learn to",
  "11:25": "build the useful thing today okay now",
  "11:28": "that means that at the end of the day",
  "11:29": "you want level of a theory okay there",
  "11:32": "will be lots of aspects of what we do",
  "11:34": "that you don't know why or how it works",
  "11:36": "that's okay",
  "11:38": "you will learn why and how it works over",
  "11:41": "the next seven weeks but for now we've",
  "11:45": "found that what works really well is to",
  "11:47": "actually get your hands dirty",
  "11:48": "coding not focusing on theory because",
  "11:53": "there's still a lot of Addison ship in",
  "11:56": "deep learning unfortunately it's still a",
  "11:59": "situation where people who are good",
  "12:01": "practitioners have a really good feel",
  "12:04": "for how to work with code and how to",
  "12:07": "work with the data and you can only get",
  "12:08": "that through experience and so the best",
  "12:11": "way to get that that that feel of how to",
  "12:13": "get good models is to create lots of",
  "12:16": "models through lots of coding and study",
  "12:19": "them carefully and it's Jupiter notebook",
  "12:21": "provides a really great way to study",
  "12:23": "them so let's try that let's try getting",
  "12:28": "started",
  "12:28": "that's so to get started you will open",
  "12:30": "your Jupiter notebook and you'll click",
  "12:35": "on lesson 1 lesson 1 yes and it will pop",
  "12:39": "open looking something like this and so",
  "12:41": "here it is so you can run a sail and a",
  "12:47": "Jupiter notebook by clicking on it and",
  "12:48": "pressing run but if you do so everybody",
  "12:52": "will know that you're not a real deep",
  "12:54": "learning practitioner because real deep",
  "12:55": "learning practitioners know the keyboard",
  "12:56": "shortcuts and the keyboard shortcut is",
  "12:59": "shift enter given how often you have to",
  "13:01": "run a cell don't be going all the way up",
  "13:05": "here finding your clicking at just shift",
  "13:07": "enter",
  "13:07": "ok so type like type shift enter don't",
  "13:09": "actually",
  "13:10": "up and down to move around to pick",
  "13:12": "something to run shift-enter to run okay",
  "13:15": "so we're going to go through this",
  "13:17": "quickly and then later on we're going to",
  "13:20": "go back over it more carefully so here's",
  "13:23": "the quick version to get a sense of",
  "13:24": "what's going on",
  "13:25": "so here we are in lesson 1 and these",
  "13:29": "three lines is what we start every",
  "13:31": "notebook with these things starting with",
  "13:34": "percent are special directives to",
  "13:36": "Jupiter notebook itself they're not",
  "13:38": "Python code they're called magics which",
  "13:41": "is kind of a cool name and these three",
  "13:43": "directives the details aren't very",
  "13:44": "important but basically it says hey if",
  "13:46": "somebody changes the underlying library",
  "13:48": "code while I'm running this place",
  "13:50": "reloaded automatically if somebody asks",
  "13:53": "to plot something then please plot it",
  "13:55": "here in this Jupiter mo book so just put",
  "13:57": "those three lines at the top of",
  "13:59": "everything the next two lines load up",
  "14:02": "the fast AI library",
  "14:06": "what is the faster a library so it's a",
  "14:08": "little bit confusing fast AI with no dot",
  "14:10": "is the name of our software and then",
  "14:13": "first dot AI with the dot is the name of",
  "14:15": "our organization so if you go to dark",
  "14:18": "start fast",
  "14:19": "AI this is the fast a I might be okay",
  "14:23": "well learn more about it in a moment but",
  "14:25": "for now just realize everything we are",
  "14:27": "going to do is going to be using",
  "14:29": "basically either first AI or the thing",
  "14:33": "that fast AI sits on top of which is",
  "14:35": "platform height which is one of the most",
  "14:39": "popular libraries for deep learning in",
  "14:42": "the world it's a bit newer than",
  "14:45": "tensorflow so in a lot of ways it's more",
  "14:47": "modern than tensorflow it's extremely",
  "14:54": "fast growing extremely popular and we",
  "14:55": "use it because we used to use tensorflow",
  "14:58": "a couple of years ago and we found we",
  "15:00": "can just do a lot more a lot more",
  "15:02": "quickly with paid watch and then we have",
  "15:07": "this software that sits on top of plate",
  "15:08": "watch unless you do far far far more",
  "15:11": "things that are far more easily than can",
  "15:13": "with plate or alone so it's a good",
  "15:14": "combination we'll be talking about about",
  "15:16": "it but for now just know that you can",
  "15:19": "use past AI by doing two things",
  "15:21": "importing",
  "15:23": "star from past AI and then importing",
  "15:25": "staff and fast AI dot something where",
  "15:29": "something is the application you want",
  "15:31": "concurrently fast AI supports for",
  "15:33": "applications computer vision natural",
  "15:35": "language text tabular data and",
  "15:38": "collaborative filtering and we're and",
  "15:41": "we're going to see lots of examples of",
  "15:42": "all of those during the seven weeks so",
  "15:43": "we're going to be doing some computer",
  "15:44": "vision at this point if you are a Python",
  "15:48": "software engineer you are probably",
  "15:50": "feeling sick because you see me go",
  "15:54": "import star which is something that",
  "15:56": "you've all been told to never ever do",
  "15:58": "okay and there's very good reasons to",
  "16:00": "not use import star in standard",
  "16:03": "production code with most libraries but",
  "16:06": "you might have also seen for those of",
  "16:08": "you that have used something like MATLAB",
  "16:09": "it's kind of the opposite everything's",
  "16:11": "there for you all the time you don't",
  "16:13": "even have to import things a lot of the",
  "16:14": "time it's kind of funny we've got these",
  "16:17": "two extremes of like how to write code",
  "16:19": "you've got a scientific programming",
  "16:21": "community that has one way and then",
  "16:24": "you've got the software engineering",
  "16:25": "community that has the other both have",
  "16:27": "really good reasons for doing things and",
  "16:29": "with the faster a library we actually",
  "16:31": "support both approaches you know you put",
  "16:34": "a note block where you want to be able",
  "16:36": "to quickly interactively try stuff out",
  "16:38": "you don't want to be constantly going",
  "16:39": "back up to the top and importing more",
  "16:41": "stuff and trying to figure out where",
  "16:42": "things are you want to be able to use",
  "16:44": "lots of tab complete be you know very",
  "16:46": "experimental so import start is great",
  "16:49": "then when you're building stuff in",
  "16:51": "production you can do the normal Pepe",
  "16:54": "style you know proper software",
  "16:57": "engineering practices so so don't worry",
  "17:00": "when you see me doing stuff which at",
  "17:03": "your workplace is found upon okay it's",
  "17:05": "it's this is a different style of coding",
  "17:08": "it's not that there are no rules in data",
  "17:10": "science programming it's that the rules",
  "17:12": "are different right when you're training",
  "17:14": "models the most important thing is to be",
  "17:16": "able to interactively experiment quickly",
  "17:19": "and so you'll see we use a lot of very",
  "17:22": "different processes styles and stuff to",
  "17:26": "what you're used to but they're there",
  "17:27": "for a reason and you'll learn about them",
  "17:29": "over time you can choose to abuse a",
  "17:31": "similar approach or not it's entirely up",
  "17:33": "to you",
  "17:34": "the other thing to mention",
  "17:35": "is that the faster a library's it",
  "17:39": "designed in a very interesting modular",
  "17:41": "way and you'll find over time that when",
  "17:43": "you do use import star there's far less",
  "17:46": "clobbering of things and you might",
  "17:47": "expect it's all explicitly designed to",
  "17:49": "allow you to pull in things and use them",
  "17:52": "quickly without having problems okay so",
  "17:57": "we're going to look at some data and",
  "17:59": "there's two main places that were",
  "18:01": "pretending to get data from for the",
  "18:03": "course one is from academic datasets",
  "18:07": "academic datasets are really important",
  "18:10": "they're really interesting they're",
  "18:11": "things where academics spend a lot of",
  "18:13": "time curating and gathering a data set",
  "18:15": "so that they can show how well different",
  "18:17": "kinds of approaches work with that data",
  "18:19": "though the end here is they try to",
  "18:20": "design data sets that are challenging in",
  "18:23": "some way and require some kind of",
  "18:25": "breakthrough to do them well so we're",
  "18:28": "going to be starting with an academic",
  "18:28": "data set called the pet data set the",
  "18:31": "other kind of data set we'll be using",
  "18:33": "during the course is data sets from the",
  "18:35": "categorical competitions platform both",
  "18:37": "academic data sets and cadwal data sets",
  "18:40": "are interesting for us particularly",
  "18:42": "because they provide strong baselines",
  "18:44": "that is to say you want to know if",
  "18:47": "you're doing a good job so with capital",
  "18:49": "data sets that have come from a",
  "18:51": "competition you can actually submit your",
  "18:53": "results to Carol and see how well would",
  "18:55": "you have gone in that competition and if",
  "18:57": "you can get in about the top 10% that",
  "18:59": "I'd say you're doing pretty well for",
  "19:03": "academic data sets academics write down",
  "19:06": "in papers what the state of the art is",
  "19:08": "so how well did they go with using",
  "19:10": "models on that data set so this is this",
  "19:12": "is what we're going to do we're going to",
  "19:13": "try and create models that get right up",
  "19:17": "towards the top of capital competitions",
  "19:19": "preferably actually in the top ten what",
  "19:21": "does the top 10% or that meet or exceed",
  "19:25": "academic state-of-the-art published",
  "19:27": "results so the when you use an academic",
  "19:33": "data set it's important to cite it so",
  "19:36": "you'll see here there's a link to the",
  "19:37": "paper that it's from you definitely",
  "19:39": "don't need to read that paper right now",
  "19:40": "but if you're interested in learning",
  "19:42": "more about it and why it was created and",
  "19:44": "how it was created all the details there",
  "19:48": "so in this case this is a pretty",
  "19:50": "difficult challenge the PEC datasets",
  "19:52": "going to ask us to distinguish between",
  "19:54": "37 different categories of dog breed and",
  "19:57": "cat breed so that's really hard in fact",
  "20:01": "every course until this one we've used a",
  "20:04": "different data set which is one where",
  "20:06": "you just have to decide is something a",
  "20:07": "dog or is it a cat so you've got a 50-50",
  "20:11": "chance right away",
  "20:12": "right and dogs and cats look really",
  "20:13": "different there are lots of dog breeds",
  "20:15": "and cat breeds look pretty much the same",
  "20:17": "so why have we changed that dataset",
  "20:19": "we've got to the point now where deep",
  "20:22": "wedding is so fast and so easy that the",
  "20:24": "dogs versus cats problem which a few",
  "20:26": "years ago was considered extremely",
  "20:28": "difficult 80% accuracy was",
  "20:31": "state-of-the-art it's now too easy",
  "20:33": "our models were basically getting",
  "20:35": "everything right all the time without",
  "20:38": "any tuning and so they want you know",
  "20:40": "really a lot of opportunities for me to",
  "20:42": "show you how to do more sophisticated",
  "20:43": "stuff so we've picked a harder problem",
  "20:45": "this year so this is the first class",
  "20:48": "where we're going to be learning how to",
  "20:49": "do this difficult problem and this kind",
  "20:51": "of thing where you have to distinguish",
  "20:53": "between similar categories it's called",
  "20:56": "in the academic context is called",
  "20:58": "fine-grained classification so we're",
  "21:00": "going to do the fine-grained",
  "21:00": "classification task with figuring out",
  "21:03": "particular kind of pet and so the first",
  "21:06": "thing we have to do is download and",
  "21:07": "extract the data that we want we're",
  "21:11": "going to be using this function called",
  "21:12": "ant our data which will download it",
  "21:15": "automatically and we'll enter it",
  "21:17": "automatically AWS has been kind enough",
  "21:20": "to give us lots of space and bandwidth",
  "21:23": "for these datasets so they are download",
  "21:24": "super quickly for you and so the first",
  "21:27": "question then would be how do I know",
  "21:30": "what entire data does so you could just",
  "21:34": "type help and you will find out what my",
  "21:37": "talk did it come from because since we",
  "21:39": "imported staff we don't necessarily know",
  "21:41": "that what does it do and something you",
  "21:44": "might not have seen before",
  "21:45": "even if you're an experienced programmer",
  "21:47": "is what exactly do you pass to it you're",
  "21:51": "probably used to seeing the names URL",
  "21:53": "file name destination but you might not",
  "21:57": "be used to seeing these bits these bits",
  "22:00": "are tight",
  "22:01": "and if you've used a tight programming",
  "22:03": "language you'll be used to seeing them",
  "22:04": "but frankly programmers are less used to",
  "22:06": "it but if you think about it you don't",
  "22:09": "actually know how to use a function",
  "22:11": "unless you know what type each thing is",
  "22:14": "that you're providing it so we make sure",
  "22:16": "that we give you that type information",
  "22:18": "directly here in the help so in this",
  "22:20": "case the URL is a string and the file",
  "22:23": "name",
  "22:23": "is either Union means either over a path",
  "22:27": "or a string and it defaults to nothing",
  "22:31": "and the destination is either a path or",
  "22:34": "a string of defaults to nothing so we'll",
  "22:36": "learn more short me about how to get",
  "22:38": "more documentation about the details of",
  "22:40": "this but for now we can see we don't",
  "22:42": "have to pass in a file name or a",
  "22:44": "destination it'll figure that out for us",
  "22:46": "from the URL so and for all the data",
  "22:49": "sets we'll be using in the course we",
  "22:51": "already have constants defined for all",
  "22:53": "of them right so in this URLs module or",
  "22:57": "class actually you can see that's where",
  "23:00": "it's going to grab it from okay so it's",
  "23:02": "going to download that to some",
  "23:05": "convenient path and untie it for us and",
  "23:07": "we'll then return the value of path okay",
  "23:12": "and then in Jupiter map book it's kind",
  "23:15": "of handy you can just write a variable",
  "23:18": "on its own and semicolon is just it in",
  "23:21": "the statement marker in Python so that's",
  "23:23": "the same as doing this you can write it",
  "23:25": "on phone and it fits it you can also say",
  "23:27": "print write but again we're trying to do",
  "23:29": "everything fast and interactively",
  "23:31": "there's write it and here is the path",
  "23:34": "where it's given us that data next time",
  "23:38": "you run this since you've already",
  "23:40": "downloaded it it won't download it again",
  "23:42": "since you've already untied it it won't",
  "23:44": "untie or it again so everything's kind",
  "23:45": "of designed to be pretty automatic",
  "23:47": "pretty easy there are some things in",
  "23:52": "Python that are less convenient for",
  "23:55": "interactive use and they should be for",
  "23:56": "example when you do have a path object",
  "23:58": "seeing what's in it actually is takes a",
  "24:01": "lot more typing that I would like so",
  "24:03": "sometimes we add functionality into",
  "24:05": "existing Python stuff one of the things",
  "24:07": "we do is we add an LS method to paths so",
  "24:10": "if you go to path type LS here is what's",
  "24:13": "inside",
  "24:14": "this path so that's what we just",
  "24:16": "downloaded so when you try this yourself",
  "24:18": "you wait a couple of minutes for it to",
  "24:20": "download unzip and then you can see",
  "24:23": "what's in there if you're an experienced",
  "24:27": "Python programmer you may not be",
  "24:29": "familiar with this approach of using a",
  "24:31": "splash like this now this is a really",
  "24:33": "convenient function that's part of",
  "24:35": "Python three its functionality from",
  "24:37": "something called path Lib these are path",
  "24:39": "objects path objects are much better to",
  "24:41": "use then strings that lets you basically",
  "24:43": "create sub paths like this it doesn't",
  "24:46": "matter if you're on Windows Linux Mac",
  "24:48": "it's always going to work exactly the",
  "24:50": "same way so here's a path to the images",
  "24:54": "in that data set alright so if you're",
  "24:59": "starting with a brand new data set",
  "25:01": "trying to do some deep learning on it",
  "25:02": "what do you do well the first thing you",
  "25:05": "would want to do is probably see what's",
  "25:07": "in there so we've found that these are",
  "25:09": "the directories that in there so what's",
  "25:13": "in this images there's a lot of",
  "25:16": "functions in fast i/o for you there's",
  "25:18": "one called get image files that will",
  "25:20": "just grab a array of all of the image",
  "25:23": "files based on extension in a path and",
  "25:26": "so here you can see we've got lots of",
  "25:30": "different files okay so this is a pretty",
  "25:33": "common way to for image computer vision",
  "25:36": "datasets to get passed around as that is",
  "25:38": "just one folder with a whole bunch of",
  "25:39": "files in it so the interesting bit then",
  "25:43": "is how do we get the labels so in",
  "25:47": "machine learning the labels refer to the",
  "25:50": "thing we're trying to predict and if we",
  "25:52": "just eyeball this we could immediately",
  "25:54": "see that the labels are actually part of",
  "25:58": "the file name you see that right it's",
  "26:00": "kind of like path slash label underscore",
  "26:04": "number extension so we need to somehow",
  "26:08": "get a list of these bits of each file",
  "26:12": "name and that will give us our labels",
  "26:13": "because that's all you need to build a",
  "26:16": "deep learning model you need see",
  "26:17": "pictures so files containing the images",
  "26:19": "and you need some labels so in fast AI",
  "26:23": "this is made really easy there's a",
  "26:27": "object called image data Bunch and an",
  "26:30": "image data bunch represents all of the",
  "26:32": "data you need to build a model and",
  "26:33": "there's basically some factory methods",
  "26:36": "which try to make it really easy for you",
  "26:39": "to create that data bunch we talked more",
  "26:42": "about this role even a training set and",
  "26:43": "the validation set with images and",
  "26:45": "labels for you now in this case we can",
  "26:49": "see we need to extract the labels from",
  "26:52": "the names okay so we're going to use",
  "26:54": "from name re so for those of you that",
  "26:57": "use Python you know re is the module in",
  "27:00": "Python that does regular expressions",
  "27:01": "things that's really useful for",
  "27:03": "extracting text I just went ahead and",
  "27:06": "created the regular expression that",
  "27:08": "would extract the label from this text",
  "27:12": "okay so those of you who are not",
  "27:16": "familiar with regular expressions super",
  "27:18": "useful to be very useful to spend some",
  "27:20": "time figuring out how and why that",
  "27:23": "particular regular expression is going",
  "27:25": "to extract the label from this text okay",
  "27:29": "so with this factory method we can",
  "27:31": "basically say okay I've got this path",
  "27:32": "containing images this is a list of file",
  "27:36": "names remember I got them back here this",
  "27:38": "is the regular expression pattern that",
  "27:40": "is going to be used to extract the label",
  "27:43": "from the filename will talk about",
  "27:46": "transforms later and then you obviously",
  "27:49": "to say what size images do you want to",
  "27:51": "work with so that might seem weird why",
  "27:54": "do I need to say what size images I want",
  "27:56": "to work with because the images have a",
  "27:58": "size we can see what size the images are",
  "28:01": "and I guess honestly this is a",
  "28:03": "shortcoming of current deep learning",
  "28:06": "technology which is that a GPU has to",
  "28:10": "apply the exact same instruction through",
  "28:13": "a whole bunch of things at the same time",
  "28:14": "in order to be fast and so if the images",
  "28:18": "are different shapes and sizes you can't",
  "28:20": "do that right so we actually have to",
  "28:23": "make all of the images the same shape",
  "28:26": "and size in part one of the course we're",
  "28:30": "always going to be making images square",
  "28:33": "shapes in part two we'll learn how to",
  "28:35": "use rectangles as well it turns out to",
  "28:37": "be surprisingly nuanced but pretty much",
  "28:40": "everybody in pretty much all computer",
  "28:42": "vision modeling nearly all of it uses",
  "28:44": "this approach of square and 224 by 224",
  "28:49": "for reasons we learn about is an",
  "28:51": "extremely common size that most models",
  "28:54": "tend to use so if you just use size",
  "28:56": "equals to 24 you're probably going to",
  "28:58": "get pretty good results most of the time",
  "29:00": "and this is kind of the little bits of",
  "29:03": "artists in the ship that I want to teach",
  "29:05": "you folks which is like what generally",
  "29:08": "just works okay so if you just use size",
  "29:10": "equal to 24 that'll generally just work",
  "29:12": "for most things most of the time so this",
  "29:17": "is kind of return a data bunch object",
  "29:20": "and in fast AI everything you model with",
  "29:22": "is going to be a data bunch object we're",
  "29:24": "going to learn all about them and what's",
  "29:25": "in them and how do we look at them and",
  "29:27": "so forth they're basically a data bunch",
  "29:28": "object contains two or three data sets",
  "29:33": "it contains your training data we'll",
  "29:36": "learn about this shortly it'll contain",
  "29:37": "your validation data and optionally it",
  "29:40": "contains your test data and for each of",
  "29:42": "those it contains your your images and",
  "29:46": "your labels or your texts and your",
  "29:48": "labels or your tabular data and your",
  "29:50": "labels or so forth and that all sits",
  "29:52": "there in this one place something we'll",
  "29:56": "learn more about a little bit is",
  "29:58": "normalization but generally in all",
  "30:00": "nearly all machine learning tasks you",
  "30:03": "have to make all of your data about the",
  "30:05": "same size they're specifically about the",
  "30:07": "same mean and about the same standard",
  "30:09": "deviation so there's a normalized",
  "30:12": "function that we can use to normalize",
  "30:14": "our data bunch in that way okay rich or",
  "30:20": "come and ask the question thanks what is",
  "30:26": "the function do an image size is not 224",
  "30:30": "great so this is propaganda known about",
  "30:33": "shortly basically this thing called",
  "30:36": "transforms is is used to do a number of",
  "30:38": "things and one of the things it does is",
  "30:40": "to make something size 224",
  "30:42": "let's take a look at a few pictures here",
  "30:44": "are a few pictures of things from my",
  "30:47": "digger from my data bunch so you can see",
  "30:49": "data dot show batch can be used to show",
  "30:52": "me the contents of",
  "30:54": "some of the contents of my data bunch so",
  "30:57": "this is going to be three by three and",
  "30:59": "you can see roughly what's happened is",
  "31:02": "that they all seem to have been kind of",
  "31:04": "zoomed and cropped in a reasonably nice",
  "31:06": "way so basically what it'll do is",
  "31:08": "something called by default center",
  "31:11": "cropping which means it'll kind of grab",
  "31:13": "the middle bit and it also resize it so",
  "31:17": "we'll talk more about the detail this",
  "31:19": "because it turns out to actually be",
  "31:20": "quite important but basically a",
  "31:22": "combination of cropping and resizing is",
  "31:25": "used something else we'll learn about is",
  "31:28": "we also use this to do something called",
  "31:30": "data augmentation so there's actually",
  "31:31": "some randomization in how much and where",
  "31:34": "it crops and stuff like that okay but",
  "31:36": "that's the basic idea is some cropping",
  "31:38": "and some resizing that often we also",
  "31:41": "also do some some padding so there's",
  "31:44": "also all kinds of different ways and it",
  "31:46": "depends on data augmentation which we're",
  "31:48": "going to learn about shortly and what",
  "31:52": "does it mean to normalize the images so",
  "31:56": "normalizing the images we're going to be",
  "31:58": "learning more about later in the course",
  "32:00": "but in short it means that the the pixel",
  "32:03": "values we're going to be learning more",
  "32:04": "about pixel values the pixel values",
  "32:06": "start out from naught to 255 and some",
  "32:09": "pixel values might tend to be really I",
  "32:15": "should say some channels because there's",
  "32:17": "red green and blue so some channels",
  "32:19": "might tend to be really bright and some",
  "32:22": "might tend to be really not bright at",
  "32:23": "all and some might be area large and",
  "32:25": "some might not very much at all it",
  "32:27": "really helps train a deep learning model",
  "32:29": "if each one of those red green and blue",
  "32:31": "channels has a mean of 0 and a standard",
  "32:34": "deviation of 1 ok we'll learn more about",
  "32:36": "that if you haven't studied or don't",
  "32:39": "remember means and standard deviations",
  "32:40": "we'll get back to some of that later but",
  "32:43": "that's the basic idea",
  "32:44": "that's what normalization does if your",
  "32:46": "data and again we'll learn much more",
  "32:48": "about details but if your data is not",
  "32:51": "normalized it can be quite difficult for",
  "32:53": "your model to train well so if you do",
  "32:56": "have trouble training a model one thing",
  "32:57": "to check is that you've normalized it as",
  "33:00": "GPU man will be in power up to doesn't",
  "33:03": "size 256",
  "33:05": "some more practical considering to be a",
  "33:07": "little utilization so we're going to be",
  "33:11": "getting into that shortly but the brief",
  "33:13": "answer is that the models are designed",
  "33:16": "so that the final layer is of size seven",
  "33:19": "by seven so we actually want something",
  "33:21": "where if you go seven times to a bunch",
  "33:23": "of times then you end up with something",
  "33:25": "that's a good size yeah all of these",
  "33:28": "details we are going to we are going to",
  "33:30": "get to but the key thing is I wanted to",
  "33:32": "get you training a model as quickly as",
  "33:33": "possible but you know one of the most",
  "33:36": "important things to be a really good",
  "33:38": "practitioner is to be able to look at",
  "33:40": "your data okay so it's really important",
  "33:42": "to remember to go do batch and take a",
  "33:45": "look it's surprising how often when you",
  "33:47": "actually look at the data set you've",
  "33:48": "been given that you realize it's got",
  "33:49": "weird black borders on earth or some of",
  "33:52": "the things have text covering up some of",
  "33:53": "it or some of its rotated in odd ways so",
  "33:56": "make sure you take a look okay and then",
  "34:01": "the other thing we want to do is not",
  "34:02": "just look at the pictures but also look",
  "34:04": "at the labels and so all of the possible",
  "34:08": "label names accord your classes that's",
  "34:12": "where the data bunch you can print out",
  "34:13": "your data type classes and so here they",
  "34:16": "are that's almost the possible labels",
  "34:18": "that we found by using that regular",
  "34:21": "expression on the file names and we",
  "34:23": "learnt earlier on in that prose I wrote",
  "34:25": "at the top that there are 37 possible",
  "34:28": "categories and so just checking length",
  "34:30": "data classes it is indeed 37 a data",
  "34:34": "bunch will always have a property called",
  "34:35": "C and that property called C the",
  "34:39": "technical details will kind of get to it",
  "34:41": "later but for now you can kind of think",
  "34:43": "of it as being a number of classes for",
  "34:46": "things like regression problems and",
  "34:48": "multi-label classification and stuff",
  "34:50": "that's not exactly accurate but it will",
  "34:52": "do for them it's it's important to know",
  "34:55": "that data dot C is a really important",
  "34:59": "piece of information that is something",
  "35:00": "like or at least for classification",
  "35:02": "problems it is the number of classes",
  "35:06": "okay believe it or not we're now ready",
  "35:10": "to train a model and so a model is",
  "35:14": "trained in fast AI using something",
  "35:18": "called a learner and just like a data",
  "35:21": "bunch is a general fast AI concept for",
  "35:24": "your data and from there there are",
  "35:27": "subclasses for particular applications",
  "35:29": "like image data bunch Alanna is a",
  "35:33": "general concept for things that can",
  "35:35": "learn to fit the model and from that",
  "35:38": "there are various subclasses to make",
  "35:40": "things easier and a particular there's",
  "35:41": "one called con flora which is something",
  "35:43": "that will create a convolutional neural",
  "35:45": "network for you and we'll be learning a",
  "35:48": "lot about that over the next few lessons",
  "35:51": "but for now just know that to create a",
  "35:53": "learner for a convolutional neural",
  "35:56": "network you just have to tell it two",
  "35:58": "things the first is what's your data and",
  "36:01": "not surprisingly it takes a data bunch",
  "36:04": "and the second thing you need to tell it",
  "36:06": "is what's your model or what's your",
  "36:09": "architecture so as I learned there are",
  "36:12": "lots of different ways of constructing a",
  "36:14": "convolutional neural network but for now",
  "36:17": "the most important thing for you to know",
  "36:19": "is that there's a particular kind of",
  "36:21": "model called a res net which works",
  "36:24": "extremely well nearly all the time and",
  "36:28": "so for a while at least you really only",
  "36:31": "need to be doing choosing between two",
  "36:33": "things which is what size ResNet do you",
  "36:36": "want don't is basically how big is it",
  "36:38": "and we'll learn them all about the",
  "36:40": "details of what that means but there's",
  "36:42": "that one quarter risen at 34 and there's",
  "36:44": "one quarter of ResNet 50 and so when",
  "36:46": "we're getting started with something up",
  "36:47": "because small one because it'll train",
  "36:49": "faster so that's kind of it that's as",
  "36:53": "much as you need to know to be a pretty",
  "36:55": "good practitioner about architectures",
  "36:56": "for now which is that there's two",
  "36:58": "architectures or two variants of one",
  "37:01": "architecture that work pretty well",
  "37:02": "present at 30 450 start with a smaller",
  "37:05": "one and see if it's good enough so that",
  "37:07": "is all the information we need to create",
  "37:09": "a convolutional neural network learner",
  "37:12": "there's one other thing I'm going to",
  "37:14": "give it though which is a list of",
  "37:16": "metrics metrics are literally just",
  "37:18": "things that get printed out as it's",
  "37:19": "training so I've saying I would like you",
  "37:22": "to print out the error rate please now",
  "37:25": "you can see the first time I ran this on",
  "37:27": "a newly installed box it downloaded",
  "37:31": "something",
  "37:31": "what's it downloading it's downloading",
  "37:35": "the rest net 30 for pre-trained weights",
  "37:39": "now what this means is that this",
  "37:41": "particular model has actually already",
  "37:44": "been trained for a particular task and",
  "37:47": "that particular task is that it was",
  "37:49": "trained on looking at about one and a",
  "37:50": "half million pictures of all kinds of",
  "37:53": "different things a thousand different",
  "37:54": "categories of things using an image data",
  "37:57": "set called image net and so we can",
  "38:00": "download those pre trained weights so",
  "38:02": "that we start start with a model that",
  "38:04": "knows nothing about anything but we",
  "38:06": "actually start with a model that knows",
  "38:08": "how to recognize there are thousand",
  "38:10": "categories of things in image net now I",
  "38:13": "don't think I'm not sure but I don't",
  "38:15": "think all of these 37 categories of pet",
  "38:17": "or in image net but there was certainly",
  "38:20": "some kinds of dog know certainly some",
  "38:22": "kinds of cat so this pre trained model",
  "38:25": "already knows quite a little bit about",
  "38:28": "what pets look like and it certainly",
  "38:30": "knows quite a lot about what animals",
  "38:31": "look like and what photos look like so",
  "38:34": "the idea is that we don't start with a",
  "38:37": "model that knows nothing at all but we",
  "38:39": "start by downloading a model that does",
  "38:41": "something about recognizing images",
  "38:44": "already so it downloads for us",
  "38:46": "automatically the first time we use it a",
  "38:48": "pre trained model and then from now on",
  "38:50": "it won't need to download it again it'll",
  "38:52": "just use the one we've got this is",
  "38:54": "really important we're going to learn a",
  "38:56": "lot about this it's kind of the focus of",
  "38:58": "the whole course which is how to do this",
  "39:01": "is called transfer learning how to take",
  "39:03": "a moral that already knows how to do",
  "39:05": "something pretty well and make it so",
  "39:08": "that it can do your thing really well I",
  "39:10": "take a pre trained model and then we fit",
  "39:13": "it so that instead of predicting Li a",
  "39:16": "thousand categories of imagenet with",
  "39:17": "image net data it predicts the 37",
  "39:20": "categories of pets using your pet data",
  "39:22": "and it turns out that by doing this you",
  "39:25": "can train models in 1/100 or less of the",
  "39:30": "time of regular model training with",
  "39:34": "1/100 or less of the data the regular",
  "39:37": "model training in fact potentially many",
  "39:39": "thousands of times less remember I",
  "39:41": "showed you the slide of nickels lesson",
  "39:43": "one",
  "39:44": "from last year he used 30 images and",
  "39:48": "there's not cricket and baseball images",
  "39:50": "in imagenet but but it just turns out",
  "39:52": "that image gets already so good at",
  "39:54": "recognizing things in the world",
  "39:56": "they're just 30 examples of people",
  "39:57": "playing baseball and cricket was enough",
  "40:00": "to build a nearly perfect classifier",
  "40:02": "okay",
  "40:03": "now you would naturally be potentially",
  "40:09": "saying well wait a minute how do you",
  "40:13": "know that it was going to actually that",
  "40:15": "it can actually recognize pictures of",
  "40:17": "people playing cricket versus baseball",
  "40:19": "in general maybe it just learnt to",
  "40:21": "recognize those 13 maybe it's just",
  "40:24": "cheating right and that's called",
  "40:26": "overfitting we'll be going talking a lot",
  "40:27": "about that during this course right but",
  "40:29": "what a fitting is where you don't learn",
  "40:32": "to recognize pictures of say cricket",
  "40:33": "versus baseball but just these",
  "40:35": "particular cricketers and these",
  "40:37": "particular photos and these particular",
  "40:38": "baseball players in these particular",
  "40:40": "photos we have to make sure that we",
  "40:43": "don't move a fit and so the way we do",
  "40:44": "that is using something called a",
  "40:46": "validation set a validation set is a set",
  "40:49": "of images that your model does not get",
  "40:52": "to look at and so these metrics like in",
  "40:56": "this case error rate get printed out",
  "40:58": "automatically using the validation set",
  "41:00": "and sort of images that our model never",
  "41:02": "got to see when we created our data",
  "41:05": "bunch it automatically created a",
  "41:08": "validation set for us okay and we'll",
  "41:11": "learn lots of ways of creating and using",
  "41:13": "validation sets but because we're trying",
  "41:16": "to bake in all of the best practices we",
  "41:18": "actually make it nearly impossible for",
  "41:21": "you not to use a validation set because",
  "41:23": "if you're not using a validation set you",
  "41:25": "don't know if you're overfitting okay so",
  "41:27": "we always print out the metrics on a",
  "41:28": "validation set we've always hold it out",
  "41:30": "we always make sure that the model",
  "41:32": "doesn't touch it that's all done for you",
  "41:34": "okay and that's all built into this data",
  "41:38": "bunch object so now that we have a",
  "41:41": "corner we can fit it you can just use a",
  "41:46": "method called fit but in practice you",
  "41:49": "should nearly always use a method called",
  "41:50": "fit one cycle we'll learn more about",
  "41:53": "this during the course but in short one",
  "41:56": "cycle learning is a paper",
  "41:57": "that was released I'm trying to think",
  "42:01": "few months ago listen a year ago yeah so",
  "42:05": "a few months ago and it turned out to be",
  "42:07": "dramatically better both more accurate",
  "42:10": "and faster than any previous approach so",
  "42:12": "again I don't want to teach you how to",
  "42:14": "do 2017 deep learning right in 2018 the",
  "42:19": "best way to fit models is to use",
  "42:21": "something called one cycle well learn",
  "42:23": "all about it but for now just know you",
  "42:25": "should probably take my own fit one",
  "42:27": "cycle okay if you forget how to type",
  "42:31": "then you can start typing a few letters",
  "42:33": "in hit tab okay and you'll get a list of",
  "42:37": "potential options and then if you forget",
  "42:41": "what to pass it you can press shift tab",
  "42:43": "and it will show you exactly what to",
  "42:46": "pass it so you don't actually have to",
  "42:47": "type help and again this is kind of nice",
  "42:49": "that we have all the types here because",
  "42:51": "we can see cycle length that we'll learn",
  "42:53": "more about what that is shortly is an",
  "42:54": "integer and then next learning rate",
  "42:56": "could either be the flow for reflection",
  "42:58": "or whatever and so forth and you can see",
  "43:00": "that the mentions will default to this",
  "43:02": "couple and so forth okay so for now just",
  "43:08": "know that this number four basically",
  "43:11": "decides how many times do we go through",
  "43:14": "the entire data set how many times do we",
  "43:16": "show the data set to the model so that",
  "43:19": "it can learn from it each time it sees a",
  "43:20": "picture it's going to get a little bit",
  "43:22": "better",
  "43:22": "but it's going to take time and it means",
  "43:26": "it could over fit but sees the same",
  "43:28": "picture too many times",
  "43:29": "it'll just learn to recognize that",
  "43:31": "picture not pets in general so we'll",
  "43:35": "learn all about how to tune this number",
  "43:39": "during the next couple of lessons but",
  "43:42": "starting out with four is a pretty good",
  "43:45": "start just to see how it goes and you",
  "43:47": "can actually see after four epochs or",
  "43:52": "four cycles we put an error rate of 6%",
  "43:58": "so a natural question is how long that",
  "44:01": "took that took a minute and 56 seconds",
  "44:04": "yeah so we're paying you know 60 cents",
  "44:08": "an hour now we just pay for two minutes",
  "44:11": "I mean we actually pay for the whole",
  "44:13": "time that it's on and running there's",
  "44:15": "two minutes of compute time and we've",
  "44:17": "got an error rate of 6% so 95% of the",
  "44:21": "time we correctly picked the exact right",
  "44:23": "one of those 94 dog and cat breeds which",
  "44:28": "feels pretty good to me",
  "44:29": "but to get a sense of how good it is",
  "44:31": "maybe we should go back and look at the",
  "44:33": "paper just remember I said the nice",
  "44:36": "thing about using academic papers or",
  "44:37": "capital data sets is we can compare our",
  "44:41": "solution to whatever the best people in",
  "44:44": "Cabell did or whatever the academics did",
  "44:46": "so this particular data set of pet",
  "44:49": "breeds is from 2012 and if I scroll",
  "44:53": "through the paper you'll generally find",
  "44:55": "in any academic paper there'll be a",
  "44:56": "section called experiments about 2/3 of",
  "44:59": "the way through and if you find the",
  "45:00": "section on experiments then you can find",
  "45:03": "the section on accuracy and they've got",
  "45:06": "lots of different models and their",
  "45:08": "models as you're read about in the paper",
  "45:10": "it's really kind of pet specific they",
  "45:13": "learn something about how pet heads look",
  "45:15": "and how pet body is broken and techne",
  "45:18": "which is in general look and they",
  "45:19": "combine them all together and once they",
  "45:21": "use all of this complex code and math",
  "45:24": "they got an accuracy of 59% okay so in",
  "45:29": "2012 this highly pet specific analysis",
  "45:34": "got an accuracy of 59% these were the",
  "45:37": "top researchers from Oxford University",
  "45:39": "today in 2018 with basically if you go",
  "45:45": "back and look at actually how much code",
  "45:46": "we just wrote it's about three lines of",
  "45:49": "code the other stuff is just printing",
  "45:51": "out things to see what we're doing",
  "45:52": "we got ninety four percent so six",
  "45:56": "percent error so like that gives you a",
  "45:58": "sense of you know how far we've come",
  "46:01": "with deep learning and particularly with",
  "46:03": "pay torch and fast AI how easy things",
  "46:06": "are yeah so um before we take a break I",
  "46:11": "just want to check to see if we've got",
  "46:12": "any and just remember if you're in the",
  "46:15": "audience and you see a question that you",
  "46:18": "want asked please click them up heart",
  "46:19": "next to it so that Rachel knows that you",
  "46:22": "want to hear about it well",
  "46:23": "if there is something with six likes and",
  "46:26": "Rachel didn't notice it which is quite",
  "46:28": "possible just just quote it in a reply",
  "46:31": "and say hey Rachel this one's got six",
  "46:34": "legs okay",
  "46:36": "so what we're going to do is we're going",
  "46:37": "to take a eight minute break so we'll",
  "46:41": "come back at five past eight so where we",
  "46:45": "got to was we just we just trained a",
  "46:48": "model we don't exactly know what that",
  "46:49": "involved or how it happened but we do",
  "46:51": "know that we're three or four lines of",
  "46:53": "code we've built something which smashed",
  "46:57": "the accuracy of the state-of-the-art of",
  "46:59": "2012 6% arrow certainly sounds like",
  "47:02": "pretty impressive for something that can",
  "47:04": "recognize different dog breeds and cat",
  "47:06": "breeds but we don't really know why it",
  "47:11": "works that we will that's okay all right",
  "47:14": "and in terms of getting the most out of",
  "47:18": "this course we very very regularly here",
  "47:23": "after the course is finished the same",
  "47:26": "basic feedback which this is literally",
  "47:29": "copy and paste it for them forum I fell",
  "47:31": "into the habit of watching the lectures",
  "47:33": "too much and googling too much about",
  "47:35": "concepts without running the code at",
  "47:38": "first I thought I should just read it",
  "47:39": "and then research the theory and we keep",
  "47:43": "hearing people saying my number one",
  "47:45": "regret is I just spent 70 hours doing",
  "47:49": "that and at the very end I started",
  "47:51": "running the code and oh it turned out I",
  "47:53": "learned a lot more",
  "47:54": "so please run the code really run the",
  "47:58": "code I should have spent the majority of",
  "48:01": "my time on the actual code and the",
  "48:03": "notebooks running it seeing what goes in",
  "48:05": "and seeing what comes out so your most",
  "48:09": "important skills to practice our",
  "48:11": "learning and we going to show you how to",
  "48:13": "do this in a lot more detail but",
  "48:15": "understanding what goes in and what goes",
  "48:18": "out so we've already seen an example of",
  "48:22": "looking at what goes in which is data",
  "48:25": "dot show batch and that's going to show",
  "48:27": "you examples of labels and images and so",
  "48:32": "next we're going to be seeing how to",
  "48:33": "look at what came out so that's the most",
  "48:37": "important thing to study as I said the",
  "48:41": "reason we've been able to do this so",
  "48:42": "quickly is heavily because of the",
  "48:44": "fostered a library now if I stay a",
  "48:46": "library is pretty new but it's already",
  "48:49": "getting an extraordinary amount of",
  "48:50": "direction as you've seen all of the",
  "48:52": "major cloud providers either support it",
  "48:54": "or are about to support it",
  "48:57": "a lot of researchers are starting to use",
  "48:59": "it it's it's - remaking a lot of things",
  "49:02": "a lot easier but it's also making new",
  "49:06": "things possible and so really",
  "49:09": "understanding the faster I software is",
  "49:11": "something which is going to take you a",
  "49:13": "long way and the best way to really",
  "49:14": "understand the faster your software well",
  "49:16": "is by using the fast AI documentation",
  "49:19": "and we'll be learning more about the",
  "49:21": "fast a documentation shortly so how does",
  "49:26": "it compare I mean there's really only",
  "49:28": "one major other piece of software like",
  "49:30": "fast AI that is something that tries to",
  "49:32": "make deep learning easy to use and",
  "49:36": "that's chaos chaos is a really terrific",
  "49:38": "piece of software we actually used it",
  "49:40": "for the previous courses until we switch",
  "49:42": "to first AI it runs on top of tensorflow",
  "49:46": "it was kind of the gold standard for",
  "49:48": "making deep learning easy to use before",
  "49:50": "but life is much easier with bostero so",
  "49:53": "if you look for example at the last",
  "49:55": "year's course exercise which is getting",
  "49:58": "dogs vs. cats fast AI lets you get more",
  "50:04": "much more accurate less than half the",
  "50:06": "error on a validation set of course",
  "50:09": "training time is less than half the time",
  "50:13": "lines of code is about a six of the",
  "50:17": "lines of code and the lines of code are",
  "50:20": "more important than you might realize",
  "50:21": "because those 31 lines of Karis code",
  "50:24": "involved you making a lot of decisions",
  "50:27": "setting lots of parameters during list",
  "50:29": "of configuration so that's all stuff",
  "50:31": "where you have to know how to set those",
  "50:34": "things to get kind of best practice",
  "50:35": "results or else these five lines of code",
  "50:38": "anytime we know what to do for you we do",
  "50:41": "it for you anytime we can pick a good",
  "50:42": "default we pick it for you okay so",
  "50:45": "hopefully your",
  "50:46": "is a really useful library not just for",
  "50:50": "learning deep learning but for taking it",
  "50:52": "a very long way how far can you take it",
  "50:54": "well as you'll see all of the research",
  "50:57": "that we do at past AI uses the library",
  "51:00": "and an example of the research we did",
  "51:03": "which was recently featured in Wired",
  "51:04": "describes a new breakthrough in a",
  "51:08": "natural language processing processing",
  "51:10": "which people are calling the image net",
  "51:12": "moment which is basically we broke a new",
  "51:15": "state of the art resolved in text",
  "51:17": "classification which open AI then built",
  "51:20": "on top of our paper to do with more",
  "51:23": "computing more data into different tasks",
  "51:24": "to take it even further and like this is",
  "51:28": "an example of something that we've done",
  "51:29": "in the last six months in conjunction",
  "51:32": "actually with my colleague Sebastian",
  "51:33": "Reuter an example of something that's",
  "51:37": "being built in the faccio library and",
  "51:39": "you're going to learn how to use this",
  "51:41": "brand-new model in three lessons time",
  "51:44": "and you're actually going to get this",
  "51:47": "exact result from this exact paper",
  "51:49": "yourself another example one of our",
  "51:53": "alums ml Hussain who you'll come across",
  "51:57": "on the forum plenty because he's a great",
  "51:59": "guy very active built a new system for",
  "52:02": "natural language semantic code search",
  "52:04": "you can find an on github where you can",
  "52:07": "actually type in English sentences and",
  "52:09": "find snippets of codes that do the thing",
  "52:11": "you asked for and again it's being built",
  "52:13": "with the FASTA a library using the",
  "52:16": "techniques you'll be learning in the",
  "52:17": "next seven weeks in production yeah well",
  "52:20": "I think this stage is a part of their",
  "52:22": "experiments platform so it's kind of",
  "52:24": "pre-production I guess and so the best",
  "52:28": "place to learn about these things and",
  "52:31": "get involved from these things is on the",
  "52:33": "forums where as well as categories for",
  "52:36": "each part of the course and there's also",
  "52:38": "a general category for deep learning",
  "52:39": "where people talk about research papers",
  "52:42": "applications so on and so forth so even",
  "52:48": "though today we're kind of got to focus",
  "52:50": "on a small number of lines of code to a",
  "52:53": "particular thing which is image",
  "52:55": "classification and we're not learning",
  "52:57": "much math or theory or whatever over",
  "53:00": "these seven weeks and then part two",
  "53:02": "another seven weeks we're going to go",
  "53:04": "deeper and deeper and deeper and so",
  "53:05": "where can that take you I want to give",
  "53:07": "you some examples that there is Sarah",
  "53:10": "hooker she did our first course a couple",
  "53:13": "of years ago her background was",
  "53:16": "economics didn't have a background in",
  "53:19": "coding math computer science I think she",
  "53:21": "started learning to code two years",
  "53:22": "before she took our costs she helped",
  "53:26": "develop something at she started a",
  "53:28": "nonprofit called Delta analytics they",
  "53:33": "helped build this amazing system where",
  "53:35": "they attached old mobile phones to trees",
  "53:38": "in the Kenyan rain forests and used it",
  "53:41": "to listen for chainsaw noises and then",
  "53:44": "they used deep learning to figure out",
  "53:45": "when there was a chainsaw being used and",
  "53:47": "then they had a system set up to alert",
  "53:49": "Rangers to go out and stop illegal",
  "53:52": "deforestation in the rainforests so that",
  "53:55": "was something that she was doing well",
  "53:57": "she was in the course as part of her",
  "53:59": "kind of class projects",
  "54:01": "what's she doing now she is now a Google",
  "54:04": "brain researcher which I guess is one of",
  "54:08": "the top if not the top place to do deep",
  "54:10": "learning",
  "54:11": "she's just been publishing some papers",
  "54:14": "now she is going to Africa to set up a",
  "54:17": "Google brains first deep learning",
  "54:19": "Research Center in Africa now I'll say",
  "54:22": "like she worked her ass off you know she",
  "54:25": "really really invested in this course",
  "54:28": "not just doing all of the assignments",
  "54:30": "but also going out and reading in",
  "54:32": "Goodfellows book and doing lots of other",
  "54:34": "things but it really shows where",
  "54:37": "somebody who has no computer science or",
  "54:40": "math background at all can be now one of",
  "54:43": "the world's top deep learning",
  "54:44": "researchers and doing very valuable work",
  "54:49": "another example from our most recent",
  "54:51": "course",
  "54:52": "Christine Payne she is now at open AI",
  "54:59": "and you can find her post and actually",
  "55:02": "listen to her music samples of she",
  "55:05": "actually built something",
  "55:06": "to automatically create chamber music",
  "55:10": "compositions you can play and you can",
  "55:12": "listen to online and so again it's her",
  "55:15": "background math and computer science",
  "55:18": "actually that's her there",
  "55:22": "classical pianist now I will say she is",
  "55:25": "not your average classical pianist she's",
  "55:27": "a festival pianist who also has a",
  "55:29": "master's a medical researcher in",
  "55:30": "Stanford and studied neuroscience and",
  "55:33": "was a high-performance computing expert",
  "55:34": "at Ian's shore and was valedictorian at",
  "55:37": "Princeton anyway she you know very",
  "55:39": "annoying person who did everything she",
  "55:41": "does but you know I think it's really",
  "55:44": "cool to see how I kind of a domain",
  "55:46": "expert in this case the domain of",
  "55:48": "playing piano can go through the",
  "55:50": "fascinator course and come out the other",
  "55:53": "end",
  "55:53": "I guess open AI would be you know of the",
  "55:56": "three top research institutes bugle",
  "55:58": "playing or open a would be two of them",
  "56:00": "probably along with Diamond and",
  "56:04": "interesting Lee actually one of our",
  "56:05": "other students or alumni of the course",
  "56:08": "recently interviewed her for a blog post",
  "56:11": "series he's doing on top AI researchers",
  "56:13": "and she said one of the most important",
  "56:15": "pieces advice she got was from me and",
  "56:18": "she said the piece of advice was kick",
  "56:20": "one project do it really well make it",
  "56:23": "fantastic okay so that was the piece of",
  "56:27": "advice she found the most useful and",
  "56:30": "we're going to be talking a lot about",
  "56:31": "you doing projects and making them",
  "56:33": "fantastic during this course having said",
  "56:37": "that I don't really want you to go to AI",
  "56:39": "or Google brain what I really want you",
  "56:41": "to do is go back to your workplace or",
  "56:44": "your passion project and apply these",
  "56:47": "skills there right like let me give you",
  "56:50": "an example",
  "56:51": "MIT released a deep learning course and",
  "56:55": "they highlighted in their announcement",
  "56:57": "for this deep learning course this",
  "56:58": "medical imaging example and one of our",
  "57:03": "students Alex who is a radiologist said",
  "57:08": "you guys just showed a model overfitting",
  "57:12": "I can tell because I'm a radiologist",
  "57:15": "and this is not what this would look",
  "57:18": "like on a chest film",
  "57:20": "this is what it should look like and",
  "57:23": "this is a deep breading practitioner",
  "57:25": "this is how I know that this is what",
  "57:27": "happened in your model so alex is",
  "57:29": "combining his knowledge of radiology and",
  "57:31": "his knowledge of deep learning to assess",
  "57:35": "mi t--'s model from just two images very",
  "57:39": "accurately right and so this is actually",
  "57:41": "what I want most of you to be doing is",
  "57:43": "to take your domain expertise and",
  "57:45": "combine it with the deep learning",
  "57:47": "practical aspects that you'll learn in",
  "57:49": "this course and bring them together like",
  "57:51": "Alex is doing here and so a lot of",
  "57:53": "radiologists have actually gone through",
  "57:55": "this course now and have built journal",
  "57:59": "clubs and American Council of radiology",
  "58:01": "practice groups there's a data science",
  "58:04": "Institute at the ACR now and so forth",
  "58:06": "and Alex is one of the people who's",
  "58:07": "providing kind of a lot of leadership in",
  "58:09": "this area I would love you to do the",
  "58:11": "same kind of thing that alex is doing",
  "58:13": "which is to really bring deep learning",
  "58:15": "related leadership into your industry",
  "58:17": "and just your social impact project",
  "58:19": "whatever it is that you're trying to do",
  "58:22": "so another great example was this was",
  "58:24": "Melissa fab bras who was a English",
  "58:26": "literature PhD who studied like gendered",
  "58:29": "language in English literature or",
  "58:32": "something and actually wrench over the",
  "58:36": "previous job taught her to code",
  "58:37": "I think and then she came into the first",
  "58:40": "day a course and she helped Kiva a micro",
  "58:44": "lending a social impact organization to",
  "58:46": "build a system that can recognize faces",
  "58:49": "why is that necessary well we're going",
  "58:51": "to be talking a lot about this but",
  "58:53": "because most a I researchers are white",
  "58:57": "men most computer vision software can",
  "59:02": "only recognize white male faces",
  "59:04": "effectively in fact I think of as IBM",
  "59:07": "system is like ninety-nine point eight",
  "59:09": "percent accurate on common white face",
  "59:12": "men versus sixty percent accurate",
  "59:17": "sixty-five percent accurate on dark",
  "59:20": "faith dark-skinned women so it's like",
  "59:23": "what is that like 30 or 40 times worse",
  "59:26": "for black women versus white men and",
  "59:29": "this is really important because for",
  "59:31": "chemo black women",
  "59:33": "you know perhaps the most common user",
  "59:36": "base for their microlending platform so",
  "59:39": "melissa after taking our course and",
  "59:42": "again working in her ass off and being",
  "59:44": "super intensive in her study and her",
  "59:46": "work",
  "59:46": "won this $1,000,000 AI challenge for her",
  "59:49": "work for Kiva Karthik did our course and",
  "59:56": "realize that the thing he wanted to do",
  "59:58": "wasn't at his company it was something",
  "59:59": "else which is to help blind people to",
  "60:01": "understand the world around them so he",
  "60:02": "started a new startup you can find it",
  "60:04": "now it's called envision you can",
  "60:06": "download the app you can point your",
  "60:08": "phone of things and it will tell you",
  "60:10": "what it sees and I actually talked to a",
  "60:12": "blind lady about these kinds of apps the",
  "60:15": "other day and she confirmed to me this",
  "60:16": "is a super useful thing for visually",
  "60:19": "disabled users and it's not it's the",
  "60:26": "level that you can get to with with the",
  "60:30": "content that you're going to get over",
  "60:31": "these seven weeks and with this software",
  "60:33": "can get you right to the cutting edge in",
  "60:37": "areas you might find surprising for",
  "60:39": "example I helped a team of some of our",
  "60:42": "students and some collaborators on",
  "60:46": "actually breaking the world record for",
  "60:49": "training remember I mentioned the",
  "60:50": "imagenet data set lots of people want to",
  "60:52": "train on the imagenet dataset we smashed",
  "60:54": "the world record for how quickly you can",
  "60:56": "train it we do standard AWS cloud",
  "61:00": "infrastructure cost of $40 of compute to",
  "61:03": "train this model using again faster",
  "61:06": "library the techniques that we learn in",
  "61:08": "this course so it can really take you a",
  "61:10": "long way so don't be kind of put off by",
  "61:13": "this what might seem pretty simple at",
  "61:16": "first we're going to get deeper and",
  "61:17": "deeper you can also use it for other",
  "61:20": "kinds of passion project so Helene",
  "61:22": "esaron actually you should definitely",
  "61:24": "check out her Twitter account like ELISA",
  "61:26": "this art is a basically a new style of",
  "61:30": "art that she's developed which combines",
  "61:33": "her painting and drawing with generative",
  "61:37": "adversarial models to create these",
  "61:39": "extraordinary results and so I think",
  "61:42": "this is super cool she's not a",
  "61:44": "professional artists she is a",
  "61:46": "professional software developer",
  "61:47": "but she just keeps on producing these",
  "61:50": "beautiful results and when she started",
  "61:53": "you know her art had not really been",
  "61:58": "shown anywhere I discussed anywhere now",
  "62:01": "there's recently been some quite",
  "62:02": "high-profile articles describing how she",
  "62:05": "is creating a new form of art again this",
  "62:07": "is come out of the FASTA a course that",
  "62:12": "she developed these skills or equally",
  "62:14": "important bred counselor who figured out",
  "62:16": "how to make a picture of Kanye out of",
  "62:18": "pictures of Patrick Stewart's head also",
  "62:21": "something you will learn to do if you",
  "62:23": "wish to this particular style this",
  "62:27": "particular type of what's called style",
  "62:28": "transfer was a really interesting tweak",
  "62:30": "it allowed him to do some things that",
  "62:32": "hadn't quite been done before and this",
  "62:35": "particular picture helped him to get a",
  "62:36": "job as a deep learning specialist at AWS",
  "62:39": "so another interesting example another",
  "62:44": "alumni actually worked at Splunk as a",
  "62:47": "software engineer and he'd signed an",
  "62:52": "algorithm after like lesson three which",
  "62:54": "basically turned out its plant to be",
  "62:56": "fantastically good at identifying fraud",
  "62:59": "and we'll talk more about it shortly if",
  "63:02": "you've seen Silicon Valley the HBO",
  "63:03": "series the the hot dog hot dog app",
  "63:06": "that's actually a real app you can",
  "63:07": "download and it was actually built by a",
  "63:09": "team on Glade as a fast AI student",
  "63:12": "project so there's a lot of cool stuff",
  "63:15": "that you can do I'm like yes it wasn't",
  "63:18": "very nominated so I think we only have",
  "63:20": "one any nominated fast day alumni at",
  "63:23": "this stage so please help change that",
  "63:29": "alright the other thing you know is is",
  "63:33": "is the forum threads can kind of turn",
  "63:35": "into these really cool things so",
  "63:37": "Francisco was actually here in the",
  "63:38": "audience he's are really boring McKinsey",
  "63:41": "consultant like me",
  "63:42": "it's a Francisco and I both have this",
  "63:44": "shameful past that we were McKinsey",
  "63:46": "consultants but we left and we're okay",
  "63:48": "now",
  "63:48": "and he started his threat saying like oh",
  "63:52": "this stuff we've just been learning",
  "63:53": "about building",
  "63:55": "NLP in different languages let's try and",
  "63:57": "do lots of different languages we",
  "63:59": "started this thing with the language",
  "64:00": "model zoom and add that there's now been",
  "64:03": "an academic competition was one in",
  "64:08": "Polish that led to an academic paper tie",
  "64:11": "state-of-the-art German state of the art",
  "64:14": "basically as students have been coming",
  "64:16": "up with new study that results across",
  "64:18": "lots of different languages and this all",
  "64:19": "is entirely being done by students",
  "64:23": "working together through the forum so",
  "64:25": "please get on the forum but don't be",
  "64:29": "intimidated because remember and one of",
  "64:32": "the people everybody you see on the",
  "64:34": "forum the vast majority posting post all",
  "64:37": "the damn time right they've been doing",
  "64:39": "this a lot and they do it a lot of the",
  "64:41": "time and so at first it can feel",
  "64:43": "intimidating because it can feel like",
  "64:44": "you're the only new person there but",
  "64:46": "you're not right all of you people in",
  "64:49": "the audience everybody who's watching",
  "64:50": "everybody who's listening you're all new",
  "64:52": "people right and so when you just get",
  "64:54": "out there and say like okay nor your",
  "64:57": "people getting these state-of-the-art",
  "64:58": "results in German language modeling if I",
  "65:02": "can't start my server I try to click the",
  "65:04": "notebook and I get an error what do I do",
  "65:07": "people will help you okay just make sure",
  "65:10": "you provide all the information this is",
  "65:12": "the you know I'm using paper space this",
  "65:14": "was the particular instance I try to use",
  "65:16": "here's a screenshot of my error people",
  "65:19": "will help you okay well if you've got",
  "65:21": "something to add so if people were",
  "65:23": "talking about crop yield analysis and",
  "65:26": "you're a farmer and you think you know",
  "65:28": "oh I've got something to add so please",
  "65:31": "mention it even even if you're not sure",
  "65:33": "it's exactly relevant it's fine you know",
  "65:35": "just get involved and because remember",
  "65:37": "everybody else in the forum's started",
  "65:39": "out also intimidated right we all start",
  "65:43": "out not knowing things and so just get",
  "65:46": "out there and try it okay",
  "65:50": "so let's get back and do some more",
  "65:54": "coding yes Rachel do we have some",
  "65:57": "questions about why you're using breast",
  "66:02": "net is opposed to this session so the",
  "66:07": "question is about this architecture",
  "66:09": "so there are lots of architectures to",
  "66:12": "choose from and it would be fair to say",
  "66:15": "there isn't one best one but if you look",
  "66:20": "at things like the Stanford dawn bench",
  "66:25": "benchmark or imagenet classification",
  "66:28": "you'll see in first place in second",
  "66:31": "place in third place in fourth place is",
  "66:33": "faster i Jeremy Hatton first a",
  "66:35": "hydrometer plus the irony response from",
  "66:37": "the Department of Defense innovation",
  "66:39": "team Google RIS net ResNet ResNet ResNet",
  "66:43": "listen it's good enough ok so it's fun",
  "66:52": "there are other architect is the main",
  "66:54": "reason you might want a different",
  "66:55": "architecture is if you want to do inch",
  "66:57": "computing so if you want to create a",
  "66:58": "model that's gonna sit on somebody's",
  "67:00": "mobile phone having said that even their",
  "67:03": "most of the time I reckon the best way",
  "67:05": "to get a model onto somebody's mobile",
  "67:06": "phone is to run it on your server and",
  "67:08": "then have your mobile phone app talk to",
  "67:10": "it it really makes life a lot easier and",
  "67:13": "you get a lot more flexibility but if",
  "67:15": "you really do need to run something on a",
  "67:16": "low powered device then there are some",
  "67:18": "special architectures for them so the",
  "67:22": "particular question was about inception",
  "67:24": "that's a particular another architecture",
  "67:27": "which tends to be pretty memory",
  "67:29": "intensive and yeah resident I'm for",
  "67:33": "inception tends to be pretty memory",
  "67:34": "intensive but it's it's ok it's also",
  "67:36": "like it's not terribly resilient one of",
  "67:39": "the things we try to show you is like",
  "67:41": "stuff which just tends to always work",
  "67:43": "even if you don't quite ruin everything",
  "67:46": "perfectly",
  "67:47": "so Reznor tends to work pretty well",
  "67:48": "across a wide range of different kind of",
  "67:53": "details around choices that you might",
  "67:54": "make so I think it's pretty good so",
  "67:59": "we've got this trained model and so",
  "68:00": "what's actually happened as we'll learn",
  "68:02": "is it's basically creating a set of",
  "68:05": "weights if you've ever done anything",
  "68:06": "like a linear regression or logistic",
  "68:08": "regression you'll be familiar with",
  "68:10": "coefficients we basically found some",
  "68:11": "coefficients and parameters that work",
  "68:13": "pretty well and it took us a minute and",
  "68:15": "56 seconds so if we want to start doing",
  "68:18": "some more playing around and come back",
  "68:19": "later we probably should save those",
  "68:22": "weights",
  "68:22": "we can save that minute and 56 seconds",
  "68:24": "so you can just go and learn got save",
  "68:25": "and give it a name it's going to put it",
  "68:28": "in a model subdirectory in the same",
  "68:31": "place the data came from so if you save",
  "68:33": "different models or different data",
  "68:35": "bunches from different data sets",
  "68:37": "they'll all be kept separate so don't",
  "68:39": "worry about it",
  "68:42": "all right so we've talked about how the",
  "68:44": "most important things that add on learn",
  "68:45": "what goes into your model what comes out",
  "68:47": "we've seen one way of seeing what goes",
  "68:49": "in now let's see what comes out this is",
  "68:52": "the other thing you need to get really",
  "68:53": "good at so to see what comes out we",
  "68:57": "could use this class for classification",
  "68:59": "interpretation and we're going to use",
  "69:02": "this factory method from learner so we",
  "69:05": "pass in a loan object so remember a",
  "69:07": "learn object from those two things",
  "69:08": "what's your data and what is your model",
  "69:12": "it's now I'm not just an architecture",
  "69:14": "it's actually a trained model inside",
  "69:16": "there and that's all the information we",
  "69:17": "need to interpret that model so if this",
  "69:20": "pass in the learner and we now have a",
  "69:22": "classification interpretation object and",
  "69:26": "so one of the things we can do it",
  "69:28": "perhaps the most useful things to do is",
  "69:30": "called plot top losses so we're going to",
  "69:35": "be learning a lot about this idea of",
  "69:36": "loss functions shortly but in short a",
  "69:40": "loss function is something that tells",
  "69:42": "you how good was your prediction and so",
  "69:45": "specifically that means if you predicted",
  "69:48": "one class of cat with great confidence",
  "69:52": "you said I am very very sure that this",
  "69:55": "is a BER man but actually you were wrong",
  "70:01": "then then that's going to have a high",
  "70:03": "loss because you were very confident",
  "70:04": "about the wrong answer okay so that's",
  "70:07": "what it basically means to have a high",
  "70:09": "loss so by putting the top losses we are",
  "70:11": "going to find out what were the things",
  "70:13": "that we were the most wrong on are the",
  "70:16": "most confident about what we got wrong",
  "70:18": "so you can see here it prints out three",
  "70:22": "things German Shorthaired before things",
  "70:25": "beat all 7.0 for 0.92 well what do they",
  "70:31": "mean perhaps we should look at the",
  "70:35": "document",
  "70:36": "so if you we've already seen help but",
  "70:39": "and help just prints out a quick little",
  "70:41": "summary but if you won't really see how",
  "70:43": "to do something use doc and doc tells",
  "70:47": "you the same information is help but it",
  "70:49": "has this very important thing which is",
  "70:51": "show in Doc's so when you click on",
  "70:54": "showing dots it pops up the",
  "70:58": "documentation for that method or class",
  "71:01": "or function or whatever starts out by",
  "71:04": "showing us the same information about",
  "71:05": "what is what are the parameters it takes",
  "71:07": "along with the doc string but then tells",
  "71:11": "you more information so in this case I",
  "71:13": "saw the thing that tells me the title of",
  "71:15": "eight shows the prediction the actual",
  "71:19": "the loss and the probability that was",
  "71:24": "predicted so for example and you can see",
  "71:26": "there's actually some code you can run",
  "71:28": "so the documentation always has working",
  "71:30": "code and so in this case it was trying",
  "71:33": "things with handwritten digits and so",
  "71:35": "the first one it was predicted to be a",
  "71:37": "seven it was actually a three the loss",
  "71:40": "is five point four four and the",
  "71:43": "probability of the actual class was 0.07",
  "71:47": "okay so I you know we did not have a",
  "71:51": "high probability associated yet for",
  "71:52": "class I can see why I thought this was a",
  "71:54": "seven unless it was wrong so this is the",
  "71:57": "documentation okay and so this is your",
  "71:59": "friend when you're trying to figure out",
  "72:01": "how to use these things the other thing",
  "72:03": "I'll mention is if you're a somewhat",
  "72:06": "experienced Python programmer you'll",
  "72:08": "find the source code of faster I'm",
  "72:09": "really easy to read we're trying to",
  "72:11": "write everything in just a small number",
  "72:14": "of you know much less than half a screen",
  "72:16": "of code generally four or five lines of",
  "72:18": "code",
  "72:18": "if you click source you can jump",
  "72:20": "straight to the source code right so",
  "72:23": "here is the plot top losses and this is",
  "72:26": "also a great way to find out how to use",
  "72:30": "the faster I'm I agree because every",
  "72:32": "line of code here nearly every line of",
  "72:33": "code is calling stuff in the faster you",
  "72:35": "library okay so don't be afraid to look",
  "72:39": "at the source code I've got another",
  "72:43": "really cool trick about the",
  "72:44": "documentation that you're going to see a",
  "72:45": "little bit later",
  "72:46": "okay so that's how we can look at these",
  "72:51": "top losses and these suppress the most",
  "72:53": "important image classification",
  "72:55": "interpretation tools that we have",
  "72:57": "because it lets us see what are we",
  "73:00": "getting wrong and quite often like in",
  "73:03": "this case if you're a dog and cat expert",
  "73:06": "you'll realize that the things that's",
  "73:08": "getting wrong breeds that are actually",
  "73:10": "very difficult to tell apart and you'd",
  "73:12": "be able to look at these and say oh I",
  "73:14": "can see why they've got this one wrong",
  "73:18": "so this is a really useful tool another",
  "73:21": "useful tool kind of is to use something",
  "73:23": "called a confusion matrix which",
  "73:25": "basically shows you for every actual",
  "73:28": "type of dog or cat how many times was it",
  "73:32": "predicted to be that dog okay but",
  "73:34": "unfortunately in this case because it's",
  "73:35": "so accurate this diagonal basically says",
  "73:38": "how it's pretty much right all the time",
  "73:40": "and you can see this in slightly darker",
  "73:42": "ones like a five here it's really hard",
  "73:44": "to read exactly what their combination",
  "73:46": "is so what I suggest you use is instead",
  "73:48": "of if you've got lots of classes don't",
  "73:50": "use a classification confusion matrix",
  "73:52": "but this is my favorite named function",
  "73:55": "in faster I are very proud of this you",
  "73:57": "can call most confused and most confused",
  "74:01": "will simply grab out of the confusion",
  "74:03": "matrix the particular combinations have",
  "74:06": "predicted and actual that got wrong the",
  "74:08": "most often so this case the",
  "74:11": "Staffordshire Bull Terrier was what it",
  "74:13": "should have predicted and instead it",
  "74:15": "predicted an American Pitbull Terrier",
  "74:17": "and so forth it should have ridiculous I",
  "74:19": "mean actually predicted Burma that",
  "74:21": "happened four times this particular",
  "74:22": "combination happens six times so this is",
  "74:24": "again a very useful thing because you",
  "74:26": "can look and you can say like with my",
  "74:28": "domain expertise does it make sense that",
  "74:31": "that would be something that was",
  "74:32": "confused about so these are some of the",
  "74:34": "kinds of tools you can use to look at",
  "74:36": "the upload let's make our model better",
  "74:39": "so how do we make the bottle better we",
  "74:42": "can make it better using fine tuning so",
  "74:46": "far we fitted for epochs and it ran",
  "74:50": "pretty quickly and the reason it ran",
  "74:52": "pretty quickly is that there was a",
  "74:53": "little trick we used these deep learning",
  "74:55": "models these convolutional networks they",
  "74:57": "have",
  "74:58": "lanes they learned a lot about exactly",
  "75:00": "what layers are but but now just know it",
  "75:01": "goes through a computer computational",
  "75:03": "computation or computational computation",
  "75:06": "what we did was we added a few extra",
  "75:09": "layers to the end and we only trained",
  "75:11": "votes we basically left most of the",
  "75:13": "model exactly as it was so that's really",
  "75:15": "fast and if we're trying to build a",
  "75:18": "model at something that's similar to the",
  "75:20": "original pre-trained model so in this",
  "75:23": "case similar the imagenet data that",
  "75:25": "works pretty well but what we really",
  "75:27": "want to do is actually go back and train",
  "75:30": "the whole model so this is why we pretty",
  "75:33": "much always use this two-stage process",
  "75:34": "so by default when we call fit or fit",
  "75:40": "one cycle on a con Florida it'll just",
  "75:43": "fine-tune these few extra layers add up",
  "75:45": "to the end and it'll run very fast it'll",
  "75:48": "basically never over fit but to really",
  "75:50": "get it good you have to call an crits",
  "75:53": "and unfreeze is the thing that says",
  "75:55": "please train the whole model and then I",
  "76:00": "can call fit one cycle again and of the",
  "76:04": "error got much worse okay",
  "76:09": "why in order to understand why we're",
  "76:13": "actually going to have to learn more",
  "76:14": "about exactly what's going on behind the",
  "76:17": "scenes so let's start out by trying to",
  "76:20": "get an intuitive understanding of what's",
  "76:22": "going on behind the scenes and again",
  "76:24": "we're going to do it by looking at",
  "76:25": "pictures we're gonna start with this",
  "76:29": "picture these pictures come from a",
  "76:31": "fantastic paper by Nets Iowa who",
  "76:33": "nowadays is CEO of clarify which is a",
  "76:35": "very successful computer vision start",
  "76:38": "and his supervisor is PhD Rob Fergus and",
  "76:43": "they kind of paper showing how you can",
  "76:44": "visualize the layers of a convolutional",
  "76:47": "neural network so a convolutional neural",
  "76:50": "network will learn mathematically about",
  "76:51": "what the layers are shortly but the",
  "76:53": "basic idea is that your red green and",
  "76:55": "blue pixel values that are numbers from",
  "76:57": "nought to 255 go into the simple",
  "76:59": "computation the first layer and",
  "77:02": "something comes out of that and then the",
  "77:04": "result of that goes into a second layer",
  "77:05": "back",
  "77:06": "the third layer and so forth and there",
  "77:11": "can be up to a thousand layers of a",
  "77:14": "neural network president 34 has 34",
  "77:17": "layers there's no 50s 50 layers but",
  "77:21": "that's not that layer one there's this",
  "77:23": "very simple computation it's a",
  "77:25": "convolution if you know what they are",
  "77:27": "we'll learn more about them shortly what",
  "77:30": "comes out of this first layer well we",
  "77:32": "can actually visualize these specific",
  "77:34": "coefficients the specific parameters by",
  "77:36": "drawing them as a picture there's",
  "77:38": "actually a few dozen of of them in the",
  "77:41": "first layer so we won't draw all of them",
  "77:42": "and let's just look at mine at random so",
  "77:45": "here are my examples of the actual",
  "77:47": "coefficients from the first layer and so",
  "77:50": "these operate on groups of pixels that",
  "77:53": "are next to each other and so this first",
  "77:55": "one basically finds groups of pixels",
  "77:57": "that have a little horizontal diagonal",
  "77:58": "line in this direction this one finds",
  "78:00": "diagonal lines in the other direction",
  "78:02": "despite ingredients that go from yellow",
  "78:04": "to blue in this direction this one finds",
  "78:07": "greated to go from pink to green in this",
  "78:09": "direction",
  "78:09": "and so forth that's a very very simple",
  "78:12": "little filters let's layer one of a",
  "78:17": "imagenet pre-trained convolutional",
  "78:19": "neural net layer two takes the results",
  "78:24": "of those filters and does a second layer",
  "78:26": "of computation and it allows it to",
  "78:28": "create so here at nine examples of kind",
  "78:32": "of a way of visualizing this one of the",
  "78:34": "second layer features and you can see",
  "78:36": "it's basically learned to create",
  "78:38": "something that looks for Connors top",
  "78:42": "left corners and this one is learn to",
  "78:44": "find things that find right-hand curves",
  "78:46": "this one is learn to find things that",
  "78:48": "find little circles right so you can see",
  "78:51": "how Maya - like this is the easiest way",
  "78:53": "to see it in layer one we have things",
  "78:55": "that can find just one line and lay it -",
  "78:57": "we can find things that have two lines",
  "78:59": "turned up or one line repeated if you",
  "79:02": "then look over here these nine show you",
  "79:05": "nine examples of actual bits of actual",
  "79:08": "photos that activated this filter a lot",
  "79:10": "that's what other words this little bit",
  "79:12": "of function math function here was good",
  "79:16": "at finding these kind of window corners",
  "79:18": "and stuff",
  "79:18": "like that this little surly one was very",
  "79:22": "good at finding bits of photos that had",
  "79:23": "circles it okay so this is the kind of",
  "79:26": "stuff you've got to get a really good",
  "79:27": "intuitive understanding for slightly the",
  "79:29": "start of my neural nets gonna find",
  "79:31": "simple very simple gradients lines the",
  "79:34": "second layer can find very simple shapes",
  "79:36": "the third layer can find combinations of",
  "79:38": "votes so now we can find repeating",
  "79:42": "patterns of two-dimensional objects or",
  "79:44": "we can find kind of things that joins",
  "79:47": "that join together or we can find well",
  "79:50": "what are these things well let's find",
  "79:52": "out what is this let's go and have a",
  "79:54": "look at some bits of picture that",
  "79:55": "activated this one highly Oh mainly",
  "79:59": "they're bits of text although sometimes",
  "80:01": "windows so it's nice to be able to find",
  "80:04": "kind of like four petered horizontal",
  "80:06": "patterns and this one here since we have",
  "80:08": "a find kind of edges of fluffy or",
  "80:12": "flowery things this one here is kind of",
  "80:14": "finding geometric patterns so layer",
  "80:17": "three was able to take all the stuff in",
  "80:19": "layer two and combine them together",
  "80:21": "layer four can take all the stuff from",
  "80:24": "layer three and combine them together by",
  "80:26": "layer four we put something that can",
  "80:28": "find dog faces and let's see what else",
  "80:32": "we've got here yeah various kinds of oh",
  "80:37": "here we have bird legs so you kind of",
  "80:40": "get the idea so by layer five we've got",
  "80:42": "something that can find the eyeballs of",
  "80:44": "birds and wizards or faces of particular",
  "80:48": "breeds of dogs and so forth so you can",
  "80:50": "see how by the time you get to layer 34",
  "80:54": "you can find specific dog breeds and cat",
  "80:58": "breeds right this is kind of how it",
  "80:59": "works",
  "80:59": "so when we first trained when we first",
  "81:04": "fine-tune that pre-trained model we kept",
  "81:07": "all of these layers that you've seen so",
  "81:09": "far and we just trained a few more",
  "81:11": "layers on top of all of those",
  "81:13": "sophisticated features that are already",
  "81:14": "being created okay and so now we're",
  "81:17": "fine-tuning we're going back and saying",
  "81:19": "let's change all of these rookies that",
  "81:21": "we'll start with them where they are",
  "81:23": "right but let's see if we can make them",
  "81:25": "better now it seemed very unlikely that",
  "81:29": "we can make these lay",
  "81:31": "lively features better like is there I",
  "81:33": "am likely that the kind of the",
  "81:35": "definition of a diagonal line is going",
  "81:36": "to be different when we look at dog and",
  "81:38": "cat breeds versus the image net data",
  "81:41": "that this is originally trained on so we",
  "81:43": "don't really want to change layer one",
  "81:45": "very much if at all or else the last",
  "81:48": "layers you know this thing of like types",
  "81:51": "of dog face seems very likely that we do",
  "81:54": "want to change that right so you kind of",
  "81:56": "want this intuition is understanding",
  "81:58": "that the different layers of a neural",
  "82:00": "network represents different levels of",
  "82:03": "kind of semantic complexity so this is",
  "82:07": "why our attempt to find through this",
  "82:10": "model didn't work is because we actually",
  "82:13": "by default it trains all the layers at",
  "82:17": "the same speed right which is to say it",
  "82:19": "will update those like things",
  "82:21": "representing diagonal lines and",
  "82:22": "gradients just as much as it tries to",
  "82:24": "update the things that represent the",
  "82:26": "exact specifics of what a my ball looks",
  "82:28": "like so we have to change that okay and",
  "82:30": "so um to change it we first of all need",
  "82:34": "to go back to where we were before okay",
  "82:36": "we did we just broke this model right",
  "82:38": "just much worse than it started out so",
  "82:40": "if we just go load this brings back the",
  "82:43": "model that we saved earlier remember we",
  "82:45": "saved it as stage one okay so let's go",
  "82:52": "ahead and load that back up so that's",
  "82:54": "now our models back to where it was",
  "82:55": "before we killed it",
  "82:57": "and let's run learning rate finder we're",
  "83:01": "learning about what that is next week",
  "83:03": "but for now just know this is the thing",
  "83:05": "that figures out what is the fastest I",
  "83:07": "can train this neural network at without",
  "83:11": "making it zip off the rails and get",
  "83:14": "blown apart okay so we can call it low",
  "83:15": "ll find and then we can go and learn",
  "83:18": "don't recorded up plot and that will",
  "83:20": "plot the result of our LR finder and",
  "83:23": "what this basically shows you is this",
  "83:25": "this is T parameter that we're going to",
  "83:27": "learn all about called the learning rate",
  "83:28": "and the learning rate basically says how",
  "83:31": "quickly am i updating the parameters in",
  "83:33": "my model and you can see that what",
  "83:36": "happens is as I in this this bottom one",
  "83:39": "here shows me what happens as I increase",
  "83:41": "the learning rate and this one here show",
  "83:44": "what hapless and so you can see once the",
  "83:48": "learning rate gets past ten to the",
  "83:50": "negative four",
  "83:51": "my last gets worse okay so it actually",
  "83:56": "so happens in fact I can check this if I",
  "83:58": "press shift tab here my learning rate",
  "84:01": "defaults to 0.003 so my default loading",
  "84:05": "rate is about here so you can see where",
  "84:08": "I lost got worse right because we kind",
  "84:09": "of fine-tune things now we can't use",
  "84:12": "such a high learning rate so based on",
  "84:15": "the learning rate finder I tried to pick",
  "84:17": "something you know well before it",
  "84:20": "started getting worse so I decided to",
  "84:23": "pick one Enix's so I decided I got to",
  "84:27": "train at that rate but there's no point",
  "84:30": "trading all the layers of that rate",
  "84:31": "because we know that the latent layers",
  "84:33": "work just fine before when we were",
  "84:36": "training much more quickly again it was",
  "84:38": "the default which was to remind us 0.003",
  "84:44": "so what we can actually do is we can",
  "84:46": "pass a range of learning rates to learn",
  "84:49": "theater and we do it like this you pass",
  "84:52": "and use this keyword in fact in Python",
  "84:54": "you may have come across fourth called",
  "84:56": "slice and that can take a start value in",
  "85:00": "a stock value and basically what this",
  "85:02": "says is trained the very first players",
  "85:04": "at a learning rate of 1e make 6 and the",
  "85:09": "very last layers at a rate of 1 enoch 4",
  "85:11": "and then kind of distribute all the",
  "85:14": "other layers across that you know",
  "85:16": "between those two values equally so",
  "85:20": "we're going to see that in a lot more",
  "85:21": "detail but basically for now this is",
  "85:25": "kind of a good rule of thumb is to say",
  "85:28": "when you after you unfreeze this is the",
  "85:31": "thing that's going to train the whole",
  "85:32": "thing past hey max learning rate",
  "85:35": "parameter pass it a slice make the",
  "85:39": "second part of that slice about 10 times",
  "85:42": "smaller than your first stage so our",
  "85:45": "first stage defaulted to about 1 in Dec",
  "85:47": "3 so let's use about what I knew for and",
  "85:48": "then this one should be a value from",
  "85:52": "your learning rate finder which is well",
  "85:54": "before things started getting worse and",
  "85:56": "you can see things",
  "85:57": "adding to get worse maybe about here so",
  "86:01": "I picked something that's at least ten",
  "86:02": "times smaller than that so if I do that",
  "86:04": "then I get 0.05 788 so I don't quite",
  "86:12": "remember what we got before now bit",
  "86:14": "better all right so we've gone down from",
  "86:16": "a six point one percent to a five point",
  "86:18": "seven percent so that's about a 10",
  "86:20": "percentage point relative improvement",
  "86:22": "with another 58 seconds of training so I",
  "86:26": "would perhaps save for most people most",
  "86:30": "of the time these two stages are enough",
  "86:32": "to get pretty much a world-class model",
  "86:36": "you won't win a Carol competition",
  "86:38": "particularly because now a lot faster I",
  "86:41": "am on liar are competing on Carol and",
  "86:42": "this is the first thing that they do but",
  "86:45": "it'll in practice you'll get something",
  "86:48": "that's you know about as good in",
  "86:50": "practice as the vast majority of",
  "86:52": "practitioners can do we can improve it",
  "86:57": "by using more layers and we'll do this",
  "86:59": "next week by basically doing a ResNet 50",
  "87:01": "instead of ResNet 34 and you can try",
  "87:05": "running this during the week if you want",
  "87:07": "to you'll see it's exactly the same as",
  "87:09": "before but I'm using resident 50 instead",
  "87:11": "of resident 34 what you'll find is it's",
  "87:15": "very likely if you try to do this you",
  "87:17": "will get an error and the error will be",
  "87:19": "your GPU is ran out of memory and the",
  "87:22": "reason for that is that resident 50 is",
  "87:23": "bigger than resident 34 and therefore it",
  "87:27": "has more parameters and therefore it",
  "87:28": "uses more of your graphics card memory",
  "87:30": "just totally separate to your normal",
  "87:32": "computer Ram this is GPU Ram if you're",
  "87:36": "using the kind of default salamander AWS",
  "87:41": "and so forth suggestion then you will be",
  "87:44": "having a 16 gig of compute the pad I use",
  "87:49": "most the time has 11 gig GPU memory the",
  "87:53": "cheaper ones have 8 gig of GPU memory",
  "87:55": "that's kind of the main range you tend",
  "87:57": "to get if you also has less than 8 gig",
  "87:59": "of GPU memory it's going to be",
  "88:01": "frustrating for you anyway so you'll be",
  "88:03": "somewhere around there and it's very",
  "88:05": "likely that we're trying to run this",
  "88:07": "you'll get",
  "88:08": "out of memory error and that's because",
  "88:10": "it's just trying to do too much too many",
  "88:12": "parameter updates for the amount of RAM",
  "88:14": "you have and that's easily fixed this",
  "88:18": "image data bunch constructor has a",
  "88:21": "parameter at the end batch size yes for",
  "88:24": "batch size and this basically says how",
  "88:26": "many images do you train at one time if",
  "88:29": "you run out of memory just make it",
  "88:31": "smaller okay",
  "88:32": "so this worked for me on an 11 gig card",
  "88:34": "it probably won't work for you if you've",
  "88:36": "got an 8 gig card if you do just make",
  "88:38": "that 32 it's fine to use a smaller batch",
  "88:43": "size it just it might take a little bit",
  "88:45": "longer that's all ok if you've got a big",
  "88:48": "oak like a 16 gig you might be able to",
  "88:50": "get away with 64 ok so that's just one",
  "88:52": "number you'll need to try during the",
  "88:53": "week and again we filled it for awhile",
  "88:56": "and we get down 44.4%",
  "89:01": "early so this is pretty extraordinary",
  "89:04": "you know I was pretty surprised because",
  "89:06": "I mean when we first did in the first",
  "89:10": "course does cats versus dogs really kind",
  "89:13": "of getting somewhere around a three",
  "89:16": "percent error for something where you've",
  "89:18": "got a fifty percent chance of being",
  "89:19": "right and the two things work totally",
  "89:20": "different so that we can get a four",
  "89:23": "point four percent error of assad's for",
  "89:24": "such a fine grain thing it's quite",
  "89:27": "extraordinary in this case I unfroze it",
  "89:31": "and fit it a little bit more than for",
  "89:33": "4.4 to 4.3 five it's a tiny improvement",
  "89:36": "basically risen at 50 is already a",
  "89:38": "pretty good model it's interesting",
  "89:43": "because again you can call the most",
  "89:45": "confused here and you can see the kinds",
  "89:48": "of things that it's getting wrong and I",
  "89:51": "actually depending on when you run it",
  "89:53": "you're going to get slightly different",
  "89:55": "numbers but you'll get roughly the same",
  "89:56": "kinds of things so quite often I find",
  "89:59": "that rag doll and bir-men of things that",
  "90:01": "it gets confused and I actually have",
  "90:02": "never heard of either of those things",
  "90:04": "so I actually looked them up on the",
  "90:06": "internet and I found a page on the cat",
  "90:12": "site called is this Superman or rag doll",
  "90:15": "and there is a long spread of cats",
  "90:19": "it's like arguing intentionally about",
  "90:22": "which it is so I feel fine that my",
  "90:25": "computer had problems I thoughtfully",
  "90:30": "similar I think was this pitbull versus",
  "90:31": "Staffordshire Bull Terrier",
  "90:32": "apparently the main difference is like",
  "90:34": "the particular Kennel Club guidelines as",
  "90:37": "to how they are assessed but some people",
  "90:40": "think that one of them might have a",
  "90:41": "slightly read in those so this is the",
  "90:43": "kind of stuff we're actually even if",
  "90:45": "you're not a domain expert it helps you",
  "90:48": "become one right because I now know more",
  "90:51": "about which kinds of pet breeds are hard",
  "90:53": "to identify than I used to so muddled",
  "90:56": "interpretation works both ways so what I",
  "90:59": "want you to do this week is to run this",
  "91:04": "notebook you know make sure you can get",
  "91:05": "through it but then what I really want",
  "91:07": "you to do is to get your own image data",
  "91:11": "set and actually um Francisco who I",
  "91:14": "mentioned earlier he started the",
  "91:16": "language to model thread and he's you",
  "91:18": "know now helping to TA the costs he's",
  "91:21": "actually putting together a dye it will",
  "91:23": "show you how to download data from",
  "91:25": "Google Images so you can create your own",
  "91:28": "data set to play with but before I do I",
  "91:31": "want to before I do I want to show you",
  "91:37": "because how to create labels in lots of",
  "91:40": "different ways because your data set",
  "91:43": "wherever you get it from won't",
  "91:44": "necessarily be that kind of regex based",
  "91:47": "approach it could be in lots of",
  "91:49": "different formats so it was telling you",
  "91:51": "how to do this I'm going to use the",
  "91:53": "feminist sample embolus is pictures of",
  "91:56": "hand drawn numbers I'm just because I",
  "91:58": "want to show you different ways of",
  "92:01": "creating these data sets the the Emnes",
  "92:09": "simple basically looks like this so I go",
  "92:13": "path LS and you can see it's got a",
  "92:18": "training set in the validation set",
  "92:19": "already so basically the people that put",
  "92:21": "together this data set have already",
  "92:23": "decided what they want you to use as a",
  "92:25": "validation set okay so if you go path",
  "92:27": "slash train dot LS you'll see there's a",
  "92:33": "Farva quadtree in a folder called seven",
  "92:35": "now this is really really common way to",
  "92:38": "just to give people labels it's",
  "92:40": "basically to say Oh everything that's a",
  "92:41": "three",
  "92:42": "I'll put in a folder called three",
  "92:43": "everything that's a seven I'll put in a",
  "92:45": "folder called seven this is a muffin",
  "92:47": "cordon imagenet style data set this is",
  "92:50": "the self-image net is distributed so if",
  "92:53": "you have something in this honor where",
  "92:55": "the labels just whatever the folders",
  "92:58": "called you can say from folder okay and",
  "93:01": "that will create an image data bunch for",
  "93:03": "you and as you can see 3/7 it's created",
  "93:07": "the labels just by using the folder",
  "93:09": "names",
  "93:11": "another possibility and as you can see",
  "93:13": "we can train there at 99.5% accuracy buh",
  "93:16": "buh buh",
  "93:17": "another possibility and for this M list",
  "93:19": "sample I've got both it might come with",
  "93:21": "a CSV file that would look something",
  "93:24": "like this for each file name",
  "93:26": "what's its label now in this case the",
  "93:28": "labels are three or seven they're 0 or 1",
  "93:31": "which is basically is it a 7 or not so",
  "93:33": "that's another possibility so if this is",
  "93:36": "how your labels are you can use from CSV",
  "93:38": "and if it's called labels dot CSV you",
  "93:41": "don't even have to pass in a file name",
  "93:43": "if it's called anything else then you",
  "93:45": "can call pass in the CSV labels bar",
  "93:48": "there okay so that's how you can use a",
  "93:49": "CSV okay there it is this is now is it a",
  "93:53": "7 or not and not the possibility and",
  "93:57": "then you can coordinated up classes to",
  "93:59": "see what them another possibility is as",
  "94:01": "we've seen this you've got paths that",
  "94:03": "look like this and so in this case this",
  "94:06": "is the same thing these are the folders",
  "94:08": "that I could actually grab the the label",
  "94:12": "by using a regular expression and so",
  "94:14": "here's the original expression so we've",
  "94:16": "already seen that approach and again you",
  "94:18": "can see that our classes is founded so",
  "94:21": "what if you it's something that's in the",
  "94:24": "file name of a path but it's not just a",
  "94:25": "regular expression it's more complex you",
  "94:28": "can create an arbitrary function that",
  "94:31": "extracts a label from the file name or",
  "94:33": "path and in that case you would say from",
  "94:35": "name and function another possibility is",
  "94:42": "that even you need something even more",
  "94:45": "flexible on there",
  "94:46": "and so you're going to write some code",
  "94:48": "to create an array of labels and so in",
  "94:51": "that case you can just pass him from",
  "94:53": "lists so here as I've created an array",
  "94:55": "of labels through my labels is from",
  "94:57": "lists okay and then I just pass in that",
  "95:00": "break so you can see there's lots of",
  "95:01": "different ways of creating labels so so",
  "95:03": "during the week try this out now you",
  "95:06": "might be wondering how would you know to",
  "95:08": "do all these things like where am I",
  "95:10": "going to find this kind of information",
  "95:13": "right now would I",
  "95:14": "how do you possibly know to do all this",
  "95:16": "stuff so I'll show you something",
  "95:18": "incredibly cool let's grab this function",
  "95:21": "and do you remember to get documentation",
  "95:24": "we type doc and here is the",
  "95:30": "documentation for the function and I can",
  "95:31": "click show in dots and it pops up the",
  "95:36": "documentation so here's the thing every",
  "95:40": "single line of code I just showed you",
  "95:42": "I took it this morning and I copied and",
  "95:45": "pasted it from the documentation so you",
  "95:48": "can see here the exact code that I just",
  "95:53": "used so the documentation for fast AI",
  "95:55": "doesn't just tell you what to do but",
  "95:59": "step to step how to do it and here is",
  "96:02": "perhaps the coolest bit if you go too",
  "96:05": "fast AI fast AI underscored drops and",
  "96:13": "click on drop sauce it turns out that",
  "96:18": "all of our documentation is actually",
  "96:20": "just stupid about books so in this case",
  "96:23": "I was looking at vision data so here is",
  "96:29": "the vision data notebook you can",
  "96:31": "download this repo you can get clone up",
  "96:33": "and if you run it you can actually run",
  "96:37": "every single line of the documentation",
  "96:39": "yourself okay so so all of our Doc's is",
  "96:45": "also code and so like this is the kind",
  "96:47": "of the ultimate example to me of of",
  "96:51": "experimenting right is that you can now",
  "96:56": "experiment and",
  "96:58": "you'll see in in github it doesn't quite",
  "97:00": "render properly this github doesn't",
  "97:02": "quite know how to render notebooks",
  "97:03": "properly but if you get plowing this and",
  "97:05": "open it up in Jupiter you can see it and",
  "97:08": "so now anything that you read about the",
  "97:10": "documentation nearly everything of the",
  "97:12": "documentation has actual working",
  "97:14": "examples in it with actual data sets",
  "97:16": "that are already sitting in there in the",
  "97:17": "repo for you and so you can actually try",
  "97:20": "every single function in your browser",
  "97:23": "try seeing what goes in and try seeing",
  "97:25": "what comes out there's a question and",
  "97:29": "can will the library use multi GPU and",
  "97:32": "parallel by default the library will use",
  "97:36": "multiple CPUs by default but just one",
  "97:38": "GPU by default we've probably what",
  "97:41": "you're looking at maka GPU into your pot",
  "97:43": "true it's easy to do and you'll find it",
  "97:45": "on the forum but most people won't be",
  "97:48": "needing to use that now and the second",
  "97:51": "question is whether the library can use",
  "97:54": "3d data centers in IR yes it can and",
  "98:01": "there is actually a forum thread about",
  "98:02": "that already although that's not as",
  "98:06": "developed as 2d yet but maybe by the",
  "98:07": "time the MOOC is out it will be so",
  "98:11": "before I wrap up I'll just show you an",
  "98:13": "example of the kind of interesting stuff",
  "98:15": "that you can do by doing this kind of",
  "98:19": "exercise remember earlier I mentioned",
  "98:21": "that one of our alums who works at",
  "98:24": "Splunk which is a nasdaq listed big",
  "98:27": "successful company created this new ad",
  "98:30": "fraud software this is actually how he",
  "98:33": "created it as part of a fast AI part one",
  "98:37": "class project he talked the telemetry of",
  "98:40": "the of users who had Splunk analytics",
  "98:43": "installed and watched their mouse",
  "98:45": "movements and included pictures of the",
  "98:47": "mouse movements he converted speed into",
  "98:50": "color and right and left clicks into",
  "98:53": "splotches he then took the exact code",
  "98:57": "that we saw with an earlier version of",
  "98:59": "the software and trained a CNN in",
  "99:01": "exactly the way we saw and use that at a",
  "99:05": "train his fraud model so he basically",
  "99:06": "took something which is not obviously a",
  "99:09": "picture and he turned it into a picture",
  "99:11": "I've got these fantastically good",
  "99:13": "results for police overall analysis",
  "99:16": "software so it they're pleased to think",
  "99:19": "creatively so if you're wanting to study",
  "99:21": "sounds a lot of people that study sounds",
  "99:24": "do it by actually creating a spectrogram",
  "99:26": "image and then sticking that into a",
  "99:29": "confident so there's a lot of cool stuff",
  "99:30": "you can do with this so during the week",
  "99:32": "yeah get your jet your GPU going try and",
  "99:35": "use your first notebook make sure that",
  "99:37": "you can use Lesson one and work through",
  "99:40": "it and then see if you can repeat the",
  "99:42": "process on your own data set get on the",
  "99:45": "forum and tell us any little success you",
  "99:47": "had it's like oh I spent three days",
  "99:49": "trying to get my GPU running and I",
  "99:51": "finally did any constraints you hit you",
  "99:56": "know try it for an hour or two but if",
  "99:58": "you get stuck please ask and if you're",
  "100:00": "able to successfully build a model with",
  "100:02": "a new data set let us know and I will",
  "100:05": "see you next week",
  "100:07": "[Laughter]"
}
