{
  "00:00": "welcome to lesson two where we're going",
  "00:04": "to be taking a deeper dive into computer",
  "00:08": "vision applications and taking some of",
  "00:11": "the amazing stuff that you've all been",
  "00:12": "doing during the week and going even",
  "00:14": "further so let's take a look before we",
  "00:17": "do a reminder that we have these two",
  "00:21": "really important topics on the forums",
  "00:25": "they're pinned at the top of the forum",
  "00:28": "category one is factory sources and",
  "00:30": "official course updates this is where if",
  "00:33": "there's something useful for you to know",
  "00:35": "during the course we will post there",
  "00:38": "nobody else can reply to that thread so",
  "00:40": "if you set that thread to watching and",
  "00:42": "notifications you're not going to be",
  "00:43": "bugged by anybody else except stuff that",
  "00:46": "we think you need to know for the course",
  "00:47": "and it's got all the official",
  "00:50": "information about how to get set up on",
  "00:52": "each platform please note a lot of",
  "00:54": "people post all kinds of other tidbits",
  "00:57": "about how they've set up things on",
  "01:00": "previous solutions or previous courses",
  "01:02": "or other places I don't recommend you",
  "01:04": "use those because these are the ones",
  "01:06": "that we're testing everyday and that the",
  "01:08": "folks involved in these platforms are",
  "01:09": "testing every day and they definitely",
  "01:11": "work okay so so I would strongly suggest",
  "01:14": "you follow those tips and if you do have",
  "01:18": "a question about using one of these",
  "01:20": "platforms please use these discussions",
  "01:22": "not some other topic that you create",
  "01:25": "because this way people that are",
  "01:27": "involved in these platforms will be able",
  "01:28": "to see it and things won't get messy and",
  "01:30": "then secondly for every lesson there",
  "01:35": "will be an official updates thread for",
  "01:39": "that lesson so lesson one official",
  "01:40": "updates and the same thing only first AI",
  "01:42": "people will be posting to that so you",
  "01:47": "can you can watch it safely and we'll",
  "01:48": "have all the things like the videos the",
  "01:50": "notebooks and so forth and they're all",
  "01:54": "wiki threads so you can help us to make",
  "01:56": "them better as well so I mentioned the",
  "01:59": "idea of watching a thread so this is a",
  "02:01": "really good idea is that you can go to a",
  "02:03": "thread like particularly those official",
  "02:05": "update ones and click at the bottom",
  "02:07": "watching ok and if you do that that's",
  "02:09": "going to enable notifications or any",
  "02:11": "updates to that thread",
  "02:13": "secondly if you go in to click on your",
  "02:14": "little user name in the top right",
  "02:16": "preferences and turn this on that'll get",
  "02:19": "gives you an email as well okay so any",
  "02:22": "of you that have missed some of the",
  "02:23": "updates so far go back and have a look",
  "02:25": "through because we're really trained to",
  "02:28": "make sure that we keep you updated with",
  "02:30": "anything that we think's important one",
  "02:33": "thing which can be more little",
  "02:34": "overwhelming is even now after just one",
  "02:36": "week the most popular thread has one",
  "02:39": "point 1000 replies so that's that's an",
  "02:42": "intimidating Li large number um I've",
  "02:45": "actually read every single one of them",
  "02:46": "and I know Rachel has and I know silver",
  "02:49": "has and I think Francisco has but you",
  "02:52": "shouldn't need to what you should do is",
  "02:55": "click summarize this topic and it'll",
  "02:58": "appear like this which is all of the",
  "03:00": "most liked ones will appear and then",
  "03:02": "they'll be view 31 hidden replies or",
  "03:04": "whatever in between so that's how you",
  "03:06": "navigate these giant topics that also",
  "03:09": "why it's important you click the like",
  "03:11": "button because that's the thing that's",
  "03:12": "going to cause people to to see it in",
  "03:15": "this recommended view so when you come",
  "03:21": "back to work hopefully you've realized",
  "03:23": "by now that on the official course",
  "03:25": "website course - v3 - faster day I you",
  "03:28": "will click returning to work you will",
  "03:30": "click the name of the platform you're",
  "03:31": "using and you will then follow the two",
  "03:34": "steps the step one will be how to make",
  "03:37": "sure that you've got the latest",
  "03:38": "notebooks and step two will be how to",
  "03:41": "make sure you've got the latest Python",
  "03:43": "library software okay",
  "03:44": "they all look pretty much like this but",
  "03:46": "they're slightly different from platform",
  "03:48": "to platform so please don't use some",
  "03:51": "different set of commands you read",
  "03:52": "somewhere else only use the commands",
  "03:54": "that you read about here and that will",
  "03:56": "make everything very smooth if things",
  "03:59": "aren't working for you if you get some",
  "04:01": "into some kind of Matthew situation",
  "04:02": "which we all do and you don't just",
  "04:06": "delete your instance and start again",
  "04:08": "unless you've got mission-critical stuff",
  "04:09": "there it's the easiest way just to get",
  "04:11": "out of a sticky situation and you know",
  "04:13": "if you follow the instructions here you",
  "04:16": "really should find it works fine",
  "04:20": "so this is what I really wanted to talk",
  "04:22": "about most of all is what people have",
  "04:24": "been doing this week if you've noticed",
  "04:27": "and a lot of you have so there's have",
  "04:29": "been a hundred and sixty-seven people",
  "04:30": "sharing their work and this is really",
  "04:33": "cool because it's pretty intimidating to",
  "04:35": "put yourself out there and say like I'm",
  "04:37": "new to all this but here's what I've",
  "04:39": "done and so example four things I",
  "04:41": "thought was really interesting was",
  "04:42": "figuring out who's talking is it Ben",
  "04:45": "Affleck or Joe Rogan I thought this is",
  "04:50": "really interesting this is like actually",
  "04:51": "very practical I wanted to clean up",
  "04:53": "while whatsapp downloaded images to get",
  "04:55": "rid of memes so I actually built a",
  "04:57": "little neural network I mean how cool is",
  "04:59": "that to say like oh yeah I've got",
  "05:01": "something that cleans up my whatsapp",
  "05:03": "it's a deep learning application I wrote",
  "05:05": "last week why not like it's so easy now",
  "05:07": "you can do stuff like this and then",
  "05:12": "there's been some really interesting",
  "05:15": "projects one was looking at the the",
  "05:20": "sounds data that was used in this paper",
  "05:23": "and in this paper they were trying to",
  "05:25": "figure out what kind of sound things",
  "05:28": "were and they got a as you would expect",
  "05:30": "since they published a paper they got a",
  "05:31": "state of the art of nearly 80% accuracy",
  "05:34": "Ethan Sutan then tried using the lesson1",
  "05:37": "techniques and got 80 point 5 percent",
  "05:40": "accuracy so I think this is pretty",
  "05:41": "awesome best as we know it's a new state",
  "05:44": "of the art for for this problem",
  "05:47": "maybe somebody since then has published",
  "05:49": "something we haven't found it yet they",
  "05:50": "take all of these of a slight grain of",
  "05:51": "salt but I've mentioned them on Twitter",
  "05:54": "and lots of people on Twitter follow me",
  "05:55": "so if everybody knew that there was a",
  "05:56": "much better approach I'm sure somebody",
  "05:58": "would have said so",
  "06:01": "this one is pretty cool Subash has a new",
  "06:03": "state of the art accuracy for for devin",
  "06:08": "gary text recognition i think he's got",
  "06:11": "it even higher than this now and this is",
  "06:13": "actually confirmed by the person on",
  "06:15": "twitter who created the data set like we",
  "06:17": "I don't think he had any idea he just",
  "06:19": "posted her here's a nice thing I did and",
  "06:20": "this guy on Twitter was like oh I made",
  "06:22": "that data set congratulations you've got",
  "06:24": "a new record so that was pretty cool I",
  "06:27": "really liked this poster milena Harley",
  "06:31": "she describes in",
  "06:33": "quite a bit of detail about the issue of",
  "06:36": "them miss fastest sizing cancers and the",
  "06:40": "use of point mutations and why that's a",
  "06:42": "challenging important problem and she's",
  "06:45": "got some nice pictures expert describing",
  "06:47": "like what she wants to do with this and",
  "06:48": "like how she can go about turning this",
  "06:51": "into pictures see this is the cool trick",
  "06:53": "right it's the same with this this",
  "06:55": "sounds one turning sounds into pictures",
  "06:58": "and then using the lesson1 approach and",
  "07:00": "here it's turning point mutations into",
  "07:03": "pictures and then using the lesson1",
  "07:05": "approach and what did she find it seems",
  "07:10": "that she's got a new strategy out result",
  "07:12": "by more than 30%",
  "07:13": "feeding the previous best somebody on",
  "07:16": "twitter who's a VP at a genomics",
  "07:17": "analysis company looked at this as well",
  "07:21": "and you know thought it looked to be a",
  "07:25": "state of the art in this particular",
  "07:26": "point mutation one as well",
  "07:28": "so that's pretty exciting so you can see",
  "07:31": "you know when we talked about last week",
  "07:32": "this idea that this simple process is",
  "07:36": "something which can take you a long way",
  "07:38": "it really can I will mention that you",
  "07:42": "know something like this one in",
  "07:43": "particular is is using a lot of domain",
  "07:45": "expertise like it's figuring out what",
  "07:48": "picture to create I wouldn't know how to",
  "07:51": "do that because I don't even really know",
  "07:53": "what a point mutation is let alone how",
  "07:55": "to create you know something that",
  "07:56": "visually is meaningful that a CNN could",
  "07:59": "recognize but the actual big learning",
  "08:02": "side is is actually pretty",
  "08:04": "straightforward another very cool result",
  "08:09": "from Simon Ellison and Natalie down they",
  "08:14": "created a cougar or not web application",
  "08:18": "over the weekend and won the science sex",
  "08:21": "Day award in San Francisco and so I",
  "08:25": "think that's pretty pretty fantastic so",
  "08:28": "lots of examples of people doing really",
  "08:30": "interesting work hopefully this will be",
  "08:33": "inspiring to you to think well this is",
  "08:36": "this is cool that I can do this with",
  "08:38": "what I've learned",
  "08:38": "it can also be intimidating to think",
  "08:40": "like wow these people are doing amazing",
  "08:42": "things but it's important to realize",
  "08:45": "that as a thousands of people during",
  "08:46": "this course",
  "08:47": "you know I'm just picking out the kind",
  "08:50": "of a few of the really amazing ones and",
  "08:53": "in fact Simon is one of these very",
  "08:55": "annoying people like Christine Payne who",
  "08:57": "talked about last week who seems to be",
  "08:58": "good at everything he does",
  "08:59": "he created Django when it's the world's",
  "09:01": "most popular web frameworks he founded a",
  "09:03": "very successful startup and bla bla bla",
  "09:04": "bla bla so you know one of these really",
  "09:06": "annoying people who tends to keep being",
  "09:09": "good at things now turns out he's good",
  "09:10": "at deep learning as well so you know",
  "09:12": "that's fine you know Simon can go and",
  "09:14": "win a hackathon on his first week of",
  "09:16": "playing with deep learning maybe it'll",
  "09:18": "take you two weeks to win your first",
  "09:20": "hackathon that's okay um and I think",
  "09:23": "like it's important to mention this",
  "09:24": "because there was this really inspiring",
  "09:25": "blog post this week from James Dellinger",
  "09:28": "who talked about how he created a bird",
  "09:31": "classifier",
  "09:31": "using the techniques from lesson one but",
  "09:34": "what I really found interesting was at",
  "09:35": "the end he said he he nearly didn't",
  "09:37": "start on deep learning at all because he",
  "09:40": "went through the scikit-learn website",
  "09:42": "which is one of the most important",
  "09:43": "libraries of python and he saw this and",
  "09:46": "he described in this blog post or how he",
  "09:48": "was just like that's not something I can",
  "09:50": "do it's not something I understand and",
  "09:52": "then this kind of realization of like oh",
  "09:53": "I can do useful things without reading",
  "09:57": "the Greek so I thought that was a really",
  "09:59": "cool message and I really want to",
  "10:02": "highlight actually Daniel Armstrong on",
  "10:04": "the forum I think really shows is a",
  "10:08": "great role model here which was here",
  "10:09": "saying I want to contribute to the",
  "10:11": "library and I looked at the docs and I",
  "10:14": "just started overwhelming and the next",
  "10:16": "message one day later was I don't know",
  "10:20": "what it is this is I didn't know how",
  "10:21": "much goes to it it caught me off guard",
  "10:23": "my brain shut down but I love the way it",
  "10:28": "forces me to learn so much and then one",
  "10:30": "day later I just submitted my first pull",
  "10:32": "request so I think that's also right",
  "10:35": "it's just kind of like it's okay to feel",
  "10:38": "intimidated there's a lot right but just",
  "10:40": "pick one piece and dig into it you don't",
  "10:43": "try and try and push a piece of code or",
  "10:45": "a documentation update or create a",
  "10:48": "classifier or whatever",
  "10:49": "so here's lots of cool classifiers",
  "10:51": "people have built it's been really",
  "10:53": "really inspiring Trinidad and Tobago",
  "10:57": "Islander versus macerator classifier a",
  "10:59": "zucchini this is cue",
  "11:01": "humbert classifier this one was really",
  "11:04": "nice this was taking the dog breeds dog",
  "11:08": "and cat breeds a thing from last week",
  "11:10": "and actually doing some exploratory work",
  "11:12": "to see what the main features were and",
  "11:14": "discovered that there they could have",
  "11:16": "create a hairiness and classifier and so",
  "11:20": "we're here we do have the most harried",
  "11:22": "dogs and the most bold cats so there are",
  "11:26": "you know interesting things you can do",
  "11:27": "with interpretation somebody else in the",
  "11:29": "forum took that and did the same thing",
  "11:30": "for anime to find that they had",
  "11:32": "accidentally discovered an anime",
  "11:33": "haircolor classifier we can now detect",
  "11:37": "the new versus the old panamanian buses",
  "11:40": "correctly apparently these are the new",
  "11:42": "ones I much prefer the old ones but",
  "11:44": "maybe that's just me this was a really",
  "11:48": "interesting Henri Pollachi discovered",
  "11:49": "that he can recognize with 85% accuracy",
  "11:52": "which of 110 City sorry which with 110",
  "11:56": "countries a satellite image is of which",
  "12:00": "you know is definitely got to be beyond",
  "12:03": "human performance of just about anybody",
  "12:05": "like I can't imagine anybody who can do",
  "12:08": "that in practice so that was fascinating",
  "12:12": "but ik+ classification with a hundred",
  "12:16": "percent accuracy those rewarded this",
  "12:20": "interesting one we actually went a",
  "12:21": "little bit further using some techniques",
  "12:22": "we'll be discussing in the next couple",
  "12:24": "of courses to build something that can",
  "12:26": "recognize complete or incomplete or",
  "12:28": "foundation buildings and actually plot",
  "12:30": "them on aerial satellite view",
  "12:34": "so lots and lots of fascinating projects",
  "12:38": "so don't worry it's only been one week",
  "12:40": "it doesn't mean everybody has to have",
  "12:42": "had a project out yet a lot of the folks",
  "12:44": "who already have a project out have done",
  "12:46": "a previous course so they've got a bit",
  "12:48": "of a head start but we'll see today how",
  "12:51": "you can definitely create your own",
  "12:53": "classifier this week so from today after",
  "12:58": "we dig a bit deeper into really how to",
  "13:01": "make these computer vision classifiers",
  "13:03": "and particular work well we're then",
  "13:06": "going to look at the same thing for text",
  "13:08": "we're then going to look at the same",
  "13:11": "thing for tabular data so they're kind",
  "13:12": "of like more like spreadsheets and",
  "13:14": "databases",
  "13:15": "then we're going to look at Labrador",
  "13:16": "filtering so we're going to",
  "13:19": "recommendation systems that's going to",
  "13:21": "take us into a topic called embeddings",
  "13:23": "which is basically a key underlying",
  "13:26": "platform behind these applications that",
  "13:30": "will take us back into more computer",
  "13:32": "vision and then back into more NLP so",
  "13:35": "the idea here is that it turns out that",
  "13:37": "it's it's much better for learning if",
  "13:39": "you kind of see things multiple times so",
  "13:43": "rather than being like okay that's",
  "13:44": "computer vision you won't see it again",
  "13:45": "for the rest of the course",
  "13:46": "we're actually going to come back to the",
  "13:48": "two key applications NLP and computer",
  "13:51": "vision a few weeks apart and that's",
  "13:53": "going to force your brain to realize",
  "13:54": "like oh I have to remember this it's not",
  "13:56": "just something I can throw away so we",
  "14:03": "are you know for people who have more of",
  "14:08": "a hard sciences kind of background in",
  "14:12": "particular a lot of folks find this hey",
  "14:18": "here's some code type it in start",
  "14:20": "running it approach rather than here's",
  "14:22": "lots of theory approach confusing and",
  "14:25": "surprising and odd at first and so for",
  "14:28": "those of those of you I just wanted to",
  "14:30": "remind you you know this basic tip which",
  "14:32": "is keep going now you're not expected to",
  "14:35": "remember everything yes you're not",
  "14:37": "expected to understand everything yet",
  "14:39": "you're not expected to know why",
  "14:41": "everything works yet you just want to be",
  "14:45": "in a situation where you can enter the",
  "14:47": "code and you can run it and you can get",
  "14:50": "something happening and then you can",
  "14:51": "start to experiment and you kind of get",
  "14:54": "a feel for what's going on and then push",
  "14:57": "on right most of the people who have",
  "15:00": "done the course and have gone on to be",
  "15:01": "really successful watch the videos at",
  "15:03": "least three times so they kind of go",
  "15:04": "through the whole lot and then go",
  "15:06": "through it slowly the second time then",
  "15:08": "they go through it really slowly the",
  "15:10": "third time and I consistently hear them",
  "15:11": "say I get a lot more out of it each time",
  "15:14": "I go through so don't pause at lesson",
  "15:16": "one and stop until you can continue so",
  "15:21": "um this approach is based on a lot of a",
  "15:26": "research academic research into learning",
  "15:28": "theory",
  "15:29": "and one guy in particular david perkins",
  "15:31": "from harvard has this really great",
  "15:33": "analogy he's a researcher into learning",
  "15:36": "theory he describes this approach of the",
  "15:38": "whole game which is basically if you're",
  "15:40": "teaching a kid to play soccer you don't",
  "15:43": "you know first of all teach them about",
  "15:45": "you know how the friction between a ball",
  "15:47": "and grass works and then teach them how",
  "15:49": "to so soccer ball with their bare hands",
  "15:52": "and then teach them the mathematics of",
  "15:55": "parabolas when you kick something in the",
  "15:56": "air no is a here's a ball let's watch",
  "16:00": "some people playing soccer okay now",
  "16:01": "we'll play soccer and then you you know",
  "16:03": "gradually over the following years learn",
  "16:06": "more and more so that you can get better",
  "16:07": "and better at it so this is kind of what",
  "16:09": "we're trying to get you to do is to play",
  "16:11": "soccer which in our case is to type code",
  "16:14": "and look at the inputs and look at the",
  "16:16": "outputs okay so let's dig into our first",
  "16:25": "notebook which is called lesson to",
  "16:27": "download and what we're going to do is",
  "16:30": "we're going to see how to create your",
  "16:34": "own classifier with your own images so",
  "16:38": "it's going to be a lot like last week's",
  "16:40": "tech detector but it'll detect whatever",
  "16:43": "you like so to be like those some of",
  "16:45": "those examples we just saw how would you",
  "16:47": "create your own Panama bus detector from",
  "16:51": "scratch so this is inspired the",
  "16:56": "approaches inspired by Adrian Rose Brock",
  "16:59": "who has a terrific website called pie",
  "17:00": "image search and he has this nice",
  "17:04": "explanation of how to create a data set",
  "17:07": "using Google images so that was",
  "17:09": "definitely an inspiration for some of",
  "17:11": "the techniques we use here so thank you",
  "17:12": "to Adrian and you should definitely",
  "17:14": "check out his site it's a really it's",
  "17:16": "full of lots of good resources so so",
  "17:22": "here we are so we are going to try to",
  "17:24": "create a teddy bear detector thanks",
  "17:31": "we're going to try and make a teddy bear",
  "17:33": "detector and we're going to try and",
  "17:35": "separate teddy bears from black bears",
  "17:38": "from grizzly bears now this is very",
  "17:40": "important",
  "17:42": "I have a three year old daughter and she",
  "17:44": "needs to know what she's dealing with in",
  "17:47": "our house you would be surprised at the",
  "17:49": "number of monsters lions and other",
  "17:52": "terrifying threats that are around",
  "17:53": "particularly around Halloween and so we",
  "17:55": "always need to be on the lookout to make",
  "17:57": "sure that the thing we're about to",
  "17:59": "cuddle is in fact a genuine teddy bear",
  "18:02": "okay",
  "18:02": "so let's deal with that with that",
  "18:04": "situation as best as we can so our",
  "18:07": "starting point is to find some pictures",
  "18:09": "of teddy bears so we can learn what they",
  "18:12": "look like so I got a images.google.com",
  "18:15": "and I type in teddy bear and I just",
  "18:22": "scroll through until I kind of find a",
  "18:25": "goodly bunch of them and it's like okay",
  "18:29": "that looks like funny of teddy bears to",
  "18:31": "me so then I'll go back to here so you",
  "18:36": "can see it says search and scroll go to",
  "18:37": "Google Images and search and the next",
  "18:40": "thing we need to do is to get a list of",
  "18:42": "all of the URLs there and so to do that",
  "18:44": "you back in your google images you hit",
  "18:48": "ctrl shift J or command option J and you",
  "18:51": "paste this into the window that appears",
  "18:58": "so I've got Windows so I go ctrl shift J",
  "19:04": "paste in that code so this is a",
  "19:06": "JavaScript console for those of you you",
  "19:08": "haven't done in JavaScript before I hit",
  "19:10": "enter and it downloads my file for me so",
  "19:14": "I would call this Teddy's dot txt and",
  "19:18": "press save okay so I now have a file of",
  "19:24": "Teddy's or URLs of Teddy's so then I",
  "19:28": "would repeat that process for black",
  "19:31": "bears and for brown bears since that's a",
  "19:34": "classifier I would want to now put each",
  "19:35": "one in a file with an appropriate name",
  "19:37": "so that's step one so step two is we now",
  "19:41": "need to download those URLs to our",
  "19:45": "server just remember it when we're using",
  "19:47": "Jupiter notebook it's not running on our",
  "19:49": "computer it's running on sage maker or",
  "19:52": "Kressel or G Google Play",
  "19:55": "or whatever so to do that we have we",
  "19:59": "start running some Jupiter cells so",
  "20:01": "let's grab the first AI library and",
  "20:03": "let's start with black bears I've",
  "20:06": "already got my black bears URL so I",
  "20:08": "click on this cell for black bears and",
  "20:09": "I'll run it so here I've got three",
  "20:12": "different cells with doing the same",
  "20:15": "thing but different information this is",
  "20:17": "this is one way I like to work with",
  "20:18": "Jupiter notebook it's something that a",
  "20:20": "lot of kind of people with a more strict",
  "20:23": "scientific background are horrified by",
  "20:25": "this is not reproducible research I",
  "20:27": "actually click here and I run this cell",
  "20:28": "to create a folder called black and a",
  "20:31": "file called URLs black for my black",
  "20:33": "bears I skip the next two cells and then",
  "20:35": "I run this cell to create that folder",
  "20:40": "okay and then I go down to the next",
  "20:44": "section and I run the next cell which is",
  "20:48": "download images for black bears right so",
  "20:53": "that's just going to download my black",
  "20:55": "bears to that folder and then I'll go",
  "20:57": "back and I'll click on Teddy's and I run",
  "21:00": "that cell and then scroll back down and",
  "21:02": "I'll run this cell and so that way I'm",
  "21:05": "just going backwards and forwards to",
  "21:06": "download each of the classes that I want",
  "21:08": "very manual but for me I'm very",
  "21:12": "iterative and very experimental that",
  "21:14": "works well for me if you're better at",
  "21:16": "kind of planning ahead than I am you can",
  "21:18": "you know write a proper loop or whatever",
  "21:20": "and and do it that way so but when you",
  "21:23": "see my notebooks and see things where",
  "21:26": "there's kind of like configuration cells",
  "21:28": "doing the same thing in different places",
  "21:30": "this is a strong sign that I I didn't",
  "21:33": "run this in order right I clicked one",
  "21:35": "place went to another around that went",
  "21:37": "back went back went back and for me I",
  "21:39": "just I'm an experimentalist I really",
  "21:42": "liked to to experiment in my book I",
  "21:45": "treat it like a lab journal I try things",
  "21:47": "out may see what happens and so this is",
  "21:49": "how my notebooks end up looking it's a",
  "21:52": "really controversial topic like for a",
  "21:54": "lot of people they feel this is like",
  "21:56": "wrong that you should only ever run",
  "21:59": "things top to bottom everything you",
  "22:00": "should do should be reproducible for me",
  "22:02": "I don't think that's the best way of",
  "22:04": "using human creativity I think human",
  "22:07": "creativity is best in",
  "22:09": "by trying things out seeing what happens",
  "22:11": "and fiddling around so you can see how",
  "22:13": "you go see what works for you so that",
  "22:17": "will download the images to your server",
  "22:20": "it's going to use multiple processes to",
  "22:24": "do so and one problem there is if is if",
  "22:27": "something goes wrong it's a bit hard to",
  "22:29": "see what went wrong so you can see in",
  "22:31": "the next section there's a commented out",
  "22:32": "section that says max workers equals",
  "22:35": "zero and that'll do it without spitting",
  "22:37": "up a bunch of processes and will tell",
  "22:39": "you the errors better so if if things",
  "22:41": "aren't downloading try using the second",
  "22:43": "version okay so it takes so I you know",
  "22:47": "grabbed a small number of each and then",
  "22:51": "the next thing that I found I needed to",
  "22:52": "do was to remove the images that aren't",
  "22:55": "actually images at all and this happens",
  "22:57": "all the time there's always a few images",
  "22:59": "in every batch that are corrupted for",
  "23:03": "whatever reason you know Google Image",
  "23:05": "tried to told us that this URL had an",
  "23:07": "image but actually it doesn't anymore so",
  "23:10": "I've got we've got this thing in the",
  "23:11": "library called verify images which will",
  "23:14": "check all of the images in a path and",
  "23:16": "will tell you if there's a problem if",
  "23:19": "you say delete equals true it will",
  "23:21": "actually delete it for you okay so",
  "23:23": "that's a really nice easy way to end up",
  "23:25": "with a clean data set so at this point I",
  "23:29": "now have a bears folder containing a",
  "23:33": "grizzly folder and a Teddy's folder and",
  "23:35": "the black folder in other words I have",
  "23:38": "the basic structure we need to create an",
  "23:40": "image data bunch to start doing some",
  "23:42": "deep learning so let's go ahead and do",
  "23:44": "that now very often when you get when",
  "23:51": "you download a data set from like Kaggle",
  "23:53": "or from some academic data set there",
  "23:56": "will often be a folder called train and",
  "23:59": "a folder called valid and a folder",
  "24:01": "called test right containing the",
  "24:03": "different data sets in this case we",
  "24:06": "don't have a separate validation set",
  "24:07": "because we just rid of grab these images",
  "24:10": "from Google search right but you still",
  "24:13": "need a validation set otherwise you",
  "24:16": "don't know how well your model is going",
  "24:18": "and we'll talk about more about this in",
  "24:19": "a moment so whatever you create a data",
  "24:22": "bunch",
  "24:23": "if you don't have a separate training",
  "24:25": "and validation set then you can just say",
  "24:27": "okay well the training set is in the",
  "24:29": "current folder because by default it",
  "24:31": "looks in a folder called train and I",
  "24:33": "want you to set aside 20 percent of the",
  "24:36": "data please so this is going to create a",
  "24:38": "validation set for you automatically and",
  "24:40": "randomly you'll see that whenever I",
  "24:43": "create a validation set randomly I",
  "24:46": "always set my random seed to something",
  "24:48": "fixed beforehand this means that every",
  "24:51": "time I run this code I'll get the same",
  "24:53": "validation set so in general I'm not a",
  "24:59": "fan of making my machine learning",
  "25:03": "experiments reproducible are you",
  "25:05": "ensuring I get exactly the same result",
  "25:07": "every time the randomness is to me",
  "25:09": "really important a really important part",
  "25:11": "of planning out is your solution stable",
  "25:13": "you know these are going to work like",
  "25:14": "each time you run it but what is",
  "25:17": "important is that you always have the",
  "25:18": "same validation set but otherwise when",
  "25:21": "you're trying to decide has this hyper",
  "25:24": "parameter change improved my model but",
  "25:26": "you've got a different set of data",
  "25:28": "you're testing it on then you don't know",
  "25:30": "maybe that set of data it just happens",
  "25:31": "to be a bit easier okay so that's why I",
  "25:34": "always said the random seed here",
  "25:37": "so we've now gone let's run that cell so",
  "25:40": "we've now got a data bunch and so you",
  "25:43": "can look inside at the data classes and",
  "25:46": "you'll see these are the folders that we",
  "25:48": "created so it knows that the classes or",
  "25:51": "you know so by classes we main all the",
  "25:52": "possible labels black bear grizzly bear",
  "25:55": "or teddy bear we can run show batch and",
  "25:58": "we can take a little look and it tells",
  "26:02": "us straight away that some of these are",
  "26:03": "going to be a little bit tricky so this",
  "26:06": "is not a photo for instance some of them",
  "26:11": "kind of crops funny some of them might",
  "26:15": "be tricky like if you ended up with a",
  "26:16": "black bear standing on top of a grizzly",
  "26:18": "bear that might be tough anyway so you",
  "26:21": "can kind of double check here data type",
  "26:22": "classes there they are remember C is the",
  "26:25": "attribute which the classifiers tells us",
  "26:28": "how many possible labels that are we'll",
  "26:30": "learn about some other more specific",
  "26:31": "meanings at C later we can see how many",
  "26:34": "things around now training set",
  "26:37": "we can see how many things are in our",
  "26:38": "validation set so we've got 473 trading",
  "26:46": "set 141 validation set so at that point",
  "26:50": "we can go ahead you'll see all these",
  "26:51": "commands are identical to the pet",
  "26:53": "classifier from last week we can create",
  "26:56": "our CNN our convolutional neural network",
  "26:59": "using that data I tend to default using",
  "27:02": "a resin at 34 and let's print out the",
  "27:05": "error rate each time and run fit one",
  "27:08": "cycle four times and see how we go and",
  "27:11": "we have a two percent error rate so",
  "27:14": "that's pretty good I personally aren't",
  "27:16": "for I mean some sometimes it's easy for",
  "27:18": "me to recognize a black bear from a",
  "27:19": "grizzly bear but sometimes it's a bit",
  "27:21": "tricky this one seems to be doing pretty",
  "27:23": "well okay so after I kind of make some",
  "27:32": "progress with my model and things",
  "27:33": "looking good I always like to save where",
  "27:35": "I'm up to to save me the 54 seconds of",
  "27:37": "going back and doing it again and as",
  "27:39": "very usual we unfreeze the rest of our",
  "27:42": "model we're going to be learning more",
  "27:43": "about what that means during the course",
  "27:45": "and then we run the learning rate finder",
  "27:49": "and plot it tells you exactly what to",
  "27:51": "type and we take a look now we're going",
  "27:54": "to be learning about learning rates",
  "27:56": "today actually but for now here's what",
  "27:59": "you need to know on the learning rate",
  "28:01": "finder what you're looking for is the",
  "28:03": "strongest downward slope that's kind of",
  "28:07": "sticking around for quite awhile right",
  "28:10": "so this one here looks more like a bump",
  "28:12": "but this looks like an actual downward",
  "28:14": "slope to me so it's kind of like it's",
  "28:16": "something you're going to have to",
  "28:17": "practice with and get a feel for like",
  "28:19": "what which fit works so like if you're",
  "28:22": "not sure is it this bit or this bit try",
  "28:25": "both learning rates and see which one",
  "28:27": "works better",
  "28:28": "okay but I'm I've been doing this for a",
  "28:30": "while and I'm pretty sure this looks",
  "28:32": "like where it's really learning properly",
  "28:34": "so I would pick something okay here it's",
  "28:37": "not so steep so I would probably pick",
  "28:39": "something back here for my learning rate",
  "28:43": "so you can see I picked three next five",
  "28:47": "so you know somewhere around here that",
  "28:50": "sounds pretty good so that's for my",
  "28:52": "bottom learning rate so my top learning",
  "28:54": "rate I normally pick you know one a neg",
  "28:57": "four or three neg four it's kind of like",
  "28:59": "I don't really think about it too much",
  "29:00": "that's a rule of thumb it always works",
  "29:02": "pretty well one of the things you'll",
  "29:05": "realize is that most of these parameters",
  "29:09": "don't actually matter that much in",
  "29:11": "detail if you just copy the numbers that",
  "29:14": "I use each time it'll the vast majority",
  "29:17": "the time it'll just work fine and we'll",
  "29:19": "see places where it doesn't today okay",
  "29:22": "so we've got a one point four percent",
  "29:24": "error rate after doing another couple of",
  "29:26": "epochs so that's looking great so we've",
  "29:28": "downloaded some images from Google Image",
  "29:31": "Search and created a classifier we've",
  "29:34": "got one point four percent error rate",
  "29:35": "let's save it and then as per usual we",
  "29:40": "can use the classification",
  "29:41": "interpretation class to have a look at",
  "29:44": "what's going on and in this case we made",
  "29:46": "one mistake there was one black bear",
  "29:49": "classified as grizzly bear so that's",
  "29:54": "that's a really good step we come a long",
  "29:57": "way but possibly you could do even",
  "30:01": "better if your data set was less noisy",
  "30:04": "like maybe Google Image Search didn't",
  "30:08": "give you exactly the right images all",
  "30:10": "the time so how do we fix that and so we",
  "30:13": "want to we want to clean it up and so",
  "30:15": "combining a human expert with a computer",
  "30:19": "learner is a really good idea almost not",
  "30:22": "no-nobody but very very few people",
  "30:24": "publish on this very very few people",
  "30:25": "teach this but to me it's like the most",
  "30:29": "useful skill particularly for you you",
  "30:31": "know most of the people watching this at",
  "30:33": "domain experts not computer science",
  "30:35": "experts and so this is where you can use",
  "30:38": "your knowledge of you know point",
  "30:41": "mutations in genomics or panamanian",
  "30:43": "buses or whatever so let's see how that",
  "30:46": "would work what I'm going to do is do",
  "30:49": "you remember the plot top losses from",
  "30:51": "last time where we saw the images which",
  "30:52": "it was like either the most wrong about",
  "30:55": "or the least confident about we're going",
  "30:57": "to look at those",
  "30:58": "and decide which of those are noisy like",
  "31:02": "if you think about it it's very unlikely",
  "31:05": "that if there is a mislabeled data that",
  "31:09": "it's going to be predicted correctly and",
  "31:11": "with high confidence but that that's",
  "31:13": "really unlikely to happen so we're going",
  "31:15": "to focus on the on the ones which the",
  "31:18": "model is saying either it's not",
  "31:20": "confident of or it was confident of that",
  "31:23": "it was wrong about they are the things",
  "31:25": "which might be mislabeled so a big",
  "31:31": "shout-out to the San Francisco fast AI",
  "31:34": "study group who created this new widget",
  "31:37": "this week called the failed Aleta so",
  "31:41": "that's Zach and Jason and Francisco",
  "31:45": "built this thing where we basically can",
  "31:47": "take the top losses from that",
  "31:50": "interpretation object we just created",
  "31:52": "right and then what we're going to do is",
  "31:55": "we're going to say okay that returns top",
  "31:57": "loss it there's not just plot top losses",
  "31:59": "but there's also just top losses and top",
  "32:01": "losses returns two things the losses of",
  "32:04": "the things that were the worst and the",
  "32:07": "indexes into the data set the things",
  "32:10": "that were the worst and if you don't",
  "32:11": "pass anything at all it's going to",
  "32:13": "actually return the entire data set but",
  "32:16": "sorted so the first things will be the",
  "32:19": "highest losses as we learned during the",
  "32:22": "course or will keep ginger in the course",
  "32:24": "every data set in fast AI has an X and a",
  "32:29": "Y and the X contains the things that are",
  "32:31": "used to in this case get the images so",
  "32:34": "this is the image file names and the Y's",
  "32:36": "will be the labels so if we grab the",
  "32:39": "indexes and pass them into the data set",
  "32:41": "X this is going to give us the file",
  "32:45": "names of the data set ordered by which",
  "32:49": "ones had the highest loss so which ones",
  "32:52": "it was either confident and wrong about",
  "32:54": "or not confident about and so we can",
  "32:58": "pass that to this new widget that",
  "33:00": "they've created called the file 2-liter",
  "33:02": "widget",
  "33:07": "so just to clarify this top plus past",
  "33:10": "contains all of the file names in our",
  "33:14": "dataset",
  "33:14": "when I think it our data set and this",
  "33:16": "particular one is in our validation data",
  "33:18": "set so what this is going to do is it's",
  "33:20": "going to clean up mislabeled images or",
  "33:25": "images that shouldn't be there and we're",
  "33:29": "going to remove them from a validation",
  "33:30": "set so that our metrics will be more",
  "33:32": "correct you then need to rerun these two",
  "33:36": "steps replacing valid des with trained",
  "33:38": "yes",
  "33:39": "to clean up your training set to get the",
  "33:41": "noise out of that as well so it's a good",
  "33:44": "practice to do both",
  "33:46": "we'll talk about test sets later as well",
  "33:48": "if you also have a test set you would",
  "33:50": "then repeat the same thing so we run",
  "33:53": "failed a leader passing in that sort of",
  "33:56": "list of paths and so what pops up is",
  "33:59": "basically the same thing as plot top",
  "34:02": "losses so in other words these are the",
  "34:05": "ones which is either wrong about or at",
  "34:08": "least confident about and so not",
  "34:10": "surprisingly this one here does not",
  "34:12": "appear to be a teddy bear or a black",
  "34:16": "bear or a brown bear right so this",
  "34:18": "shouldn't be in our data set so what I",
  "34:20": "do is I work on the delete button okay",
  "34:24": "and all the rest do look indeed like",
  "34:26": "bears and then so I can click confirm",
  "34:28": "and it'll bring up another five what's",
  "34:32": "that is that's not a bear is it so",
  "34:35": "anybody know what that is I'm going to",
  "34:38": "say that's not a bear delete confirm oh",
  "34:43": "not there well that's a teddy bear I'll",
  "34:47": "leave that that's not really I'll get",
  "34:49": "rid of that one",
  "34:50": "confirm okay so what I tend to do when I",
  "34:54": "do this is I'll keep going confirm until",
  "34:57": "I get to a couple of screen for the",
  "34:58": "things that all look okay and that",
  "35:00": "suggests to me that I've kind of got",
  "35:02": "past the worst bits of the data okay and",
  "35:05": "that's it and so now you can go back",
  "35:07": "once you do it for the training set as",
  "35:09": "well and retrain your model so I'll just",
  "35:13": "note here that what our San Francisco",
  "35:16": "study group did here was that they",
  "35:18": "actually built a little app",
  "35:20": "inside Jupiter notebook which you might",
  "35:23": "not have realized as possible but not",
  "35:25": "only is it possible it's actually",
  "35:28": "surprisingly straightforward and just",
  "35:31": "like everything else you can hit double",
  "35:32": "question mark to find out their secrets",
  "35:35": "so here is the source code okay and",
  "35:38": "really if you've done any GUI",
  "35:41": "programming before it'll look incredibly",
  "35:44": "normal you know there's there's",
  "35:47": "basically callbacks for what happens",
  "35:48": "when you click on a button where you",
  "35:50": "just do standard Python things and to",
  "35:53": "actually render it you just use widgets",
  "35:56": "and you can lay it out using standard",
  "35:58": "boxes and whatever so it's it this idea",
  "36:03": "of creating applications inside",
  "36:05": "notebooks is like it's really underused",
  "36:08": "but it's super neat because it lets you",
  "36:10": "create tools for your fellow",
  "36:13": "practitioners to your fellow",
  "36:14": "experimenters right and you could",
  "36:17": "definitely envisage taking this a lot",
  "36:20": "further in fact by the time you're",
  "36:21": "watching this on the MOOC you will",
  "36:23": "probably find that there's a whole lot",
  "36:25": "more buttons here because we've already",
  "36:26": "got a long list of to do that we're",
  "36:28": "going to add to this particular thing so",
  "36:33": "so that's it so I think like I'd love",
  "36:38": "for you to have a think about now that",
  "36:40": "you know it's possible to write",
  "36:42": "applications in your notebook what are",
  "36:44": "you going to write and if you google for",
  "36:47": "I PI widgets you can learn about the",
  "36:52": "little GUI framework to find out what",
  "36:56": "kind of widgets you can creation what",
  "36:58": "they look like and how they work and so",
  "37:00": "forth and you'll find it's you know it's",
  "37:02": "actually a pretty you know complete GUI",
  "37:06": "programming environment you can play",
  "37:09": "with and this will all work nicely with",
  "37:11": "your models and so forth it's not a",
  "37:14": "great way to productionize an",
  "37:16": "application because it is sitting inside",
  "37:18": "a notebook this is really for things",
  "37:20": "which are going to help other",
  "37:23": "practitioners other experimentalists and",
  "37:26": "so forth for production izing things you",
  "37:30": "need to actually build a production web",
  "37:33": "app which",
  "37:34": "look at next okay so after you have",
  "37:39": "cleaned up your noisy images you can",
  "37:43": "then retrain your model and hopefully",
  "37:45": "you'll find it's a little bit more",
  "37:46": "accurate one thing you might be",
  "37:48": "interested to discover when you do this",
  "37:50": "is it actually doesn't matter most of",
  "37:53": "the time very much now I'm on the whole",
  "37:55": "these models are pretty good at dealing",
  "37:58": "with moderate amounts of noisy data the",
  "38:03": "problem would occur is if your data was",
  "38:06": "not randomly noisy but biased noisy so I",
  "38:10": "guess the main thing I'm saying is if",
  "38:11": "you go through this process of cleaning",
  "38:13": "up your data and then rerun your model",
  "38:15": "and point it's like point zero one",
  "38:16": "percent better that's normal",
  "38:19": "okay that's that's it's fine but it's",
  "38:21": "still a good idea just to make sure that",
  "38:22": "you don't have too much noise in your",
  "38:25": "data in case it is biased so at this",
  "38:27": "point we're ready to put our model in",
  "38:30": "production and this is where I hear a",
  "38:34": "lot of people ask me about you know",
  "38:37": "which mega Google Facebook highly",
  "38:42": "distributed serving system they should",
  "38:45": "use and how do they use a thousand GPUs",
  "38:48": "at the same time and whatever else for",
  "38:51": "the bath bath vast majority of things",
  "38:53": "that you all do you will want to",
  "38:56": "actually run in production on a CPU not",
  "38:59": "a GPU why is that because the GPU is",
  "39:02": "good at doing lots of things at the same",
  "39:04": "time but unless you have a very busy",
  "39:06": "website it's pretty unlikely that you're",
  "39:08": "going to have 64 images to classify at",
  "39:11": "the same time to put into a batch into a",
  "39:14": "GPU and if you did you've got to deal",
  "39:16": "with all that queuing and running it all",
  "39:18": "together all of your users have to wait",
  "39:20": "until that batch has got filled up and",
  "39:21": "run it's a whole lot of hassle right and",
  "39:24": "then if you want to scale that there's",
  "39:26": "another whole lot of hassle it's much",
  "39:28": "easier if you just wrap one thing throw",
  "39:32": "it at a CPU to get it done and it comes",
  "39:34": "back again so yes it's going to take you",
  "39:38": "know maybe 10 or 20 times longer right",
  "39:41": "so maybe it'll take 0.2 seconds rather",
  "39:44": "than 0.01 seconds that's about the kind",
  "39:47": "of times we talk",
  "39:47": "about but it's so easy to scale all",
  "39:50": "right you can chuck it on any standard",
  "39:52": "serving infrastructure it's going to be",
  "39:54": "cheap as hell",
  "39:55": "you can horizontally scale it really",
  "39:57": "easily okay so most people I know who",
  "40:00": "are running apps that aren't kind of at",
  "40:02": "Google scale based on deep learning are",
  "40:04": "using CPUs and the term we use is",
  "40:07": "inference right so when you're running",
  "40:09": "when you're not training a model but",
  "40:11": "you've got a trained model and you're",
  "40:12": "getting to predict things we call that",
  "40:14": "inference so that's why we see here you",
  "40:16": "probably want to use CPU for inference",
  "40:21": "so at inference time you've got your pre",
  "40:24": "trained model you saved those weights",
  "40:26": "and how are you going to use them to",
  "40:29": "create something like Simon relations",
  "40:31": "cougar detector well first thing you're",
  "40:34": "going to need to know is what were the",
  "40:35": "classes that you trained with right you",
  "40:39": "need to not know not just what are they",
  "40:41": "but what were the order okay so you will",
  "40:44": "actually need to like serialize that or",
  "40:47": "just type them in or in some way make",
  "40:49": "sure you've got exactly the same classes",
  "40:51": "that you trained with if you don't have",
  "40:56": "a GPU on your server it will use the CPU",
  "40:59": "automatically if you want to test if you",
  "41:02": "have a GPU machine and you want to test",
  "41:04": "using a CPU you can just uncomment this",
  "41:06": "line and that tells first AI that you",
  "41:09": "want to use CPU by passing it back to",
  "41:13": "pay torch so here's an example we're not",
  "41:16": "we don't have a cougar detector we have",
  "41:18": "a teddy bear detector and my daughter",
  "41:21": "Claire is about to decide whether to",
  "41:23": "cuddle his friend okay so what she does",
  "41:26": "is she takes daddy's deep learning model",
  "41:29": "and she gets a picture of this and",
  "41:31": "here's a picture that she's uploaded to",
  "41:32": "the web app okay and here's a picture of",
  "41:35": "the potentially cattle some object and",
  "41:39": "so we're going to store that in a",
  "41:40": "variable called image so open image is",
  "41:42": "how you open an image in fast AI finally",
  "41:44": "enough here is that list of classes that",
  "41:48": "we saved earlier and so as per usual we",
  "41:52": "created a data bunch but this time we're",
  "41:55": "not going to create a data bunch from a",
  "41:57": "folder full of images we're going to",
  "42:00": "create a special kind of data bunch",
  "42:01": "which is one that's going to grab one",
  "42:03": "single image at a time so we're not",
  "42:06": "actually passing at any data the only",
  "42:09": "reason we pass it a path is so that it",
  "42:11": "knows where to load our model from right",
  "42:13": "that's just the path that's the folder",
  "42:15": "that the model is going to be in but",
  "42:18": "what we do need to do is that we need to",
  "42:19": "pass it the same information that we",
  "42:21": "trained with so the same transforms the",
  "42:23": "same size the same normalization this is",
  "42:26": "all stuff we'll learn more about but",
  "42:28": "just make sure it's the same stuff that",
  "42:29": "you use the port and so now you've got a",
  "42:31": "data bunch that actually doesn't have",
  "42:33": "any data in it at all it's just",
  "42:35": "something that knows how to transform a",
  "42:38": "new image in the same way that you",
  "42:40": "trained with so that you can now do",
  "42:41": "inference so you can now create a CNN",
  "42:45": "with this kind of fake data bunch and",
  "42:47": "again you would use exactly the same",
  "42:49": "model that you trained with you can now",
  "42:52": "load in those saved weights okay and so",
  "42:55": "this is the stuff that you do once just",
  "42:58": "once when your web app starting up okay",
  "43:00": "and it takes you know 0.1 of a second to",
  "43:02": "run this code and then you just go learn",
  "43:05": "to predict image and it's lucky we did",
  "43:09": "that because it is not a teddy bear this",
  "43:12": "is actually a black bear so thankfully",
  "43:14": "due to this excellent deep learning",
  "43:18": "model my daughter will avoid having a",
  "43:21": "very embarrassing black bear cut or",
  "43:24": "incident so what does this look like in",
  "43:28": "production well I took Simon Wilson's",
  "43:31": "code and shamelessly stole it made it",
  "43:35": "probably a little bit worse and but",
  "43:38": "basically it's going to look something",
  "43:39": "like this so Simon used a really cool",
  "43:41": "web app toolkit called starlett if",
  "43:44": "you've ever used flask",
  "43:46": "this will look extremely similar but",
  "43:47": "it's kind of a more modern approach by",
  "43:51": "modern what I really mean is that you",
  "43:53": "can use a weight it's basically means",
  "43:57": "that you can wait for something that",
  "43:59": "takes a while such as grabbing some data",
  "44:03": "without using up a process so for things",
  "44:06": "like I want to get a prediction or I",
  "44:08": "want to load up some data or whatever",
  "44:09": "it's really great to be able to use this",
  "44:12": "modern Python 3 asynchronous stuff",
  "44:15": "so starlet would come highly recommended",
  "44:17": "for creating your web app and so yeah",
  "44:21": "you just create a route as per usual in",
  "44:24": "a web app and in that you say this is",
  "44:28": "you say this is a think to ensure that",
  "44:31": "it doesn't steal the process while it's",
  "44:34": "waiting for things you open your image",
  "44:36": "you call dot predict and you return that",
  "44:40": "response and then you can use a you know",
  "44:42": "whatever JavaScript client or whatever",
  "44:45": "to to show it and that's it that's",
  "44:48": "basically the the main contents of your",
  "44:51": "web app so give it a go right you know",
  "44:57": "this week even if you've never created a",
  "45:00": "web application before there's a lot of",
  "45:02": "you know nice little tutorials online",
  "45:05": "and kind of start a code you know if in",
  "45:08": "doubt why don't you try a solid there's",
  "45:11": "a free hosting that you can use there's",
  "45:15": "one called Python Python anywhere for",
  "45:17": "example the one that Simon's used will",
  "45:20": "go mentioned that on the forum it's",
  "45:22": "something you can basically package it",
  "45:23": "up as a docker thing and should it off",
  "45:25": "and it'll serve it up for you so it",
  "45:28": "doesn't even need to cost you any money",
  "45:29": "and so all these classifiers that you're",
  "45:32": "creating you can turn them into web",
  "45:34": "applications so I'll be really",
  "45:36": "interested to see what you're able to to",
  "45:40": "make of that that will be really fun",
  "45:43": "okay so let's take a break we'll come",
  "45:47": "back at 7:35 see you then:",
  "45:55": "okay so let's move on so I mentioned",
  "46:07": "that most of the time the kind of rules",
  "46:13": "of farm I've shown you will probably",
  "46:15": "work and if you look at the share your",
  "46:18": "work thread you'll find most of the time",
  "46:20": "people are posting things saying I",
  "46:22": "downloaded these images I tried this",
  "46:24": "thing they worked much better than",
  "46:27": "expected well that's cool",
  "46:29": "and then like 1 out of 20 says like ah I",
  "46:33": "had a problem so let's have a talk about",
  "46:36": "what happens when you have a problem and",
  "46:38": "this is where we're status start getting",
  "46:39": "into a little bit of theory because in",
  "46:42": "order to understand why we have these",
  "46:43": "problems and how we fix them it really",
  "46:45": "helps to know a little bit about what's",
  "46:46": "going on so first of all let's look at",
  "46:49": "examples of some problems the problems",
  "46:52": "basically will be either your learning",
  "46:55": "rate is too high or low or your number",
  "46:58": "of epochs is too high or low so we're",
  "47:01": "going to learn about what does mean and",
  "47:02": "why they matter but first of all because",
  "47:06": "we're experimentalists let's try them",
  "47:08": "all right so let's grow with our teddy",
  "47:10": "bear detector and let's make our",
  "47:13": "learning rate really high the default",
  "47:16": "learning rate is zero point zero zero",
  "47:18": "three that works most of the time so",
  "47:21": "what if we try a learning rate of 0.5",
  "47:23": "that's huge",
  "47:24": "what happens our validation Lofts gets",
  "47:28": "pretty damn high remember this is",
  "47:31": "normally something that's underneath one",
  "47:33": "right so if you see your validation loss",
  "47:36": "do that right before we even learn what",
  "47:39": "validation loss is just know this if it",
  "47:41": "does that your learning rates too high",
  "47:43": "that's all you need to know okay make it",
  "47:47": "lower doesn't matter how many epochs you",
  "47:49": "do it's and if this happens there's no",
  "47:52": "way to undo this you have to go back and",
  "47:54": "create your neural net again and fit",
  "47:57": "from scratch with a lower learning rate",
  "47:59": "so that's learning rate to high learning",
  "48:02": "rate to low what if we use a learning",
  "48:06": "rate not of 0.003 but one a next five so",
  "48:12": "0.00001 right so this is just I've just",
  "48:17": "copied and pasted what happened when we",
  "48:19": "trained before with a default error",
  "48:20": "right now without default learning rate",
  "48:22": "and within one epoch we were down to a",
  "48:24": "two or three percent error rate with",
  "48:27": "this really low learning rate our error",
  "48:30": "rate does get better but very very",
  "48:33": "slowly right and you can plot it if you",
  "48:37": "go learn to learn dot recorder is an",
  "48:40": "object which is going to keep track of",
  "48:42": "lots of things",
  "48:42": "happening where you train you can call",
  "48:44": "plot losses to print to plot out the",
  "48:46": "validation and training loss and you can",
  "48:50": "just see them just like gradually going",
  "48:52": "down so slow right so if you see that",
  "48:55": "happening then you have a learning rate",
  "48:58": "which is too small okay so bump it up by",
  "49:01": "10 or bump it up by 100 and try again",
  "49:05": "the other thing you'll see if your",
  "49:07": "learning rate is too small is that your",
  "49:10": "training loss will be higher than your",
  "49:13": "validation loss you never want a model",
  "49:18": "where your training loss is higher than",
  "49:21": "your validation loss that always means",
  "49:24": "you haven't fitted enough which means",
  "49:27": "either your learning rate is too low or",
  "49:30": "your number of epochs is too low so if",
  "49:32": "you have a model like that train it some",
  "49:35": "more or train it with a higher learning",
  "49:38": "rate okay too few epochs so what if we",
  "49:45": "train for just one epoch our error rate",
  "49:49": "certainly better than random 5% but look",
  "49:53": "at this the difference between training",
  "49:55": "loss and validation loss a training loss",
  "49:57": "is much higher than the validation loss",
  "49:59": "so too few epochs and to lower learning",
  "50:04": "rate look very similar right and so you",
  "50:07": "can just try running more epochs and if",
  "50:09": "it's taking forever you can try a higher",
  "50:10": "learning rate where we try a higher",
  "50:12": "learning rate and the loss goes off to",
  "50:15": "100,000 million then put it back to",
  "50:17": "where it was and try a few more epochs",
  "50:19": "that's the balance right that's",
  "50:21": "basically all you care about 99% of the",
  "50:25": "time and this is only the one in 20",
  "50:26": "times that the defaults don't work for",
  "50:28": "you okay too many epochs we're going to",
  "50:33": "be talking more about this create",
  "50:34": "something called overfitting if you",
  "50:37": "train for too long as we're going to",
  "50:38": "learn about it will learn to recognize",
  "50:40": "your particular teddy bears",
  "50:43": "but not teddy bears in general here's",
  "50:46": "the thing despite what you may have",
  "50:48": "heard it's very hard to overfit with",
  "50:50": "deep learning so we were trying today to",
  "50:53": "show you an example of overfitting and I",
  "50:55": "turned off",
  "50:56": "and I turned off everything",
  "51:00": "I turned and we're going to learn all",
  "51:01": "about these terms soon I turned up all",
  "51:03": "the data augmentation I turned off",
  "51:07": "dropout I turned off weight decay I",
  "51:09": "tried to make it over fit as much as I",
  "51:10": "can I trained it on a small issue",
  "51:13": "earning rate I trained it for a really",
  "51:14": "long time and like maybe I started to",
  "51:19": "get it to overfit maybe but so the only",
  "51:25": "thing that tells you that your",
  "51:27": "overfitting is that the error rate",
  "51:29": "improves for a while",
  "51:31": "and then starts getting worse again you",
  "51:36": "will see a lot of people even people",
  "51:39": "that claim to understand machine",
  "51:41": "learning tell you that if you're",
  "51:43": "training loss is lower than your",
  "51:46": "validation loss then you are overfitting",
  "51:48": "as you will learn today in more detail",
  "51:51": "and during the rest of course that is",
  "51:52": "absolutely not true",
  "51:54": "any model is trained correctly will",
  "51:57": "always have trained loss lower than",
  "51:59": "validation loss that is not a sign of",
  "52:01": "overfitting that is not a sign you've",
  "52:02": "done something wrong that is a sign you",
  "52:04": "have done something right okay the sign",
  "52:08": "that you are overfitting is that your",
  "52:10": "error start getting worse because that's",
  "52:12": "what you care about right you want your",
  "52:14": "model to have a low error so as long as",
  "52:16": "your training and your model error is",
  "52:19": "improving you are not overfitting how",
  "52:22": "could you be okay so there's a basically",
  "52:25": "the four possible there the main four",
  "52:26": "things that can go wrong there are some",
  "52:28": "other details that we will learn about",
  "52:30": "during the rest of this course but",
  "52:32": "honestly if you stopped listening now",
  "52:34": "please don't that would be embarrassing",
  "52:36": "and you just like okay I'm going to go",
  "52:39": "and download images I'm going to create",
  "52:42": "CNN's with resinate 34 or isn't it 50",
  "52:44": "I'm going to make sure that my learning",
  "52:46": "rate and number of epochs is okay and",
  "52:47": "then I'm going to check them up in a in",
  "52:49": "a starlet Web API most of the time",
  "52:53": "you're done okay at least your computer",
  "52:55": "vision hopefully you'll stick around",
  "52:58": "because you want to learn about NLP and",
  "53:01": "collaborative filtering and tabular data",
  "53:03": "and segmentation and stuff like that as",
  "53:06": "well",
  "53:10": "let's now understand what's actually",
  "53:14": "going on what does it mean loss mean",
  "53:17": "water as an epoch man what is learning",
  "53:20": "rate mean because for you to really",
  "53:21": "understand these ideas you need to know",
  "53:24": "what's going on and so we're going to go",
  "53:26": "all the way to the other side rather",
  "53:28": "than creating a state-of-the-art Krueger",
  "53:32": "detector we're going to go back and",
  "53:35": "create the simplest possible linear",
  "53:37": "model okay so we're going to actually",
  "53:41": "start seeing we're actually going to",
  "53:47": "start seeing a little bit of math okay",
  "53:50": "but don't be turned off it's okay right",
  "53:53": "we're going to do a little bit of math",
  "53:55": "but it's going to be totally fine",
  "53:57": "even if maths not your thing because the",
  "53:59": "first thing we're going to realize is",
  "54:01": "that when we see a picture like this",
  "54:03": "number eight it's actually just a bunch",
  "54:06": "of numbers it's a matrix of numbers for",
  "54:09": "this grayscale or one it's a matrix of",
  "54:11": "numbers if it was a color image it would",
  "54:14": "be have a third dimension so when you",
  "54:18": "add an extra dimension we call it a",
  "54:19": "tensor rather than a matrix it would be",
  "54:21": "a 3d tensor of numbers red green and",
  "54:25": "blue so when we created that teddy bear",
  "54:31": "detector what we actually did was we",
  "54:34": "created a mathematical function that",
  "54:37": "took the numbers from the images of the",
  "54:39": "teddy bears and the mathematical",
  "54:41": "function converted those numbers into in",
  "54:45": "our case three numbers a number for the",
  "54:48": "probability that it's a teddy a",
  "54:50": "probability that it's a grizzly and the",
  "54:52": "probability is a black bear in this case",
  "54:54": "there's some hypothetical function",
  "54:56": "that's taking the pixels representing a",
  "54:58": "handwritten digit and returning ten",
  "55:01": "numbers the probability for each",
  "55:04": "possible outcome the numbers from zero",
  "55:07": "to nine and so what you'll often see in",
  "55:12": "in our code and other deep learning code",
  "55:15": "is that you're you'll find this a bunch",
  "55:18": "of probabilities and then you'll find",
  "55:20": "something called Max or Arg max",
  "55:23": "attached to it a function called and so",
  "55:26": "what that function is doing is it's",
  "55:27": "saying find the highest number to the",
  "55:30": "highest probability and tell me what the",
  "55:33": "index is",
  "55:34": "so NP dog Max or torch dog max of this",
  "55:38": "array would return this number here okay",
  "55:42": "we return index hey that makes sense in",
  "55:45": "fact let's try it so we know that the",
  "55:52": "function to predict something is called",
  "55:55": "learn dot predict okay so we can check",
  "56:03": "two question marks before or after it to",
  "56:05": "get the source code and here it is right",
  "56:09": "pred equals res result Arg max and then",
  "56:15": "what is the class where you just pass",
  "56:17": "that into the classes array so like you",
  "56:19": "should find that the source code in the",
  "56:21": "Farsi library can both kind of",
  "56:25": "strengthen your understanding of the",
  "56:27": "concepts and make sure that you know you",
  "56:29": "know what's going on and and really help",
  "56:31": "you here you've got a question come on",
  "56:34": "over we have a definition of the error",
  "56:40": "rate being discussed and how it is",
  "56:42": "calculated I assume it's cross",
  "56:44": "validation error sure so one way to",
  "56:50": "answer the question of how is error rate",
  "56:52": "calculated would be to type error rate",
  "56:56": "question mark and look at the source",
  "56:58": "code and it is one - accuracy fair",
  "57:03": "enough and so then a question might be",
  "57:05": "what is accuracy accuracy question mark",
  "57:10": "it is AG max so we now know that means",
  "57:14": "find out which particular thing it is",
  "57:16": "and then look at how often that equals",
  "57:19": "the target so in other words the actual",
  "57:21": "value and take the mean so that's",
  "57:24": "basically what it is and so then the",
  "57:27": "question is okay well what does that",
  "57:28": "being applied to and always in faster",
  "57:32": "far say I metrics so these things that",
  "57:35": "we pass in we call",
  "57:37": "metrics are always going to be applied",
  "57:39": "to the validation set okay",
  "57:42": "so anytime you put a metric here it'll",
  "57:45": "be applied to the validation set because",
  "57:47": "that's your best practice right that's",
  "57:48": "like that's what you always want to do",
  "57:50": "is make sure that you're checking your",
  "57:53": "performance on data that your model",
  "57:56": "hasn't seen and we'll be learning more",
  "57:58": "about the validation set",
  "57:59": "shortly remember you can also type doc",
  "58:05": "if the source code is not what you want",
  "58:08": "which it will not be you actually want",
  "58:10": "the documentation that will both give",
  "58:13": "you a summary of the types in and out of",
  "58:17": "the function and a link to the full",
  "58:20": "documentation where you can find out all",
  "58:23": "about how metrics work and what other",
  "58:26": "metrics there are and so forth and",
  "58:30": "generally speaking you'll also find",
  "58:32": "links to more information where for",
  "58:36": "example you will find complete runs",
  "58:38": "through and sample code and so forth",
  "58:40": "showing you how to use all these things",
  "58:41": "so don't forget that the doc function is",
  "58:45": "your friend okay",
  "58:47": "and also in the documentation both in",
  "58:50": "the doc function and in the",
  "58:52": "documentation you'll see a source link",
  "58:54": "this is like question mark question mark",
  "58:56": "but what the source link does is it",
  "59:00": "takes you into the exact line of code in",
  "59:03": "github so you can see exactly how that's",
  "59:05": "implemented and what else is around it",
  "59:06": "so lots of good stuff there why were you",
  "59:12": "using threes for your learning rates",
  "59:14": "earlier with three back five and three",
  "59:17": "next four we found that three a neg",
  "59:25": "three is that just a really good default",
  "59:27": "learning rate it works most of the time",
  "59:30": "for your initial fine-tuning before you",
  "59:34": "unfreeze and then I tend to kind of just",
  "59:38": "multiply from there so I generally find",
  "59:40": "then that the the next stage I will pick",
  "59:43": "ten times lower than that so the second",
  "59:46": "part of the slice and whatever the LR",
  "59:48": "Finder found for the first part of this",
  "59:51": "the second part of the slice doesn't",
  "59:54": "come from the LR finder it's just a rule",
  "59:55": "of thumb which is like ten times less",
  "59:57": "than your your first part which defaults",
  "60:00": "to three in x-ray and then the first",
  "60:03": "part of the slice is what comes out of",
  "60:05": "the LR finder and we'll be learning a",
  "60:06": "lot more about these learning rate",
  "60:08": "details both today and in the coming",
  "60:11": "lessons but yeah for now",
  "60:13": "all you need to remember is that in your",
  "60:15": "you know your basic approach looked like",
  "60:17": "this it was learned fit one cycle some",
  "60:23": "number of epochs I often pick four and",
  "60:26": "some learning rate which defaults to 3e",
  "60:29": "next three I'll just type it up fully so",
  "60:33": "you can see and then we do that for a",
  "60:35": "bit and then we unfreeze it right and",
  "60:39": "then we learn some more and so this is a",
  "60:43": "bit where I just take whatever I did",
  "60:45": "last time and divided by ten and then I",
  "60:49": "also write like that and then I have to",
  "60:53": "put one more number in here and that's",
  "60:57": "the number that I get from the learning",
  "60:58": "rate finder a bit where it's got the",
  "61:00": "strongest slope so that's kind of the",
  "61:02": "kind of don't have to think about it",
  "61:05": "don't really have to know what's going",
  "61:06": "on rule of thumb that works most of the",
  "61:09": "time but let's now DV dig in and",
  "61:13": "actually understand it more completely",
  "61:17": "so we're going to create this",
  "61:19": "mathematical function that takes the",
  "61:21": "numbers that represent the pixels and",
  "61:22": "spits out probabilities for each",
  "61:24": "possible plus and by the way a lot of",
  "61:28": "the stuff that we're using here we are",
  "61:30": "dealing from other people who are",
  "61:31": "awesome and so we are putting their",
  "61:34": "details here so like please check out",
  "61:36": "their work because they've got great",
  "61:39": "work that we are highlighting in our",
  "61:41": "course I really like this idea of this",
  "61:44": "little animated gif of the numbers so",
  "61:47": "thank you for adding Daiki for creating",
  "61:49": "that and I guess that was probably on",
  "61:52": "Quora by the looks of this medium I oh",
  "61:55": "yes it was - that terrific medium post I",
  "61:57": "remember I've had a whole series of",
  "62:00": "medium posts",
  "62:02": "so so let's look and see what how we",
  "62:10": "create one of these functions and let's",
  "62:15": "start with the simplest function I know",
  "62:20": "y equals a X plus B okay that's a line",
  "62:28": "right that's a line and the the gradient",
  "62:37": "of the line is here and the intercept of",
  "62:40": "the line is here okay so hopefully when",
  "62:44": "we said that you need to know high",
  "62:45": "school math to do this course these are",
  "62:47": "the things we're assuming that you",
  "62:48": "remember if we do kind of mention some",
  "62:52": "math thing which I'm assuming you",
  "62:53": "remember and you don't remember it don't",
  "62:55": "freak out right happens to all of us",
  "62:59": "Khan Academy is actually terrific it's",
  "63:02": "not just for school kids go to Khan",
  "63:04": "Academy find the concept you need a",
  "63:06": "refresher on and he explains things",
  "63:08": "really well so strongly recommend",
  "63:11": "checking that out",
  "63:14": "you know remember I'm just a philosophy",
  "63:16": "student right so I all the time and",
  "63:19": "trying to either remind myself about",
  "63:20": "something or I never learnt something",
  "63:22": "and so we have the whole Internet to",
  "63:24": "teach us these things so I'm going to",
  "63:27": "rewrite this slightly y equals a 1 X",
  "63:34": "plus a 2 so let's just replace B with a",
  "63:41": "2 just give it a different name ok so",
  "63:43": "there's another way of saying the same",
  "63:46": "thing and then another way of saying",
  "63:48": "that would be if I could multiply a 2 by",
  "63:52": "the number 1 ok this still is the same",
  "63:55": "thing ok and so now at this point I'm",
  "64:00": "actually going to say let's not put the",
  "64:02": "number 1 there but let's put an X 1 here",
  "64:06": "and an X 2 here and I'll say X 2 equals",
  "64:12": "1",
  "64:13": "ok so so far this is not",
  "64:15": "you know this is pretty early high",
  "64:16": "school math this is multiplying by 1",
  "64:18": "which I think we can handle ok so these",
  "64:21": "two are equivalent with a bit of",
  "64:24": "renaming now in machine learning we",
  "64:30": "don't just have one equation we've got",
  "64:32": "lots right so if we've got some data",
  "64:35": "that represents the temperature versus",
  "64:45": "the number of ice creams sold then we",
  "64:51": "kind of have lots of dots and so each",
  "64:56": "one of those dots we might hypothesize",
  "64:58": "you know is based on this this formula y",
  "65:01": "equals a 1 X 1 plus a 2 X 2 all right",
  "65:05": "and so basically there's lots of so this",
  "65:08": "is our Y this is our X there's lots of",
  "65:11": "values of Y so we can stick it or I here",
  "65:13": "and there's lots of values of X so we",
  "65:16": "can stick little X here okay so the way",
  "65:19": "we kind of do that is a lot like numpy",
  "65:21": "indexing right there rather than things",
  "65:23": "in square brackets or PI to watch",
  "65:24": "indexing rather than things in square",
  "65:25": "brackets we kind of put them down here",
  "65:31": "in our kind of in the subscript of our",
  "65:35": "equation ok so this is now saying",
  "65:37": "there's actually lots of these different",
  "65:39": "Y eyes based on lots of different xi1",
  "65:43": "and ex-situ ok but notice there's only",
  "65:46": "this is still only one of each of these",
  "65:47": "that's it so these these things here",
  "65:50": "called the coefficients for the",
  "65:54": "parameters so this is our linear",
  "65:58": "equation and this is still we're going",
  "66:01": "to say that every X I 2 is equal to 1 ok",
  "66:07": "why did I do it that way because I want",
  "66:11": "to do linear algebra why do I want to do",
  "66:14": "in linear algebra well one reason is",
  "66:16": "because Rachel teaches the world's best",
  "66:18": "linear algebra course so if you're",
  "66:21": "interested check out computational",
  "66:22": "linear algebra for coders so it's a good",
  "66:24": "opportunity for me to throw in a pitch",
  "66:26": "for this",
  "66:29": "course which we make no money but never",
  "66:31": "mind",
  "66:32": "but more to the point right now it's",
  "66:35": "going to make life much easier right",
  "66:37": "because I hate writing loops I hate",
  "66:40": "writing code right I just I just want",
  "66:42": "the computer to do everything for me at",
  "66:45": "anytime you see like these little I",
  "66:47": "subscripts that sounds like you're going",
  "66:48": "to have to do loops and all kind of",
  "66:49": "stuff but what you might remember from",
  "66:52": "school is that when you've got like two",
  "66:55": "things being multiplied together two",
  "66:57": "things being multiplied together and",
  "66:58": "then they get added up",
  "66:59": "that's called a dot product and then if",
  "67:06": "you do that for lots and lots of",
  "67:08": "different numbers I then that's called a",
  "67:11": "matrix product so in fact this whole",
  "67:15": "thing can be written like this",
  "67:16": "rather than lots of different way eyes",
  "67:18": "we can see there's one vector called Y",
  "67:21": "which is equal to one matrix called",
  "67:27": "x times one vector called a now at this",
  "67:34": "point I know a lot of you don't remember",
  "67:37": "that so that's fine we have a picture to",
  "67:41": "show you I don't know who created this",
  "67:44": "so now I do",
  "67:44": "somebody called Andres touts credit this",
  "67:47": "fantastic thing called matrix",
  "67:48": "multiplication XYZ and here we have a",
  "67:52": "matrix by a vector and we're going to do",
  "67:56": "a matrix vector product go that times",
  "68:02": "that times that plus plus plus plus that",
  "68:04": "times that times that Plus that Plus",
  "68:06": "that times that times a plus plus plus",
  "68:07": "plus finished",
  "68:10": "that is what matrix vector",
  "68:12": "multiplication does in other words it's",
  "68:17": "just that except his version is much",
  "68:19": "less messy okay so let's this is",
  "68:26": "actually an excellent spot to have a",
  "68:28": "little break and find out what questions",
  "68:29": "we have coming through our students what",
  "68:32": "are they asking ritual when generating",
  "68:36": "new image data set how do you know how",
  "68:38": "many images are enough what are ways to",
  "68:41": "measure enough yeah that's a great",
  "68:43": "question",
  "68:44": "so I'm another possible problem you have",
  "68:47": "is you don't have enough data how do you",
  "68:49": "know if you don't have enough data",
  "68:51": "because you found a good learning rate",
  "68:53": "because if you make it higher then it",
  "68:56": "goes off into massive losses if you make",
  "68:58": "it lower it goes really slowly so you've",
  "69:00": "got a good learning rate and then you",
  "69:02": "train for such a long time that your",
  "69:06": "arrow starts getting worse okay so you",
  "69:08": "know that you're trained for long enough",
  "69:09": "and you're still not happy with the",
  "69:12": "accuracy it's not good enough for the",
  "69:14": "you know teddy bear cuddling level of",
  "69:18": "safety you want so if that happens",
  "69:20": "there's a number of things you can do",
  "69:22": "and we'll learn about some of them",
  "69:25": "during roll and pretty much all of them",
  "69:26": "during this course but one of the",
  "69:28": "easiest ones is get more data now if you",
  "69:31": "get more data then you can train for",
  "69:33": "longer get a higher accuracy lower error",
  "69:36": "rate without overfitting unfortunately",
  "69:41": "there's no shortcut I wish there was I",
  "69:43": "wish so somewhere to know ahead of time",
  "69:44": "how much data you need but I will say",
  "69:47": "this most of the time you need less data",
  "69:49": "than you think so organizations very",
  "69:51": "commonly spend too much time gathering",
  "69:53": "data getting more data than it turned",
  "69:55": "out they actually needed so get a small",
  "69:57": "amount first and see how you go what do",
  "70:00": "you do if you have unbalanced classes",
  "70:02": "such as 200 Grizzlies and 50 teddies ah",
  "70:07": "nothing try it",
  "70:09": "works a lot of people ask this question",
  "70:12": "about how do I deal with unbalanced data",
  "70:13": "I've done lots of analysis with",
  "70:17": "unbalanced data over the last couple of",
  "70:18": "years and I just can't make it not work",
  "70:20": "it always works so there's a there's",
  "70:26": "actually a paper that said like if you",
  "70:28": "want to get it slightly better then the",
  "70:30": "best thing to do is to take that",
  "70:31": "uncommon class and just make a few",
  "70:34": "copies of it that's called over sampling",
  "70:36": "but you're like I haven't found a",
  "70:39": "situation in practice where I needed to",
  "70:40": "do that I've found it always just works",
  "70:42": "plain for me once you unfreeze and",
  "70:49": "retrain with one cycle again if you're",
  "70:51": "training loss is still lower than your",
  "70:53": "validation loss likely underfitting",
  "70:55": "do you retrain it unfrozen again which",
  "70:58": "will technically be more than one cycle",
  "71:00": "or do you redo everything with a longer",
  "71:02": "epoch for the cycle hey you guys asked",
  "71:06": "me that last week my answers still the",
  "71:08": "same I don't know I just find if you do",
  "71:12": "another cycle then it'll kind of maybe",
  "71:15": "generalize a little bit better if you",
  "71:17": "start again do twice as long it's kind",
  "71:20": "of annoying depends how patient you are",
  "71:22": "it won't make much difference you know",
  "71:24": "for me personally I normally just train",
  "71:26": "a few more cycles but yeah it doesn't",
  "71:30": "make much difference most of the time so",
  "71:38": "showing the code sample where you were",
  "71:40": "creating a CNN with resin at 34 for the",
  "71:44": "grizzly Teddy classifier it says this",
  "71:48": "requires res not resident 34 which I",
  "71:51": "find surprising I had assumed that the",
  "71:53": "model created by dot save which is about",
  "71:55": "85 megabytes on disk would be able to",
  "71:58": "run without also needing a copy of resin",
  "72:01": "at 34 yeah and I understand we're going",
  "72:11": "to be learning all about this shortly",
  "72:14": "[Music]",
  "72:15": "you don't there's a copy of ResNet 34",
  "72:20": "written at 34 is actually how what we",
  "72:22": "call an architect",
  "72:23": "we're going to be learning a lot about",
  "72:24": "this it's a functional form just like",
  "72:26": "this is a linear functional form it",
  "72:29": "doesn't take up any room it doesn't",
  "72:31": "contain anything it's just a function",
  "72:32": "resident 34 is just a function it",
  "72:35": "doesn't contain anything it doesn't",
  "72:36": "store anything I think the confusion",
  "72:38": "here is that we often use a pre trained",
  "72:43": "neural net that's been learned on",
  "72:45": "imagenet in this case we don't need to",
  "72:49": "use a pre trained you're on it and",
  "72:51": "actually to entirely avoid that even",
  "72:58": "getting created you can actually pass",
  "73:02": "pre-trained equals false and that'll",
  "73:06": "ensure that nothing even gets loaded",
  "73:07": "which will save you another 0.2 seconds",
  "73:10": "I guess so yeah but we'll be learning a",
  "73:13": "lot more about this so don't worry this",
  "73:14": "is a bit unclear but the basic idea is",
  "73:16": "this this thing here is is the basically",
  "73:19": "equivalent of saying is it a line or is",
  "73:22": "it a quadratic or is it a reciprocal",
  "73:24": "this is if this is just a function this",
  "73:27": "is the resonate 34 function it's a",
  "73:28": "mathematical function it has no doesn't",
  "73:31": "take any storage it doesn't have any",
  "73:33": "numbers doesn't it be loaded as opposed",
  "73:36": "to a pre-trained model and so that's why",
  "73:42": "when we used when we did it at inference",
  "73:44": "time the thing that took space is this",
  "73:51": "bit which is where we load our",
  "73:53": "parameters which is basically saying as",
  "73:56": "we're ready to find out what are the",
  "73:57": "values of a and B we have to store those",
  "74:02": "numbers but for ResNet 34 you don't",
  "74:05": "distort two numbers you store a few",
  "74:08": "million or few tens of millions of",
  "74:11": "numbers so why did we do all this well",
  "74:17": "it's because I wanted to be able to",
  "74:19": "write it out like this and then I think",
  "74:22": "I think I would write it out like this",
  "74:23": "is that we can now do that in pi torch",
  "74:28": "with no loops single line of code and",
  "74:32": "it's also going to run faster pi torch",
  "74:35": "really doesn't like loop",
  "74:37": "right it really wants you to send it a",
  "74:39": "whole equation to do all at once which",
  "74:41": "means you really want to try and specify",
  "74:43": "things in these kind of linear algebra",
  "74:45": "ways so let's go and take a look because",
  "74:49": "what we're going to try and do then is",
  "74:50": "we're going to try and take this we're",
  "74:55": "going to call it an architecture like",
  "74:56": "that this is like the tiniest world's",
  "74:58": "tiniest neural network it's got two",
  "75:00": "parameters you know a 1 and a 2 we're",
  "75:03": "going to try and fit this architecture",
  "75:04": "to some data so let's let's jump into a",
  "75:07": "notebook and generate some dots right",
  "75:11": "and see if we can get it to fit a line",
  "75:15": "somehow and the somehow is going to be",
  "75:18": "using something called s G D what is s",
  "75:24": "GD well there's two types of SGD the",
  "75:27": "first one is where I said in Lesson one",
  "75:30": "hey you should all try building these",
  "75:33": "models and try and come up with",
  "75:34": "something cool and you guys all",
  "75:35": "experimented and found really good stuff",
  "75:37": "so that's where the s would be student",
  "75:39": "that would be student gradient descent",
  "75:41": "so that's version one of fgd version two",
  "75:45": "of SGD which is what I'm going to talk",
  "75:46": "about today is where we're going to have",
  "75:48": "a computer try lots of things and try",
  "75:50": "and come up with a really good function",
  "75:51": "and that will be called stochastic",
  "75:53": "gradient descent so the other one that",
  "75:58": "you hear a lot in the on Twitter is",
  "76:00": "stochastic grad student descent so",
  "76:03": "that's the other one for you here so",
  "76:08": "we're going to jump into lesson two SGD",
  "76:12": "and so we're going to kind of go bottom",
  "76:15": "up rather than top down we're going to",
  "76:17": "create the simplest possible model we",
  "76:21": "can which is going to be a linear model",
  "76:23": "and the first thing that we need is we",
  "76:25": "need some data and so we're going to",
  "76:27": "generate some data the data we're going",
  "76:30": "to generate looks like this so this",
  "76:32": "might represent temperature and this",
  "76:33": "rate represent number of ice creams we",
  "76:35": "sell or something like that but we're",
  "76:37": "just going to create some synthetic data",
  "76:39": "that we know is following a line and so",
  "76:41": "as we build this we're actually going to",
  "76:43": "learn a little bit about PI torch as",
  "76:46": "well so basically the way we're going to",
  "76:49": "generate this data",
  "76:51": "is by creating some coefficients a 1",
  "76:55": "will be 3 and a 2 will be 2 and we're",
  "77:00": "going to create some like which looks at",
  "77:04": "before basically a column of numbers",
  "77:07": "through axis and a whole bunch of ones",
  "77:09": "and then we're going to do this X at a",
  "77:12": "what is X at a X at a in Python means a",
  "77:17": "matrix product between X and a it",
  "77:22": "actually is even more general for that",
  "77:23": "it can be a vector vector product a",
  "77:25": "matrix vector product a vector matrix",
  "77:27": "product or a matrix matrix product and",
  "77:30": "then actually in pi torch specifically",
  "77:32": "it can mean even more general things",
  "77:34": "where we get into higher rank tensors",
  "77:35": "which we will learn all about very soon",
  "77:38": "right but this is basically the key",
  "77:41": "seeing that's going to go on in all of",
  "77:44": "our deep learning the vast majority of",
  "77:46": "the time our computers are going to be",
  "77:48": "basically doing this multiplying numbers",
  "77:50": "together at adding them up which is the",
  "77:52": "surprisingly useful thing to do",
  "77:57": "ok so we basically are going to generate",
  "78:01": "some data by by creating a line and then",
  "78:04": "we're going to add some random numbers",
  "78:05": "to it but let's go back and see how we",
  "78:07": "created X 1/8 so I mentioned that you",
  "78:11": "know we've basically got these two",
  "78:12": "coefficients three and two and you'll",
  "78:16": "see that we've wrapped it in this",
  "78:17": "function called",
  "78:18": "cancer you might have heard this word",
  "78:21": "tensor before who's heard the word",
  "78:22": "tensor before about two-thirds of you",
  "78:25": "okay so it's one of these words that",
  "78:28": "sounds scary and apparently if you're a",
  "78:32": "physicist it actually is scary but in",
  "78:35": "the world of deep learning is actually",
  "78:36": "not scary at all tensor means array okay",
  "78:41": "it means array so specifically it's an",
  "78:43": "array of a regular shape right so it's",
  "78:46": "not an array where Row one has two",
  "78:47": "things and Row three has three things",
  "78:49": "and row four has one thing what you call",
  "78:51": "a jagged array that's not a tensor a",
  "78:53": "tensor is any array which has a",
  "78:56": "rectangular or cube or whatever you know",
  "79:00": "as a shape where every element every row",
  "79:03": "is the same length",
  "79:04": "and then every column is the same length",
  "79:06": "so four by three matrix would be a",
  "79:08": "tensor a vector of length four would be",
  "79:12": "a tensor a 3d array of length three by",
  "79:16": "four by six would be a tensor",
  "79:19": "that's all intensity is okay and so we",
  "79:24": "have these all the time",
  "79:25": "for example an image is a three",
  "79:29": "dimensional tensor it's got number of",
  "79:32": "rows by number of columns by number of",
  "79:35": "channels normally red green blue so for",
  "79:38": "example a kind of a vga texture would be",
  "79:41": "640 by 480 by 3 or actually we do things",
  "79:48": "backwards so when people talk about",
  "79:49": "images they normally go width by height",
  "79:52": "but when we talk mathematically we",
  "79:54": "always go a number of rows by number of",
  "79:55": "columns so it'd actually be 480 by 6 40",
  "79:59": "by 3 that will catch you out we don't",
  "80:03": "say dimensions so with tensors we use",
  "80:06": "one of two words we had to say rank or",
  "80:08": "or axes rank specifically means how many",
  "80:12": "axes are there how many dimensions are",
  "80:14": "there so an image is generally a rank 3",
  "80:18": "tensor so what we've created here is a",
  "80:23": "rank 1 tensor or also known as the",
  "80:29": "vector right but like in math people",
  "80:33": "come up with slightly different words or",
  "80:35": "actually not they come up with very",
  "80:37": "different words for slightly different",
  "80:38": "concepts why is a one dimensional array",
  "80:40": "a vector and a two dimensional arrays",
  "80:43": "and matrix and then a three dimensional",
  "80:45": "array does that even have a name not",
  "80:48": "really doesn't have a name like it",
  "80:50": "doesn't make any sense we also you know",
  "80:53": "with computers we try to have some",
  "80:54": "simple consistent naming conventions",
  "80:56": "they're all called tensors rank 1 tensor",
  "80:59": "rank two tensor rank 3 tensor you can",
  "81:01": "certainly have a rank 4 tensor if you've",
  "81:03": "got 64 images then that would be a rank",
  "81:07": "4 tensor of 64 by 480 by 640 by 3 for",
  "81:12": "example so tensors are very simple they",
  "81:15": "just mean arrays and so",
  "81:18": "in play torch you say tensor and you",
  "81:20": "pass in some numbers and you get back in",
  "81:23": "this case just a list I get back a",
  "81:25": "vector okay so this then represents our",
  "81:31": "coefficients the slope and the intercept",
  "81:34": "of our line and so because remember",
  "81:37": "we're not actually going to have a",
  "81:39": "special case of ax plus B instead we're",
  "81:43": "going to say there's always this second",
  "81:45": "x value which is always 1 you can see it",
  "81:48": "here always 1 which allows us just to do",
  "81:51": "a simple matrix vector product ok so",
  "81:55": "that's that's a and then we wanted to",
  "81:58": "generate this X array of data which is",
  "82:02": "going to have we're going to put random",
  "82:04": "numbers in the first column and a whole",
  "82:06": "bunch of ones in the second column so to",
  "82:08": "do that we basically say 2 pi torch",
  "82:11": "create a rank two tensor actually notice",
  "82:19": "I said again we see the PI torch that we",
  "82:24": "want to create a tensor of n by 2 so",
  "82:30": "since we passed in a total of 2 things",
  "82:32": "we get a rank two tensor the number of",
  "82:35": "rows will be N and the number of columns",
  "82:37": "will be 2 and in there every single",
  "82:41": "thing in it will be a 1 that's what",
  "82:43": "torch dot ones means and then this is",
  "82:47": "really important you can index into that",
  "82:51": "just like you can index into a list in",
  "82:53": "Python but you can put a colon anywhere",
  "82:57": "and a colon means every single value on",
  "83:00": "that axis or every single value on that",
  "83:03": "dimension so this here means every",
  "83:06": "single row and then this here means",
  "83:09": "column 0 so this is every row of column",
  "83:13": "0 I want you to grab a uniform random",
  "83:17": "number and here's another very important",
  "83:21": "concept in PI torch anytime you've got a",
  "83:24": "function that ends in an underscore it",
  "83:26": "means don't return to me that uniform",
  "83:29": "random number but replay",
  "83:31": "whatever this is being called on with",
  "83:34": "the result of this function so this",
  "83:36": "takes column zero and replaces it with a",
  "83:40": "uniform random number between minus 1",
  "83:43": "and 1 so there's a lot to unpack there",
  "83:47": "right but the good news is those two",
  "83:50": "lines of code plus this one which we're",
  "83:53": "coming to cover 95% of what you need to",
  "83:57": "know about pay torch how to create an",
  "84:00": "array how to change things in an array",
  "84:02": "and how to do matrix operations on an",
  "84:05": "array okay so that's a there's a lot to",
  "84:07": "unpack but these these small number of",
  "84:10": "concepts are incredibly powerful so I",
  "84:13": "can now print out the first five rows",
  "84:18": "okay so colon 5 is standard - slicing",
  "84:25": "syntax to say the first five rows so",
  "84:28": "here are the first five rows two columns",
  "84:30": "looking like my random numbers and my",
  "84:33": "ones so now I can do a matrix product of",
  "84:37": "that X by my a add in some random",
  "84:43": "numbers to add a bit of noise and then I",
  "84:46": "can do a scatter plot and I'm not really",
  "84:48": "interested in my scatter plot in this",
  "84:49": "column of ones right there just there to",
  "84:52": "make my linear function more convenient",
  "84:55": "so I'm just going to flip plot my zero",
  "84:59": "index column against my Y's and there it",
  "85:03": "is PLT is what we universally use to",
  "85:09": "refer to the plotting library matplotlib",
  "85:13": "and that's what most people use for most",
  "85:16": "of their plotting in Python in",
  "85:19": "scientific python we use matplotlib it's",
  "85:22": "certainly a library you'll want to get",
  "85:24": "familiar with because being able to plot",
  "85:26": "things is really important there are",
  "85:29": "lots of other plotting packages lots of",
  "85:33": "them the other packages are better at",
  "85:35": "certain things than that plot lib but",
  "85:38": "like matplotlib can do everything",
  "85:41": "reasonably well sometimes it's a little",
  "85:45": "could but you know I for me I do pretty",
  "85:48": "much everything in that flight lib",
  "85:50": "because there's really nothing it can't",
  "85:52": "do even though some libraries can do",
  "85:54": "other things a little bit better or a",
  "85:56": "little bit prettier but it's really",
  "85:59": "powerful so once you know matplotlib you",
  "86:02": "can do everything so here I'm asking",
  "86:04": "matplotlib to give me a scatterplot with",
  "86:06": "my X's against my Y's and there it is",
  "86:09": "okay so this is my my dummy data",
  "86:13": "representing like you know of",
  "86:15": "temperature and ice cream sales so now",
  "86:18": "what we're going to do is we're going to",
  "86:20": "pretend we were given this data and we",
  "86:22": "don't know that the values of our",
  "86:25": "coefficients are 3 & 2 so we're going to",
  "86:28": "pretend that we never knew that we have",
  "86:29": "to figure them out okay so how would we",
  "86:32": "figure them out how would we draw a line",
  "86:34": "to fit to this data and why would that",
  "86:38": "even be interesting well we're going to",
  "86:41": "look at more about why it's interesting",
  "86:43": "in just a moment but the basic idea is",
  "86:45": "this if we can find this is going to be",
  "86:47": "kind of perhaps really surprising but if",
  "86:51": "we can find a way to find those two",
  "86:54": "parameters to fit that line to those how",
  "86:57": "many points were there and was a hundred",
  "87:01": "if we can find a way to fit that line to",
  "87:04": "those 100 points we can also fit these",
  "87:08": "arbitrary functions that convert from",
  "87:11": "pixel values to probabilities",
  "87:14": "it'll turn out that this techniques that",
  "87:16": "we that we're going to learn to find",
  "87:19": "these two numbers works equally well for",
  "87:22": "the 50 million numbers in resident 34 so",
  "87:27": "we're actually going to use an almost",
  "87:28": "identical approach so that this and this",
  "87:32": "is a bit that I found in previous",
  "87:33": "classes people have the most trouble",
  "87:36": "digesting like I often find even after",
  "87:39": "week four or week type five people will",
  "87:41": "come up to me and say I don't get it how",
  "87:44": "do we actually train these models and",
  "87:47": "I'll say it's it's SGD it's that it's",
  "87:49": "that thing we throw in the notebook with",
  "87:50": "the T numbers it's like yep it but we're",
  "87:52": "fitting a neural network so I know and",
  "87:56": "we can't print the 50 million numbers",
  "87:58": "anymore",
  "87:59": "but it is literally identically doing",
  "88:01": "the same thing and the reason this is",
  "88:03": "hard to digest is that the human brain",
  "88:05": "has a lot of trouble conceptualizing of",
  "88:08": "what an equation was fifteen milk 50",
  "88:10": "million numbers looks like and can do so",
  "88:13": "you're just kind of for now we'll have",
  "88:15": "to take my word for it that can do",
  "88:17": "things like recognize teddy deaths and",
  "88:21": "all these functions turn out to be very",
  "88:22": "powerful now we're going to learn a",
  "88:23": "little bit more in just a moment about",
  "88:24": "how to make them extra powerful but for",
  "88:27": "now this thing we're going to learn to",
  "88:30": "fit these two numbers is the same thing",
  "88:32": "that we've just been using to fit 50",
  "88:34": "million numbers okay so we want to find",
  "88:38": "what pi torch calls parameters or in",
  "88:42": "statistics you'll often hear called",
  "88:43": "coefficients these values a 1 and a 2 we",
  "88:47": "want to find these parameters such that",
  "88:50": "the line that they create minimizes the",
  "88:54": "error between that line and the points",
  "89:00": "so in other words you know if we created",
  "89:09": "you know if the if the a 1 and a 2 we",
  "89:12": "came up with resulted in this line then",
  "89:16": "we'd look and we'd see like how far away",
  "89:18": "is that line from each point I would say",
  "89:20": "oh that's quite a long way and so maybe",
  "89:22": "there was some other a 1 or a 2 which",
  "89:25": "resulted in this line and they would say",
  "89:30": "like oh how far away is each of those",
  "89:31": "points and then eventually we come up",
  "89:34": "with blue we come up with this line and",
  "89:43": "it's like Oh in this case each of those",
  "89:45": "is actually very close all right so you",
  "89:47": "can see how in each case we can say how",
  "89:49": "far away is the line at each spot away",
  "89:52": "from its point and then we can take the",
  "89:54": "average of all those and that's called",
  "89:57": "the loss and that is the value of our",
  "90:00": "loss right so you need some mathematical",
  "90:02": "function that can basically say how far",
  "90:05": "away is this line from those points",
  "90:10": "for this kind of problem which is called",
  "90:12": "a regression problem a problem where",
  "90:14": "your dependent variable is continuous so",
  "90:21": "rather than being Grizzly's or Teddy's",
  "90:23": "it's like some number between minus 1",
  "90:27": "and 6 this is called a regression",
  "90:28": "problem and for regression the most",
  "90:30": "common loss function is called mean",
  "90:32": "squared error which pretty much",
  "90:34": "everybody calls MSE you may also see our",
  "90:38": "MSE just root mean squared error and so",
  "90:41": "the mean squared error is a loss it's",
  "90:43": "the difference between some prediction",
  "90:45": "that you've made okay",
  "90:47": "which you know is like the value of the",
  "90:49": "line and the actual number of ice cream",
  "90:52": "sales and so in in the mathematics of",
  "90:57": "this people normally refer to the actual",
  "90:58": "they normally call it Y and the",
  "91:01": "prediction they normally call it y hat",
  "91:03": "as in they they write it like that and",
  "91:10": "so what I try to do like when we're",
  "91:14": "writing something like it you know means",
  "91:16": "grid error equation",
  "91:17": "there's no point writing ice cream here",
  "91:20": "and temperature here because we wanted",
  "91:21": "to apply it to anything so we tend to",
  "91:23": "use these like mathematical placeholders",
  "91:27": "so the value of mean squared error is",
  "91:30": "simply the difference between those two",
  "91:33": "squared all right and then we can take",
  "91:36": "the mean because remember that is",
  "91:39": "actually a vector or what we now call it",
  "91:42": "a rank 1 tensor and that is actually a",
  "91:45": "rank 1 tensor so it's the value of the",
  "91:48": "number of ice cream sales at each place",
  "91:50": "and so when we subtract 1 vector from",
  "91:54": "another vector we're going to be",
  "91:56": "learning a lot more about this but it",
  "91:57": "does something called element wise",
  "91:58": "arithmetic in other words it subtracts",
  "92:00": "each each one from each other and so we",
  "92:04": "end up with a vector of differences and",
  "92:05": "then if we take the square of that it",
  "92:08": "squares everything in that vector and so",
  "92:10": "then we can take the mean of that to",
  "92:12": "find the average square of the",
  "92:15": "differences between the actuals and the",
  "92:17": "predictors so",
  "92:20": "if you're more comfortable with",
  "92:23": "mathematical notation what we just wrote",
  "92:26": "there was the some of which we rounded",
  "92:30": "we do it y hat minus y squared over n",
  "92:41": "right so that equation is the same as",
  "92:45": "that equation so one of the things I'll",
  "92:49": "note here is I don't think this is you",
  "92:54": "know more complicated or unwieldy than",
  "92:59": "this right but the benefit of this is",
  "93:02": "you can experiment with it like once you",
  "93:05": "have to find it",
  "93:06": "you can use it you can send things into",
  "93:09": "it and get stuff out of it and see how",
  "93:10": "it works alright so for me most of the",
  "93:13": "time I prefer to explain things with",
  "93:16": "code rather than with math right because",
  "93:19": "I can actually they're the same now",
  "93:21": "they're doing in this case at least in",
  "93:23": "all the cases we'll look at they exactly",
  "93:26": "the same they're just different",
  "93:27": "notations for the same thing but one of",
  "93:30": "the notations is executable it's",
  "93:32": "something that you can experiment with",
  "93:34": "and one of them is abstract so that's",
  "93:37": "why I'm generally going to show code so",
  "93:40": "the good news is if you're a coder with",
  "93:44": "not much of a math background actually",
  "93:47": "you do have a math background because",
  "93:48": "code is math right if you've got more of",
  "93:52": "a math background and less of a code",
  "93:53": "background then actually a lot of the",
  "93:56": "stuff that you learned from math is",
  "93:57": "going to translate very directly into",
  "93:59": "code and now you can start to experiment",
  "94:01": "really with your math okay so this is",
  "94:04": "some lost function this is something",
  "94:05": "that tells us how good our line is so",
  "94:08": "now we have to kind of come up with what",
  "94:12": "is the line that fits through here",
  "94:14": "remember we don't know we're going to",
  "94:16": "pretend we don't know so what you",
  "94:18": "actually have to do is you have to guess",
  "94:20": "you actually have to come up with a",
  "94:22": "guess what are the values of a 1 and a 2",
  "94:24": "so let's say we guess that a 1 and a 2",
  "94:27": "are both 1 so this is our tensor a is 1",
  "94:32": "comma 1",
  "94:34": "so here is how we create that tenser and",
  "94:38": "I wanted to write it this way because",
  "94:40": "you'll see this all the time like",
  "94:42": "written out it should be 1.0 olives so",
  "94:45": "it's also it was telling of minus 1",
  "94:47": "minus 1 written out fully it would be",
  "94:51": "minus 1.0 1.0 like that's that's written",
  "94:55": "out fully we can't write it without the",
  "94:57": "point because that's now an INT not a",
  "95:02": "floating point so that's going to spit",
  "95:04": "the dummy if you try to do calculations",
  "95:06": "with that neural Nets",
  "95:07": "ok I'm lazy I'm far too lazy to type dot",
  "95:13": "0 every time Playford knows perfectly",
  "95:15": "well that if you added dot next to any",
  "95:17": "of these numbers then the whole thing is",
  "95:20": "now floats right so that's that's why",
  "95:22": "you'll often see it written this way",
  "95:24": "particularly by lazy people let me okay",
  "95:27": "so a is a chancer you can see it's",
  "95:33": "floating-point you see like even pi",
  "95:34": "torch is lazy they just put a dot they",
  "95:36": "don't bother with a zero right but if",
  "95:38": "you want to actually see exactly what it",
  "95:40": "is you can write dot type and you can",
  "95:46": "see it's a float tensor okay and so now",
  "95:52": "we can calculate our predictions with",
  "95:54": "this like random guess X at a matrix",
  "95:58": "product of X and a and we can now",
  "96:01": "calculate the mean squared error of our",
  "96:03": "predictions and their actuals and that's",
  "96:06": "our loss okay so for this regression our",
  "96:09": "loss is 0.9 and so we can now plot a",
  "96:15": "scatter plot of X against Y and we can",
  "96:18": "plot the scatter plot of X against Y hat",
  "96:20": "our predictions and there they are",
  "96:23": "okay so this is the 1 1 comma minus 1",
  "96:27": "line so it minus 1 comma 1 line and",
  "96:30": "here's actuals so that's not great - not",
  "96:33": "surprising it's just a guess so FGD or",
  "96:38": "gradient descent more generally and",
  "96:40": "anybody who's done in d engineering or",
  "96:43": "probably computer science at school will",
  "96:45": "have done plenty of this like Newton's",
  "96:47": "method what",
  "96:47": "all the stuff that you did University if",
  "96:50": "you didn't don't worry we're going to",
  "96:51": "learn it now it's basically about taking",
  "96:54": "this guess and trying to make it a",
  "96:56": "little bit better so how do we make it a",
  "96:59": "little bit better well there's only two",
  "97:02": "numbers right and the two numbers are",
  "97:05": "and the two numbers are the intercept of",
  "97:09": "that orange line and the gradient of",
  "97:11": "that orange line so what we're going to",
  "97:13": "do with gradient descent is we're going",
  "97:15": "to simply say what if we change those",
  "97:18": "two numbers a little bit what if we made",
  "97:20": "the intercept a little bit higher or a",
  "97:23": "little bit lower what if we made the",
  "97:28": "gradient a little bit more positive or a",
  "97:33": "little bit more negative so there's like",
  "97:36": "four possibility and then we can just",
  "97:38": "calculate the loss for each of those",
  "97:41": "four possibilities and see what see what",
  "97:43": "work did lifting it up or down make it",
  "97:46": "better there tilting it more positive or",
  "97:48": "more negative make it better and then",
  "97:50": "all we do is we say okay well whichever",
  "97:52": "one of those made it better that's what",
  "97:55": "we're going to do and that's it right",
  "97:58": "but here's the cool thing",
  "97:59": "for those of you that remember calculus",
  "98:01": "you don't actually have to move it up",
  "98:04": "and down and round about you can",
  "98:07": "actually calculate the derivative the",
  "98:09": "derivative is the thing that tells you",
  "98:11": "we're moving it up or down make it",
  "98:13": "better or would rotating it this way or",
  "98:15": "that way make it better",
  "98:17": "okay so the good news is if you didn't",
  "98:19": "do calculus or you don't remember",
  "98:20": "calculus I just told you everything you",
  "98:23": "need to know about it right which is",
  "98:26": "that it tells you how changing one thing",
  "98:29": "changes the function right that's what",
  "98:32": "that's what the derivative is kind of",
  "98:35": "not quite strictly speaking right close",
  "98:37": "enough also called the gradient okay so",
  "98:39": "the gradient or the derivative tells you",
  "98:41": "how changing a one up or down would",
  "98:45": "change our MSE now changing a true up or",
  "98:48": "down will change your MSE and this does",
  "98:51": "it more quickly does it more quickly",
  "98:52": "than actually moving it up and down okay",
  "98:55": "so um",
  "98:59": "in school unfortunately they forced us",
  "99:02": "to sit there and calculate these",
  "99:04": "derivatives by hand we have computers",
  "99:07": "computers can do that for us we are not",
  "99:10": "going to calculate them by hand instead",
  "99:13": "we're going to call dot bread on our",
  "99:19": "computer that will calculate the",
  "99:20": "gradient for us so here's what we're",
  "99:23": "going to do we're going to create a loop",
  "99:26": "we're going to loop through 100 times",
  "99:28": "and we're going to call a function",
  "99:30": "called update that function is going to",
  "99:33": "calculate Y hat our prediction it is",
  "99:38": "going to calculate loss now means grad",
  "99:41": "error from time to time it will print",
  "99:44": "that out so we can see how we're going",
  "99:47": "it will then calculate the gradient and",
  "99:50": "in pi torch calculating the gradient is",
  "99:52": "done by using a method called backward",
  "99:55": "so you'll see something really",
  "99:57": "interesting which is mean squared error",
  "99:59": "was just a simple standard mathematical",
  "100:04": "function pi torch for us keeps track of",
  "100:09": "how it was calculated and lets us",
  "100:12": "calculate the derivatives so if you do a",
  "100:14": "mathematical operation on a tensor in pi",
  "100:17": "torch you can call backward to calculate",
  "100:20": "the derivative what happens to that",
  "100:22": "derivative that gets stuck inside an",
  "100:25": "attribute called dot Brad so I'm going",
  "100:29": "to take my coefficients a and I am going",
  "100:32": "to subtract from them my gradient and",
  "100:36": "there's an underscore here why because",
  "100:40": "that's going to do it in place so it's",
  "100:42": "going to actually update those",
  "100:44": "coefficients a to subtract the gradients",
  "100:49": "from them right so why do we subtract",
  "100:52": "well because the gradient tells us if I",
  "100:54": "move the whole thing downwards the loss",
  "100:59": "goes up if I move the whole thing",
  "101:00": "upwards the loss goes down so I want to",
  "101:03": "like do the opposite of the thing that",
  "101:05": "makes it go up right so because our last",
  "101:07": "we want to loss to be small so that's",
  "101:10": "why we have to subtract",
  "101:12": "and then there's something here called",
  "101:14": "LR LR is our learning rate and so",
  "101:22": "literally all it is is the thing that we",
  "101:24": "multiply by the gradient why is there",
  "101:29": "any LR at all let me show you why let's",
  "101:36": "take a really simple example a quadratic",
  "101:45": "okay and let's see your algorithms job",
  "101:49": "was to find where that quadratic was at",
  "101:51": "its lowest point and so well how could",
  "101:54": "it do this well just like what we're",
  "101:55": "doing now the starting point would just",
  "101:57": "be to pick some x value at random and",
  "102:01": "then pop up here to find out what the",
  "102:04": "value of y is okay that's the starting",
  "102:07": "point and so then it can calculate the",
  "102:10": "gradient and the gradient is simply the",
  "102:12": "slope but it tells you moving in which",
  "102:16": "direction is going to make you go down",
  "102:17": "and so the gradient tells you you have",
  "102:20": "to go this way so if the gradient was",
  "102:25": "really big you might jump this way a",
  "102:29": "very long way so you might jump all the",
  "102:32": "way over to here maybe even here right",
  "102:40": "and so if you jumped over to there then",
  "102:46": "that's actually not going to be very",
  "102:47": "helpful because then you see well where",
  "102:50": "does that take us to Oh it's now worse",
  "102:53": "right we jumped too far so we want don't",
  "102:59": "want to jump too far so maybe we should",
  "103:01": "just jump a little bit maybe to here and",
  "103:06": "the good news is that is actually a",
  "103:09": "little bit closer and so then we'll just",
  "103:11": "do another little jump see what the",
  "103:13": "gradient is into another liberal jump",
  "103:14": "that takes us to here and another little",
  "103:16": "jump that takes us to here here yeah",
  "103:20": "right so in other words we find our",
  "103:23": "gradient to tell us kind of what",
  "103:25": "direction to go and like",
  "103:26": "we have to go a long way or not too far",
  "103:28": "but then we multiply it by some number",
  "103:31": "less than one so we don't jump too far",
  "103:34": "and so hopefully at this point this",
  "103:37": "might be reminding you of something",
  "103:38": "which is what happened when our learning",
  "103:45": "rate was too high so do you see why that",
  "103:49": "happened now our learning rate was too",
  "103:51": "high",
  "103:52": "meant that we jumped all the way past",
  "103:56": "the right answer further than we started",
  "103:59": "with",
  "103:59": "and it got worse and worse and worse so",
  "104:04": "that's what a learning rate to high does",
  "104:10": "on the other hand if our learning rate",
  "104:13": "is too low then you just take tiny",
  "104:17": "little steps and so eventually you're",
  "104:20": "going to get there but you're doing lots",
  "104:22": "and lots of calculations along the way",
  "104:23": "so you really want to find something",
  "104:26": "where it's kind of either like this or",
  "104:30": "maybe it's kind of a little bit",
  "104:31": "backwards and forwards maybe it's kind",
  "104:32": "of like this something like that you",
  "104:36": "know you want something that kind of",
  "104:37": "gets in there quickly but not so quickly",
  "104:40": "it jumps out and diverges not so slowly",
  "104:44": "that it takes lots of steps so that's",
  "104:46": "why we need a good learning rate and so",
  "104:50": "that's all it does so if you look inside",
  "104:52": "the source code of any deep learning",
  "104:55": "library you will find this you will find",
  "104:58": "something that says coefficients dot",
  "105:00": "subtract learning rate times gradient",
  "105:03": "and we'll learn about some minor up not",
  "105:06": "minor what about so easy bad important",
  "105:09": "optimizations we can do to make this go",
  "105:11": "faster but that's basically it there's a",
  "105:16": "couple of other little minor issues that",
  "105:18": "we don't need to talk about now one",
  "105:19": "involving zeroing out the gradients and",
  "105:21": "other involving making sure that you",
  "105:23": "turn gradient calculation off when you",
  "105:25": "do the SGD update if you're interested",
  "105:29": "we can discuss them on the forum or you",
  "105:32": "can do our introduction to machine",
  "105:35": "learning course which covers the other",
  "105:38": "mechanics of this in more detail",
  "105:41": "but this is the basic idea so if we run",
  "105:44": "update 100 times printing out the loss",
  "105:47": "from time to time you can see it starts",
  "105:49": "at 8.9 it goes down down down down down",
  "105:53": "down down and so we can then print out",
  "105:55": "scatter plots and there it is that's it",
  "105:59": "but leave it or not that's gradient",
  "106:02": "descent so we just need to start with a",
  "106:05": "function that's a bit more complex than",
  "106:08": "X at a but as long as we have a function",
  "106:13": "that can represent things like is this a",
  "106:15": "teddy bear we now have a way to fit it",
  "106:18": "okay and so let's now take a look at",
  "106:22": "this as a picture as an animation and",
  "106:24": "this is one of the nice things that you",
  "106:26": "can do with this is one of the nice",
  "106:33": "things that you can do with matplotlib",
  "106:35": "is you can take Eddie plot and turn it",
  "106:38": "into an animation mat and so you can now",
  "106:40": "actually see it updating each step so",
  "106:42": "let's see what we did here we simply",
  "106:45": "said as before create a scatter plot but",
  "106:50": "then rather than having a loop we used",
  "106:53": "matplotlib func animation so call 100",
  "106:57": "times this function and this function",
  "107:01": "just called that update that we created",
  "107:03": "earlier and then updated the Y data in",
  "107:07": "our line and so did that 100 times",
  "107:10": "waiting 20 milliseconds after each one",
  "107:12": "and there it is right so you might think",
  "107:15": "that like visualizing your algorithms",
  "107:19": "with animations is some amazing and",
  "107:22": "complex thing to do but actually now you",
  "107:24": "know it's 1 2 3 4 5 6 7 8 9 10 11 lines",
  "107:28": "of code okay so I think that is pretty",
  "107:33": "damn cool",
  "107:35": "so that is SGD visualized and so we",
  "107:39": "can't visualize as conveniently what",
  "107:42": "updating 50 million parameters in a",
  "107:44": "resonant 34 looks like but basically",
  "107:46": "doing the same thing okay and so",
  "107:49": "studying these simple versions is",
  "107:50": "actually a great way to get an intuition",
  "107:52": "so you should try running this No",
  "107:54": "book with a really big learning rate",
  "107:56": "with a really small learning rate and",
  "107:58": "see what this animation looks like that",
  "108:01": "and try get a feel for it maybe you can",
  "108:03": "even try a 3d plot I haven't tried that",
  "108:05": "yet but I'm sure it would work fine - so",
  "108:09": "the only difference between stochastic",
  "108:12": "gradient descent and this is something",
  "108:14": "called mini-batches",
  "108:15": "you'll see what we did here was we",
  "108:17": "calculated the value of the loss on the",
  "108:20": "whole data set on every iteration but if",
  "108:23": "your data set is one and a half million",
  "108:25": "images in image net that's going to be",
  "108:27": "really slow right just to do a single",
  "108:29": "update of your parameters you've got to",
  "108:31": "calculate the loss on one and a half",
  "108:33": "million images you wouldn't want to do",
  "108:36": "that so what we do is we grab 64 images",
  "108:40": "or so at a time at random and we",
  "108:44": "calculate the loss on those 64 images",
  "108:46": "and we update our weights and then we",
  "108:49": "have another 64 random images we update",
  "108:51": "the weights so in other words the loop",
  "108:54": "basically looks exactly the same but at",
  "108:57": "this point here so it'd basically be Y",
  "109:00": "square bracket and some random indexes",
  "109:04": "here you know and some random indexes",
  "109:08": "here and we'd basically do the same",
  "109:10": "thing and well actually so it would be",
  "109:16": "there right so some random indexes on",
  "109:19": "our X and some random indexes on our way",
  "109:21": "to do a mini batch at a time and that",
  "109:23": "would be the basic difference and so",
  "109:25": "once you add those you know grab a",
  "109:29": "random few points each time those random",
  "109:32": "few points accord your mini batch and",
  "109:34": "that approach is called SGD for",
  "109:36": "stochastic gradient descent okay so",
  "109:40": "there's quite a bit of vocab we've just",
  "109:44": "covered right so let's just remind",
  "109:47": "ourselves the learning rate is a thing",
  "109:51": "that we multiply our gradient by to",
  "109:53": "decide how much to update the weights by",
  "109:55": "an epoch is one complete run through all",
  "110:01": "of our data points all of our images so",
  "110:05": "for the non stochastic gradient descent",
  "110:08": "we just did every single loop we did the",
  "110:11": "entire data set but if you've got a data",
  "110:13": "set with a thousand images and your mini",
  "110:17": "batch size is 100 then it would take you",
  "110:19": "ten iterations to see every image once",
  "110:22": "so that would be one epoch the epochs",
  "110:26": "are important because if you do lots of",
  "110:28": "epochs then you're looking at your",
  "110:30": "images lots of times and so every time",
  "110:33": "you see an image there's a bigger chance",
  "110:36": "of overfitting so we generally don't",
  "110:38": "want to do too many epochs a mini batch",
  "110:41": "is just a random bunch of points that",
  "110:44": "you use to update your weights SGD is",
  "110:48": "just gradient descent using mini-batches",
  "110:53": "architecture and model kind of mean the",
  "110:56": "same thing in this case our architecture",
  "110:59": "is y equals XA and the architecture is",
  "111:06": "the mathematical function that you're",
  "111:08": "fitting the parameters to and we're",
  "111:10": "going to learn later today or next week",
  "111:14": "what the mathematical function of things",
  "111:17": "like ResNet 34 actually is but it's",
  "111:20": "basically pretty much what you've just",
  "111:22": "seen it's a bunch of matrix products",
  "111:26": "parameters also known as coefficients",
  "111:29": "also known as weights the set the",
  "111:32": "numbers that you're updating and then",
  "111:35": "loss function is the thing that's",
  "111:37": "telling you how far away or how close",
  "111:39": "you are to the correct answer any",
  "111:41": "questions all right so these model these",
  "111:48": "predictors these teddybear classifiers",
  "111:50": "are functions that take pixel values and",
  "111:52": "return probabilities they start with",
  "111:55": "some functional form like y equals XA",
  "112:00": "and they fit the parameters a using SGD",
  "112:05": "to try and do the best to calculate your",
  "112:09": "predictions so far we've learned how to",
  "112:11": "do regression which is a single number",
  "112:15": "next week we'll learn how to do the same",
  "112:18": "thing for classification where we have",
  "112:20": "multiple numbers",
  "112:21": "the same in the process we had to do",
  "112:29": "some math we had to do some linear",
  "112:31": "algebra and we had to do some calculus",
  "112:33": "and a lot of people get a bit scared at",
  "112:37": "that point and tell us I am NOT a math",
  "112:40": "person if that is you that's totally",
  "112:44": "okay but you're wrong you are a math",
  "112:47": "person in fact it turns out that when in",
  "112:50": "the actual academic research around this",
  "112:53": "there are not math people and non math",
  "112:55": "people it turns out to be entirely a",
  "112:58": "result of culture and expectations so",
  "113:02": "you should check out Rachel's talk",
  "113:05": "there's no such thing as not a math",
  "113:08": "person where she will introduce you to",
  "113:11": "some of that academic research and so if",
  "113:13": "you think of yourself as not a math",
  "113:14": "person you should watch this so that you",
  "113:17": "learn that you're wrong that your",
  "113:19": "thoughts are actually there because",
  "113:21": "somebody has told you you're not a math",
  "113:23": "person but there's actually no academic",
  "113:27": "research to suggest that there is such a",
  "113:29": "thing in fact there are some cultures",
  "113:31": "like Romania and China where the not a",
  "113:35": "math person concept never even appeared",
  "113:38": "there that it's almost unheard of in",
  "113:41": "some cultures for somebody to say I'm",
  "113:43": "not a math person because they're just",
  "113:45": "never entered that cultural identity so",
  "113:50": "don't freak out if words like derivative",
  "113:53": "and gradient and matrix product are",
  "113:56": "things that you're kind of scared of",
  "113:58": "it's something you can learn it's",
  "114:00": "something you'll be okay with okay",
  "114:04": "so the last thing that we're going to",
  "114:06": "close with today",
  "114:10": "oh I just got a message from Simon",
  "114:13": "Willison ah",
  "114:17": "Simon's telling me he's actually not",
  "114:19": "that special",
  "114:20": "lots of people won medals so",
  "114:24": "that's the worst part about Simon is not",
  "114:27": "only is he really smart he's also really",
  "114:29": "modest which I think it's just awful",
  "114:31": "I mean if you're going to be that smart",
  "114:35": "at least be a horrible human being and",
  "114:36": "you know make it okay okay so the last",
  "114:43": "thing I want to close with is the idea",
  "114:45": "of and we're going to look at this more",
  "114:47": "next week underfitting over and over",
  "114:49": "fitting we just fit a line to our data",
  "114:56": "but imagine that our data wasn't",
  "114:57": "actually line shaped right and so if we",
  "115:01": "try to fit something which was like",
  "115:03": "constant plus constant times X ie align",
  "115:06": "to it that it's never going to fit very",
  "115:08": "well right no matter how much we change",
  "115:11": "these two coefficients it's never going",
  "115:14": "to get really close on the other hand we",
  "115:17": "could fit some much bigger equation so",
  "115:20": "in this case it's a higher degree",
  "115:21": "polynomial with lots of lots of Wiggly",
  "115:23": "bits like so right but if we did that",
  "115:26": "it's very unlikely we go and look at",
  "115:29": "some other place to find out the",
  "115:31": "temperature that it is and how much ice",
  "115:32": "cream they're selling and that will get",
  "115:34": "a good result because like the Wiggles",
  "115:36": "are far too Wiggly so this is called",
  "115:39": "overfitting we're looking for some",
  "115:42": "mathematical function that fits just",
  "115:44": "right to stay with a teddy bear",
  "115:46": "analogies so you might think if you have",
  "115:52": "a statistics background the way to make",
  "115:54": "things fit just right is to have exactly",
  "115:57": "the right number of parameters it's to",
  "115:59": "use a mathematical function that doesn't",
  "116:01": "have too many parameters in it",
  "116:03": "it turns out that actually completely",
  "116:05": "not the right way to think about it",
  "116:07": "there are other ways to make sure that",
  "116:09": "we don't over fit and in general this is",
  "116:12": "called regularization regularization or",
  "116:15": "all the techniques to make sure that",
  "116:17": "when we train our model that it's going",
  "116:20": "to work not not only well on the data",
  "116:23": "its seen but on the data it hasn't seen",
  "116:26": "yet so the most important thing to know",
  "116:30": "when you've trained a model is actually",
  "116:33": "how well does it work",
  "116:34": "on data that it hasn't been trained with",
  "116:37": "and so as we're going to learn a lot",
  "116:39": "about next week that's why we have this",
  "116:42": "thing called a validation set so what",
  "116:44": "happens with the validation set is that",
  "116:48": "we do our mini batch F GED training loop",
  "116:52": "with one set of data with one set of",
  "116:55": "teddy bears Grizzlies black bears and",
  "116:57": "then when we're done we check the lost",
  "117:00": "function and the accuracy to see how",
  "117:03": "good is it on a bunch of images which",
  "117:05": "were not included in the training and so",
  "117:08": "if we do that then if we have something",
  "117:10": "which is too Wiggly it'll tell us oh",
  "117:13": "your loss function in your air is really",
  "117:15": "bad because on the Bears that it hasn't",
  "117:17": "been trained with the wiggly bits are in",
  "117:19": "the wrong spot where if it was under",
  "117:21": "fitting it would also tell us that your",
  "117:24": "validation sets really bad so like even",
  "117:29": "for people that don't go through this",
  "117:32": "course and don't learn about the details",
  "117:34": "of deep learning like if you've got",
  "117:37": "managers or colleagues or whatever at",
  "117:39": "work who are kind of wanting to like",
  "117:41": "moan about AI the only thing that you",
  "117:43": "really need to be teaching them is about",
  "117:45": "the idea of a validation set because",
  "117:47": "that's the thing they can then use to",
  "117:48": "figure out you know if somebody's",
  "117:51": "telling them snake oil or not you know",
  "117:53": "they're like hold back some data and",
  "117:54": "then they get told like oh here's a",
  "117:56": "model that we're going to roll out and",
  "117:58": "then you say okay fine I'm just going to",
  "118:00": "check it on this held out data to see",
  "118:02": "whether it generalizes there's a lot of",
  "118:04": "details to get right when you design",
  "118:07": "your validation set we will talk about",
  "118:10": "them briefly next week but a more full",
  "118:14": "version would be in Rachel's piece on",
  "118:17": "the first day I blog called how and why",
  "118:19": "to create a good validation set and this",
  "118:22": "is also one of the things we go into in",
  "118:24": "a lot of detail in the intro to machine",
  "118:26": "learning course so we're going to try",
  "118:28": "and give you enough to get by for this",
  "118:31": "course but it is certainly something",
  "118:32": "that's worth deeper study as well any",
  "118:35": "questions or comments before we wrap up",
  "118:38": "okay good all right well thanks",
  "118:41": "everybody I hope you have a great time",
  "118:42": "building your web applications see you",
  "118:44": "next week"
}
