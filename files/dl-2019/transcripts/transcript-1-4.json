{
"00:00": "okay welcome to lesson 4 we are going to",
"00:06": "finish our journey through these kind of",
"00:09": "key applications we've already looked at",
"00:11": "a range of vision applications we've",
"00:14": "looked at classification localization",
"00:17": "image regression we've briefly touched",
"00:20": "on NLP we're going to do a deeper dive",
"00:23": "into NLP transfer learning today we're",
"00:26": "going to then look at tabular data and",
"00:29": "we're going to look at collaborative",
"00:31": "filtering which are both super useful",
"00:33": "applications and then we're going to",
"00:35": "take a complete u-turn we're going to",
"00:37": "take that collaborative filtering",
"00:38": "example and dive deeply into it to",
"00:41": "understand exactly what's happening",
"00:43": "mathematically exactly what's happening",
"00:45": "in the computer and we're going to use",
"00:47": "that to gradually go back in reverse",
"00:49": "order through the applications again in",
"00:52": "order to understand exactly what's going",
"00:54": "on behind the scenes of all of those",
"00:55": "applications before we do somebody on",
"01:01": "the forum was kind enough to point out",
"01:03": "that when we compared ourselves to the",
"01:06": "what we think might be the",
"01:08": "state-of-the-art but was recently the",
"01:09": "state of the art for camford there",
"01:11": "wasn't a fair comparison because the",
"01:14": "paper actually used a small subset of",
"01:16": "the classes and we used all of the",
"01:19": "classes so jason in our study group was",
"01:22": "kind enough to rerun the experiments",
"01:24": "with the correct subset of classes from",
"01:27": "the paper and our accuracy went up to 94",
"01:30": "percent compared to 91.5% in the paper",
"01:34": "so I think that's a really cool result",
"01:36": "and a great example of how some pretty",
"01:40": "you know pretty much just using the",
"01:43": "defaults nowadays can can get you far",
"01:46": "beyond what was the best of a year or",
"01:48": "two ago now it's certainly the best last",
"01:51": "year when we were doing this course",
"01:52": "because we started it quite quite",
"01:54": "intensely so that's really exciting so",
"02:01": "what I wanted to start with is going",
"02:07": "NLP a little bit to understand really",
"02:11": "what was going on there so first of all",
"02:12": "a quick review",
"02:15": "so remember NLP is natural language",
"02:18": "processing it's about taking text and",
"02:22": "doing something with it and text",
"02:25": "classification is particularly useful",
"02:27": "kind of practically useful applications",
"02:30": "it's what we're going to start off",
"02:31": "focusing on because classifying a text",
"02:35": "classifying a document can be used for",
"02:38": "anything from spam prevention to",
"02:41": "identifying fake news to finding a",
"02:46": "diagnosis or medical reports finding",
"02:51": "mentions of your product in Twitter so",
"02:54": "on and so forth",
"02:55": "so it's pretty interesting and actually",
"02:58": "there was a great example there was a",
"03:02": "great example during the week from one",
"03:04": "of our students who is a lawyer and he",
"03:10": "mentioned on the forum that he had a",
"03:13": "really great results from classifying",
"03:16": "legal texts using this NLP approach and",
"03:21": "I thought this was a great example so",
"03:22": "this is the post that they presented at",
"03:25": "an academic conference this week",
"03:27": "describing the approach and actually",
"03:30": "this series of three steps that you see",
"03:34": "here and I'm sure you recognize these",
"03:35": "classification matrix this series of",
"03:38": "three steps here is what we're going to",
"03:40": "start by digging into so we're going to",
"03:44": "start out with a movie review like this",
"03:46": "one and going to decide whether it's",
"03:48": "positive or negative sentiment about the",
"03:52": "movie that is the problem we have in the",
"03:58": "training set 25,000 movie reviews so",
"04:04": "we've got 25,000 movie reviews and for",
"04:08": "each one we have like one bit of",
"04:10": "information they liked it or they didn't",
"04:13": "like it and that's we're going to look",
"04:14": "into a lot more detail of today and in",
"04:17": "the current lessons our neural networks",
"04:19": "remember they're just a bunch of matrix",
"04:22": "multiplies and simple nonlinearities",
"04:25": "particularly replacing negatives with",
"04:27": "zeros those weight matrices start out",
"04:30": "random and so if you start out with with",
"04:34": "some random parameters and try to train",
"04:38": "those parameters to learn how to",
"04:40": "recognize positive versus negative movie",
"04:42": "reviews",
"04:43": "you only have 20 literally 25,000 ones",
"04:46": "and zeros to actually tell you I like",
"04:48": "this one I don't like that one that's",
"04:49": "clearly not enough information to learn",
"04:53": "basically how to speak English how to",
"04:55": "speak English well enough to recognize",
"04:57": "they liked this or they didn't like this",
"05:00": "and sometimes that can be pretty nuanced",
"05:03": "right the English language often",
"05:04": "particularly would like movie reviews",
"05:06": "people because these are like online",
"05:08": "movie reviews on IMDB people can often",
"05:11": "like use sarcasm it could be really",
"05:12": "quite tricky so it for a long time until",
"05:16": "in fact until very recently like this",
"05:19": "year neural nets didn't do a good job at",
"05:24": "all of this kind of classification",
"05:27": "problem and and that was why there's not",
"05:29": "enough information available so the",
"05:33": "trick hopefully you can all guess it's",
"05:36": "to use transfer learning it's always the",
"05:38": "trick so last year in this course I",
"05:42": "tried something crazy which was I",
"05:44": "thought what if I try transfer learning",
"05:46": "to demonstrate that it can work for an",
"05:49": "LP as well and and I tried it out and it",
"05:53": "worked extraordinarily well and so here",
"05:55": "we are a year later and transfer",
"05:58": "learning in NLP is absolutely the the",
"06:00": "hit thing now and so I'm going to",
"06:02": "describe to you what happens the key",
"06:05": "thing is we're going to start with the",
"06:07": "same kind of thing that we used for",
"06:11": "computer vision a pre trained model",
"06:12": "that's been trained to do something",
"06:14": "different to what we're doing with it",
"06:16": "and so for imagenet that was originally",
"06:20": "built as a model to predict which of a",
"06:22": "thousand categories each photo falls",
"06:25": "into and people then fine-tune that for",
"06:27": "all kinds of different things as we've",
"06:28": "seen so we're going to start with a pre",
"06:31": "trained model that's going to do",
"06:32": "something else",
"06:33": "not movie review classification we're",
"06:36": "going to start with a pre train model",
"06:37": "which is called a language model a",
"06:39": "language model is a very very specific",
"06:42": "meeting in NLP and it's this a language",
"06:45": "model is a model that learns to predict",
"06:47": "the next word of a sentence and to",
"06:51": "predict the next word of a sentence you",
"06:53": "actually have to know quite a lot about",
"06:55": "English assuming you're doing it in",
"06:58": "English and quite a lot of world",
"07:00": "knowledge by world knowledge a different",
"07:02": "example here's your language model and",
"07:04": "as read I'd like to eat a hot what",
"07:08": "obviously",
"07:10": "dog right it was a heart what",
"07:14": "probably day right now previous",
"07:17": "approaches to NLP use something called",
"07:20": "engrams largely which is basically",
"07:22": "saying how often do these pairs or",
"07:24": "triplets of words tend to appear next to",
"07:26": "each other",
"07:27": "and engrams are terrible at this kind of",
"07:29": "thing as you can see there's not enough",
"07:31": "information here to decide what the next",
"07:33": "word probably is but with a neural net",
"07:36": "you're absolutely can so here's the nice",
"07:40": "thing if you train a neural net to",
"07:43": "predict the next word of a sentence then",
"07:47": "you actually have a lot of information",
"07:49": "rather than having a single bit for",
"07:51": "every 2000 word movie review liked it or",
"07:54": "different like it every single word you",
"07:57": "can try and predict the next word so in",
"07:59": "a 2,000 word movie review",
"08:01": "there are 1999 opportunities to predict",
"08:05": "the next word better still you don't",
"08:09": "just have to look at movie reviews",
"08:11": "because really the hard thing isn't so",
"08:14": "much is does this person like the movie",
"08:16": "or not but how do you speak English and",
"08:20": "so you can learn how do you speak",
"08:22": "English roughly from some much bigger",
"08:25": "set of documents and so what we did was",
"08:28": "we started with Wikipedia and Stephen",
"08:32": "Merritt II and some of his colleagues",
"08:33": "built something called the wiki text 103",
"08:35": "data set which is simply a subset of",
"08:39": "most of the largest articles from",
"08:41": "Wikipedia with a little bit of",
"08:44": "pre-processing that's available for",
"08:45": "download",
"08:46": "and so you're basically grabbing",
"08:48": "Wikipedia and then I built a language",
"08:50": "model on all of Wikipedia right so I've",
"08:53": "just built a neural net which would",
"08:55": "predict the next word in every",
"08:57": "significantly sized Wikipedia article",
"09:00": "and that's a lot of information if I",
"09:03": "remember correctly it's something like a",
"09:04": "billion tokens all right so we've got a",
"09:06": "billion separate things to predict every",
"09:08": "time we make a mistake on one of those",
"09:10": "predictions we get the loss can get we",
"09:13": "get gradients from that and we can",
"09:15": "update our weights and make them better",
"09:16": "and better until we can get pretty good",
"09:18": "at predicting the next word of Wikipedia",
"09:21": "why is that useful because at that point",
"09:23": "I've got a model that knows probably how",
"09:25": "to complete sentences like this and so",
"09:28": "it knows quite a lot about English and",
"09:30": "quite a lot about how the world works",
"09:32": "what kinds of things tend to be hot in",
"09:35": "different situations for instance I mean",
"09:37": "ideally it would learn things like in",
"09:41": "1996 in a speech to the United Nations",
"09:44": "United States President blah said now",
"09:49": "that would be a really good language",
"09:50": "model because it would actually have to",
"09:51": "know who was this United States",
"09:53": "president in that year so like getting",
"09:55": "really good at training language models",
"09:58": "is a great way to learn a lot about or",
"10:01": "teacher neural-net",
"10:01": "a lot about you know what is our world",
"10:05": "what's in our world how do things work",
"10:08": "in our world so it's a really",
"10:09": "fascinating topic and it's actually one",
"10:12": "that philosophers have been studying for",
"10:14": "hundreds of years now there's actually a",
"10:16": "whole theory of philosophy which is",
"10:18": "about like what can be learned from",
"10:21": "studying language alone so it turns out",
"10:24": "empirically quite a lot and so here's",
"10:27": "the interesting thing you can start by",
"10:29": "training a language model on all of",
"10:30": "Wikipedia and then we can make that",
"10:32": "available to all of you just like a pre",
"10:34": "trained imagenet model her vision we've",
"10:36": "now made available a pre trained",
"10:38": "wikitext model for NLP not because it's",
"10:41": "particularly useful of itself predicting",
"10:43": "the next word of sentences is somewhat",
"10:46": "useful but not normally what we want to",
"10:48": "do but it tells us it's a it's a model",
"10:51": "that understands a lot about language",
"10:53": "and a lot about what language describes",
"10:55": "so then we can take that and we can do",
"10:59": "transfer learning to create a new",
"11:02": "language model that's specifically good",
"11:05": "at predicting the next word of movie",
"11:07": "reviews so if we can build a language",
"11:12": "model that's good at predicting the next",
"11:14": "word of movie reviews pre trained with",
"11:17": "the wikitext model right then that's",
"11:20": "going to understand a lot about my",
"11:22": "favorite actor is Tom who write or you",
"11:26": "know I thought the photography was",
"11:29": "fantastic but I wasn't really so happy",
"11:30": "about the director whatever right it's",
"11:34": "going to learn a lot about specifically",
"11:35": "how movie reviews are written it'll even",
"11:39": "learned things like what are the names",
"11:40": "of some popular movies so that would",
"11:45": "then mean we can still use a huge corpus",
"11:48": "of lots of movie reviews even if we",
"11:50": "don't know whether they're positive or",
"11:51": "negative right to learn a lot about how",
"11:53": "movie reviews are written so for all of",
"11:54": "this pre training and all of this",
"11:56": "language model fine-tuning we don't need",
"11:58": "any labels at all",
"11:59": "it's what the researcher Yan Lacan calls",
"12:02": "self supervised learning in other words",
"12:05": "it's a classic supervisor model we have",
"12:07": "labels",
"12:08": "right but the labels are not things that",
"12:09": "somebody else have created they're kind",
"12:11": "of built into the data set itself so",
"12:14": "this is really really neat because at",
"12:16": "this point we've now got something",
"12:17": "that's good at understanding movie",
"12:19": "reviews and we can fine-tune that with",
"12:22": "transfer learning to do the thing we",
"12:24": "want to do which in this case is to",
"12:26": "classify movie reviews to be positive or",
"12:28": "negative and so my hope was when I tried",
"12:30": "this last year that at that point 25,000",
"12:33": "ones and zeros would be enough feedback",
"12:36": "to fine-tune that model and it turned",
"12:39": "out it absolutely was all right Rachel",
"12:43": "let's go with a question does the",
"12:47": "language model approach work for text in",
"12:50": "forums that are informal English",
"12:51": "misspelled words are slang or short form",
"12:54": "like S six instead of Samsung S six yes",
"13:01": "absolutely it does particularly if you",
"13:04": "start with your wikitext model and then",
"13:07": "fine tune it with your we call it a",
"13:09": "target corpus",
"13:10": "so your tech or purse is just a bunch of",
"13:12": "documents right could be emails or",
"13:15": "tweets or medical reports or whatever so",
"13:19": "you could fine tune it so it can learn a",
"13:23": "bit about the specifics of the slang if",
"13:25": "you know or abbreviations or whatever",
"13:27": "that didn't appear in the full corpus",
"13:29": "and so interestingly this is one of the",
"13:32": "big things that people were surprised",
"13:33": "about when we did this research last",
"13:35": "year",
"13:35": "people thought that learning from",
"13:37": "something like Wikipedia wouldn't be",
"13:40": "that helpful because it's not that",
"13:42": "representative of how people tend to",
"13:43": "write but it turns out it's extremely",
"13:45": "helpful because there's a much bigger",
"13:47": "difference between Wikipedia and random",
"13:50": "words than there is between like",
"13:52": "wikipedia and read it say so it kind of",
"13:55": "gets you 99% of the way there",
"14:01": "so these language models themselves can",
"14:05": "be quite powerful so for example there",
"14:06": "was a blog post from what are they",
"14:10": "called SwiftKey swiftlet SwiftKey the",
"14:15": "folks that do the mobile phone",
"14:17": "predictive text keyboard and they",
"14:19": "described how they kind of rewrote their",
"14:22": "their underlying model to use neural",
"14:25": "nets so and now this was a year or two",
"14:27": "ago now most phone keyboards seem to do",
"14:30": "this you'll be typing away on your",
"14:31": "mobile phone and in the predictions",
"14:33": "there'll be something telling you what",
"14:34": "words you might want next so that's a",
"14:36": "language model in your phone another",
"14:39": "example was the researcher on drake",
"14:41": "apathy who's now runs all this stuff at",
"14:45": "Tesla Beck when he has a PhD student he",
"14:48": "created a language model of text in",
"14:51": "latex documents and created these",
"14:54": "automatic generation of latex documents",
"14:57": "that then became these kind of",
"14:58": "automatically generated papers that's",
"15:00": "pretty cute so we're not really that",
"15:04": "interested in the output of the language",
"15:06": "model ourselves we're just interested in",
"15:07": "it because it's helpful with this",
"15:09": "process so um we briefly looked at the",
"15:16": "process last week so that's like just",
"15:18": "have a reminder right that the basic",
"15:21": "process is we're going to start with",
"15:23": "the the data in some format so for",
"15:27": "example we've prepared a little IMDB",
"15:29": "sample that you can use where it's in",
"15:30": "CSV file so you can read it in with",
"15:33": "pandas and see there's negative or",
"15:35": "positive the text of each movie review",
"15:38": "and boolean of is it in the validation",
"15:40": "set or the training set so there's an",
"15:43": "example of a movie review and so you can",
"15:45": "just go text date a bunch from CSV to",
"15:47": "grab a language model specific data",
"15:51": "bunch and then you can create a learner",
"15:52": "from that in the usual way and fit it",
"15:54": "you can save there's a data bunch which",
"15:58": "means that the pre-processing that is",
"16:00": "done you don't have to do it again you",
"16:02": "can just load it so what goes on behind",
"16:07": "the scenes well what happens behind the",
"16:09": "scenes if we now load it as a",
"16:11": "classification data bunch that's going",
"16:13": "to allow us to see the labels as well",
"16:15": "then as we described it basically",
"16:18": "creates a separate unit we call it a",
"16:21": "token for each separate part of a word",
"16:24": "so most of them are just small words but",
"16:27": "sometimes if it's like an apostrophe s",
"16:28": "from its you know get its own token",
"16:33": "every bit of punctuation tends to get",
"16:35": "its own pro cone like a comma or a",
"16:36": "full-stop and so forth and then the next",
"16:43": "thing that we do is a numerical ization",
"16:45": "which is where we find what are all of",
"16:47": "the unique tokens that appear here and",
"16:52": "we create a big list of them here's the",
"16:53": "first ten in order of frequency and that",
"16:55": "big list of unique possible tokens is",
"16:58": "called the vocabulary no it's called a",
"17:00": "vocab and so what we then do is we",
"17:02": "replace the tokens with the ID of where",
"17:08": "is that token in the vocab okay and that",
"17:11": "that's numerical ization here's the",
"17:14": "thing though as you'll learn every word",
"17:18": "in our vocabulary and so to avoid that",
"17:26": "weight matrix getting too huge we",
"17:29": "restrict the vocab to no more than by",
"17:33": "default 60,000 words and if a word",
"17:36": "doesn't",
"17:36": "appear more than two times we don't put",
"17:38": "it in the vocab either so we kind of",
"17:40": "keep the vocab to a reasonable size in",
"17:43": "that way and so when you see these xx",
"17:48": "UNK that's an unknown token so when you",
"17:53": "see those unknown tokens it just means",
"17:55": "this was something that was not a common",
"18:00": "enough word to appear in our vocab okay",
"18:04": "so there is the numerical lowest version",
"18:06": "we also have a couple of other special",
"18:08": "tokens like XX field this is a special",
"18:12": "thing where if you've got like title",
"18:15": "summary abstract body like separate",
"18:18": "parts of a document each one will get a",
"18:20": "separate field and so they will get",
"18:21": "numbered also you'll find if there's",
"18:24": "something in all caps it gets lower",
"18:25": "cased and a token called xx cap will get",
"18:28": "added to it personally I more often use",
"18:34": "the data block API because you get kind",
"18:38": "of there's less to remember about",
"18:40": "exactly what data bunch to use and what",
"18:41": "parameters and so forth and it can be a",
"18:43": "bit more flexible so another approach to",
"18:45": "doing this is to just decide what kind",
"18:48": "of list you're creating so what's your",
"18:50": "independent variable so in this case my",
"18:52": "independent variable is text",
"18:54": "what is it coming from a CSV how do you",
"18:57": "want to split it into validation versus",
"19:00": "training so in this case column number",
"19:02": "two was the is validation flag how do",
"19:06": "you want to label it with positive or",
"19:09": "negative sentiment for example so column",
"19:11": "0 had that and then turn that into a",
"19:13": "database that's going to do the same",
"19:15": "thing okay",
"19:18": "so now let's grab the whole data set",
"19:23": "which has 25,000 reviews in trading",
"19:26": "25,000 reviews in validation and then",
"19:29": "50,000 what they call unsupervised movie",
"19:32": "reviews so fifty thousand movie reviews",
"19:34": "that haven't been scored at all so there",
"19:39": "it is positive negative unsupervised so",
"19:45": "we're going to start as we described",
"19:49": "with the language model now the good",
"19:52": "news is we don't have to train the",
"19:53": "wikitext 103 language model not that",
"19:56": "it's difficult you can use exactly the",
"19:57": "same steps you see here just download",
"19:59": "the wiki text 103 corpus and run the",
"20:03": "same code but it takes two or three days",
"20:06": "on a decent GPU so not much point you",
"20:10": "doing it you may as well start with",
"20:11": "hours even if you've got a big corpus of",
"20:13": "like medical documents or legal",
"20:15": "documents you should still start with",
"20:17": "wikitext 103 like there's just no reason",
"20:19": "to start with random weights it's always",
"20:21": "good to use transfer learning if you can",
"20:26": "so we're going to start then at this",
"20:29": "point which is fine-tuning our IMDB",
"20:32": "language language model so we can say",
"20:34": "okay it's a list of text files and the",
"20:36": "full IMDB actually is not in a CSV each",
"20:40": "each document is a separate text file so",
"20:43": "that's why we use a different",
"20:44": "constructor for our independent variable",
"20:46": "text files list say where it is and in",
"20:49": "this case we have to make sure we just",
"20:50": "don't include the train and test folders",
"20:52": "and we randomly split it by 0.1 now this",
"20:58": "is interesting",
"20:59": "10% why are we randomly splitting it by",
"21:01": "10% rather than using the predefined",
"21:03": "train and test they gave us this is one",
"21:06": "of the cool things about transfer",
"21:07": "learning even though our test set or a",
"21:11": "validation set has to be held aside it's",
"21:13": "actually only the labels that we have to",
"21:16": "keep aside so we're not allowed to use",
"21:17": "the labels and the test set so if you",
"21:20": "think about saying like a capital",
"21:20": "competition you certainly can't use the",
"21:22": "labels because they don't even give them",
"21:24": "to you",
"21:24": "but you can certainly use the",
"21:26": "independent variables so in this case",
"21:28": "you could absolutely use the text that",
"21:30": "is in the the test set to train your",
"21:33": "language model so this is a good trick",
"21:35": "right is actually when you do the",
"21:36": "language model concatenate the training",
"21:39": "and test set together and then just let",
"21:42": "out a smaller validation set so you've",
"21:44": "got more data to train your language",
"21:47": "model so that's a little trick and so if",
"21:49": "you're doing NLP stuff on kaggle for",
"21:52": "example or you know you've just got a",
"21:54": "smaller subset of labelled data make",
"21:58": "sure that you use all of the text you",
"22:00": "have to train",
"22:01": "your language model because there's no",
"22:02": "reason not to how are we going to label",
"22:05": "it well remember a language model kind",
"22:07": "of has its own labels so the text itself",
"22:09": "is label so label for language model",
"22:11": "does that for us and create a data bunch",
"22:14": "and save it and that takes a few minutes",
"22:17": "to tokenize and numerical s so since it",
"22:23": "takes a few minutes we save it later on",
"22:24": "you can just load it no need to run that",
"22:26": "again so here's what it looks like and",
"22:30": "at this point things are going to look",
"22:32": "very familiar we create a learner but",
"22:35": "instead of creating a CNN learner we're",
"22:39": "going to create a language model learner",
"22:42": "so behind the scenes this is actually",
"22:45": "not going to create a CNN a",
"22:46": "convolutional neural network it's going",
"22:48": "to create an AR and in a recurrent",
"22:50": "neural network so we're going to be",
"22:51": "learning exactly how they're built over",
"22:53": "the coming lessons but in short they're",
"22:57": "the same basic structure the input goes",
"22:59": "into a weight matrix a matrix multiply",
"23:03": "that then you replace the negatives with",
"23:05": "zeroes and it goes into another matrix",
"23:07": "multiply and so forth a bunch of times",
"23:09": "so it's the same basic structure so as",
"23:15": "usual when we create a learner you have",
"23:17": "to pass in two things the data so here's",
"23:20": "our language model data and in this case",
"23:24": "what pre-trade model we want to use and",
"23:26": "so here the pre-trade model is the",
"23:29": "wikitext 1:03 model that will be",
"23:32": "downloaded for you from first AI if you",
"23:34": "haven't used it before just like the",
"23:36": "same thing with things like image net",
"23:38": "pre-trained models are downloaded for",
"23:39": "you this here sets the amount of dropout",
"23:44": "we haven't talked about that yet we've",
"23:46": "talked briefly about this idea that",
"23:47": "there's something called regularization",
"23:48": "and you can reduce the regularization to",
"23:51": "avoid underfitting",
"23:52": "so for now just know that by using a",
"23:55": "number lower than 1 is because when I",
"23:58": "first tried to run this I was under",
"24:00": "fitting and so if you reduced that",
"24:01": "number then it will avoid under fitting",
"24:05": "okay so we've got a loner we can LR find",
"24:08": "looks pretty standard and so then we can",
"24:12": "see it one cycle",
"24:13": "so what's happening here is we are just",
"24:16": "fine-tuning the last layers so normally",
"24:22": "after we fine-tune the last layers the",
"24:25": "next thing we do is we go",
"24:27": "unfreeze and train the whole thing and",
"24:32": "so here it is",
"24:33": "unfreeze and train the whole thing and",
"24:35": "as you can see even on a pretty beefy",
"24:37": "GPU that takes 2 or 3 hours and in fact",
"24:41": "I'm still under fitting all right so I",
"24:45": "probably tonight I might train it",
"24:46": "overnight and train to a little bit",
"24:47": "better because you can see oh I guess",
"24:52": "I'm not underfitting oh I'm guessing I",
"24:54": "could probably train this a bit longer",
"24:56": "because you can see the accuracy hasn't",
"24:57": "started going down again that's I",
"24:59": "wouldn't mind trying to train that a bit",
"25:01": "longer but the accuracy it's interesting",
"25:03": "point three means you know we're",
"25:06": "guessing the next word of the movie",
"25:08": "review correctly about a third of the",
"25:10": "time so that sounds like a pretty high",
"25:12": "number the idea that you can actually",
"25:13": "guess the next word that often so it's a",
"25:17": "good sign that my language model is",
"25:20": "doing pretty well for kind of more",
"25:23": "limited domain documents like medical",
"25:27": "transcripts and legal transcripts you'll",
"25:29": "often find this accuracy Gertz gets a",
"25:32": "lot higher so sometimes this can be even",
"25:35": "50% or more but you know point three or",
"25:39": "more is is pretty good so you can now",
"25:44": "run learn dot predict and pass in the",
"25:48": "start of a sentence and it will try and",
"25:50": "finish off that sentence for you now I",
"25:53": "should mention we this is not designed",
"25:56": "to be a good text generation system this",
"25:59": "is really more designed to kind of check",
"26:01": "that it seems to be creating something",
"26:03": "that's vaguely sensible there's a lot of",
"26:06": "tricks that you can use to generate much",
"26:08": "higher quality text none of which we're",
"26:11": "using here right but you can kind of see",
"26:14": "that it's it's it's you know certainly",
"26:19": "not random words that it's generating it",
"26:21": "sounds vaguely English like even though",
"26:23": "it doesn't make any sense",
"26:25": "so at this point we have a movie review",
"26:30": "model so now we're gonna save that in",
"26:38": "order to load it into our classifier to",
"26:41": "be a pre trained model for the",
"26:43": "classifier but I actually don't want to",
"26:44": "save the whole thing a lot of this you",
"26:47": "know kind of the second half as we'll",
"26:48": "learn the second half of the language",
"26:50": "model is all about predicting the next",
"26:53": "word rather about rather than about",
"26:55": "understanding the sentence so far so the",
"26:58": "bit which is specifically about",
"26:59": "understanding the sentence so far is",
"27:01": "called the encoder so I just saved that",
"27:04": "alright so and again we're going to",
"27:06": "learn the details of this there coming",
"27:08": "weeks",
"27:09": "Rena's going to save the encoder so the",
"27:11": "bit that understands the sentence rather",
"27:14": "than the bit that generates the word so",
"27:18": "now we're ready to create our classifier",
"27:20": "so step one as per usual is to create a",
"27:23": "data bunch and we're going to do",
"27:24": "basically exactly the same thing bring",
"27:26": "it in okay and here's our path but we",
"27:30": "want to make sure that it uses exactly",
"27:32": "the same vocab that are used for the",
"27:35": "language model if word number 10 was ver",
"27:38": "in the language model we need to make",
"27:40": "sure that word number 10 is the in the",
"27:43": "classifier because otherwise the",
"27:45": "pre-trained model is going to be totally",
"27:48": "meaningless so that's why we pass in the",
"27:51": "vocab from the language model to make",
"27:54": "sure that this data bunch is going to",
"27:55": "have exactly the same vocab that's an",
"27:57": "important step split by folder and this",
"28:01": "time label so remember the last time we",
"28:03": "had split randomly okay but this time we",
"28:07": "need to make sure that the labels of the",
"28:08": "test set are not touched so we split by",
"28:11": "folder and then this time we label it",
"28:14": "not for a language model but we label",
"28:16": "these classes and then finally create a",
"28:21": "data bunch and remember sometimes you'll",
"28:24": "find that you ran out of GPU memory this",
"28:27": "will very often happen to you if you so",
"28:30": "I was running this in an 11 gig machine",
"28:32": "so you should make sure this numbers a",
"28:34": "bit lower if you run out of memory you",
"28:36": "may also want to make sure you restart",
"28:38": "the notebook and kind of started just",
"28:40": "from here so batch size 50 is as high as",
"28:43": "I could get on an 11 gig card if you are",
"28:45": "using a p2 or p3 on Amazon or the kad on",
"28:52": "Google for example I think you'll get 16",
"28:54": "gigs so you might be able to make this a",
"28:55": "bit higher cut it up to 64 so you can",
"28:58": "find whatever batch size fits on your",
"29:01": "card so here's our data bunch as we saw",
"29:05": "before and the labels so this time",
"29:08": "rather than creating a language model",
"29:11": "learner we're creating a text classifier",
"29:13": "learner but again same thing pass in the",
"29:15": "data that we want figure out how much",
"29:17": "regularization we need again if you're",
"29:19": "overfitting then you can increase this",
"29:22": "number if you're under fitting you can",
"29:24": "decrease the number and most importantly",
"29:26": "load in a pre trained model and remember",
"29:29": "specifically it's just this this half of",
"29:31": "the model called the encoder which is",
"29:33": "the bit that we want to load in and",
"29:36": "freeze now I find find the learning rate",
"29:40": "and fit for a little bit and we're",
"29:43": "already up nearly to 92% accuracy after",
"29:47": "less than three minutes of training so",
"29:50": "this is a nice thing in your particular",
"29:53": "domain whether it be law or medicine or",
"29:57": "journalism or government or whatever you",
"29:59": "probably only need to train your domains",
"30:02": "language model once and that might take",
"30:06": "you know overnight to Train well but",
"30:10": "once you've got it you can now very",
"30:12": "quickly create all kinds of different",
"30:14": "classifiers and models with that in you",
"30:17": "know in this case already a pretty good",
"30:19": "model after three minutes right so so",
"30:22": "when you first start doing this you",
"30:23": "might find it a bit it's like annoying",
"30:26": "that your first models take four hours",
"30:29": "more or more to create that language",
"30:31": "model but the key thing to remember is",
"30:32": "you only have to do that once for your",
"30:35": "entire kind of domain of stuff that",
"30:37": "you're interested in and then you can",
"30:38": "build lots of different classifiers and",
"30:41": "other models on top of that in a few",
"30:42": "minutes okay",
"30:45": "all right so we can save that to make",
"30:48": "sure you directly run it again and then",
"30:49": "here's something interesting now I'm",
"30:51": "gonna explain this more",
"30:52": "just a few minutes I'm not gonna say",
"30:54": "unfreeze instead of going to save fries",
"30:57": "- and what that says is unfreeze the",
"31:00": "last two layers don't unfreeze the whole",
"31:03": "thing and so we've just found it really",
"31:05": "helps with these text classification not",
"31:08": "to unfreeze the whole thing but to",
"31:10": "unfreeze one layer at a time",
"31:12": "so unfreeze the last two layers train it",
"31:15": "a little bit more and freeze the next",
"31:17": "layer again train a little bit more",
"31:20": "unfreeze the whole thing train it a",
"31:23": "little bit more you'll also see I'm",
"31:25": "passing in this thing Momentum's equals",
"31:28": "point eight point seven we're going to",
"31:30": "learn exactly what that means in the",
"31:33": "next week or two probably next week but",
"31:36": "for now and we may even automate it so",
"31:39": "maybe by the time you watch the video of",
"31:40": "this this won't even be necessary",
"31:41": "anymore basically we found for training",
"31:46": "recurrent neural networks our own ends",
"31:48": "it really helps to decrease the momentum",
"31:51": "a little bit so that's what that is",
"31:54": "so that gets us a ninety four point for",
"31:57": "accuracy after about half an hour or",
"32:00": "less of training actually quite a lot",
"32:02": "less of training the actual classifier",
"32:05": "and we can actually get this quite a bit",
"32:09": "better with a few tricks I don't know if",
"32:12": "we learned all the tricks this part it",
"32:14": "might be next part but even this very",
"32:16": "simple kind of standard approach is",
"32:19": "pretty great if we compare it to last",
"32:23": "year's state of the art on IMDb's is",
"32:26": "from The Cove paper from McCann at L at",
"32:30": "Salesforce Research their paper was",
"32:33": "ninety one point eight percent accurate",
"32:35": "in the best paper they could find they",
"32:38": "found a fairly domain-specific sentiment",
"32:41": "in analysis paper from 2017 they've got",
"32:44": "ninety four point one and here we've got",
"32:47": "ninety four point four and the best",
"32:50": "models I've been able to build since",
"32:51": "have been about ninety five ninety five",
"32:54": "point one so if you're looking to do",
"32:57": "text classification this you know really",
"32:59": "standardized transfer learning approach",
"33:03": "works work super well any questions",
"33:06": "Rachel okay so that was that was an LP",
"33:14": "and we'll be learning more about NLP",
"33:15": "later in this course but now I wanted to",
"33:18": "switch over and look at tabular now",
"33:22": "tabular data is pretty interesting",
"33:24": "because it's the stuff that for a lot of",
"33:27": "you is actually what you use day-to-day",
"33:29": "at work in spreadsheets and relational",
"33:32": "databases just come close I guess hey so",
"33:38": "where does the magic number of 2.6 to",
"33:41": "the fourth in the learning rate come",
"33:44": "from yeah good question so the learning",
"33:50": "rate is various various things divided",
"33:57": "by 2.6 to the fourth",
"34:00": "the reason it's to the fourth you will",
"34:03": "learn about at the about the end of",
"34:06": "today so let's focus on the 2.6 why 2.6",
"34:13": "basically this as we're as we're going",
"34:16": "to see in more detail later day this",
"34:18": "this number there are the difference",
"34:20": "between the bottom of the slice and the",
"34:22": "top of the slice is basically what's the",
"34:24": "difference between how quickly the",
"34:26": "lowest layer of the model learns versus",
"34:28": "the highest layer of their model learns",
"34:30": "so this is called discriminative",
"34:32": "learning rates and so really the",
"34:34": "question is like as you go from layer to",
"34:36": "layer",
"34:37": "how much do I decrease the learning rate",
"34:39": "by when we found out that for NLP are n",
"34:44": "ends that the answer is 2.6 how do we",
"34:47": "find out that it's 2.6 I ran lots and",
"34:51": "lots of different models like a year ago",
"34:54": "or so using lots of different sets of",
"34:57": "hyper parameters of various types drop",
"34:59": "out learning rates and discriminative",
"35:01": "learning rate and so forth and then I",
"35:03": "created something called a random forest",
"35:05": "which is the kind of model where I",
"35:07": "attempted to predict how accurate my NLP",
"35:10": "classifier would be based on the hyper",
"35:12": "parameters and then I",
"35:15": "used random forest interpretation",
"35:17": "methods to basically figure out what the",
"35:21": "optimal parameter settings were and I",
"35:23": "found out that the answer for this",
"35:25": "number was 2.6 so that's actually not",
"35:28": "something I've published or I don't",
"35:30": "think I've even talked about it before",
"35:31": "so there's a new piece of information",
"35:33": "you can actually a few months after I",
"35:38": "did this I think David marady and",
"35:41": "somebody else did publish a paper",
"35:44": "describing a similar approach so the",
"35:46": "basic idea may be out there already some",
"35:49": "of that idea comes from a researcher",
"35:52": "named Frank Hatter and one of his",
"35:54": "collaborators they did some interesting",
"35:56": "work showing how you can use random",
"35:58": "forests to actually find optimal",
"36:01": "hyperparameters so it's kind of a neat",
"36:03": "trick you know a lot of people are very",
"36:06": "interested in this in court auto ml",
"36:08": "which is this idea of like building",
"36:10": "models to figure out how to train your",
"36:12": "model we're not big fans of it on the",
"36:15": "whole but we do find that building",
"36:18": "models to better understand how your",
"36:21": "hyper parameters work and then finding",
"36:23": "like those rules of thumb like oh",
"36:25": "basically it can always be two-point-six",
"36:27": "quite helpful so that's just something",
"36:31": "we're kind of been playing with okay so",
"36:40": "yeah so let's talk about tabular data so",
"36:42": "tabular data such as you might see in a",
"36:46": "spreadsheet or a relational database you",
"36:48": "know or a financial report it can",
"36:51": "contain all kinds of different things it",
"36:56": "can contain all kinds of different",
"36:57": "things and I kind of tried to make a",
"36:58": "little list of some of the kinds of",
"36:59": "things that I've seen tabular data",
"37:02": "analysis used for using neural nets for",
"37:07": "analyzing tabular data is or at least",
"37:11": "last year when I first presented this",
"37:13": "was maybe we started this two years ago",
"37:16": "yeah when we first presented this people",
"37:20": "were deeply skeptical and they thought",
"37:21": "it was a terrible idea to use neural",
"37:23": "nets to analyze tabular data because",
"37:25": "like everybody knows that you should use",
"37:28": "logistic regression or random forests or",
"37:30": "gradient boosting machines all of which",
"37:32": "have their place but certain certain",
"37:34": "types of things but since that time you",
"37:37": "know it's become clear that the commonly",
"37:42": "held wisdom is is wrong it's not true",
"37:45": "that neural nets are not useful for",
"37:46": "tabular data in fact the extremely",
"37:48": "useful now we've shown this in in quite",
"37:51": "a few of our courses but what's really",
"37:54": "kind of also helped is that some really",
"37:58": "effective organizations have started",
"38:01": "publishing papers and posts and stuff",
"38:04": "describing how they've been using neural",
"38:05": "nets for analyzing tabular data um one",
"38:09": "of the key things that comes up again",
"38:11": "and again is that although feature",
"38:14": "engineering doesn't go away it certainly",
"38:17": "becomes simpler right so Pinterest for",
"38:19": "example replaced the gradient boosting",
"38:21": "machines that they were using to decide",
"38:23": "how to put stuff on their homepage with",
"38:26": "neural nets and they presented at a",
"38:29": "conference this approach and they",
"38:30": "described how it really made engineering",
"38:32": "a lot easier because a lot of the hand",
"38:35": "created features weren't necessary",
"38:39": "anymore you still need some but it was",
"38:41": "just simpler right so they ended up",
"38:43": "something that was more accurate and but",
"38:46": "perhaps even more importantly it",
"38:47": "required less maintenance right so I",
"38:52": "wouldn't say you know it's the only tool",
"38:55": "that you need in your toolbox for",
"38:56": "analyzing tabular data but you know",
"38:58": "where else I used to use random forests",
"39:02": "99% of the time when I was doing machine",
"39:05": "learning with tabular data I knew or",
"39:08": "Nets 90% of the time it's it's it's kind",
"39:12": "of my standard first go-to approach now",
"39:15": "and it tends to be pretty reliable",
"39:18": "pretty effective one of the things",
"39:21": "that's made it difficult is that until",
"39:23": "now there hasn't been an easy way to",
"39:27": "kind of create and train tabular neural",
"39:29": "Nets like nobody's really made it",
"39:31": "available on a library so we've actually",
"39:33": "just created fast AI tabula and I think",
"39:39": "this is pretty",
"39:40": "the first time that's become really easy",
"39:42": "to to use neural nets with tabular data",
"39:46": "and so let me show you how easy it is",
"39:50": "this is actually coming directly from",
"39:53": "the examples folder in the FASTA guy",
"39:56": "repo I haven't changed at all and as per",
"39:59": "usual as well as importing first AI you",
"40:02": "should import your application so in",
"40:04": "this case it's tabular we assume that",
"40:09": "your data is in a panda's data frame a",
"40:13": "panda's data frame is kind of the",
"40:15": "standard format for tabular data in",
"40:17": "Python and it's lots of ways to get it",
"40:20": "in there but probably the most common",
"40:22": "might be PD don't read CSV but you know",
"40:25": "whatever your data is in you can",
"40:27": "probably get it into a panda's data",
"40:28": "frame easily enough okay what are the",
"40:41": "10% of cases where you would not default",
"40:44": "to neural nets good question I guess I",
"40:53": "still tend to kind of give them a try",
"40:57": "but yeah I don't know it's it's it's",
"41:03": "kind of like as you do things for a",
"41:05": "while you start to get a sense of the",
"41:07": "areas where things don't quite work as",
"41:10": "well I have to think about that during",
"41:11": "the week I don't think I have a rule of",
"41:13": "thumb but I would say you may as well",
"41:15": "try both like I would say try a random",
"41:19": "forest and try on your own net they're",
"41:20": "both pretty quick and easy to run and",
"41:21": "see how it looks and if they're roughly",
"41:25": "similar I might go and dig into H and",
"41:27": "see if I can make them better and better",
"41:29": "but you know if the random forest is",
"41:31": "doing way better I'd probably just stick",
"41:33": "with that use whatever works so I",
"41:42": "currently have the wrong notebook in the",
"41:45": "lesson repo so I'll update it after the",
"41:48": "class so sorry about that so we start",
"41:53": "with the data in a data frame and so",
"41:57": "we've got a little thing adult sample",
"42:02": "it's a it's a classic old data set I",
"42:05": "have to dig up the citation for it so",
"42:06": "I've got put it in this sum in this",
"42:08": "notebook but it's a pretty small simple",
"42:11": "old data set that's good for",
"42:13": "experimenting with basically and it's",
"42:16": "CSV file so you can read it into a data",
"42:19": "frame with pandas read CSV PD don't read",
"42:22": "CSV if your data is in a relational",
"42:26": "database pandas can read from that if",
"42:28": "it's in spark or Hadoop pandas can read",
"42:30": "from that pandas can read from most",
"42:32": "stuff that you can throw at it so that's",
"42:34": "why we kind of use it as a default",
"42:37": "starting point and as per usual you know",
"42:41": "it's I think it's nice to use the data",
"42:43": "block API and so in this case the list",
"42:48": "that we're trying to create is a tabular",
"42:51": "list and we're going to create it from a",
"42:53": "data frame and so you can tell it what",
"42:55": "the data frame is and what the path that",
"42:57": "you're going to use to kind of save",
"42:58": "models and intermediate steps is and",
"43:00": "then you need to tell it what are your",
"43:03": "categorical variables and what are your",
"43:05": "continuous variables so we're going to",
"43:08": "be learning a lot more about what that",
"43:10": "means to the neural net next week but",
"43:14": "for now the quick summary is this your",
"43:17": "independent variables are the things",
"43:19": "that you're using to make predictions",
"43:21": "with right so things like education and",
"43:24": "marital status and age and so forth some",
"43:30": "of those variables like age are",
"43:33": "basically numbers they could be any",
"43:36": "number you know you could be thirteen",
"43:38": "point three six years old or nineteen",
"43:40": "point four years old or whatever where",
"43:43": "else things like marital status options",
"43:47": "that can be selected from a discrete",
"43:49": "group married single divorce whatever",
"43:52": "sometimes those options might be",
"43:55": "a lot more like occupation there's a lot",
"43:57": "of possible occupations and sometimes",
"44:01": "they might be binary could be just true",
"44:04": "or false but anything which you can",
"44:07": "select the the answer from a small group",
"44:10": "of possibilities is called a categorical",
"44:13": "variable and so we're going to need to",
"44:17": "use a different approach in the neural",
"44:18": "net to modeling categorical variables to",
"44:21": "what we use for continuous variables for",
"44:23": "categorical variables we're going to be",
"44:24": "using something called embeddings which",
"44:26": "we'll be learning about later today for",
"44:29": "continuous variables they could just be",
"44:31": "sent into the neural net just like",
"44:33": "pixels in a neural net can because like",
"44:34": "pixels in a neural net are already",
"44:36": "numbers these continuous things are",
"44:38": "already numbers as well so that's that's",
"44:41": "easy okay so that's why you have to tell",
"44:44": "the tabular list from data frame which",
"44:50": "ones are which there are some other ways",
"44:53": "to do that by pre-processing them in",
"44:55": "pandas to make things categorical",
"44:58": "variables but it's kind of nice to have",
"44:59": "one API for doing everything you don't",
"45:01": "have to think too much about it then",
"45:05": "we've got something which is a lot like",
"45:07": "transforms in in computer vision",
"45:13": "transforms in computer vision do things",
"45:15": "like flip a photo when it's access or",
"45:18": "turn it a bit or brighten it or",
"45:19": "normalize it",
"45:21": "but for tabular data instead of having",
"45:26": "transforms we have things called",
"45:27": "processes and they're nearly identical",
"45:30": "but the key difference which is quite",
"45:31": "important is that a processor is",
"45:34": "something that happens ahead of time",
"45:36": "right so we basically pre-process the",
"45:39": "data frame rather than doing it as we go",
"45:43": "right so transformations are really that",
"45:46": "data augmentation where you want to like",
"45:48": "randomize it and do it differently each",
"45:49": "time where else processes the things",
"45:52": "that you want to do once ahead of time",
"45:54": "so we have a number of processes in the",
"45:58": "Farseer library and the ones we're going",
"46:00": "to use this time are fill missing so",
"46:03": "that's going to look for missing values",
"46:07": "and deal with them some way we're going",
"46:11": "to find categorical variables and turn",
"46:14": "them into pandas categories and we're",
"46:16": "going to do normalization ahead of time",
"46:18": "which is to take continuous variables",
"46:20": "and subtract their mean and divided by",
"46:23": "them by their standard deviation so",
"46:25": "they're 0 1 variables the way we deal",
"46:32": "with missing data we'll talk more about",
"46:35": "next week but in short we replace it",
"46:38": "with a median and add a new column which",
"46:41": "is a binary column of saying whether",
"46:43": "that was missing or not normalization",
"46:46": "there's an important thing here which is",
"46:48": "in fact for all of these things whatever",
"46:51": "you do to the training set you need to",
"46:55": "do exactly the same thing to the",
"46:56": "validation set and the test set so",
"46:59": "whatever you replaced your missing",
"47:01": "values with you need to replace them",
"47:03": "with exactly the same thing in the",
"47:04": "validation set so first AI handles all",
"47:06": "these details for you they're the kinds",
"47:09": "of things that if you have to do it",
"47:10": "manually at least if you like me you'll",
"47:12": "screw it up",
"47:12": "lots of times until you finally get it",
"47:14": "right so that's what these processes",
"47:18": "here then we're going to split into",
"47:23": "training versus validation sets and in",
"47:27": "this case we do it by providing a list",
"47:31": "of indexes so the index is from 800 to",
"47:33": "1,000 it's very common I don't quite",
"47:36": "remember the details of this data set",
"47:37": "but it's very common for wanting to keep",
"47:41": "your validation sets to be contiguous",
"47:42": "groups of things like if they're map",
"47:45": "tiles there should be the map tiles that",
"47:46": "are next to each other if their time",
"47:49": "periods they should be time period you",
"47:51": "know days that are next to each other if",
"47:52": "their video frames there should be video",
"47:54": "frames next to each other",
"47:55": "because otherwise you're kind of",
"47:56": "cheating right so it's often a good idea",
"47:59": "to use split by DX and to grab a range",
"48:02": "that's next to each other if your data",
"48:04": "has some kind of structure like that or",
"48:06": "find some other way to structure it in",
"48:08": "that way all right so that's now given",
"48:12": "us a training and a validation set we",
"48:14": "now need to add labels and in this case",
"48:16": "the labels can come straight from the",
"48:18": "data frame we grabbed earlier so we just",
"48:19": "have to tell it which column it",
"48:20": "and so the dependent variable is I think",
"48:23": "it's whether they're making over $50,000",
"48:26": "salary that's the thing we're trying to",
"48:28": "predict in this case we'll talk about",
"48:32": "test sets later but in this case we can",
"48:34": "have a test set and finally get our data",
"48:38": "bunch so at that point we have something",
"48:42": "that looks like this",
"48:43": "okay so there is our there is our data",
"48:49": "and then to use it it looks very",
"48:53": "familiar you get a loner in this case",
"48:56": "it's a tabular learner passing in the",
"48:59": "data some information about your",
"49:01": "architecture and some metrics Andrew",
"49:04": "then call fit you have some questions",
"49:08": "all right let's hit the questions how to",
"49:15": "combine an LP tokenize data with",
"49:18": "metadata such as tabular data with fast",
"49:20": "AI for instance for imbd classification",
"49:24": "how to use information like who the",
"49:25": "actors are your maid Jean right it",
"49:27": "cetera",
"49:31": "yeah we're not quite up for that yet so",
"49:33": "we need to learn a little bit more about",
"49:35": "how euronet architecture as well work",
"49:38": "and but conceptually it's kind of the",
"49:42": "same as the way we combine categorical",
"49:44": "variables and continuous variables",
"49:45": "basically in the neural network you can",
"49:47": "have two different sets of inputs",
"49:52": "merging together into some layer could",
"49:55": "go into an early layer or into a later",
"49:57": "layer it kind of depends if it's like",
"50:00": "text and an image and some metadata you",
"50:03": "probably want the text going into an",
"50:04": "errand in the image going into a CNN the",
"50:07": "metadata going into some kind of tabular",
"50:09": "model like this and then you'd have them",
"50:11": "basically all concatenated together and",
"50:13": "then go through some fully connected",
"50:14": "layers train them into end will probably",
"50:18": "largely get into that in part two in",
"50:20": "fact we made entirely get in that into",
"50:22": "part part two I'm not sure if we have",
"50:24": "time to cover it in in part one but",
"50:27": "conceptually it's it's a fairly simple",
"50:30": "extension of what we'll be learning in",
"50:32": "the next three weeks",
"50:35": "next question is do you think things",
"50:37": "like scikit-learn annex G boost will",
"50:40": "eventually become outdated will everyone",
"50:42": "use deep learning tools in the future",
"50:44": "except for maybe small datasets I have",
"50:49": "no idea I'm not good at making",
"50:51": "predictions I I'm not a machine learning",
"50:56": "model",
"50:57": "I mean XJ boost is a really nice piece",
"51:03": "of software there's quite a few really",
"51:05": "nice pieces of software for gradient",
"51:07": "boosting in particular they have some",
"51:10": "really nice features or actually random",
"51:11": "forests in particular has some really",
"51:13": "nice features for interpretation which",
"51:15": "I'm sure will find similar versions for",
"51:17": "neural nets but they don't necessarily",
"51:19": "exist yet so I don't know so now they're",
"51:25": "both useful tools scikit-learn you know",
"51:31": "is a library that's often used for kind",
"51:34": "of pre-processing and running models",
"51:37": "yeah I mean again it's it's hard to",
"51:40": "predict where things will end up it's",
"51:42": "it's kind of in some ways it's more",
"51:43": "focused on some older approaches to",
"51:47": "modeling but I don't know they keep on",
"51:50": "adding new things so we'll see I keep",
"51:54": "trying to incorporate more scikit-learn",
"51:55": "stuff into fast AI and then I keep",
"51:57": "finding ways I think I can do it better",
"51:59": "and I throw it away again so so that's",
"52:02": "why there's still no scikit-learn",
"52:04": "dependencies in fast AI I keep finding",
"52:07": "other ways to do self okay so we're",
"52:16": "gonna learn what layers equals means",
"52:18": "either towards the end of class today or",
"52:20": "the start of class next week but this is",
"52:22": "where we're basically defining our",
"52:24": "architecture just like when we chose",
"52:26": "ResNet 34 or whatever for convinence",
"52:31": "will look at more about metrics in a",
"52:33": "moment but just to remind you metrics",
"52:35": "are just the things that get printed out",
"52:36": "they don't change our model at all so in",
"52:39": "this case we're saying I want you to",
"52:40": "print out the accuracy to see how we're",
"52:42": "doing",
"52:45": "okay so that's how to do tabular this is",
"52:49": "going to work really well because we're",
"52:50": "going to hit our break soon and the idea",
"52:53": "was that after three and a half lessons",
"52:55": "we're going to hit the end of all of the",
"52:57": "quick overview of applications and then",
"52:59": "we're going to go down the other side I",
"53:00": "think we're going to be to the minute",
"53:01": "we're going to hit it right because the",
"53:04": "next one is collaborative filtering okay",
"53:08": "so collaborative filtering is where you",
"53:14": "have information about who bought what",
"53:19": "or who liked what you know it's",
"53:22": "basically something where you have",
"53:24": "something like a user or a reviewer or",
"53:28": "whatever and information about what",
"53:32": "they've bought or what they've written",
"53:34": "about or what they reviewed right so in",
"53:36": "the most basic version of collaborative",
"53:38": "filtering you just have two columns",
"53:41": "something like user ID and movie ID and",
"53:44": "that just says this user bought that",
"53:46": "movie this user bought that movie this",
"53:48": "user for that review so for example",
"53:49": "Amazon has a really big list of user IDs",
"53:53": "and product IDs are like what did you",
"53:55": "buy then you can add additional",
"53:57": "information to that table such as oh",
"54:00": "they left a review what review did they",
"54:03": "give it so it's now like user ID movie",
"54:05": "ID number of stars you could add a",
"54:09": "timecode so like this user bought this",
"54:13": "product at this time and gave it this",
"54:16": "review but they're all basically the",
"54:18": "same kind of structure so there's kind",
"54:22": "of like two ways you could draw that",
"54:25": "collaborative filtering structure one is",
"54:29": "kind of a two-column approach where",
"54:32": "you've got like user and I don't know",
"54:35": "movie all right and you've got user ID",
"54:38": "movie oh do you know each each pair",
"54:40": "basically describes that user watch that",
"54:43": "movie possibly also plus number of stars",
"54:48": "you know three or one whatever well the",
"54:53": "other way you could write it",
"54:57": "would be you could have like all the",
"54:59": "users down here and all the movies along",
"55:10": "here right and and then you know you can",
"55:20": "look and find a particular cell in there",
"55:22": "to find out you know could be the rating",
"55:26": "of that user for that movie or there's",
"55:28": "just a one there if that user watch that",
"55:30": "movie or whatever so there's like two",
"55:32": "different ways of representing the same",
"55:34": "information conceptually it's often",
"55:39": "easier to think of it this way right but",
"55:44": "most of the time you won't store it that",
"55:46": "way explicitly because most of the time",
"55:48": "you'll have what's called a very sparse",
"55:50": "matrix which is to say most users",
"55:53": "haven't watched most movies or most",
"55:56": "customers haven't purchased most",
"55:59": "products so if you store it as a matrix",
"56:02": "where every combination of customer and",
"56:05": "product is a separate cell in that",
"56:07": "matrix it's going to be enormous so you",
"56:09": "tend to store it like this or you can",
"56:13": "store it as a matrix using some kind of",
"56:15": "special sparse matrix format and if that",
"56:18": "sounds interesting you should check out",
"56:20": "Rachel's computational linear algebra",
"56:22": "course on first AI where we have lots",
"56:25": "and lots and lots of information about",
"56:27": "sparse matrix storage approaches for now",
"56:30": "though we're just going to kind of keep",
"56:33": "it in this format on the left hand side",
"56:35": "so for collaborative filtering there's a",
"56:40": "really nice dataset called movie lens",
"56:48": "created by the group lens group very",
"56:51": "hopefully and you can download various",
"56:53": "different sizes 20 million ratings a",
"56:57": "hundred thousand ratings we've actually",
"56:59": "created a an extra small version for",
"57:03": "playing around with which is what we'll",
"57:04": "start with today and then",
"57:08": "probably next week we'll use the bigger",
"57:11": "version but so you can grab the small",
"57:14": "version using your RL ml sample and it's",
"57:18": "a CSV so you can read it with pandas and",
"57:24": "here it is right it's basically a list",
"57:26": "of user IDs we don't actually know",
"57:28": "anything about who these users are",
"57:29": "there's some movie IDs there is some",
"57:32": "information about what the movies are",
"57:33": "but we won't look at that until next",
"57:35": "week and then there's the rating and",
"57:37": "then there's the timestamp",
"57:40": "we're going to ignore the timestamp now",
"57:45": "so that's a subset of our data that's",
"57:48": "the head so the head in pandas is just",
"57:50": "the first few rows so now that we've got",
"57:55": "a data frame I mean the nice thing about",
"57:56": "collaborative filtering is is it's it's",
"58:00": "incredibly simple like that's all the",
"58:01": "data that we need so you can now go",
"58:04": "ahead and say get collaborative learner",
"58:07": "and you can actually just pass in the",
"58:09": "data frame directly the the architecture",
"58:14": "you have to tell it how many factors you",
"58:15": "want to use and we're going to learn",
"58:17": "what that means after the break and then",
"58:20": "something that can be helpful is to tell",
"58:21": "it what the range of scores are and",
"58:24": "we're going to see how that helps up the",
"58:25": "brick as well now in this case the",
"58:27": "minimum score is zero it's an excellent",
"58:29": "score is five so now that you've got a",
"58:31": "learner you can go ahead and call fit",
"58:35": "one cycle and trains for a few a pox and",
"58:40": "there it is so at the end of it you now",
"58:43": "have something where you can pick a user",
"58:46": "ID and a movie ID and guess whether or",
"58:50": "not that user will like that movie",
"58:53": "there's a lot of so this is obviously a",
"58:56": "super useful application that a lot of",
"59:00": "you are probably going to try over",
"59:01": "during the week in past classes a lot of",
"59:03": "people have taken this collaborative",
"59:05": "filtering approach back to their",
"59:06": "workplaces and and discovered that using",
"59:10": "it in practice is much more tricky than",
"59:13": "this because in practice you have",
"59:14": "something called the cold start problem",
"59:16": "so the cold start problem is that the",
"59:18": "time you particularly want to be good at",
"59:22": "recommending movies is when you have a",
"59:24": "new user and the time you particularly",
"59:26": "care about recommending a movie is when",
"59:30": "it's a new movie but at that point you",
"59:32": "don't have any data in your",
"59:33": "collaborative filtering system and it's",
"59:34": "really hard as I say this we don't",
"59:39": "currently have anything built into fast",
"59:40": "AI to handle the cold start problem and",
"59:43": "that's really because the cold start",
"59:45": "problem the only way I know of to solve",
"59:47": "it in fact the anyway I think that",
"59:48": "conceptually you can solve it is to have",
"59:50": "a second model which is not a",
"59:52": "collaborative filtering model but a",
"59:54": "metadata driven model for new users or",
"59:57": "new movies I don't know if Netflix still",
"60:02": "does this but certainly what they used",
"60:03": "to do when I signed up to Netflix was",
"60:06": "they started showing me lots of movies",
"60:08": "and saying have you seen this did you",
"60:10": "like it have you seen this did you like",
"60:11": "it you know and so they fixed the cold",
"60:14": "start problem through the UX so there",
"60:17": "was no you know called start problem",
"60:19": "they found like 20 really common movies",
"60:22": "and asked me if I liked them they used",
"60:24": "my replies to those 20 to show me 20",
"60:26": "more that I might have seen and you know",
"60:28": "by the time I had gone through 60 I",
"60:30": "wasn't you know there was no cold start",
"60:32": "problem anymore and for new movies it's",
"60:35": "not really a problem because like the",
"60:37": "first hundred users who haven't seen the",
"60:39": "movie you know go in and say whether",
"60:41": "they liked it and then the next hundred",
"60:43": "thousand the next million it's not a",
"60:46": "cold start problem anymore",
"60:47": "but the other thing you can do if you",
"60:50": "for whatever reason kind of can't go",
"60:52": "through that UX of like asking people",
"60:54": "did you like those things so for example",
"60:56": "if you're selling products and you don't",
"60:58": "really want to show them like a big",
"61:00": "selection of your products and say did",
"61:02": "you like this because you just want them",
"61:03": "to buy you could instead try and use a",
"61:06": "metadata based kind of tabular model you",
"61:08": "know what what geography did they come",
"61:11": "from maybe you know their age and sex",
"61:13": "you know you can try and make some",
"61:14": "guesses about the initial",
"61:16": "recommendations",
"61:17": "that's so collaborative filtering is",
"61:19": "specifically for once you have a bit of",
"61:22": "information about your users and movies",
"61:25": "or customers and products or or whatever",
"61:30": "yeah",
"61:36": "how does the language model trained in",
"61:39": "this manner perform on code-switch data",
"61:41": "such as Hindi written in English words",
"61:44": "or text with a lot of emojis and then do",
"61:48": "it the second question there certainly",
"61:52": "yeah that's a good question so text with",
"61:57": "emojis it'll be fine",
"62:01": "there's not many emojis in Wikipedia and",
"62:06": "where they are in Wikipedia it's more",
"62:08": "like a Wikipedia page amount about the",
"62:11": "emoji rather than the emoji being used",
"62:12": "in you know sensible place but you can",
"62:16": "insured through this language model fine",
"62:23": "tuning where you take a corpus of text",
"62:26": "where people are using emojis in usual",
"62:28": "ways and so you fine-tune the wiki text",
"62:30": "language model to your reddit or Twitter",
"62:33": "or whatever language model and there",
"62:35": "aren't that many emojis right if you",
"62:37": "think about it there's like hundreds of",
"62:39": "thousands of possible words that people",
"62:41": "can be using but a small number of",
"62:43": "possible emojis so it'll very quickly",
"62:45": "learn how those emojis are being used so",
"62:48": "that's that's a piece of cake",
"62:54": "so I'm not very familiar with Hindi but",
"62:56": "I'll take an example I'm very familiar",
"62:57": "with which is Mandarin in Mandarin you",
"63:00": "could have a model that's trained with",
"63:02": "Chinese characters so there's kind of",
"63:05": "five or six thousand Chinese characters",
"63:08": "in common use but there's also a",
"63:09": "romanization of those characters called",
"63:11": "an opinion and it's a bit tricky because",
"63:14": "although there's a nearly direct mapping",
"63:18": "from the character to the pinyin I mean",
"63:21": "there is a direct mapping the",
"63:22": "pronunciations not exactly direct there",
"63:25": "isn't a direct mapping from the pinyin",
"63:27": "to the character because one pinyin is",
"63:30": "was corresponds to multiple characters",
"63:33": "so the first thing to note is that if",
"63:36": "you're going to use this approach for",
"63:42": "Chinese you would need to start with",
"63:45": "his language model so actually first AI",
"63:49": "has something called a model zoo where",
"63:52": "we're adding more and more language",
"63:54": "models for different languages and also",
"63:57": "increasingly for different domain areas",
"64:00": "like English medical texts or even",
"64:03": "language models for things other than",
"64:04": "NLP like genome sequences molecular data",
"64:08": "musical midi notes and so forth so you",
"64:13": "would obviously start there to then",
"64:17": "convert that you know that'll be in you",
"64:20": "know either simplified or traditional",
"64:21": "chinese to then convert that into a if",
"64:24": "you want to do pinyin you could either",
"64:26": "kind of map the vocab directly or as",
"64:33": "you'll learn these multi-layer models",
"64:35": "it's only the first layer that basically",
"64:37": "converts the the tokens into a set of",
"64:43": "vectors you can actually throw that away",
"64:44": "and fine tune just a the first layer of",
"64:49": "the model so that second part is going",
"64:51": "to require a bit more few more weeks of",
"64:54": "learning before you exactly understand",
"64:56": "how to do that and so forth but if",
"64:58": "there's something you're interested in",
"64:59": "doing we can talk about it on the forum",
"65:01": "because it's a kind of a nice test of",
"65:04": "understanding so what about time series",
"65:10": "on tabular data is there an RNN model",
"65:13": "involved in tabular models so we're",
"65:19": "going to look at time series tabular",
"65:22": "data next week and but the short answer",
"65:25": "is generally speaking you don't use a",
"65:30": "RNN for time series tabular data but",
"65:33": "instead you extract a bunch of columns",
"65:35": "for things like day of week is it a",
"65:38": "weekend is it a holiday was the store",
"65:41": "open stuff like that and it turns out",
"65:44": "that adding those extra columns which",
"65:47": "you can do somewhat automatically",
"65:51": "basically gives you state-of-the-art",
"65:53": "results there are some good uses of RN",
"65:57": "ends for",
"65:59": "for time series but not really for these",
"66:02": "kind of tabular style time series like",
"66:05": "you know retail store logistics",
"66:09": "databases and stuff like that okay and",
"66:14": "is there a source to learn more about",
"66:16": "the cold start problem I'm gonna have to",
"66:23": "look that up if you know a good resource",
"66:28": "please pin turn it on the forums okay",
"66:33": "okay so that is both the break in the",
"66:39": "middle of lesson four it's the halfway",
"66:41": "point of the course and it's the point",
"66:46": "at which we have now seen an example of",
"66:49": "all the key applications and so the rest",
"66:51": "of this course is going to be digging",
"66:54": "deeper into how they actually work",
"66:55": "behind the scenes more of the theory",
"66:58": "more of how the code the source code is",
"67:00": "written and so forth so it's a good time",
"67:04": "to have a nice break come back and",
"67:10": "furthermore it's my birthday today so",
"67:13": "it's really you know a special moment so",
"67:17": "yeah so let's have a break and come back",
"67:21": "at five past eight so Microsoft Excel",
"67:31": "this is one of my favorite ways to",
"67:34": "explore data and understand models now",
"67:41": "make sure I put this in the repo and",
"67:43": "actually this one we can probably",
"67:46": "largely do in Google sheets I've tried",
"67:49": "to move as much as I can over the last",
"67:51": "few weeks into Google sheets but I just",
"67:53": "keep finding it's just such a terrible",
"67:55": "product so I yeah you know please try to",
"68:01": "find a copy of Microsoft Excel because",
"68:03": "there's nothing close I've tried",
"68:05": "everything anyway spreadsheets get up",
"68:12": "a bad rap from people that basically",
"68:15": "don't know how to use them just like",
"68:16": "people who better they'll spend their",
"68:18": "lives on Excel and then they start using",
"68:19": "Python and they're like what the hell is",
"68:20": "this stupid thing I mean you know it",
"68:23": "takes thousands of hours to get really",
"68:24": "good at spreadsheets but a few dozen",
"68:27": "hours to get competent at them and once",
"68:30": "you're competent at them you can see",
"68:32": "everything in front of you it's all laid",
"68:34": "out it's it's really great I'll give you",
"68:38": "one spreadsheet tip today which is if",
"68:41": "you hold down the ctrl key or command",
"68:43": "key on your keyboard and press the arrow",
"68:45": "keys",
"68:46": "here's control right it takes you to the",
"68:49": "end of a block of a table that you're in",
"68:52": "and like it's by far the best way to",
"68:54": "move around the place so there you go so",
"68:59": "in this case you know I want to like",
"69:01": "skip around through this table so I can",
"69:03": "hit ctrl down right to get to the bottom",
"69:06": "right control left up to get to the top",
"69:08": "left cuz I skip around and see what's",
"69:10": "going on so here's hey wait so here's",
"69:13": "some data and as we talked about one way",
"69:20": "to look at collaborative filtering data",
"69:21": "is like this and so what we did was we",
"69:25": "grabbed from the movie lens data the",
"69:28": "people that watched the most movies and",
"69:30": "the movies that were the most watched",
"69:33": "and just filtered the data set down to",
"69:35": "those 15 and as you can see when you do",
"69:42": "it that way it's not sparse anymore",
"69:43": "there's just a small number of yeah",
"69:46": "there's a small number of gaps right so",
"69:52": "this is something that we can now build",
"69:56": "a model with",
"70:00": "and so how can we build a model like",
"70:03": "what we want to do is we want to create",
"70:05": "something which can predict for user",
"70:10": "true 9-3 will they like movie 49 for",
"70:15": "example okay",
"70:16": "so we've got to come up with some way of",
"70:19": "you know some function that can",
"70:22": "represent that decision and so here's a",
"70:29": "simple possible approach and so we're",
"70:31": "going to take this idea of doing some",
"70:33": "matrix multiplications so I've created",
"70:36": "here a random matrix so here's one",
"70:42": "matrix of random numbers and I've",
"70:44": "created here and other matrix of random",
"70:49": "numbers more specifically for each movie",
"70:53": "I've created five random numbers and for",
"70:58": "each user I've created five random",
"71:03": "numbers and so we could say then that",
"71:09": "user 14 movie 27 did they like it or not",
"71:17": "well they're parading what we could do",
"71:20": "would be to multiply together this",
"71:24": "vector and that vector we can do a dot",
"71:26": "product right and here's the dot product",
"71:31": "right and so then we can basically do",
"71:33": "that for every possible thing in here",
"71:38": "we've got the dot product and you know",
"71:40": "thanks to spreadsheets we can just do",
"71:43": "that in one place and copy it over and",
"71:45": "it fills in the whole thing for us why",
"71:48": "would we do it this way well this is the",
"71:51": "basic starting point of a neural net",
"71:54": "isn't it a basic starting point of a",
"71:55": "neural net is that you take the matrix",
"71:58": "multiplication of two matrices and",
"72:01": "that's that's what your first layer",
"72:03": "always is and so we just have to come up",
"72:07": "with some way of saying like well what",
"72:08": "are two matrices that we can multiply",
"72:11": "and",
"72:13": "clearly you know you need a matrix for a",
"72:19": "user you know or a vector for a user a",
"72:23": "matrix for all the users and a vector",
"72:27": "for a movie or a matrix for all the",
"72:30": "movies and multiply them together and",
"72:35": "you get some numbers right like so they",
"72:40": "don't mean anything yet they're just",
"72:41": "random right but we can now use gradient",
"72:45": "descent to try to make these numbers and",
"72:49": "these numbers give us results that are",
"72:54": "closer to what we wanted so how do we do",
"73:00": "that well we set this up now as a as a",
"73:04": "linear model all right so the next thing",
"73:07": "we need is a loss function so we can",
"73:11": "calculate our loss function by saying",
"73:13": "well okay movie 3 for user ID 14 should",
"73:27": "have been a rating of 3 with this random",
"73:30": "matrices it's actually a rating of 0.9 1",
"73:32": "so we can find the sum of squared errors",
"73:34": "would be 3 minus 0.9 1 squared and then",
"73:45": "we can add them up so there's actually a",
"73:48": "sum squared in excel already some X",
"73:55": "minus y squared so we can use just some",
"73:57": "X minus y squared function passing in",
"74:00": "those two ranges and then divide by the",
"74:04": "count to get the mean so here is a",
"74:07": "number that is the mean that's exactly",
"74:10": "the square root of the mean squared",
"74:13": "error so like you sometimes you'll see",
"74:15": "people talk about MSE so that's the mean",
"74:18": "squared error sometimes you'll see our",
"74:20": "MSE that's the root mean squared error",
"74:22": "so since I've got a square root at the",
"74:24": "front this is the",
"74:26": "root mean square error so we have a loss",
"74:31": "so now all we need to do is use gradient",
"74:35": "descent to try to modify our weight",
"74:39": "matrices to make that loss smaller so",
"74:45": "Excel will do that for me I have other",
"74:51": "them installed so it's probably worth",
"74:54": "knowing how to do that",
"74:55": "so we have to install add-ins not",
"75:01": "solvers there okay this is obviously",
"75:03": "forgotten where it was oh yeah okay",
"75:07": "so the gradient descent solver in Excel",
"75:11": "is called solver and it just does normal",
"75:13": "gradient descent so you just go data",
"75:15": "solver you need to make sure that in",
"75:17": "your settings that you've enabled the",
"75:19": "solver extension it comes with Excel and",
"75:21": "all you need to do is say which cell",
"75:23": "represents my loss function so there it",
"75:26": "is c41 right so which where is your loss",
"75:29": "function stored which cells contain your",
"75:33": "your variables right since so you can",
"75:37": "see here I've got H 90 into V 23 which",
"75:42": "is up here and B 25 to have 39 which is",
"75:45": "over there and then you can just say",
"75:49": "okay set your loss function to a minimum",
"75:53": "by changing those cells and solve and",
"75:59": "you'll see the starts a 2.81 and you can",
"76:03": "see the numbers going down and so all",
"76:05": "that's doing is using gradient descent",
"76:07": "exactly the same way that we did when we",
"76:10": "did it manually in the notebook the",
"76:12": "other day okay but it's it's rather than",
"76:14": "solving the means grid error for a at B",
"76:19": "in the a at X in the Python instead it",
"76:24": "is solving the loss function here which",
"76:27": "is the mean squared error if the dot",
"76:29": "product of each of those vectors by each",
"76:31": "of these vectors and so there it goes",
"76:36": "so we'll let that run for a little while",
"76:38": "and see what happens",
"76:42": "but basically in in micro here is a",
"76:45": "simple way of creating a neural network",
"76:50": "which is really in this case it's like",
"76:52": "just a single linear layer with gradient",
"76:58": "descent to solve a collaborative",
"76:59": "filtering problem so let's go back and",
"77:04": "see what we do over here",
"77:08": "so over here we used get collab learner",
"77:14": "okay so the the function that was called",
"77:18": "in the notebook was get collab learner",
"77:21": "and so as you dig deeper into deep",
"77:25": "learning one of the really good ways to",
"77:27": "dig deeper into deep deep learning is to",
"77:29": "dig into the fast AI source code and see",
"77:33": "what's going on and so if you're going",
"77:34": "to be able to do that you need to know",
"77:36": "how to use your editor well enough to",
"77:38": "dig through the source code right and",
"77:40": "basically there's two main things you",
"77:42": "need to know how to do one is to jump to",
"77:44": "a particular symbol like a particular",
"77:45": "class or function by like by its name",
"77:48": "and the other is that when you're",
"77:50": "looking at a particular symbol to be",
"77:51": "able to jump to its its implementation",
"77:53": "so for example in this case I want to",
"77:55": "find Det collab Lana so in most in most",
"78:03": "editors including the one I use VM you",
"78:05": "can set it up so that you can kind of",
"78:06": "hit tap or something and it jumps",
"78:10": "through all the possible completions and",
"78:12": "you can hit enter and it jumps and it",
"78:15": "jumps straight to the definition for you",
"78:18": "alright so here is the definition of get",
"78:20": "collab alona and as you can see it's",
"78:25": "pretty small as these things tend to be",
"78:29": "and the keys in this case it kind of",
"78:32": "wraps data frame and automatically",
"78:34": "creates the data bunch for you because",
"78:36": "it's so simple but the key thing it does",
"78:38": "then is to create a model the whole",
"78:40": "particular kind which is an embedding",
"78:42": "bias model passing in the various things",
"78:46": "you asked for so you want to find out in",
"78:48": "your editor how you jump to the",
"78:49": "definition of that which",
"78:51": "in vim you just hit control right square",
"78:55": "bracket and here is the definition of",
"78:59": "embedding bias and so now we have",
"79:05": "everything on screen at once and as you",
"79:08": "can see there's not much going on in so",
"79:14": "the models that are being created for",
"79:16": "you by first AI are actually paid watch",
"79:19": "models and a PI torch model is called an",
"79:25": "NN module that's the name in hi torch of",
"79:29": "their models it's a little more nuanced",
"79:32": "than that but that's a good starting",
"79:33": "point for now and when a PI torch and",
"79:37": "end module is is run when you calculate",
"79:41": "the value know the result of that layer",
"79:44": "or neural net or whatever specifically",
"79:46": "it always calls a method for you called",
"79:48": "forward so it's in here that you get to",
"79:52": "find out how this thing's actually",
"79:53": "calculated when the model is built at",
"79:57": "the start it calls this thing called",
"80:00": "underscore underscore in it and the",
"80:03": "supportt underscore and as I think we've",
"80:05": "briefly mentioned before in - people",
"80:08": "tend to call this dunder init double",
"80:10": "underscore in it so dunder init is how",
"80:12": "we create the model and forward is how",
"80:16": "we run the model one thing if you're",
"80:19": "watching carefully you might notice is",
"80:21": "there's nothing here saying - how to",
"80:24": "calculate the gradients of the model and",
"80:27": "that's because height which does it for",
"80:29": "us okay so you only have to tell it how",
"80:31": "to calculate the output of your model",
"80:33": "and PI torch will go ahead and calculate",
"80:37": "the gradients for you",
"80:40": "and so in this case the model contains a",
"80:48": "set of weights through a user a set of",
"80:51": "weights for an item a set of biases for",
"80:54": "a user a set of biases for an item and",
"80:56": "each one of those is called",
"80:59": "is coming from this thing called get",
"81:01": "embedding",
"81:07": "so let's see get embedding so here is",
"81:12": "the definition of get embedding and all",
"81:16": "it does basically is it calls this",
"81:19": "height watch thing called n n dot",
"81:21": "embedding so in pi torch they have a lot",
"81:24": "of like standard neural network layers",
"81:27": "set up for you so gates and embedding",
"81:30": "and then this thing here is it just",
"81:34": "randomizes it so this is something which",
"81:36": "creates normal random numbers through",
"81:40": "the embedding so what's an embedding and",
"81:43": "embedding not surprisingly is a matrix",
"81:47": "of weights specifically it's a matrix of",
"81:51": "weights specifically an embedding is a",
"82:00": "matrix of weights that looks something",
"82:02": "like this",
"82:03": "it's a matrix of weights which you can",
"82:06": "basically look up into and grab one item",
"82:11": "out of it right so basically any kind of",
"82:15": "weight matrix and we're going to be",
"82:16": "digging into this in a lot more detail",
"82:18": "in the coming lessons but an embedding",
"82:21": "matrix is just a weight matrix that is",
"82:23": "designed to be something that you kind",
"82:25": "of index into it as an array and grab",
"82:28": "one vector out of it all right that's",
"82:31": "what an embedding matrix is and so in",
"82:35": "our case we have an embedding matrix for",
"82:38": "a user and an embedding matrix for a",
"82:41": "movie and here we have been taking the",
"82:46": "dot product of them all right but if you",
"82:49": "think about it that's not quite enough",
"82:51": "because we're missing this idea that",
"82:54": "like maybe there are certain movies that",
"82:57": "everybody likes more maybe there are",
"83:00": "some users that just tend to like movies",
"83:02": "more all right so I don't really just",
"83:04": "want to multiply these two vectors",
"83:07": "together but I really want to add a",
"83:09": "single number of like how popular is",
"83:12": "this movie and add a single number of",
"83:14": "like how much does this user like",
"83:17": "is in general so those are called bias",
"83:19": "terms remember how I said like there's",
"83:22": "this kind of idea of like bias and we",
"83:24": "the way we dealt with that in our",
"83:26": "gradient descent notebook was we added a",
"83:27": "column of ones okay but what we tend to",
"83:31": "do in practice is we actually explicitly",
"83:35": "say I want to add a bias term so we",
"83:40": "don't just want to have prediction",
"83:43": "equals dot product of these two things",
"83:46": "we want to say it's the dot product of",
"83:48": "those two things plus a bias term for a",
"83:51": "movie plus a bias term for user ID so",
"83:57": "that's basically what happens we when we",
"84:00": "set up the model we set up the embedding",
"84:03": "matrix for the users and the embedding",
"84:05": "matrix for the items and then we also",
"84:09": "set up the bias vector for the users and",
"84:11": "the bias vector for the items and then",
"84:14": "when we calculate the model we literally",
"84:17": "just multiply the two together just like",
"84:23": "we did right we just take that that",
"84:25": "product call it dot right and then we",
"84:28": "add the bias and then putting aside the",
"84:34": "min and Max score for a moment that's",
"84:35": "what we return so you can see that our",
"84:38": "model is literally doing what we did",
"84:44": "here with the tweak that we're also",
"84:46": "adding a bias right so it's it's an",
"84:53": "incredibly simple linear model and for",
"85:01": "for these kinds of collaborative",
"85:03": "filtering problems this kind of simple",
"85:05": "linear model actually tends to work",
"85:08": "pretty well and then there's one tweak",
"85:15": "that we do at the end which is that in",
"85:18": "our case we said that there's a min",
"85:19": "score of zero and a max score of five",
"85:23": "and so here's something to point out",
"85:29": "here's something to point out so if you",
"85:33": "have you know a range so you'd like you",
"85:40": "do that dot product and you add on the",
"85:42": "two biases and that gives you you know",
"85:44": "that can give you any possible number",
"85:46": "along the number line from very negative",
"85:48": "through to very positive numbers but we",
"85:50": "know that we always want to end up with",
"85:52": "a number between zero and five let's say",
"85:56": "that's five and of course this is zero",
"86:00": "so what if we match that number line",
"86:05": "like so",
"86:07": "to this function okay and so the shape",
"86:13": "of that function is called a sigmoid",
"86:19": "right and so it's gonna asymptote to",
"86:23": "five and it's gonna asymptote to zero",
"86:26": "and so that way whatever whatever number",
"86:31": "comes out of our dot product and adding",
"86:34": "the biases if we then stick it through",
"86:36": "this function it's never going to be",
"86:37": "higher than five and never going to be",
"86:39": "smaller than zero now strictly speaking",
"86:42": "that's not necessary right because our",
"86:47": "parameters could learn a set of weights",
"86:51": "that gives about the right number right",
"86:53": "so why would we do this extra thing if",
"86:56": "it's not necessary well the reason is we",
"86:58": "wouldn't make his life as easy for our",
"87:00": "model as possible",
"87:03": "so if we actually set it up so it's",
"87:08": "impossible for it to ever predict too",
"87:10": "much or ever predict too little then it",
"87:13": "can spend more of its weights predicting",
"87:15": "the thing we care about which is",
"87:16": "deciding who's going to like what movie",
"87:18": "so this is an idea we're going to keep",
"87:20": "coming back to when it comes to like",
"87:22": "making neural networks work better is",
"87:26": "it's about all these little decisions",
"87:27": "that we make to basically make it easier",
"87:30": "for the network to learn the right thing",
"87:33": "so that's the last tweak here we",
"87:36": "as we take the result of this dot",
"87:42": "product plus biases we put it through a",
"87:45": "sigmoid and so a sigmoid is just a",
"87:47": "function it's basically 1 over 1 plus e",
"87:49": "to the X the definition doesn't much",
"87:51": "matter but it just has the shape that I",
"87:53": "just mentioned and that goes between 0 &",
"87:57": "1 and if you then multiply that by max",
"88:00": "minus min plus min then that's going to",
"88:03": "give you something that's between min",
"88:04": "score and Max score so that means that",
"88:08": "this tiny little neural network I mean",
"88:12": "it's a push to call it a neural network",
"88:13": "but it is it's a neural network with",
"88:15": "with one weight matrix and no none when",
"88:19": "the arrow DS so it's kind of the world's",
"88:20": "most boring neural network with a",
"88:23": "sigmoid at the end that's actually",
"88:26": "because it does have a non-linearity the",
"88:28": "sigmoid at the end is the non-linearity",
"88:29": "just it only has one layer of weights",
"88:33": "that actually turns out to give close to",
"88:40": "state-of-the-art performance like I've",
"88:42": "looked up online to find out like what",
"88:44": "are the best results people have on this",
"88:46": "movie lends 100k database and the",
"88:49": "results I get from this little thing",
"88:50": "better than any of the results I can",
"88:53": "find from like the standard commercial",
"88:54": "products that you can download that are",
"88:56": "specialized for this and the trick seems",
"88:58": "to be that adding this little sigmoid",
"89:00": "makes a big difference and did you have",
"89:04": "a question there was a question",
"89:10": "you set up your VIN and I've already",
"89:12": "linked here dot them RC but I wanted to",
"89:14": "know if you had more to say about that",
"89:16": "they really like your setup you like my",
"89:20": "setup there's almost nothing in my setup",
"89:23": "it's pretty bare honestly yeah I I mean",
"89:29": "whatever you're doing with your editor",
"89:31": "you probably want it to look like this",
"89:32": "which is like when you've got a class",
"89:35": "that you're not currently working on it",
"89:37": "should be this is called folded this is",
"89:38": "what folding right it should be closed",
"89:40": "up so you can't see it and so you",
"89:44": "basically want something where it's easy",
"89:46": "to close and open fold so them already",
"89:48": "does all this for you and then as I",
"89:52": "mentioned you also want something where",
"89:53": "you can kind of jump to the definition",
"89:55": "of things which in VM it's called using",
"89:58": "tags so for the jump to the definition",
"90:01": "of learner basically them already does",
"90:03": "all this for you you just have two",
"90:05": "instructions that my VMRC is minimal I",
"90:07": "basically hardly use any extensions or",
"90:10": "anything",
"90:11": "another great editor who uses a vs code",
"90:14": "Visual Studio code it's free and it's",
"90:18": "it's awesome and it has all the same",
"90:20": "features that you're seeing that vim",
"90:22": "does basically the s code does all of",
"90:24": "those things as well I quite like using",
"90:30": "vim because I can use it on the remote",
"90:31": "machine and play around but you can of",
"90:35": "course just clone get onto your the git",
"90:40": "repo into your local computer and open",
"90:41": "it up and vs code to play around with it",
"90:43": "just don't like don't try and look",
"90:46": "through the code just on github or",
"90:48": "something like that's going to drive you",
"90:49": "crazy you need to be able to open it and",
"90:51": "close it and jump and jump back maybe",
"90:55": "people can create some threads on the",
"90:58": "forum for them tips fierce code tips",
"91:00": "sublime tips whatever yeah for me I",
"91:04": "would say like if you're gonna pick an",
"91:06": "editor if you want to use something on",
"91:09": "your local I would go with vs code today",
"91:11": "I think it's the best if you want to use",
"91:13": "something on the terminal side I would",
"91:15": "go with them or Emacs to me there",
"91:18": "they're clear winners",
"91:25": "so what I wanted to close with today is",
"91:28": "to kind of take this collaborative",
"91:31": "filtering example and describe how we're",
"91:33": "going to build on top of it for the next",
"91:34": "three lessons to create the more complex",
"91:37": "neural networks we've been seeing and so",
"91:40": "roughly speaking you know this is the",
"91:44": "bunch of concepts that we need to learn",
"91:46": "about let's think about let's think",
"91:59": "about",
"91:59": "what happens when when you're using a",
"92:06": "CNN - or you know whatever a neural",
"92:08": "network to do image recognition",
"92:11": "basically let's take a single pixel",
"92:14": "right you've got lots of pixels but",
"92:16": "let's take a single pixel so you've got",
"92:19": "a red a green and a blue pixel okay and",
"92:26": "so each one of those is some number",
"92:29": "between Norton 255 well we kind of",
"92:31": "normalized them so they're you know",
"92:34": "floating point between well with the",
"92:36": "mean of 0 and a standard deviation of 1",
"92:38": "but let's just do that you know let's",
"92:40": "say whatever they're like do that not to",
"92:43": "255 fish and so it's like 10 20 30",
"92:47": "whatever okay so what do we do with",
"92:54": "these well what we do is we take we",
"92:57": "basically treat that as a vector and we",
"93:01": "multiply it by a matrix right so this",
"93:06": "matrix depending on how you think of the",
"93:09": "rows and the columns let's trade the",
"93:11": "matrix is having three rows and then how",
"93:15": "many columns well you get to pick right",
"93:19": "you get to pick just like with the",
"93:21": "collaborative filtering version I",
"93:23": "decided to pick a vector of size five",
"93:27": "for each of my embedding vectors right",
"93:30": "so that would mean that that that's an",
"93:31": "embedding basically of size five right",
"93:35": "you can get to pick how big your weight",
"93:37": "matrix is so let's make it size five",
"93:40": "okay so this is three five five so",
"93:46": "initially this weight matrix contains",
"93:49": "random numbers remember when we looked",
"93:51": "up get embedding weight matrix just now",
"93:53": "and there were like two lines the first",
"93:54": "line is like create the matrix and the",
"93:56": "second was fill it with random numbers",
"93:58": "that's what we do",
"93:59": "right I mean lore gets hidden behind the",
"94:01": "scenes by fast AI and PI torch that's",
"94:03": "all it's doing just creating a matrix of",
"94:06": "random numbers when you set it up and",
"94:09": "the number of rows has to be three to",
"94:12": "match the",
"94:13": "and the number of columns can be as big",
"94:15": "as you like and so after you multiply",
"94:16": "the vector the input vector by that",
"94:19": "weight matrix you're going to end up",
"94:21": "with a vector of size five so people",
"94:29": "often asked like how much linear algebra",
"94:31": "do I need to know to be able to do deep",
"94:34": "learning this is the amount you need",
"94:36": "right so and and if you're not familiar",
"94:39": "with this that's that's fine you need to",
"94:41": "know about matrix products now you don't",
"94:45": "need to know a lot about them you just",
"94:46": "need to know like math and like",
"94:48": "computationally what are they what do",
"94:51": "they do and you've got to be very",
"94:52": "comfortable with like if a you know a",
"94:54": "matrix of size bla times a matrix of",
"94:57": "size bla gives a matrix of size bla like",
"94:59": "powder the dimensions match up so if you",
"95:02": "have three and they remember in num PI",
"95:05": "and PI torch we use at times three by",
"95:09": "five gives a vector of size five okay",
"95:12": "and then what happens next it goes",
"95:15": "through an activation function such as r",
"95:19": "lu which is just max zero comma X and",
"95:27": "spits out a new vector which is of",
"95:30": "course going to be exactly the same size",
"95:32": "because no activation function changes",
"95:36": "the size that it only changes the",
"95:38": "contents so that's still a size five",
"95:43": "what happens next",
"95:45": "we multiply by",
"95:47": "another matrix and again it can be any",
"95:50": "number of columns but the number of rows",
"95:53": "has to map nicely so it's going to be",
"95:54": "five by whatever but oh so maybe this",
"96:01": "one has you know five say by ten and so",
"96:07": "that's going to give some output which",
"96:13": "will be size ten and again we put that",
"96:16": "through value and again that gives us",
"96:20": "something of the same size okay and then",
"96:24": "we can put that through another H matrix",
"96:30": "actually just to make this a bit clearer",
"96:32": "you'll see why in a moment I'm going to",
"96:33": "use eight not ten just so that these",
"96:39": "let's say we're doing digit recognition",
"96:41": "right so there are ten possible digits",
"96:44": "so my last weight matrix has to be ten",
"96:52": "in size because then my that's going to",
"96:56": "mean my final output is a vector of ten",
"96:59": "in size and remember if you're doing",
"97:01": "that digit recognition what happens did",
"97:04": "we take our actuals right which is ten",
"97:13": "in size and like if the number that",
"97:16": "we're trying to predict was the number",
"97:17": "three that's our like that's the thing",
"97:22": "we're trying to predict then that means",
"97:25": "that there is a three zero zero zero in",
"97:30": "the third position right so what happens",
"97:35": "is our neural net runs along okay it's",
"97:41": "starting with our input and going wait",
"97:44": "mate",
"97:44": "Rick's value white bag tricks value",
"97:47": "weight matrix final output and then we",
"97:51": "compare these two together to see how",
"97:56": "close they are how Plus they match using",
"97:58": "some loss function and we'll learn about",
"98:00": "all the loss functions that we use next",
"98:02": "week for now the only one we've learned",
"98:03": "his means great error and yeah we",
"98:07": "compare the actual you can think of them",
"98:12": "as probabilities for each of the 10 to",
"98:14": "the actual each of the 10 to get a loss",
"98:16": "and then we find the gradients of every",
"98:19": "one as the weight matrices with respect",
"98:20": "to that and we update the weight",
"98:22": "matrices so the main thing I wanted to",
"98:24": "show right now is the terminology we use",
"98:26": "because it's really important these",
"98:31": "things contain numbers specifically they",
"98:36": "initially matrices containing random",
"98:39": "numbers and we can refer to these yellow",
"98:41": "things as in pi touch they're called",
"98:47": "parameters",
"98:50": "sometimes we'll refer to them as weights",
"98:55": "although weights is slightly less",
"98:57": "accurate because they can also be biases",
"98:59": "right but you know we kind of use the",
"99:02": "terms a little bit interchangeably but",
"99:03": "strictly speaking we should call them",
"99:04": "parameters and then after each of those",
"99:07": "metrics products that calculates a",
"99:10": "vector of numbers so here are some",
"99:13": "numbers that are calculated by this one",
"99:17": "here are some numbers that are",
"99:18": "calculated by a weight matrix multiply",
"99:23": "and then there are some other sets of",
"99:27": "numbers that are calculated as a result",
"99:29": "of a rail you as well as an activation",
"99:31": "function okay either one",
"99:46": "is called Accord activations so",
"99:52": "activations and parameters both refer to",
"99:55": "numbers right they are numbers the",
"99:58": "parameters are numbers that are stored",
"100:01": "they're used to make a calculation",
"100:05": "activations are the result of a",
"100:08": "calculation the numbers that are",
"100:10": "calculated right so they're the two key",
"100:13": "things you need to remember so use these",
"100:16": "terms right and use them correctly and",
"100:23": "accurately right and if you read these",
"100:26": "terms they mean these very specific",
"100:28": "things so don't mix them up in your head",
"100:30": "and remember they're nothing weird and",
"100:33": "magical they're very simple things an",
"100:35": "activation is the result of either a",
"100:39": "matrix multiply or an activation",
"100:41": "function okay and a parameter are the",
"100:45": "numbers inside the weights inside the",
"100:47": "matrices that we multiply by okay that's",
"100:49": "it and then there are some special",
"100:52": "layers so every one of these things that",
"100:56": "does a calculation all of these things",
"100:59": "that does a calculation are all called",
"101:04": "layers they're the layers of our neural",
"101:08": "net so every layer results in a set of",
"101:11": "activations because there's a",
"101:13": "calculation that results in a set of",
"101:15": "results okay",
"101:18": "there's a special layer at the start",
"101:20": "which is called the input layer and then",
"101:24": "at the end you just have a set of",
"101:26": "activations okay and we can refer to",
"101:29": "those special I mean they're not special",
"101:30": "mathematically but they're semantically",
"101:32": "special we can call those the outputs",
"101:35": "right so the important point to realize",
"101:38": "here is the outputs of a neural net and",
"101:40": "not actually like mathematically special",
"101:43": "they're just the activations of a layer",
"101:45": "and so what we did in our collaborative",
"101:48": "filtering example we did something",
"101:49": "interesting we actually added an",
"101:54": "additional activation function right at",
"101:58": "the very end",
"102:00": "right we added an extra activation",
"102:02": "function which was sigmoid and",
"102:06": "specifically it was a scaled sigmoid",
"102:08": "curve between 0 & 5 right and that's",
"102:10": "really common right it's very common to",
"102:13": "have an activation function as your last",
"102:15": "layer and it's almost never going to be",
"102:18": "a rel you because it's very unlikely",
"102:19": "that what you actually want is something",
"102:21": "that stops the truncates at zero it's",
"102:24": "very often going to be a sigmoid or",
"102:26": "something similar because it's very",
"102:27": "likely that actually what you want is",
"102:29": "something that's between two values okay",
"102:31": "and kind of scaled in that way so that's",
"102:35": "nearly it right so we've got inputs",
"102:38": "weights activations activation functions",
"102:42": "which we sometimes call nonlinearities",
"102:44": "output and then the function that",
"102:47": "compares those two things together right",
"102:50": "is called the loss function which so far",
"102:53": "we've used MSE yeah okay",
"103:00": "and that's if that's enough for today so",
"103:02": "what we're going to do what we're going",
"103:05": "to do next week is we're going to kind",
"103:07": "of add in a few more extra bits in which",
"103:10": "is we're going to learn the loss",
"103:11": "function that's used for classification",
"103:12": "which is called cross-entropy",
"103:14": "we're going to use the activation",
"103:16": "function that's used for single label",
"103:18": "classification which is called softmax",
"103:20": "and we're also going to learn exactly",
"103:22": "what happens when we do fine tuning in",
"103:26": "terms of how these layers actually what",
"103:28": "happens with unfreeze and what happens",
"103:29": "when we create transfer learning so",
"103:32": "thanks everybody",
"103:34": "looking forward to seeing you next week"
}
