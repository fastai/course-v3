{
  "00:00": "all right welcome to lesson 6 where",
  "00:04": "we're going to do a deep dive into",
  "00:07": "computer vision convolutional neural",
  "00:10": "networks what is a convolution and we're",
  "00:15": "also going to learn the final",
  "00:16": "regularization tricks after last lesson",
  "00:20": "learning about weight decay and /lt",
  "00:23": "regularization",
  "00:26": "I want to start by showing you something",
  "00:29": "that I'm really excited about and I've",
  "00:31": "had a small hand and helping to to",
  "00:35": "create for those of you that saw my talk",
  "00:38": "on ted.com you might have noticed this",
  "00:42": "really interesting demo that we did",
  "00:43": "about four years ago showing a way to",
  "00:46": "quickly build models with unlabeled data",
  "00:51": "it's been four years but we're finally",
  "00:53": "at a point where we're we're we're ready",
  "00:56": "to put this out in the world and let",
  "00:58": "people use it and the first people we're",
  "00:59": "going to let use it are you folks so the",
  "01:04": "company is called platform delay I and",
  "01:06": "the reason I'm mentioning it here is",
  "01:08": "that it's going to let you create models",
  "01:11": "on different types of data sets to what",
  "01:13": "you can do now that is to say data sets",
  "01:15": "that you don't have labels for yet we're",
  "01:18": "actually going to help you label them so",
  "01:20": "this is the first time this has been",
  "01:24": "shown before so I'm pretty thrilled",
  "01:29": "about it and let me give you a quick",
  "01:35": "demo when you so if you'd go to platform",
  "01:38": "AI and choose get started you'll be able",
  "01:44": "to create a new project and if you",
  "01:47": "create a new project you can either",
  "01:48": "upload your own images uploading it at",
  "01:52": "500 or so works pretty well you can",
  "01:55": "upload a few thousand but you know to",
  "01:58": "start upload 500 or so they all have to",
  "02:00": "be in a single folder and so we're",
  "02:04": "assuming that you've got a whole bunch",
  "02:05": "of images that you haven't got any",
  "02:06": "labels for or you can start with one of",
  "02:08": "the existing collections if you want to",
  "02:10": "play around so I've started with the",
  "02:12": "cars",
  "02:13": "collection kind of going back to what we",
  "02:15": "did four years ago and so this is what",
  "02:19": "happens when you first go into",
  "02:22": "platformer AI and look at the collection",
  "02:24": "of images you're uploaded a random",
  "02:26": "sample of them will appear on the screen",
  "02:28": "and as you'll recognize probably they",
  "02:32": "are projected from a deep learning space",
  "02:36": "into a 2d space using a pre trained",
  "02:39": "model and for this initial version it's",
  "02:42": "an image net model we're using as things",
  "02:44": "move along",
  "02:45": "we'll be adding more and more pre train",
  "02:47": "models and what I'm going to do is I",
  "02:50": "want to add labels to this data set",
  "02:53": "representing which angle a photo of the",
  "02:57": "car was taken from which is something",
  "02:58": "that actually image that's going to be",
  "03:01": "really bad at isn't it because image net",
  "03:04": "has learnt to recognize the difference",
  "03:06": "between cars versus bicycles and image",
  "03:09": "net knows that the angle you take a",
  "03:11": "photo on actually doesn't matter so we",
  "03:13": "want to try and create labels using the",
  "03:16": "kind of thing that actually image net",
  "03:18": "specifically learn to ignore so the",
  "03:22": "projection that you see we can click",
  "03:24": "these layer buttons at the top to switch",
  "03:26": "to user projection using a different",
  "03:29": "layer of the neural net right and so",
  "03:32": "here's the last layer which is going to",
  "03:34": "be a total waste of time for us because",
  "03:36": "it's really going to be projecting",
  "03:38": "things based on what kind of thing it",
  "03:40": "thinks it is and the first layer is",
  "03:42": "probably going to be a waste of time for",
  "03:43": "us as well because there's very little",
  "03:46": "interesting semantic content there but",
  "03:49": "if I go into the middle in layer 3 we",
  "03:52": "may well be able to find some some some",
  "03:54": "differences there so then what you can",
  "03:57": "do is you can click on the projection",
  "03:58": "button here and you can actually just",
  "04:00": "press up and down rather than just",
  "04:02": "pressing the the arrows at the top to",
  "04:05": "switch between projections or left and",
  "04:07": "right so switch between layers and what",
  "04:09": "you can do is you can basically look",
  "04:10": "around until you notice that there's a",
  "04:14": "projection which is kind of separated",
  "04:16": "out things you're interested in and so",
  "04:18": "this one actually I notice that it's got",
  "04:22": "a whole bunch of",
  "04:27": "cars that are kind of from the top front",
  "04:30": "front right over here okay so if we zoom",
  "04:35": "in a little bit we can double check",
  "04:37": "because like yeah that looks pretty good",
  "04:39": "they're all kind of front right so we",
  "04:41": "can click on here to go to selection",
  "04:43": "mode and we can cut a grab a few and",
  "04:46": "then you should check and so what we're",
  "04:49": "doing here is we're trying to take",
  "04:50": "advantage of the combination of human",
  "04:52": "plus machine the the machine is pretty",
  "04:54": "good at quickly doing calculations but",
  "04:57": "as a human I'm pretty good at looking at",
  "04:59": "a lot of things at once and seeing the",
  "05:01": "odd one out so in this case I'm looking",
  "05:02": "for cars that aren't front right and so",
  "05:05": "by laying the one on in front of me I",
  "05:06": "can do that really quickly it's like",
  "05:07": "okay definitely that one so just click",
  "05:08": "on the ones that you don't want all",
  "05:13": "right it's all good so then you can just",
  "05:15": "go back and so then what you can do is",
  "05:18": "you can either put them into a new",
  "05:19": "category but I can create a new label or",
  "05:22": "you can click on one of the existing",
  "05:23": "ones so before I came I just created a",
  "05:24": "few so here's friend right so I just",
  "05:26": "click on it here there we go okay and so",
  "05:31": "that's the basic idea is that you kind",
  "05:33": "of keep flicking through different",
  "05:35": "layers or projections to try and find",
  "05:37": "groups that represent the things you're",
  "05:38": "interested in and then over time you'll",
  "05:40": "start to realize that there are some",
  "05:41": "things that are a little bit harder so",
  "05:45": "for example I'm having trouble finding",
  "05:46": "sides so what I can do is I can see over",
  "05:49": "here there's a few sides so I can zoom",
  "05:52": "in here and click on a couple of them",
  "05:55": "like this one and this one that one that",
  "06:02": "one okay I mean I'll say find similar",
  "06:06": "and so this is going to basically look",
  "06:08": "in that that projection space and not",
  "06:12": "just at the images that are currently",
  "06:14": "displayed but all of the images that you",
  "06:15": "uploaded and hopefully I might be able",
  "06:17": "to label now a few more side images at",
  "06:21": "that point so it's going through and",
  "06:24": "checking you know all of the images that",
  "06:27": "you uploaded to see if any of them have",
  "06:31": "projections in this space which similar",
  "06:34": "to the ones I've selected and hopefully",
  "06:36": "we'll find a few more of what I'm",
  "06:39": "interested in",
  "06:42": "okay so now if I want to try to find a",
  "06:46": "projection that separates the sides from",
  "06:49": "the front right I can click on each of",
  "06:51": "those two and then over here this button",
  "06:53": "is now called switch to the projection",
  "06:55": "that maximizes the distance between the",
  "06:57": "labels so now what this is going to do",
  "06:59": "is try and find the best projection that",
  "07:01": "separates out those classes and so the",
  "07:04": "goal here is to you know help me",
  "07:07": "visually inspect and quickly find a",
  "07:09": "bunch of things that I can use to label",
  "07:13": "so like they're the kind of the the key",
  "07:15": "features and it's done a good job you",
  "07:18": "can see down here we've now got a whole",
  "07:20": "bunch of sides which I can now grab",
  "07:22": "because I was having a lot of trouble",
  "07:24": "finding them before and it's always",
  "07:26": "worth double-checking it's kind of",
  "07:32": "interesting to see how the neural Nets",
  "07:34": "behave like there seems to be more",
  "07:36": "sports cars in this group than average",
  "07:38": "as well so it's kind of found side",
  "07:39": "angles of sports cars so that's kind of",
  "07:42": "interesting so then I can click all",
  "07:43": "right so I've got those four an arrow",
  "07:44": "clicks side and there we go",
  "07:47": "so once you've done that a few times I",
  "07:50": "find if you've got you know a hundred or",
  "07:52": "so labels you can then click on the",
  "07:56": "train model button and it'll take a",
  "07:58": "couple of minutes and come back and show",
  "08:00": "you your train model and after it's",
  "08:02": "trained which I did it on a smaller",
  "08:04": "number of labels earlier you can then",
  "08:06": "switch this very opacity button and",
  "08:09": "it'll actually kind of fade out the ones",
  "08:12": "that are already predicted pretty well",
  "08:13": "and it'll also give you a estimate as to",
  "08:16": "how accurate it thinks the model is the",
  "08:19": "main reason I mentioned this for you is",
  "08:20": "that so that you can now click the",
  "08:23": "download button and it'll download the",
  "08:25": "predictions which is what we hope will",
  "08:27": "be interesting to most people but what I",
  "08:28": "think will be interesting to you as deep",
  "08:30": "learning students is it'll download your",
  "08:32": "labels so now you can use that labeled",
  "08:36": "subset of data along with the unlabeled",
  "08:39": "set that you haven't labeled yet to see",
  "08:42": "if you can you know see if you can build",
  "08:43": "a better model and platform a I stand",
  "08:46": "for you see if you can use that initial",
  "08:48": "set of data to kind of get going",
  "08:49": "creating models and stuff which you",
  "08:52": "weren't able to label before",
  "08:54": "clearly there are some things that this",
  "08:56": "systems better that than others",
  "08:59": "for things that require you know really",
  "09:02": "zooming in closely and taking a very",
  "09:04": "very close inspection this isn't going",
  "09:06": "to work very well but is really designed",
  "09:08": "for things that the human eye can kind",
  "09:10": "of pick up fairly readily but we'd love",
  "09:13": "to get feedback as well and you can",
  "09:15": "click on the Help button to get feedback",
  "09:18": "give feedback and also there's a",
  "09:20": "platform AI discussion topic in our",
  "09:23": "forum where so are shocked if you can",
  "09:25": "stand up our checks the CEO of the",
  "09:27": "company he'll be there helping out",
  "09:30": "answering questions and so forth so yeah",
  "09:34": "I hope people find that useful it's been",
  "09:37": "many years getting to this point and I'm",
  "09:39": "glad we're we're finally there",
  "09:46": "okay so one of the reasons I wanted to",
  "09:50": "mention this today is that we're going",
  "09:51": "to be doing a big dive into convolutions",
  "09:54": "later in this lesson so I'm going to",
  "09:56": "circle back to this to try and explain a",
  "09:58": "little bit more about how that is",
  "09:59": "working under the hood and give you a",
  "10:01": "kind of a sense of what's what's going",
  "10:03": "on but before we do we have to finish",
  "10:06": "off last week's discussion of",
  "10:08": "regularization and so we were talking",
  "10:11": "about regularization specifically in the",
  "10:13": "context of the tabular learner because",
  "10:17": "the tabular learner",
  "10:17": "this was the forward method sorry this",
  "10:19": "is the init method in the tabular",
  "10:22": "learner and our goal was to understand",
  "10:24": "everything here and we're not quite",
  "10:27": "there yet",
  "10:28": "last week we were looking at the adult",
  "10:32": "data set which is a really simple kind",
  "10:35": "of over simple data set that's just a",
  "10:37": "toy purposes so this lit week let's look",
  "10:39": "at a data set that's much more",
  "10:41": "interesting a kegel competition data set",
  "10:43": "so we know kind of what the the best in",
  "10:45": "the world",
  "10:46": "and you know care girl competition was",
  "10:47": "results tend to be much harder to beat",
  "10:50": "than academic state-of-the-art results",
  "10:52": "tend to be because a lot more people",
  "10:54": "work on cowgirl competitions than most",
  "10:56": "academic data sets so it's a really good",
  "10:58": "challenge to try and do well on a",
  "10:59": "caracal competition data set so this one",
  "11:02": "the rossmann data set is if they've got",
  "11:06": "three thousand drugs",
  "11:08": "in Europe and you're trying to predict",
  "11:10": "how many products they're going to sell",
  "11:13": "in the next couple of weeks so one of",
  "11:16": "the interesting things about this is",
  "11:17": "that the test set for this is from a",
  "11:21": "time period that is more recent than the",
  "11:24": "training set and this is really common",
  "11:26": "right if you want to predict things",
  "11:27": "there's no point predicting things that",
  "11:29": "are in the middle of your training set",
  "11:30": "you want to predict things in the future",
  "11:33": "another interesting thing about it is",
  "11:35": "the evaluation metric they provided is",
  "11:38": "the root mean squared percent error so",
  "11:40": "this is just a normal root mean squared",
  "11:42": "error except we go actual minus",
  "11:44": "prediction divided by actual so in other",
  "11:46": "words it's the percent error that we're",
  "11:49": "taking the root mean squared of so",
  "11:52": "there's a couple of interesting features",
  "11:53": "always interesting to look at the",
  "11:55": "leaderboard",
  "11:55": "so the leaderboard the winner was 0.1",
  "11:59": "the paper that we've roughly replicated",
  "12:02": "was point 105 106 and 10th place out of",
  "12:09": "3,000 was 0.11 ish bit less all right so",
  "12:20": "we're gonna skip over a little bit which",
  "12:23": "is that the data that was provided here",
  "12:25": "was they provided a small number of",
  "12:29": "files but they also let competitors",
  "12:33": "provide additional external data as long",
  "12:36": "as they shared it with all the",
  "12:37": "competitors and so in practice the data",
  "12:39": "set we're going to use contains account",
  "12:41": "remember six or seven tables the way",
  "12:44": "that you join tables and stuff isn't",
  "12:47": "really part of a deep learning course so",
  "12:49": "I'm going to skip over it and instead",
  "12:51": "I'm going to refer you to introduction",
  "12:52": "to machine learning for coders which",
  "12:54": "will take you step-by-step through the",
  "12:56": "data preparation for this we've provided",
  "12:59": "it for you",
  "13:03": "we've provided it for you in Russman",
  "13:07": "data clean so you'll see the whole",
  "13:09": "process there and so you'll need to run",
  "13:11": "through that notebook to create these",
  "13:14": "pickle files that we read here can you",
  "13:17": "see this in the back okay",
  "13:20": "I just want to mention one particularly",
  "13:24": "interesting part of the rossmann data",
  "13:26": "clean",
  "13:27": "notebook which is you'll see there's",
  "13:30": "something that says add date part and I",
  "13:32": "wanted to explain what's going on here",
  "13:33": "I've been mentioning for a while that",
  "13:35": "we're going to look at time series and",
  "13:37": "pretty much everybody who I've spoken to",
  "13:39": "about it has assumed that I'm going to",
  "13:41": "do some kind of recurrent neural network",
  "13:42": "but I'm not interestingly the kind of",
  "13:47": "the main academic group that studies",
  "13:49": "time series is econometrics and but they",
  "13:51": "tend to study one very specific kind of",
  "13:53": "time series which is where the only data",
  "13:56": "you have is a sequence of time points of",
  "13:59": "one thing like that's the only thing you",
  "14:01": "have is one sequence in real life that's",
  "14:04": "almost never the case normally you know",
  "14:06": "if we would have some information about",
  "14:07": "the store that that represents or the",
  "14:09": "people that it represents we'd have",
  "14:11": "metadata we'd have sequences of other",
  "14:14": "things measured at similar time periods",
  "14:15": "or different time periods and so most of",
  "14:20": "the time I find in practice the the",
  "14:24": "state-of-the-art results when it comes",
  "14:26": "to competitions on kind of more",
  "14:28": "real-world data sets",
  "14:29": "don't gender you it's recurrent neural",
  "14:30": "networks but instead they tend to take",
  "14:32": "it's a time piece which in this case it",
  "14:35": "was a date we were given in the data and",
  "14:38": "they add a whole bunch of metadata so in",
  "14:41": "our case for example we've added day of",
  "14:43": "week so we were given a date right we've",
  "14:46": "had a day of week year month week of",
  "14:51": "year day of month day of week day of",
  "14:54": "year and then a bunch of boolean ziz at",
  "14:56": "the month start or end quarter year",
  "14:58": "start or end elapsed time since 1970 so",
  "15:02": "forth if you run this one function at",
  "15:05": "date part and pass it a date it'll add",
  "15:07": "all of these columns to your data set",
  "15:08": "for you and so what that means is that",
  "15:12": "let's take a very reasonable example",
  "15:15": "purchasing behavior probably changes on",
  "15:17": "payday payday might be the fifteenth of",
  "15:20": "the month so if you have a thing here",
  "15:22": "called this is day of month here right",
  "15:24": "then it'll be able to recognize every",
  "15:27": "time something is a fifteen there and",
  "15:29": "associated it with a higher in this case",
  "15:32": "embedding matrix value",
  "15:34": "but so this way it basically the the you",
  "15:39": "know we can't expect a neural net to do",
  "15:41": "all of our feature engineering for us we",
  "15:43": "can expect it to kind of find",
  "15:44": "nonlinearities and interactions and",
  "15:46": "stuff like that but for something like",
  "15:47": "taking a date like this and figuring out",
  "15:52": "that the fifteenth of the month is",
  "15:54": "something when interesting things happen",
  "15:56": "it's much better if we can provide that",
  "15:58": "information for it so this is a really",
  "16:00": "useful function to use and once you've",
  "16:02": "done this you can treat many kinds of",
  "16:05": "time-series problems as regular tabular",
  "16:07": "problems I say many kinds not all you",
  "16:11": "know if there's very complex kind of",
  "16:12": "state involved in a time series such as",
  "16:15": "you know equity trading or something",
  "16:17": "like that this probably won't be the",
  "16:19": "case or this won't be the only thing you",
  "16:22": "need but in this case it'll get us a",
  "16:26": "really good result and it's in practice",
  "16:29": "most of the time I find this works well",
  "16:31": "tabular data is normally in pandas so we",
  "16:34": "just stored them as standard Python",
  "16:36": "pickerel files we can read them in we",
  "16:38": "can take a look at the first five",
  "16:40": "records and so the key thing here is",
  "16:42": "that we're trying to on a particular",
  "16:44": "date for a particular store ID we want",
  "16:48": "to predict the number of sales sales is",
  "16:50": "the dependent variable so the first",
  "16:55": "thing I'm going to show you is something",
  "16:57": "called pre processes you've already",
  "16:59": "learned about transforms transforms are",
  "17:01": "bits of code that run every time",
  "17:04": "something is grabbed from a data set and",
  "17:06": "so it's really good for data",
  "17:07": "augmentation that we'll learn about",
  "17:08": "today which is that it's going to get a",
  "17:11": "different random value every time it's",
  "17:12": "sampled pre processes are like",
  "17:15": "transforms but they're a little bit",
  "17:18": "different which is that they run once",
  "17:20": "before you do any training and really",
  "17:24": "importantly they run once on the",
  "17:27": "training set and then any kind of State",
  "17:31": "or metadata that's created is then",
  "17:33": "shared with the validation and test set",
  "17:35": "let me give you an example when we've",
  "17:37": "been doing image recognition and we've",
  "17:40": "had a set of classes to like all the",
  "17:42": "different pet breeds and they've been",
  "17:44": "turned into numbers the thing that's",
  "17:46": "actually doing that for us",
  "17:47": "is a preprocessor that's being created",
  "17:49": "in the background so that makes sure",
  "17:51": "that the classes for the training set",
  "17:53": "are the same as the classes for the",
  "17:54": "validation and the classes of the test",
  "17:56": "set so we're going to do something very",
  "17:59": "similar here for example if we create a",
  "18:02": "little small subset of a data for",
  "18:04": "playing with this is a really good idea",
  "18:06": "when you start with a new data set so",
  "18:08": "I've just grabbed two thousand IDs at",
  "18:10": "random okay and then I'm just going to",
  "18:13": "grab a little training set in a little",
  "18:15": "test set half and half of those 2,000",
  "18:17": "IDs and it's going to grab five columns",
  "18:20": "okay and then we can just play around",
  "18:21": "with this nice and easy so here's the",
  "18:24": "first few of those from the training set",
  "18:26": "and you can see one of them is called",
  "18:29": "promo interval and it has these strings",
  "18:31": "and sometimes it's missing in pandas",
  "18:34": "missing is na M so the first",
  "18:40": "preprocessor I'll show you is category",
  "18:42": "fee and category does basically the same",
  "18:45": "thing that that classes thing for image",
  "18:48": "recognition does for a dependent",
  "18:49": "variable it's going to take these",
  "18:51": "strings it's going to find all of the",
  "18:53": "possible unique values of it and it's",
  "18:55": "going to create a list of them and then",
  "18:57": "it's going to turn the strings into",
  "18:59": "numbers so if I call it on my training",
  "19:01": "set that'll create categories there and",
  "19:03": "then I call it on my test set passing in",
  "19:06": "testicles true that makes sure it's",
  "19:09": "going to use the same categories that I",
  "19:10": "had before and now when I say dot head",
  "19:13": "it looks exactly the same and that's",
  "19:16": "because pandas has turned this into a",
  "19:18": "categorical variable which internally is",
  "19:21": "storing numbers but externally is",
  "19:24": "showing me the strings but I can look",
  "19:26": "inside promo interval to look at the cat",
  "19:30": "categories this is all standard pandas",
  "19:32": "here to show me a list of all of them",
  "19:36": "what we would call classes in first day",
  "19:38": "a or would be called just categories in",
  "19:41": "pandas and so then if I look at the cat",
  "19:43": "codes you can see here this list here is",
  "19:48": "the numbers that are actually stored",
  "19:49": "minus 1 minus 1 1 minus 1 1 right why am",
  "19:53": "boy one of these minus ones the minus",
  "19:56": "ones represent ni n they",
  "19:59": "missing so pandas uses the special code",
  "20:02": "- one to be mean missing now as you know",
  "20:05": "these are going to end up in an",
  "20:07": "embedding matrix and we can't look up",
  "20:09": "item -1 and an embedding matrix so",
  "20:13": "internally in first AI we add one to all",
  "20:16": "of these another useful preprocessor is",
  "20:20": "fixed missing and so again you can call",
  "20:23": "it on the data frame you can call on the",
  "20:25": "test passing in testicles true and this",
  "20:27": "will create for everything that's",
  "20:30": "missing anything that has a missing",
  "20:32": "value it'll create an additional column",
  "20:34": "with the column name underscore na so",
  "20:36": "competition distance underscore na and",
  "20:38": "it will set it for true for any time",
  "20:42": "that was missing and then what we do is",
  "20:45": "we replace competition distance with the",
  "20:48": "median for those why do we do this well",
  "20:51": "because very commonly the fact that",
  "20:53": "something's missing is of itself",
  "20:56": "interesting like you know it turns out",
  "20:59": "the fact that this is missing helps you",
  "21:00": "predict your outcome alright so we've",
  "21:03": "certainly want to keep that information",
  "21:04": "in a convenient boolean column so that",
  "21:07": "our deep learning model can use it to",
  "21:08": "predict things but then we need",
  "21:10": "competition distance to be a continuous",
  "21:13": "variable so we can use it in the",
  "21:14": "continuous variable part of our model so",
  "21:16": "we can replace it with almost any number",
  "21:18": "right because if it turns out that the",
  "21:21": "missingness is important it can use the",
  "21:23": "interaction of competition distance na",
  "21:25": "and competition distance to make",
  "21:27": "predictions so that's what fixed missing",
  "21:29": "does you don't have to manually call pre",
  "21:33": "processes yourself when you call any",
  "21:41": "kind of item list creating creator you",
  "21:44": "can pass in a list of pre processes",
  "21:46": "which you can create like this ok so if",
  "21:50": "this is saying ok I want to feel missing",
  "21:52": "I want to category Phi I want to",
  "21:54": "normalize so for continuous variables",
  "21:56": "it'll subtract the mean and divide by",
  "21:58": "the standard deviation to help a train",
  "21:59": "more easily and so you just say those",
  "22:01": "are my procs and then you can just pass",
  "22:03": "it in there and that's it and later on",
  "22:05": "you can go data export and it'll save",
  "22:08": "all the metadata for that data bunch so",
  "22:11": "you can later on load it in",
  "22:13": "knowing exactly what your category codes",
  "22:15": "are exactly what median values used for",
  "22:17": "replacing the missing values and exactly",
  "22:19": "what means and standard deviations you",
  "22:21": "normalize by okay so the main thing you",
  "22:27": "have to do if you want to create a data",
  "22:29": "bunch of tabular data is find out or",
  "22:32": "tell it what are your categorical",
  "22:33": "variables and what are your continuous",
  "22:35": "variables and as we discussed last week",
  "22:38": "briefly your categorical variables are",
  "22:42": "not just strings and things but also I",
  "22:45": "include things like day of week and",
  "22:48": "month and day of month even though",
  "22:51": "they're numbers and make them",
  "22:52": "categorical variables because for",
  "22:54": "example day of month I don't think it's",
  "22:57": "going to have a nice smooth curve I",
  "23:00": "think that the fifteenth of the month",
  "23:01": "and the first of the month and the 30th",
  "23:04": "of the month are probably going to have",
  "23:05": "different purchasing behavior to other",
  "23:08": "days of the month and so therefore if I",
  "23:11": "make it a categorical variable it's",
  "23:13": "going to end up creating an embedding",
  "23:14": "matrix and those different days of the",
  "23:16": "month can get different behaviors so",
  "23:19": "you've actually got to think carefully",
  "23:20": "about which things should be categorical",
  "23:23": "variables and on the whole if in doubt",
  "23:25": "and there are not too many levels in",
  "23:28": "your category that's called the",
  "23:29": "cardinality if your cardinality is not",
  "23:31": "too high I would have put it as a",
  "23:33": "categorical variable you can always try",
  "23:35": "an H and see which works best so our",
  "23:39": "final data frame that we're going to",
  "23:40": "pass in is going to be a training set",
  "23:43": "with the categorical variables and the",
  "23:44": "continuous variables and the dependent",
  "23:45": "variable and the date and the date we're",
  "23:49": "just going to use to create a validation",
  "23:51": "set where we go Stickley going to say",
  "23:53": "the validation set is going to be the",
  "23:55": "same number of Records at the end of the",
  "23:58": "time period that the test set is for",
  "24:00": "cattle and so that way we should be able",
  "24:02": "to validate our model nicely ok so now",
  "24:07": "we can create a tabular list so this is",
  "24:10": "our standard data block API that you've",
  "24:12": "seen a few times from a data frame",
  "24:13": "passing all of that information split it",
  "24:17": "into valid vs. train label it with a",
  "24:19": "dependent variable and here's something",
  "24:22": "I don't think you've seen before label",
  "24:26": "this is our dependent variable and as",
  "24:30": "you can see this is this is sales it's",
  "24:32": "not a float",
  "24:33": "it's an n64 if this was a float then",
  "24:38": "first day I would automatically know or",
  "24:40": "guess that you want to do a regression",
  "24:41": "okay but this is not a float it's an int",
  "24:45": "so first I was going to assume you want",
  "24:46": "to do a classification so when we label",
  "24:49": "it we have to tell it that the clasp of",
  "24:51": "the labels we want is a list of floats",
  "24:54": "okay not a list of categories which",
  "24:57": "would otherwise be the default so this",
  "24:59": "is the thing that's going to",
  "25:00": "automatically turn this into a",
  "25:01": "regression problem for us and then we",
  "25:04": "create a data bunch so I wanted to",
  "25:10": "remind you again about dock which is how",
  "25:13": "we find out more information about this",
  "25:15": "stuff in this case all of the labeling",
  "25:17": "functions in the data blocks API will",
  "25:20": "pass on any keywords they don't",
  "25:21": "recognize to the label class so one of",
  "25:24": "the things I've passed in here is log",
  "25:26": "and so that's actually going to end up",
  "25:28": "in float list and so if I go dock float",
  "25:31": "list I can see a summary okay and I can",
  "25:33": "even jump into the full documentation",
  "25:35": "and it shows me here that log is",
  "25:37": "something which if true it's going to",
  "25:40": "take the logarithm of my dependent",
  "25:43": "variable why am i doing that so this is",
  "25:45": "the thing that's actually going to",
  "25:47": "automatically take the log of my way the",
  "25:50": "reason I'm doing that is because as I",
  "25:53": "mentioned before the evaluation metric",
  "25:56": "is root mean squared percentage error",
  "25:59": "and first I'd either fastener iron or PI",
  "26:05": "torch has a root mean squared percentage",
  "26:07": "error loss function built in I don't",
  "26:10": "even know if such a loss function would",
  "26:12": "work super well but if you want to spend",
  "26:15": "the time thinking about it you'll notice",
  "26:16": "that this ratio if you first take the",
  "26:20": "log of Y and Y hat then becomes a",
  "26:22": "difference rather than the ratio so in",
  "26:25": "other words if you take the log of Y",
  "26:26": "then if this becomes root means great",
  "26:30": "error so that's what we're going to do",
  "26:32": "we're going to take the log of Y and",
  "26:34": "then we're just going to use root mean",
  "26:37": "square error which is the default for a",
  "26:39": "regression",
  "26:39": "problems we won't even have to mention",
  "26:40": "it the reason that we have this year is",
  "26:44": "because this is so common right",
  "26:46": "basically anytime you're trying to",
  "26:48": "predict something that's like a",
  "26:50": "population or a dollar amount of sales",
  "26:53": "these kind of things tend to have long",
  "26:57": "tail distributions where you care more",
  "26:59": "about percentage differences and exact",
  "27:01": "differences you know absolute",
  "27:02": "differences so you're very much very",
  "27:05": "likely to want to do things with log",
  "27:07": "equals true and to measure the root mean",
  "27:09": "squared percent error we've learned",
  "27:14": "about the Y range before which is going",
  "27:17": "to use that sigmoid to help us get in",
  "27:18": "the right range because this time the Y",
  "27:22": "values are going to be taken the log of",
  "27:24": "it first we need to make sure that the Y",
  "27:26": "range we want is also the log so I'm",
  "27:29": "going to take the maximum of the sales",
  "27:31": "column I'm going to multiply it by a",
  "27:34": "little bit so that cuz remember how we",
  "27:35": "said it's nice if your range is a bit",
  "27:37": "wider than the range of the data and",
  "27:40": "then we're going to take the log and",
  "27:42": "that's going to be our maximum so then",
  "27:45": "our Y range will be from zero to a bit",
  "27:49": "more than the maximum so now we've got",
  "27:52": "our data bunch we can create a tabular",
  "27:55": "from it and then we have to pass in our",
  "27:57": "architecture and as we briefly discussed",
  "28:00": "for a tabular model our architecture is",
  "28:05": "literally the most basic fully connected",
  "28:08": "network just like we showed in this",
  "28:11": "picture it's an import matrix multiply",
  "28:15": "non-linearity matrix multiply",
  "28:17": "non-linearity matrix model play",
  "28:19": "non-linearity done okay what are the",
  "28:23": "interesting things about this is that",
  "28:25": "this competition is three years old but",
  "28:27": "I'm not aware of any significant",
  "28:30": "advances at least in terms of",
  "28:32": "architecture that would cause me to",
  "28:34": "choose something different to what the",
  "28:36": "third-placed folks did three years ago",
  "28:39": "we're still basically using simple fully",
  "28:43": "connected models for this problem now",
  "28:48": "the intermediate wait may",
  "28:52": "Trix is going to have to go from a 1000",
  "28:54": "activation input to a 500 activation",
  "28:58": "output which means it's going to have to",
  "29:00": "be 500,000 elements in that weight",
  "29:04": "matrix that's an awful lot for a data",
  "29:07": "set with only a few hundred thousand",
  "29:08": "rows so this is going to overfit and we",
  "29:12": "need to make sure it doesn't so one way",
  "29:14": "to make sure it does Bob",
  "29:15": "the way to make sure it doesn't is to",
  "29:17": "use regularization all right not to",
  "29:20": "reduce the number of parameters to use",
  "29:21": "regularization so one way to do that",
  "29:24": "will be to use weight decay which first",
  "29:27": "day I will use automatically and you can",
  "29:29": "vary it to something other than the",
  "29:31": "default if you wish it turns out in this",
  "29:33": "case we're going to want more",
  "29:35": "regularization and so we're going to",
  "29:37": "pass in something called peas this is",
  "29:40": "going to provide dropout and also this",
  "29:43": "one here M prop this is going to provide",
  "29:45": "embedding dropout so let's learn about",
  "29:48": "what is dropout but the short version is",
  "29:51": "dropout is a kind of regularization this",
  "29:54": "is the dropout paper nitish how do you",
  "30:01": "say this through vast Java",
  "30:03": "it was surest Ava's master's thesis",
  "30:06": "under Geoffrey Hinton and this picture",
  "30:11": "from the original paper is a really good",
  "30:13": "picture of what's going on this first",
  "30:16": "picture is a picture of a standard fully",
  "30:18": "connected Network it's a picture of this",
  "30:21": "and what each line shows is a",
  "30:24": "multiplication of an activation times a",
  "30:27": "weight and then when you've got multiple",
  "30:29": "arrows coming in that represents a sum",
  "30:31": "so this activation here is the sum of",
  "30:36": "all of these inputs times all of these",
  "30:39": "activations so that's what a normal",
  "30:41": "neural fully connected neural net looks",
  "30:43": "like for dropout we throw that away",
  "30:49": "we're at random we throw away some",
  "30:53": "percentage of the activations not the",
  "30:56": "weights right not the parameters",
  "30:58": "remember there's only two types of",
  "30:59": "number in a neural net parameters also",
  "31:03": "called weights kind of and activations",
  "31:06": "so we're going to throw away some",
  "31:08": "activation so you can see that when we",
  "31:10": "throw away this activation all of the",
  "31:13": "things that were connected to it are",
  "31:15": "gone too okay for each mini batch we",
  "31:21": "throw away a different subset of",
  "31:23": "activations how many do we throw away we",
  "31:26": "throw them of each one away with a",
  "31:28": "probability P a common value of P is 0.5",
  "31:35": "so what does that mean and you'll see in",
  "31:38": "this case not only have they deleted at",
  "31:43": "random some of these in hidden layers",
  "31:45": "but they've actually deleted some of the",
  "31:47": "inputs as well deleting the inputs is",
  "31:49": "pretty unusual normally we only delete",
  "31:53": "activations in the hidden layers so what",
  "31:58": "is this - well every time I have a mini",
  "31:59": "batch going through I at random throw",
  "32:03": "away some of the activations and then",
  "32:04": "the next mini batch I put them back and",
  "32:06": "I throw away some different ones okay so",
  "32:09": "it means that it's no 1 activation can",
  "32:14": "kind of memorize some part of the input",
  "32:17": "because that's what happens if we over",
  "32:19": "fit right if we over fit some some part",
  "32:21": "of the model is basically learning to",
  "32:24": "recognize a particular image rather than",
  "32:27": "a feature in general or a particular",
  "32:28": "item with dropout it's going to be very",
  "32:34": "hard for it to do that in fact Geoffrey",
  "32:39": "Hinton described one of the kind of part",
  "32:44": "of the thinking behind this as follows",
  "32:46": "he said he noticed every time he went to",
  "32:47": "his bank that all the tellers and staff",
  "32:50": "moved around and he realized the reason",
  "32:53": "for this must be that they're trying to",
  "32:54": "avoid fraud if they keep moving them",
  "32:56": "around",
  "32:57": "nobody can specialize so much in that",
  "32:59": "one thing that they're doing that they",
  "33:01": "can figure out kind of a conspiracy to",
  "33:02": "defraud the bank now of course depends",
  "33:06": "when you ask Hinton at other times he",
  "33:08": "says that the reason for this was",
  "33:10": "because he thought about how spiking",
  "33:11": "neurons work and there's a view he's a",
  "33:13": "neuroscientist by training there's a",
  "33:16": "view that spiking neurons might help",
  "33:17": "regularization and dropout is kind",
  "33:20": "a way of matching this idea of biking",
  "33:23": "neurons",
  "33:23": "I mean it's interesting when you",
  "33:26": "actually ask people where did your idea",
  "33:29": "for some some algorithm come from it",
  "33:33": "basically never comes from math it",
  "33:36": "always comes from intuition and kind of",
  "33:39": "thinking about physical analogies and",
  "33:40": "stuff like that so anyway the truth is a",
  "33:43": "bunch of ideas I guess we're all flowing",
  "33:45": "around and they came up with this idea",
  "33:47": "of dropout but the important thing to",
  "33:49": "know is it worked really really well",
  "33:52": "right and so we can use it in our models",
  "33:57": "to get generalization for free now too",
  "34:01": "much dropout of course is reducing the",
  "34:03": "capacity of your model so it's going to",
  "34:05": "under fit and so you've got to play",
  "34:06": "around with different dropout values for",
  "34:08": "each of your layers to decide so in",
  "34:11": "pretty much every fast AI learner",
  "34:15": "there's a parameter called",
  "34:16": "P's PS which will be the p-value for the",
  "34:20": "dropout for each layer so you can just",
  "34:22": "pass in a list or you can pass it an int",
  "34:25": "and it'll create a list with that value",
  "34:28": "everywhere sometimes it's a little",
  "34:31": "different for CNN for example it",
  "34:33": "actually if you pass in an int it will",
  "34:35": "use that for the last layer and half",
  "34:37": "that value for the earlier layers we",
  "34:39": "basically try to do things or kind of",
  "34:41": "represent best practice but you can",
  "34:44": "always pass in your own list to get",
  "34:45": "exactly the drop out that you want there",
  "34:48": "is an interesting feature of drop out",
  "34:50": "which is that we talk about training",
  "34:54": "time and test time test time we also",
  "34:56": "call inference time training time is",
  "34:58": "when we're actually doing that those",
  "35:00": "wait updates the backpropagation and the",
  "35:02": "training time dropout works the way we",
  "35:04": "just saw at test time we turn off",
  "35:08": "dropout but we're not going to do",
  "35:10": "dropout anymore because we wanted to be",
  "35:12": "as accurate as possible we're not",
  "35:13": "training so we can't cause it to overfit",
  "35:15": "when we're doing inference so we remove",
  "35:18": "dropout but what that means is if",
  "35:20": "previously P was point OV was 0.5 then",
  "35:24": "half the activations were being removed",
  "35:26": "which means when they're all there now",
  "35:28": "our overall activation level is twice",
  "35:30": "what it used to be and so therefore in",
  "35:33": "the paper they suggest",
  "35:34": "multiplying all of your weights at test",
  "35:36": "time by P interestingly you can dig into",
  "35:42": "the PI torch source code and you can",
  "35:44": "find the actual C code where dropout is",
  "35:47": "implemented and here it is and you can",
  "35:50": "see what they're doing is something",
  "35:51": "quite interesting they first of all do a",
  "35:54": "Bernoulli trial so a Bernoulli trial is",
  "35:56": "with probability 1 minus P return the",
  "36:00": "value 1 otherwise return the value 0",
  "36:02": "that's all it means",
  "36:03": "okay so in this case P is the",
  "36:06": "probability of dropout so 1 minus P is a",
  "36:09": "probability that we keep the activation",
  "36:12": "so we end up here with either a 1 or a 0",
  "36:15": "ok and then this is interesting we",
  "36:19": "divide in place remember",
  "36:21": "underscore means in place in play torch",
  "36:23": "we divide in place that 1 or 0 by 1",
  "36:26": "minus P if it's a 0 nothing happens it's",
  "36:29": "still 0 if it's a 1 and P was 0.5 that",
  "36:34": "one now becomes 2 and then finally we",
  "36:37": "multiply in place our input by this",
  "36:42": "noise this dropout mask so in other",
  "36:44": "words we actually don't do in play torch",
  "36:48": "we don't do the change at test time we",
  "36:50": "actually do the change at training time",
  "36:53": "which means that you don't have to do",
  "36:54": "anything special at inference time with",
  "36:56": "play torch it's not a spite watch it's",
  "36:58": "quite a common pattern but it's kind of",
  "37:01": "nice to look inside the pipe torch",
  "37:02": "source code and see you know drop out",
  "37:05": "this incredibly cool incredibly valuable",
  "37:07": "thing is really just these three lines",
  "37:09": "of code which they do in C because I",
  "37:12": "guess it ends up a bit faster when it's",
  "37:14": "all fused together but lots of libraries",
  "37:16": "do it in Python and that works well as",
  "37:18": "well you can even write your own drop",
  "37:20": "out layer and it should give exactly the",
  "37:23": "same results as this that'd be a good",
  "37:26": "exercise to try see if you can create",
  "37:28": "your own drop out layer in Python and",
  "37:32": "see if you can replicate the results",
  "37:33": "that we get with this drop out there",
  "37:38": "so that's drop",
  "37:41": "and so in this case we're going to use a",
  "37:43": "tiny bit of drop out on the first layer",
  "37:45": "and a little bit of drop out on the next",
  "37:48": "layer and then we're going to use",
  "37:50": "special drop out on the embedding layer",
  "37:52": "now why do we do special drop out on the",
  "37:55": "embedding layer so if you look inside",
  "37:57": "the FASTA a source code is our tabular",
  "38:05": "model you'll see that in the section",
  "38:11": "that checks that there's some embeddings",
  "38:12": "we call it embedding and then we",
  "38:15": "concatenate the embeddings into a single",
  "38:17": "matrix and then we call embedding",
  "38:19": "dropout an embedding dropout is simply",
  "38:21": "just a drop out right so it's just an",
  "38:27": "instance of a drop out module this kind",
  "38:31": "of makes sense right for continuous",
  "38:33": "variables that continuous variable is",
  "38:35": "just in one column you wouldn't want to",
  "38:38": "do dropout on that because you're",
  "38:39": "literally deleting the existence of that",
  "38:41": "whole input which is almost certainly",
  "38:42": "not what you want but for an embedding",
  "38:45": "and embedding is just effectively a",
  "38:49": "matrix multiplied by a one hot encoded",
  "38:52": "matrix so it's just another layer so it",
  "38:55": "makes perfect sense to have dropout on",
  "38:57": "the output of the embedding because",
  "38:59": "you're putting drop out on those",
  "39:00": "activations of that layer and so you're",
  "39:02": "basically saying let's delete that",
  "39:05": "random some of the results of that",
  "39:09": "embedding some of those activations so",
  "39:12": "that makes sense the other reason we do",
  "39:15": "it that way is because I did very",
  "39:17": "extensive experiments about a year ago",
  "39:19": "where on this data set I tried lots of",
  "39:23": "different ways of doing clone of",
  "39:25": "everything and you can actually see it",
  "39:29": "here I put it all in a spreadsheet of",
  "39:31": "course Microsoft Excel put them into a",
  "39:33": "pivot table to summarize them all",
  "39:34": "together to find out kind of which",
  "39:37": "different choices and hyper parameters",
  "39:39": "and architectures worked well and worked",
  "39:40": "less well and then I created all these",
  "39:43": "little graphs and these are like little",
  "39:45": "summary training graphs for different",
  "39:47": "combinations of high parameters and",
  "39:48": "architectures and I found that there was",
  "39:50": "one of them which ended up consistently",
  "39:53": "getting a good",
  "39:55": "predictive accuracy the kind of",
  "39:57": "bumpiness of the training was pretty low",
  "40:00": "and you can see on it was just a nice",
  "40:03": "smooth curve and so like this is an",
  "40:06": "example of the kind of experiments that",
  "40:08": "I do that end up in the first day I",
  "40:10": "library right so embedding embedding",
  "40:13": "dropout was one of those things that I",
  "40:14": "just found work really well and",
  "40:16": "basically these the results of these",
  "40:17": "experiments is why it looks like this",
  "40:22": "rather than something else well it's a",
  "40:25": "combination of these experiments but",
  "40:26": "then why did I do these particular",
  "40:28": "experiments well because it was very",
  "40:30": "influenced by what worked well in the",
  "40:33": "that cagoule Prize winners paper but",
  "40:37": "there are quite a few parts of that",
  "40:38": "paper I thought there were some other",
  "40:40": "choices they could have made I wonder",
  "40:42": "why they didn't and I tried them out and",
  "40:44": "found out what actually works and what",
  "40:46": "doesn't work as well and found a few",
  "40:48": "little improvements so that's the kind",
  "40:51": "of experiments that you can play around",
  "40:53": "with as well when you try different",
  "40:55": "models and architectures different",
  "40:57": "dropouts layer numbers number of",
  "41:00": "activations and so forth so I'm having",
  "41:03": "created our learner we can type learned",
  "41:05": "up model to take a look at it and as you",
  "41:08": "would expect in that there is a whole",
  "41:09": "bunch of embeddings each of those",
  "41:12": "abetting matrices tells you well this is",
  "41:15": "the number of levels of the input for",
  "41:17": "each input right and you can match these",
  "41:20": "with with your list cat bars",
  "41:23": "okay so the first one will be store so",
  "41:26": "that's not surprising there are a",
  "41:27": "thousand 116 stores and then the second",
  "41:30": "number of course is the size of the",
  "41:33": "embedding and that's a number that you",
  "41:34": "get to choose and so fast AI has some",
  "41:38": "defaults which actually work really",
  "41:42": "really well nearly all the time so I",
  "41:44": "almost never changed them but when you",
  "41:46": "create your tabular Lerner",
  "41:48": "you can absolutely pass in an embedding",
  "41:51": "size dictionary which Maps variable",
  "41:54": "names to embedding sizes for anything",
  "41:57": "where you want to override the defaults",
  "41:59": "and then we've got our embedding dropout",
  "42:04": "layer and then we've got a batch norm",
  "42:07": "layer with six",
  "42:08": "inputs okay the 16 inputs make sense",
  "42:12": "because we have 16 continuous variables",
  "42:17": "the length of countenance is 16 so this",
  "42:21": "is something for our continuous",
  "42:23": "variables and specifically it's over",
  "42:27": "here the N conte on our continuous",
  "42:30": "variables and BN conte is a batch norm",
  "42:34": "one d what's that",
  "42:35": "well the first short answer is it's one",
  "42:39": "of the things that I experimented with",
  "42:41": "as to having batch normal not in this",
  "42:44": "and I found that it worked really well",
  "42:46": "and then specifically what it is is",
  "42:50": "extremely unclear let me describe it to",
  "42:54": "you it's kind of a bit of regularization",
  "42:56": "it's kind of a bit of training helper",
  "43:00": "it's called batch normalization and it",
  "43:04": "comes from this paper actually before I",
  "43:08": "do this I was want to mention one other",
  "43:09": "really funny thing dropout I mentioned",
  "43:14": "it was a master's thesis not only was it",
  "43:16": "a master's thesis one of the most",
  "43:18": "influential papers of the last ten years",
  "43:20": "it was rejected from the main neural",
  "43:24": "Nets conference what was then called",
  "43:26": "nips",
  "43:26": "now Courtney rips I think this is just",
  "43:30": "it's very interesting because it's just",
  "43:32": "a reminder that you know a our academic",
  "43:37": "community is generally extremely poor at",
  "43:40": "recognizing which things are going to",
  "43:42": "turn out to be important generally",
  "43:46": "people are looking for stuff that are in",
  "43:48": "the field that they're working on and",
  "43:50": "understand so drop out kind of came out",
  "43:52": "of left field it's kind of hard to",
  "43:54": "understand what's going on and so that's",
  "43:56": "kind of interesting and so you know it's",
  "43:59": "a reminder that if you just follow you",
  "44:03": "know as you kind of develop it beyond",
  "44:05": "being just a practitioner into actually",
  "44:07": "doing your own research don't just focus",
  "44:10": "on the stuff everybody's talking about",
  "44:12": "focus on the stuff you think might be",
  "44:14": "interesting because the stuff",
  "44:15": "everybody's talking about generally",
  "44:17": "turns out not to be very interesting the",
  "44:19": "community is very poor at",
  "44:21": "amazing high-impact papers when they",
  "44:26": "come out match normalization on the",
  "44:31": "other hand was immediately recognized as",
  "44:32": "high-impact I definitely remember",
  "44:34": "everybody talking about it in 2015 when",
  "44:36": "it came out and that was because it's so",
  "44:38": "obvious they showed this picture showing",
  "44:40": "the current then state of the art image",
  "44:43": "net model inception this is how long it",
  "44:46": "took them to get you know a pretty good",
  "44:49": "result and then they tried the same",
  "44:52": "thing with this new thing core batch",
  "44:53": "norm and they just did it way way way",
  "44:56": "quickly and so that was enough for",
  "44:58": "pretty much everybody to go wow this is",
  "45:00": "interesting and specifically they said",
  "45:02": "this thing's called batch normalization",
  "45:04": "and it's accelerating training by",
  "45:06": "reducing internal covariant shift so",
  "45:09": "what is internal covariant shift well it",
  "45:13": "doesn't matter because this is one of",
  "45:14": "those things where researchers came up",
  "45:18": "with some intuition and some idea about",
  "45:19": "the scene they wanted to try they did it",
  "45:21": "it worked well they then post hoc added",
  "45:24": "on some mathematical analysis to try and",
  "45:26": "claim where it worked and it turned out",
  "45:28": "they were totally wrong in the last two",
  "45:30": "months there's been two papers so it",
  "45:33": "took three years for people to really",
  "45:34": "figure this out in the last two months",
  "45:35": "there's been two papers that have shown",
  "45:37": "batch normalization doesn't reduce",
  "45:39": "covariate shift at all and even if it",
  "45:42": "did that has nothing to do with why it",
  "45:43": "works so so I think that's a kind of an",
  "45:48": "interesting insight again you know which",
  "45:50": "is like why we should be focusing on",
  "45:52": "being practitioners and experimentalists",
  "45:54": "and developing an intuition right what",
  "45:58": "batch norm does is what you see in this",
  "46:00": "picture here in this paper here are",
  "46:03": "steps or batches right and here is loss",
  "46:06": "and here the red line is what happens",
  "46:10": "when you train without batch norm very",
  "46:12": "very bumpy and here the blue line is",
  "46:14": "what happens when you train with batch",
  "46:16": "norm not very bumpy at all what that",
  "46:19": "means is you can increase your learning",
  "46:22": "rate with batch norm because these big",
  "46:25": "bumps represent times that you're really",
  "46:28": "at risk of your set of weights jumping",
  "46:30": "off into some awful part of the weight",
  "46:32": "space that it can never get out of again",
  "46:34": "so if it's",
  "46:35": "bumpy then you can train at a higher",
  "46:37": "learning rate so that's actually what's",
  "46:39": "going on and here's what it is this is",
  "46:43": "the algorithm and it's really simple",
  "46:45": "the algorithm is going to take a mini",
  "46:48": "batch all right so we have a mini batch",
  "46:51": "and remember this is a layer so the",
  "46:54": "thing coming into it is activations okay",
  "46:57": "so it's a layer and it's going to take",
  "46:59": "in some activations and so that's",
  "47:02": "evasions it's calling X 1 X 2 X 3 and so",
  "47:06": "forth the first thing we do is we find",
  "47:07": "the mean with those activations sum",
  "47:10": "divided by the count let's just the mean",
  "47:11": "and the second thing we do is we find",
  "47:13": "the variance of those activations a",
  "47:16": "difference squared divided by the mean",
  "47:17": "is the variance and then we normalize so",
  "47:19": "then the values minus the mean divided",
  "47:22": "by the standard deviation is the",
  "47:25": "normalized version ok it turns out that",
  "47:28": "B it's actually not that important we",
  "47:30": "used to think it was ok it turns out it",
  "47:31": "not the really important bit is the next",
  "47:33": "bit we take those values and we add a",
  "47:39": "vector of biases they call it beta here",
  "47:42": "and we've seen that before we've used a",
  "47:44": "bias term before okay so we're just",
  "47:46": "going to add a bias term as per usual",
  "47:48": "and then we're going to use another",
  "47:50": "thing that's a lot like a bias term but",
  "47:53": "rather than adding it we're going to",
  "47:54": "multiply by it so there's these",
  "47:56": "parameters gamma and beta which are",
  "48:00": "learnable parameters remember at a",
  "48:02": "neural net there's only two kinds of",
  "48:03": "number activations and parameters these",
  "48:06": "are parameters okay they're things that",
  "48:09": "are learnt with gradient descent this is",
  "48:11": "just a normal bias layer data and this",
  "48:15": "is a model Piketty of bias layer nobody",
  "48:17": "calls it that but that's all it is right",
  "48:18": "it's just like bias but we multiply",
  "48:20": "rather than add that's what batch norm",
  "48:23": "is that's what the layer does so why is",
  "48:27": "that able to achieve this fantastic",
  "48:30": "result I'm not sure anybody has exactly",
  "48:35": "written this down before if they have I",
  "48:41": "apologize for failing to cite Ray",
  "48:43": "because I haven't seen it but let me",
  "48:44": "explain what's actually going on here",
  "48:47": "the value",
  "48:49": "of our predictions y-hat is some",
  "48:58": "function of our various weights there",
  "49:04": "could be millions of them wait 1 million",
  "49:07": "and it's also a function of course of",
  "49:09": "the inputs to our layer this function",
  "49:13": "here is our neuron that function",
  "49:15": "whatever is going on and our neuron",
  "49:17": "there and then our loss let's say it's",
  "49:20": "mean squared error is just our actuals",
  "49:22": "minus our predicted squared okay so",
  "49:30": "let's say we're trying to predict movie",
  "49:32": "review outcomes and they're between 1",
  "49:35": "and 5 okay and we've been trying to",
  "49:40": "train our model and the activations at",
  "49:43": "the very end currently between minus 1",
  "49:47": "and 1 so they're way off where they need",
  "49:51": "to be the scale is off the mean is off",
  "49:53": "so what can we do one thing we could do",
  "49:57": "would be to try and come up with a new",
  "50:00": "set of weights that cause the spread to",
  "50:03": "increase and cause the mean to increase",
  "50:05": "as well but that's going to be really",
  "50:07": "hard to do because remember all these",
  "50:09": "weights interact in very intricate ways",
  "50:11": "right we've got all those nonlinearities",
  "50:13": "and they all combine together so to kind",
  "50:16": "of just move up it's going to require",
  "50:18": "navigating through this complex",
  "50:20": "landscape and we you know we use all",
  "50:22": "these tricks like momentum and atom and",
  "50:24": "stuff like that to help us but it still",
  "50:26": "requires a lot of twiddling around to",
  "50:28": "get there so that's going to take a long",
  "50:31": "time and it's going to be bumpy but what",
  "50:34": "if we did this what if we went times G",
  "50:40": "Plus B we added 2 more parameter vectors",
  "50:46": "or now it's really easy right in order",
  "50:50": "to increase the scale that number has a",
  "50:53": "direct gradient to increase the scale to",
  "50:58": "change the me",
  "50:59": "that number has a direct gradient to",
  "51:01": "change the mean there's no interactions",
  "51:03": "or complexities it's just straight up",
  "51:04": "and down straight in and out and that's",
  "51:07": "what batch Nam does right so batch norm",
  "51:10": "is basically making it easier for it to",
  "51:13": "do this really important thing which is",
  "51:15": "to shift the app puts up and down and in",
  "51:17": "and out and that's why we end up with",
  "51:20": "these results so those details in some",
  "51:23": "ways don't matter terribly the really",
  "51:25": "important thing to know is you",
  "51:27": "definitely want to use it right or if",
  "51:30": "not it's something like it there's",
  "51:32": "various other types of normalization",
  "51:33": "around nowadays but batch norm works",
  "51:37": "great",
  "51:38": "the other main normalization type we use",
  "51:41": "in first AI is something called weight",
  "51:43": "norm which is a much more just in the",
  "51:45": "last few months",
  "51:46": "development okay so that's batch norm",
  "51:51": "and so what we do is we create a batch",
  "51:56": "norm layer for every continuous variable",
  "51:59": "and conte is a number of continuous",
  "52:00": "variables in fast AI n underscore",
  "52:03": "something always means the count of that",
  "52:05": "thing can't always means continuous so",
  "52:08": "then here is where we use it we grab our",
  "52:10": "continuous variables and we throw them",
  "52:12": "through a batch norm layer and so then",
  "52:14": "over here you can see it in a model one",
  "52:19": "interesting thing is this momentum here",
  "52:20": "this is not momentum like in",
  "52:23": "optimization but this is momentum as in",
  "52:25": "exponentially weighted moving average",
  "52:28": "specifically this mean and standard",
  "52:32": "deviation we don't actually use a",
  "52:34": "different mean and standard deviation",
  "52:35": "for every mini batch if we did it would",
  "52:39": "vary so much did it be very hard to",
  "52:41": "train so instead we take an",
  "52:44": "exponentially weighted moving average of",
  "52:46": "the mean and standard deviation okay and",
  "52:49": "if you don't remember what I mean by",
  "52:50": "that look back at last week's lesson to",
  "52:52": "remind yourself about exponentially",
  "52:54": "weighted moving averages which we",
  "52:56": "implemented in excel for the momentum",
  "53:00": "and atom gradient squared terms",
  "53:09": "you can vary the amount of momentum in a",
  "53:11": "batch norm layer by passing a different",
  "53:14": "value to the constructor in plate watch",
  "53:16": "if you use a smaller number it means",
  "53:19": "that the mean and standard deviation",
  "53:20": "will vary less from mini batch to mini",
  "53:23": "batch and that will have less of a",
  "53:25": "regularization effect a larger number",
  "53:27": "will mean the variation will be greater",
  "53:29": "for a mini batch to mini batch that will",
  "53:31": "have more of a regularization effect so",
  "53:33": "as well as this thing of training more",
  "53:35": "nicely because it's parameterised better",
  "53:37": "this momentum term in the mean and",
  "53:40": "standard deviation is the thing that",
  "53:42": "adds is nice regularization piece when",
  "53:47": "you add batch norm you should also be",
  "53:49": "able to use a higher learning rate so",
  "53:52": "that's our model so then you can go ll",
  "53:54": "find you can have a look and then you",
  "53:57": "can go fit you can save it you can plot",
  "54:00": "the losses you can fit a bit more and we",
  "54:03": "end up 0.1 oh three tenths place in the",
  "54:07": "competition was 0.108 so it's looking",
  "54:11": "good all right again take it with a",
  "54:17": "slight grain of salt because what you",
  "54:20": "actually need to do is use the real",
  "54:21": "training set and submit it to cow go but",
  "54:24": "you can see we're very much you know",
  "54:26": "amongst the kind of cutting-edge of",
  "54:28": "models at least as of 2015 and as I say",
  "54:32": "they haven't really been any",
  "54:33": "architectural improvements since then",
  "54:35": "there wasn't batch norm when this was",
  "54:37": "around so the fact we added batch norm",
  "54:38": "means that we should get better results",
  "54:40": "and certainly more quickly and if I",
  "54:42": "remember correctly in their model they",
  "54:44": "had to train at a slow lower learning",
  "54:45": "rate for quite a lot longer as you can",
  "54:48": "see this is about less than 45 minutes",
  "54:50": "of training so that's nice and fast",
  "54:55": "any questions in what proportion would",
  "55:01": "you use dropout versus other",
  "55:03": "regularization errors like weight decay",
  "55:05": "L two norms etc so remember that l2",
  "55:12": "regularization and weight decay a kind",
  "55:14": "of two ways of doing the same thing and",
  "55:16": "we should always use the weight decay",
  "55:17": "version not the l2 regularization",
  "55:19": "version so there's",
  "55:21": "when Takei there's batch norm which kind",
  "55:24": "of has a regularizing effect there's",
  "55:27": "data augmentation which we'll see soon",
  "55:29": "and this drop out so that's normally",
  "55:35": "pretty much always want so that's easy",
  "55:39": "data augmentation we'll see in a moment",
  "55:41": "so then it's really between dropout",
  "55:43": "versus weight okay",
  "55:45": "I have no idea I don't I don't think",
  "55:48": "I've seen anybody to fight a compelling",
  "55:50": "study of how to combine those two things",
  "55:55": "can you always use one instead of the",
  "55:57": "other why why not I don't think anybody",
  "56:01": "has figured that out I think in practice",
  "56:06": "it seems that you generally want a bit",
  "56:10": "of both you pretty much always want some",
  "56:14": "weight decay but you often also want a",
  "56:17": "bit of dropout but honestly I don't know",
  "56:20": "why I've not seen anybody really explain",
  "56:22": "why or how to decide so this is one of",
  "56:25": "these things you have to try out and",
  "56:27": "kind of get a feel for what tends to",
  "56:31": "work for your kinds of problems I think",
  "56:34": "the defaults that we provide in most of",
  "56:37": "our learners should work pretty well in",
  "56:39": "most situations but yeah definitely play",
  "56:42": "around with it okay the next kind of",
  "56:48": "regularization we're going to look at is",
  "56:50": "data augmentation and data augmentation",
  "56:55": "is one of the least well studied types",
  "56:58": "of regularization but it's the kind that",
  "57:00": "I think I'm kind of the most excited",
  "57:02": "about the reason I'm kind of the most",
  "57:08": "about it is that you basically there's",
  "57:12": "basically almost no cost to it you can",
  "57:15": "do data augmentation and get better",
  "57:17": "generalization without it taking longer",
  "57:19": "to train without underfitting",
  "57:22": "to an extent at least so let me explain",
  "57:26": "so what we're going to do now is we're",
  "57:29": "going to come back to a computer vision",
  "57:30": "and we're going to come back to our pets",
  "57:32": "data set again so let's let's load it in",
  "57:35": "all right our pets data set the images",
  "57:37": "were inside the images subfolder I'm",
  "57:39": "going to call get transforms as per",
  "57:42": "usual but when we call get transforms",
  "57:46": "there's a whole long list of things that",
  "57:49": "we can provide and so far we haven't",
  "57:52": "been varying that much at all but in",
  "57:54": "order to really understand data",
  "57:57": "augmentation I'm going to kind of",
  "57:58": "ratchet up all of the defaults so",
  "58:03": "there's a parameter here for what's the",
  "58:05": "probability of an affine transform",
  "58:08": "happening what's the probability of a",
  "58:10": "light lighting transfer happening so I",
  "58:12": "set them both to one so they're all",
  "58:13": "gonna get transformed I'm going to do",
  "58:14": "more rotation more zoom more lighting",
  "58:16": "transforms and more warping what are all",
  "58:20": "those mean well you should check the",
  "58:23": "documentation and to do that by typing",
  "58:25": "doc and there's a doc the brief",
  "58:27": "documentation but the real documentation",
  "58:29": "is in dogs so I'll click on show in",
  "58:32": "Doc's and here it is okay and so this",
  "58:36": "tells you what all those do but",
  "58:40": "generally the most interesting parts of",
  "58:41": "the Doc's tend to be at the top where",
  "58:44": "you kind of get the summaries of what's",
  "58:46": "going on and so here there's something",
  "58:48": "called list of transforms and here you",
  "58:52": "can see every transform has a something",
  "58:55": "showing you lots of different values of",
  "58:57": "it right so here's brightness so make",
  "59:01": "sure you read these and remember these",
  "59:04": "notebooks you can open up and run this",
  "59:06": "code yourself and get this output all of",
  "59:09": "these know all of these HTML",
  "59:11": "documentation documents are",
  "59:13": "auto-generated from the notebooks in the",
  "59:15": "docs underscore source directory in the",
  "59:17": "FASTA a repo okay so you will see the",
  "59:20": "exact same cats",
  "59:22": "if you try this so if I really likes",
  "59:26": "cats so there's a lot of cats in the",
  "59:27": "documentation",
  "59:29": "and I think you know because he's been",
  "59:31": "so awesome at creating great",
  "59:32": "documentation he gets to pick the cats",
  "59:34": "so so for example looking at different",
  "59:40": "values of brightness what I do here is I",
  "59:44": "look to see two things the first is for",
  "59:47": "which of these levels of transformation",
  "59:50": "is it still clear what the picture is a",
  "59:53": "picture of so this is kind of getting to",
  "59:55": "a point where it's pretty unclear this",
  "59:57": "is possibly getting a little unclear the",
  "60:00": "second thing I do is I look at the",
  "60:02": "actual data set that I'm modeling or",
  "60:04": "particularly the data set that I'll be",
  "60:06": "using as validation set and I try to get",
  "60:08": "a sense of what the variation in this",
  "60:10": "case in lighting is so referred like",
  "60:13": "nearly all professionally taking photos",
  "60:15": "I would probably want them all to be",
  "60:17": "about in the middle but if the if the",
  "60:20": "kind of their photos that are taken",
  "60:23": "inside some pretty amateur photographers",
  "60:24": "they are likely to be something they're",
  "60:26": "very overexposed some very underexposed",
  "60:28": "right so you should pick a value of the",
  "60:30": "estate or augmentation for brightness",
  "60:32": "that both allows the image to still be",
  "60:35": "seen clearly and also represents the",
  "60:38": "kind of data that you're going to be",
  "60:39": "using this to model on in practice so",
  "60:43": "you kind of see the same thing for",
  "60:44": "contrast right it'd be unusual to have a",
  "60:46": "data set with such ridiculous contrast",
  "60:49": "where perhaps you do in which case you",
  "60:51": "should use data augmentation up to that",
  "60:52": "level but if you don't then you",
  "60:55": "shouldn't this one called dihedral is",
  "61:02": "just one that does every possible",
  "61:05": "rotation and flip and so obviously most",
  "61:07": "of your pictures are not going to be",
  "61:09": "upside down cats",
  "61:10": "that's so you probably would say hey",
  "61:12": "this doesn't make sense I won't use this",
  "61:14": "for this data set that if you're looking",
  "61:16": "at satellite images of course you would",
  "61:19": "on the other hand flip makes perfect",
  "61:22": "sense so you would include that a lot",
  "61:28": "of things that you can do with fast AI",
  "61:30": "lets you pick a padding mode and this is",
  "61:33": "what padding mode looks like you can",
  "61:34": "pick zeros",
  "61:36": "you can pick border which just",
  "61:38": "replicates or you can pick reflection",
  "61:41": "which as you can see is it's as if the",
  "61:43": "last little few pixels are in a mirror",
  "61:46": "reflections nearly always better by the",
  "61:48": "way I don't know that anybody else has",
  "61:51": "really studied this but we've we we have",
  "61:53": "studied it in some depth haven't",
  "61:55": "actually written a paper about it but",
  "61:56": "just enough for our own purposes to say",
  "61:58": "reflection works best most of the time",
  "62:01": "so that's the default then there's a",
  "62:04": "really cool bunch of perspective warping",
  "62:06": "ones which I'll probably show you by",
  "62:12": "using symmetric warp if you look at the",
  "62:15": "kind of the we've added black borders to",
  "62:17": "this so it's more obvious for what's",
  "62:18": "going on and as you can see what",
  "62:20": "symmetric warp is doing it's as if the",
  "62:23": "camera is being moved above or to the",
  "62:25": "side of the object and literally warping",
  "62:28": "the whole thing like that right and so",
  "62:33": "the cool thing is that as you can see",
  "62:34": "each of these pictures it's as if this",
  "62:37": "cat was being taken kind of from",
  "62:39": "different angles right so they're all",
  "62:41": "kind of optically sensible right and so",
  "62:45": "this is a really great type of data",
  "62:47": "augmentation it's also one which I don't",
  "62:50": "know of any other library that does it",
  "62:52": "or at least certainly one that does it",
  "62:53": "in a way that's both fast and keeps the",
  "62:56": "image crisp as it is in first AI so this",
  "62:58": "is like if you're looking to whit win a",
  "63:00": "cattle competition this is the kind of",
  "63:02": "thing that's going to like get you above",
  "63:04": "the people that aren't using the first",
  "63:05": "area library so having looked at all",
  "63:09": "that we are going to add this have a",
  "63:15": "little get data function that just does",
  "63:17": "the usual game data block stuff but",
  "63:19": "we're going to add padding mode",
  "63:21": "explicitly so that we can turn on",
  "63:23": "padding mode of zeros just so we can see",
  "63:25": "what's going on better fast AI has this",
  "63:29": "handy little function called plot multi",
  "63:31": "which is going to create a three by",
  "63:33": "three grid of plots and each one will",
  "63:35": "contain the result of calling this",
  "63:37": "function which will receive the",
  "63:40": "what coordinates and the axis and so I'm",
  "63:43": "actually going to plot the exact same",
  "63:44": "thing in every box but because this is a",
  "63:47": "training data set it's going to use data",
  "63:49": "augmentation and so you can see the same",
  "63:53": "Dougy using lots of different kinds of",
  "63:57": "data augmentation and so you can see why",
  "63:59": "this is going to work really well",
  "64:00": "because these pictures all look pretty",
  "64:02": "different right but we didn't have to do",
  "64:06": "any extra hand labeling or anything",
  "64:08": "they're like it's like free extra data",
  "64:11": "okay",
  "64:12": "so data augmentation is really really",
  "64:14": "great and one of the big opportunities",
  "64:17": "for research is to figure out ways to do",
  "64:20": "data augmentation in other domains so",
  "64:23": "how can you do data augmentation with",
  "64:26": "text data or genomic data or",
  "64:30": "histopathology data or whatever right",
  "64:35": "almost nobody's looking at that and to",
  "64:37": "me it's one of the biggest opportunities",
  "64:38": "that could let you decrease data",
  "64:40": "requirements by like five to ten x so",
  "64:47": "here's the same thing again but with",
  "64:49": "reflection padding instead of zero",
  "64:51": "padding and you can kind of see like see",
  "64:55": "this doggies legs are actually being",
  "64:57": "reflected at the bottom here so",
  "65:01": "reflection padding tends to create",
  "65:03": "images that are kind of much more",
  "65:06": "naturally reasonable like in the real",
  "65:08": "world you don't get black borders like",
  "65:10": "this so they do seem to work better okay",
  "65:14": "so because we're going to study",
  "65:16": "convolutional neural networks we are",
  "65:19": "going to create a convolutional neural",
  "65:20": "network you know how to create them so",
  "65:23": "I'll go ahead and create one",
  "65:24": "I will fit it for a little bit they will",
  "65:26": "unfreeze it",
  "65:27": "I will then create a larger version of",
  "65:30": "the data set 352 by 352 and fit for a",
  "65:34": "little bit more and I will save it",
  "65:38": "okay so we have a CNN and we're going to",
  "65:42": "try and figure out what's going on",
  "65:44": "and our CNN and the way we're going to",
  "65:47": "try and figure it out is explicitly",
  "65:49": "specifically that we're going to try to",
  "65:50": "learn how to create this picture this is",
  "65:58": "a heat map right this is a picture which",
  "66:00": "shows me what part of the image did the",
  "66:04": "CNN focus on when it was trying to",
  "66:07": "decide what this picture is so we're",
  "66:11": "going to make this heat map from scratch",
  "66:17": "when we so we're kind of at a point now",
  "66:21": "in the course where I'm assuming that if",
  "66:25": "you've got to this point you know when",
  "66:27": "you're still here thank you",
  "66:29": "then you're interested enough that",
  "66:31": "you're prepared to kind of dig into some",
  "66:32": "of these details so we're actually going",
  "66:34": "to learn how to create this heat map",
  "66:37": "without almost any fast AI stuff we're",
  "66:39": "going to use pure kind of tensor",
  "66:41": "arithmetic in PI torch and we're going",
  "66:44": "to try and use that to really understand",
  "66:46": "what's going on so to warn you none of",
  "66:49": "it's rocket science but a lot of its",
  "66:51": "going to look really new so don't expect",
  "66:53": "to get it the first time but expect to",
  "66:56": "like listen jump into the notebook try a",
  "67:00": "few things test things out look",
  "67:02": "particularly at like tensor shapes and",
  "67:04": "inputs and outputs to check your",
  "67:05": "understanding then go back and listen",
  "67:07": "again but and kind of try it a few times",
  "67:09": "because you will get there right it's",
  "67:13": "just that there's going to be a lot of",
  "67:15": "new concepts because we haven't done",
  "67:17": "that much stuff in pure by touch okay so",
  "67:20": "what we're going to do is going to have",
  "67:22": "a seven minute break and then we're",
  "67:24": "going to come back and we're going to",
  "67:25": "learn all about the innards of a CNN so",
  "67:27": "I'll see you at 7:50 so let's learn: 67:33: about convolutional neural networks you",
  "67:39": "know the funny thing is it's pretty",
  "67:44": "unusual to get",
  "67:45": "close to the end of a course and only",
  "67:48": "then look at convolutions but like when",
  "67:51": "you think about it knowing actually how",
  "67:54": "batch norm works or how dropout works or",
  "67:56": "how convolutions work isn't nearly as",
  "68:00": "important as knowing how it all goes",
  "68:03": "together and what to do with them and",
  "68:05": "how to figure out how to do those things",
  "68:07": "better but it's you know we're kind of",
  "68:11": "at a point now where we want to be able",
  "68:15": "to do things like that and although you",
  "68:22": "know where we're adding this",
  "68:23": "functionality directly into the library",
  "68:25": "so you can kind of run a function to do",
  "68:27": "that you know the more you do the more",
  "68:29": "you'll find things that you want to do a",
  "68:30": "little bit differently to how we do them",
  "68:32": "or there'll be something in your domain",
  "68:34": "where you think like oh I could do a",
  "68:36": "slight variation of that so you're kind",
  "68:38": "of getting to a point in your experience",
  "68:40": "now where it helps to know how to do",
  "68:43": "more stuff yourself and that means you",
  "68:45": "need to understand what's really going",
  "68:47": "on behind the scenes so what's really",
  "68:52": "going on behind the scenes is that we",
  "68:57": "are creating a neural network that looks",
  "69:02": "a lot like this right but rather than",
  "69:05": "doing a matrix multiply here and here",
  "69:09": "and here we're actually going to do",
  "69:12": "instead a convolution and a convolution",
  "69:16": "is just a kind of matrix multiply which",
  "69:20": "has some interesting properties you",
  "69:24": "should definitely check out this website",
  "69:26": "certo certo slash Eevee explain visually",
  "69:29": "where we have stolen this beautiful",
  "69:32": "animation it's actually a JavaScript",
  "69:34": "thing that you can actually play around",
  "69:35": "with yourself in order to show you how",
  "69:39": "convolutions work and it's actually",
  "69:41": "showing you a convolution as we move",
  "69:44": "around these little red squares so",
  "69:46": "here's here's a picture a black and",
  "69:49": "white or grayscale picture right and so",
  "69:51": "each 3x3 bit of this picture is this red",
  "69:54": "thing moves around it shows you a",
  "69:55": "different 3x3 part right it shows you",
  "69:58": "over here the",
  "69:59": "of the pixels right so in first ice case",
  "70:04": "our pixel values are between Norton one",
  "70:06": "in this case there between Norton 255",
  "70:08": "right so here are nine pixel values this",
  "70:12": "area is pretty white so they're pretty",
  "70:14": "high numbers okay and so as we move",
  "70:17": "around you can see the nine big numbers",
  "70:20": "change and you can also see their colors",
  "70:23": "change up here is another nine numbers",
  "70:28": "and you can see those in the little X 1",
  "70:32": "X 2 X 1 here 1 2 1 now what you might",
  "70:36": "see going on is as we move this little",
  "70:39": "red block as these numbers change we",
  "70:41": "then multiply them by the corresponding",
  "70:44": "numbers up here and so let's start using",
  "70:48": "some nomenclature the thing up here we",
  "70:51": "are going to call the kernel the",
  "70:55": "convolutional kernel so we're going to",
  "70:57": "take each little 3x3 part of this image",
  "71:00": "and we're going to do an element-wise",
  "71:02": "multiplication of each of the 9 pixels",
  "71:05": "that we are mousing over with each of",
  "71:09": "the 9 items in our kernel and so once we",
  "71:13": "multiply each set together we can then",
  "71:15": "add them all up and that is what's shown",
  "71:18": "on the right as the little bunch of red",
  "71:21": "things move over there you can see",
  "71:23": "there's one red thing that appears over",
  "71:24": "here the reason there's one red thing",
  "71:27": "over here is because each set of 9 after",
  "71:30": "getting through the element-wise",
  "71:31": "multiplication with the kernel get added",
  "71:34": "together to create one output so",
  "71:38": "therefore the size of this image has one",
  "71:42": "pixel less on each edge than the",
  "71:45": "original as you can see see how there's",
  "71:48": "black borders on it that's because at",
  "71:50": "the edge the 3x3 kernel can't quite go",
  "71:54": "any further",
  "71:55": "right so the furthest you can go is to",
  "71:57": "end up with a dot in the middle just off",
  "72:00": "the corner ok so why are we doing this",
  "72:05": "well perhaps you can see what's happened",
  "72:07": "this face has turned into some white",
  "72:11": "parts outlining the horizontal edges how",
  "72:17": "well the how is just by doing this",
  "72:20": "element wise multiplication of each set",
  "72:22": "of 9 pixels with this kernel adding them",
  "72:25": "together and sticking the result in the",
  "72:26": "corresponding but over here why is that",
  "72:31": "creating white spots with the horizontal",
  "72:34": "edges are well let's think about it",
  "72:37": "let's look up here so if we're just in",
  "72:42": "this little bit here right then the",
  "72:45": "spots above it all pretty white so they",
  "72:49": "have high numbers so the bits above it",
  "72:52": "big numbers who are getting multiplied",
  "72:54": "by 1 to 1 so that's going to create a",
  "72:56": "big number and the ones in the middle",
  "72:59": "are all zeros so don't care about that",
  "73:00": "and then the ones underneath are all",
  "73:03": "small numbers because they're all close",
  "73:04": "to 0 so that really doesn't do much at",
  "73:07": "all so therefore that little set there",
  "73:10": "is going to end up with right white okay",
  "73:15": "whereas on the other side right down",
  "73:18": "here you've got light pixels underneath",
  "73:22": "so they're going to get a lot of",
  "73:24": "negative dark pixels on top which are",
  "73:29": "very small so not much happens",
  "73:31": "so therefore over here we're going to",
  "73:33": "end up with very negative so this thing",
  "73:39": "where we take H 3x3 area and element",
  "73:45": "wise multiply them with a kernel and add",
  "73:52": "each of those up together to create one",
  "73:55": "output is called a convolution that's it",
  "74:00": "that's a completion so that might look",
  "74:04": "familiar to you",
  "74:05": "right because what we did back a while",
  "74:09": "ago is we looked at that Zeiler and",
  "74:11": "furgus paper where we saw like each",
  "74:12": "different layer and we visualized what",
  "74:16": "the weights were doing and remember how",
  "74:18": "the first layer was basically like",
  "74:19": "finding diagonal edges and gradient",
  "74:22": "that's because that's what a convolution",
  "74:24": "can do right H of our layers is just a",
  "74:27": "convolution so the first layer can do",
  "74:29": "nothing more than this kind of thing but",
  "74:33": "the nice thing is the next layer could",
  "74:35": "then take the results of this right and",
  "74:37": "it could kind of combine one channel but",
  "74:41": "so one or the output of one",
  "74:42": "convolutional field is called a channel",
  "74:43": "right so it could take one channel that",
  "74:45": "found top edges and another channel that",
  "74:48": "finds left edges and then the layer",
  "74:51": "above that could take those two as input",
  "74:53": "and create something that finds top left",
  "74:56": "corners as we saw when we looked at",
  "74:58": "those earlier and focused visualizations",
  "75:01": "so let's take a look at this from",
  "75:03": "another angle or quite a few other",
  "75:05": "angles and we're going to look at a",
  "75:07": "fantastic post tramatic or Matt Klein",
  "75:10": "Smith who was actually a student in the",
  "75:13": "first year that we did this course and",
  "75:15": "he wrote this as part of his project",
  "75:18": "work back then and what he's going to",
  "75:22": "show here is here is our image it's a",
  "75:25": "three by three image and our kernel is a",
  "75:28": "two by two kernel and what we're going",
  "75:31": "to do is we're going to apply this",
  "75:32": "kernel to the top left 2x2 part of this",
  "75:35": "image and so the pink bit will be",
  "75:39": "correspondingly multiplied by the pink",
  "75:41": "bit the green by the green and so forth",
  "75:44": "and they all get added up together to",
  "75:46": "create this top left in the output so in",
  "75:51": "other words P equals alpha times a beta",
  "75:57": "times be gamma times D Delta times e",
  "76:02": "there it is plus B which is a bias okay",
  "76:06": "so that's fine that's just a normal bias",
  "76:09": "so you can see how basically each of",
  "76:12": "these output pixels is the result of",
  "76:15": "some different linear equation that",
  "76:18": "makes sense and you can see these same",
  "76:20": "four weights are being moved around",
  "76:23": "because this is our convolutional kernel",
  "76:26": "here",
  "76:27": "the way of looking at it from that which",
  "76:30": "is here is a classic neural network view",
  "76:33": "and so P now is result of multiplying",
  "76:38": "every one of these inputs by a weight",
  "76:42": "and then adding them all together except",
  "76:45": "the gray ones I've got to have a value",
  "76:48": "of zero right because remember P was",
  "76:52": "only connected to a B D and E a B D P so",
  "77:01": "in other words remembering that this",
  "77:04": "represents a matrix multiplication",
  "77:08": "therefore we can represent this as a",
  "77:12": "matrix multiplication so here is our",
  "77:15": "list of pixels in our 3x3 image",
  "77:18": "flattened out into a vector and here is",
  "77:23": "a matrix vector multiplication plus bias",
  "77:26": "and then a whole bunch of them we're",
  "77:29": "just going to set to zero all right so",
  "77:32": "you can see here we've got a zero zero",
  "77:34": "zero zero zero which corresponds to zero",
  "77:38": "zero zero zero zero so in other words a",
  "77:43": "convolution is just a matrix",
  "77:46": "multiplication where two things happen",
  "77:48": "some of the entries are set to zero all",
  "77:51": "the time and all of the ones are the",
  "77:53": "same color always have the same weight",
  "77:56": "so when you've got multiple things with",
  "77:58": "the same weight",
  "77:59": "that's called weight time okay so",
  "78:04": "clearly we could implement a convolution",
  "78:07": "using matrix multiplication but we don't",
  "78:10": "because it's slow at swim practice our",
  "78:13": "libraries have specific convolution",
  "78:17": "functions that we use and they're",
  "78:19": "basically doing this which is this which",
  "78:24": "is this equation which is says the same",
  "78:26": "as this matrix multiplication and as we",
  "78:31": "discussed we have to think about padding",
  "78:33": "because if you have a 3 by 3 kernel and",
  "78:35": "a 3 by 3 image",
  "78:38": "then that can only create one pixel of",
  "78:41": "output there's only one place that this",
  "78:43": "3x3 can go so if we want to create more",
  "78:46": "than one pixel of output we have to do",
  "78:48": "something called padding which is to put",
  "78:50": "additional numbers all around the",
  "78:53": "outside so what most libraries do is",
  "78:56": "that they just put a layer of zeros",
  "78:58": "normal layer a bunch of zeros of all",
  "79:01": "around the outside so for 3x3 kernel a",
  "79:04": "single zero on every edge piece here and",
  "79:08": "so once you've pattern it like that you",
  "79:10": "can now move your 3x3 kernel all the way",
  "79:12": "across and give you the same output size",
  "79:15": "that you started with okay now as we",
  "79:19": "mention in fast AI we don't normally",
  "79:22": "necessarily use zero padding where",
  "79:25": "possible we use reflection padding",
  "79:26": "although for these simple convolutions",
  "79:29": "we often use zero padding because it's",
  "79:31": "doesn't matter too much in a big image",
  "79:34": "it doesn't make too much difference okay",
  "79:40": "so that's what a convolution is so a",
  "79:46": "convolutional neural network wouldn't be",
  "79:49": "very interesting if it can only create",
  "79:53": "top edges so we have to take it a little",
  "79:58": "bit further so if we have an input",
  "80:10": "and it might be you know standard kind",
  "80:13": "of red-green-blue picture right then we",
  "80:24": "can create a kernel a 3x3 kernel like so",
  "80:32": "and then we could pass that kernel over",
  "80:37": "all of the different pixels but if you",
  "80:39": "think about it we actually don't have a",
  "80:41": "2d and put anymore we have a 3d input a",
  "80:44": "rank 3 tensor so we probably don't want",
  "80:49": "to use the same kernel values for each",
  "80:52": "of red and green and blue because for",
  "80:55": "example if we're creating a green frog",
  "80:56": "detector we would want more activations",
  "80:59": "on the green then we would on the blue",
  "81:01": "right or if we're trying to find",
  "81:03": "something that could actually find a",
  "81:04": "gradient that goes from green to blue",
  "81:06": "then the different kernels for each",
  "81:10": "channel need to have different values in",
  "81:12": "so therefore we need to create a 3 by 3",
  "81:17": "by 3 kernel okay so this is still our",
  "81:24": "kernel and we're still good a very it",
  "81:28": "across the height and the width but",
  "81:32": "rather than doing an element-wise",
  "81:33": "multiplication of 9 things we're going",
  "81:37": "to do an element-wise multiplication of",
  "81:38": "27 things 3 by 3 by 3 and we're still",
  "81:42": "going to then add them up into a single",
  "81:44": "number so as we pass this cube over this",
  "81:50": "and the kind of like a little bit that's",
  "81:52": "going to be sitting behind it right as",
  "81:55": "we do that part of the convolution it's",
  "81:59": "still going to create just one number",
  "82:02": "because we do an element-wise",
  "82:04": "multiplication of all 27 and add them",
  "82:06": "all together so we can do that across",
  "82:11": "the whole padded single unit padded",
  "82:16": "input and so we started with 1 2 3 4 5",
  "82:19": "by 5 so we're going to end up with an",
  "82:21": "output that's also",
  "82:23": "five by foe right",
  "82:27": "but now input was three channels and our",
  "82:31": "output is only one Channel",
  "82:33": "now we're not going to be able to do",
  "82:35": "very much with just one channel because",
  "82:37": "all we've done now is found the top edge",
  "82:40": "how we're going to find a side edge and",
  "82:42": "a gradient and an area of constant",
  "82:47": "weight well we're going to have to",
  "82:49": "create another kernel and we're going to",
  "82:54": "have to do that convert convolved over",
  "82:58": "the input and that's going to create",
  "83:00": "another 5x5 and then we can just stack",
  "83:05": "those together across this there's",
  "83:11": "another axis and we can do that lots and",
  "83:13": "lots of times and that's going to give",
  "83:15": "us another rank",
  "83:20": "sensor output so that's what happens in",
  "83:25": "practice now I'd in practice we start",
  "83:28": "with an input which is H ok which is H",
  "83:34": "by W by 4 images 3 we pass it through a",
  "83:41": "bunch of convolutional kernels but we",
  "83:44": "compare to pick how many we want and it",
  "83:46": "gives us back an output of and it gives",
  "83:50": "us back an output of height by width by",
  "83:54": "however many kernels we had and so often",
  "83:57": "that might be something like 16 in the",
  "84:01": "first player and so now we've got 16",
  "84:04": "channels they're called sixteen channels",
  "84:10": "representing things like how much left",
  "84:12": "egg edge was on this pixel how much top",
  "84:14": "edge was in this pixel how much blue to",
  "84:17": "red gradient was on this problem this",
  "84:19": "set of 2709 pixels each with RGB and so",
  "84:25": "then you can just do the same thing",
  "84:26": "right you can have another bunch of",
  "84:31": "kernels",
  "84:34": "and that's going to create",
  "84:37": "another output ranked 310 sir again",
  "84:40": "height by width by whatever might still",
  "84:44": "be 16 now what we really like to do is",
  "84:48": "as we get deeper in the network or you",
  "84:51": "actually want to have more and more",
  "84:53": "channels we want to be able to find like",
  "84:55": "a richer and richer set of features so",
  "84:57": "that after a few as we saw in the Siler",
  "84:59": "and Fergus paper by layer four or five",
  "85:01": "we've kind of got eyeball detectors and",
  "85:04": "fur detectors and things right so you",
  "85:05": "really need a lot of channels so in",
  "85:08": "order to avoid our memory going out of",
  "85:10": "control",
  "85:11": "from time to time we create a",
  "85:14": "convolution where we don't step over",
  "85:17": "every single set of 3x3 but instead we",
  "85:23": "skip over two at a time so we would",
  "85:26": "start with a 3x3 centered at 2 comma 2",
  "85:29": "and then we'd jump over to 2 comma 4 2",
  "85:32": "comma 6 2 comma 8 and so forth and",
  "85:35": "that's called a stride to convolution",
  "85:40": "and so what that does is it looks",
  "85:44": "exactly the same right it's still just a",
  "85:46": "bunch of kernels but we're just",
  "85:54": "over to it it's time right we're",
  "85:57": "skipping every alternate input pixel and",
  "86:01": "so the output from that will be H over 2",
  "86:06": "by W over 2 and so when we do that we",
  "86:10": "generally create twice as many kernels",
  "86:12": "so we can now have say 32 activations in",
  "86:18": "each of those spots and so that's what",
  "86:21": "modern convolutional neural networks",
  "86:23": "kind of tend to look like right and so",
  "86:26": "we can actually see that if we go into",
  "86:33": "our pets and we grab our CNN right and",
  "86:36": "we're going to take a look at this",
  "86:38": "particular cat so if we go X comma y",
  "86:41": "equals valid data set some index so it's",
  "86:44": "just grab the 0th we'll go touch show",
  "86:46": "and would print out the value of y",
  "86:49": "apparently this cat is of category Main",
  "86:52": "Hoon so until a week ago I was not at",
  "86:55": "all familiar that there's a cat called a",
  "86:57": "Maine Coon having spent all week with",
  "86:59": "this particular cat I am now deeply",
  "87:02": "familiar with this Maine Coon so we can",
  "87:07": "if we go learn summary remember that our",
  "87:12": "input we asked for was 352 by 352 pixels",
  "87:17": "generally speaking the very first",
  "87:19": "convolution tends to have a stride too",
  "87:20": "so after the first layer its 176 by 176",
  "87:25": "so this is lone dot summary we'll print",
  "87:28": "out for you the output shape up to every",
  "87:30": "layer 176 by 176 and the first set of",
  "87:35": "convolutions is has 64 activations and",
  "87:39": "we can actually see that if we type in",
  "87:41": "learn belt model you can see here it's a",
  "87:48": "2d con input channels and 64 output",
  "87:53": "channels and it's tried of - okay and",
  "88:00": "interestingly it actually starts with a",
  "88:01": "kernel size of 7 by 7 so like nearly all",
  "88:04": "of the convolutions are 3 by 3 so either",
  "88:06": "all 3 by 3",
  "88:08": "right for reasons we'll talk about in",
  "88:10": "part two we often use a larger kernel",
  "88:12": "for the very first one if you here's a",
  "88:15": "larger kernel you have to use more",
  "88:17": "padding so we have to use kernel size",
  "88:19": "int / 2 padding to make sure we don't",
  "88:22": "lose anything anyway so we're now have",
  "88:27": "64 output channels and since it was",
  "88:29": "straight - it's now 176 by 176 and then",
  "88:33": "as we go along you'll see that from time",
  "88:37": "to time we have go from 88 by 88 to 40",
  "88:41": "by 40 by 40 for the grid size so that",
  "88:44": "was a 2d con and then when we do that we",
  "88:47": "generally double the number of channels",
  "88:54": "so we keep going through a few more",
  "88:57": "calms and they've as you can see they've",
  "89:00": "got batch norm and rally that's kind of",
  "89:01": "pretty standard and eventually we do it",
  "89:05": "again now the Strad - cons which again",
  "89:08": "doubles okay we can have about 512 by 11",
  "89:11": "by 11 and that's basically where we",
  "89:17": "finish the main part of the network we",
  "89:19": "end up with 5 12 channels 11 by 11",
  "89:23": "okay so we're actually at a point where",
  "89:27": "we're going to be able to do this heat",
  "89:28": "map now so let's try and work through it",
  "89:30": "before we do I want to show you how you",
  "89:34": "can do your own manual convolutions",
  "89:38": "because it's kind of fun so we're going",
  "89:40": "to start with this picture of a Maine",
  "89:42": "Coon and I've created a convolutional",
  "89:46": "kernel and so as you can see this one",
  "89:49": "has a right edge and a bottom edge with",
  "89:52": "positive numbers and just inside that",
  "89:55": "it's got negative numbers so I'm",
  "89:57": "thinking this should show me",
  "89:58": "bottom-right edges ok so that's my",
  "90:04": "tensor now one complexity is that that",
  "90:08": "3x3 kernel cannot be used for this",
  "90:15": "purpose because I need two more",
  "90:17": "dimensions the first is I need the third",
  "90:19": "dimension to say how to combine",
  "90:21": "the red green and blue so what I do is I",
  "90:27": "say don't expand this is my 3x3 and I",
  "90:33": "pop another three on the start what",
  "90:35": "don't expand does is it says create a 3",
  "90:38": "by 3 by 3 tensor by simply copying this",
  "90:42": "one 3 times I mean honestly it doesn't",
  "90:46": "actually copy it it pretends to have",
  "90:49": "copied it you know but it just basically",
  "90:50": "refers to the same block of memory so it",
  "90:53": "kind of copies it in a memory efficient",
  "90:55": "way so this one here is now 3 copies of",
  "91:00": "that and the reason for that is that I",
  "91:03": "want to treat red and green and blue the",
  "91:05": "same way for this little manual kernel",
  "91:07": "I'm showing you and then we need one",
  "91:10": "more access because rather than actually",
  "91:14": "having a separate kernel like I've kind",
  "91:16": "of printed these as if they were",
  "91:17": "multiple kernels what we actually do is",
  "91:21": "we use a rank 4 tensor and so the very",
  "91:24": "first access is for the every separate",
  "91:28": "kernel that we have so in this case I'm",
  "91:31": "just going to create one kernel so to do",
  "91:33": "a convolution I still have to put this",
  "91:35": "unit access on the front so you can see",
  "91:39": "k dot shape is now 1 comma 3 comma 3",
  "91:41": "comma 3 so it's a 3 by 3 kernel there",
  "91:45": "are three of them and then that's just",
  "91:48": "the one kernel that I have so it kind of",
  "91:50": "takes awhile to get the feel for these",
  "91:52": "higher dimensional tensors because we're",
  "91:54": "not used to writing out before D tensor",
  "91:57": "but like just think of them like this",
  "91:59": "before T tensor is just a bunch of 3d",
  "92:02": "tensors sitting on top of each other",
  "92:04": "ok so this is our um 40 tensor and then",
  "92:09": "you can just call kana 2d passing in",
  "92:14": "some image and so the image I'm going to",
  "92:16": "use is the first part of my validation",
  "92:18": "data set and the kernel there's one more",
  "92:22": "trick which is that in pi torch pretty",
  "92:26": "much everything is expecting to work on",
  "92:28": "a mini-batch not on an individual thing",
  "92:31": "okay so in our case we have to create a",
  "92:35": "a batch of size 1 so our original image",
  "92:38": "is three channels by 352 by 352 hoped by",
  "92:42": "width that's remember paid Watchers",
  "92:44": "channel by height by width I want to",
  "92:46": "create a mini design I need to create a",
  "92:48": "rank 4 tensor where the first axis is 1",
  "92:53": "in other words it's a mini batch of size",
  "92:55": "1 because that's what plate watch",
  "92:57": "expects so there's something you can do",
  "92:59": "in both pi torch and numpy which is you",
  "93:02": "can index into an array or a tensor with",
  "93:04": "a special value none and that creates a",
  "93:08": "new unit access in that point point so T",
  "93:13": "is my image of dimensions 3 by 3 52 by",
  "93:17": "352 T none is a rank 4 tensor a mini",
  "93:22": "batch of one image of 1 by 3 by 3 50 by",
  "93:25": "352 and so now I can go to D and get",
  "93:29": "back ok specifically my Maine Coon ok so",
  "93:40": "that's how you can play around with",
  "93:42": "convolutions yourself so how are we",
  "93:47": "going to do this to create a heat map",
  "93:50": "this is where things get fun remember",
  "94:01": "mentioned was that I basically have like",
  "94:07": "my input red-green-blue and it goes",
  "94:13": "through a bunch of convolutional layers",
  "94:16": "let us write a little line to say a",
  "94:19": "convolutional layer to create",
  "94:21": "activations which have more and more",
  "94:24": "channels and eventually less and less",
  "94:27": "smaller and smaller height by widths",
  "94:35": "until eventually remember we looked at",
  "94:37": "the summary we ended up with something",
  "94:39": "which was 11 by 11 by 512 and there's a",
  "94:51": "hope there's a whole bunch more layers",
  "94:52": "that we skipped over now there are 37",
  "95:05": "classes because remember data dot C is",
  "95:08": "the number of classes we have and we can",
  "95:11": "see that at the end here we end up with",
  "95:12": "37 features in our model so that means",
  "95:16": "that we end up with a probability for",
  "95:18": "every one of the 37 breeds of cat and",
  "95:21": "dog so it's a vector of length 37 that's",
  "95:25": "our final output that we need because",
  "95:27": "that's what we're going to compare",
  "95:29": "implicitly to our one hot encoded matrix",
  "95:32": "which will have a 1 in the location for",
  "95:35": "Maine Coon yeah so somehow we need to",
  "95:40": "get from this 11 by 11 by 512 to this 37",
  "95:46": "and so the way we do it is we actually",
  "95:50": "take the average of every one of these",
  "95:53": "11 by 11 faces we just take the mean so",
  "95:57": "we're going to take the mean of this",
  "96:00": "first face take the mean that gets this",
  "96:06": "one value and then we'll take",
  "96:08": "second of the five twelve faces and take",
  "96:10": "that mean and that'll give us one more",
  "96:12": "value that's a we'll do that for every",
  "96:14": "face and that will give us a five twelve",
  "96:19": "long vector okay and so now all we need",
  "96:25": "to do is pop that through a single",
  "96:28": "matrix multiply of five twelve by thirty",
  "96:33": "seven and that's going to give us an",
  "96:38": "output vector of length thirty-seven",
  "96:41": "okay so this step here where we take the",
  "96:45": "average of each face is called average",
  "96:48": "pooling so let's go back to our model",
  "96:53": "and take a look there it is here is our",
  "96:57": "final five twelve and here is we will",
  "97:01": "talk about what a concat pooling is in",
  "97:03": "part two for now we'll just focus on",
  "97:05": "that this is a fast AI specialty",
  "97:06": "everybody else just does this average",
  "97:08": "pool average pool duty with an output",
  "97:11": "size of one so here it is output average",
  "97:15": "pool 2d with an output size of one and",
  "97:19": "then again there's a bit of a special",
  "97:28": "faster I think that we actually have two",
  "97:30": "layers here but normally people then",
  "97:31": "just have the one linear layer with the",
  "97:35": "input of 512 and the output of 37 okay",
  "97:42": "so what that means is that this little",
  "97:44": "box over here where we want a one for",
  "97:48": "Maine Coon we've got to have a box over",
  "97:51": "here which needs to have a high value in",
  "97:54": "that place so that the lots of below so",
  "97:58": "if we're going to have a high value",
  "97:59": "there the only way to get it is with",
  "98:03": "this matrix multiplication is that it's",
  "98:05": "going to represent a simple weighted",
  "98:09": "linear combination of all of the 512",
  "98:12": "values here so if we're going to be able",
  "98:15": "to say I'm pretty confident this is a",
  "98:17": "Maine Coon just by taking the weighted",
  "98:21": "sum of a",
  "98:21": "of inputs those inputs are going to have",
  "98:23": "to represent features like how fluffy is",
  "98:27": "it what color is it snows how long as",
  "98:30": "its legs how point here it's ears you",
  "98:32": "know all the kinds of things that can be",
  "98:34": "used because for the other thing which",
  "98:36": "figures out is this a bulldog it's going",
  "98:39": "to use exactly the same kind of 512",
  "98:42": "inputs with a different set of weights",
  "98:44": "because that's all a matrix",
  "98:45": "multiplication is right it's just a",
  "98:48": "bunch of weighted sums a different",
  "98:51": "weighted sum for each output okay so",
  "98:55": "therefore we know that this you know",
  "98:59": "potentially dozens or even hundreds of",
  "99:02": "layers of convolutions must have",
  "99:04": "eventually come up with an 11 by 11 face",
  "99:09": "for each of these features saying in",
  "99:12": "this little bit here how much is that",
  "99:17": "part of the image like a pointy ear how",
  "99:21": "much is it fluffy how much is it like a",
  "99:24": "long leg how much is it like a very red",
  "99:26": "nodes right so that's what all of those",
  "99:29": "things must represent so each face is",
  "99:31": "what we call each of these represents a",
  "99:35": "different feature okay so the outputs of",
  "99:41": "these we can think of as different",
  "99:43": "features so what we really want to know",
  "99:49": "then is not so much what's the average",
  "99:54": "across the 11 by 11 to get this set of",
  "99:57": "outputs but what we really want to know",
  "100:00": "is what's in each of these 11 by 11",
  "100:01": "spots so what if instead of averaging",
  "100:04": "across the 11 by 11 let's instead",
  "100:07": "average across the 512 if we average",
  "100:13": "across the 512 that's going to give us a",
  "100:17": "single 11 by 11 matrix and each item",
  "100:21": "each each grid point in that 11 by 11",
  "100:24": "matrix will be the average of how",
  "100:27": "activated was that area when it came to",
  "100:30": "figuring out that this was a Maine Coon",
  "100:33": "how many",
  "100:35": "signs of Maine Coon ish Ness was there",
  "100:38": "in that part of the 11 by 11 grid and so",
  "100:44": "that's actually what we do to create our",
  "100:46": "heat map so I think maybe the easiest",
  "100:48": "way is to kind of work backwards here's",
  "100:52": "our heat map and it comes from something",
  "100:55": "called",
  "100:55": "average activations and it's just a",
  "100:58": "little bit of matplotlib and faster a",
  "101:02": "faster I to show the image and then",
  "101:05": "matplotlib to take the heat map which we",
  "101:08": "passed in which was called average",
  "101:09": "activations hm for heat map alpha 0.6",
  "101:13": "means make it a bit transparent and",
  "101:16": "matplotlib extent means expand it from",
  "101:20": "11 by 11 to 352 by 352 he is by linear",
  "101:24": "interpolations it's not all blocky and",
  "101:26": "use a different color map to kind of",
  "101:28": "highlight things that's just the",
  "101:30": "matplotlib is not important the key",
  "101:32": "thing here is that average activations",
  "101:33": "is the 11 by 11 matrix we wanted here it",
  "101:37": "is average activations touch shape is 11",
  "101:39": "by 11 so to get there we took the mean",
  "101:44": "of activations across dimension 0 which",
  "101:47": "is what I just said in PI torch the",
  "101:50": "channel dimension is the first dimension",
  "101:52": "so the main across dimension 0 took us",
  "101:55": "from something of size 512 by 11 by 11",
  "101:57": "as promised",
  "101:59": "to something of 11 by 11 so therefore",
  "102:03": "activations axe contains the activations",
  "102:06": "we're averaging where did they come from",
  "102:09": "they came from something called a hook",
  "102:12": "so a hook is a really cool more advanced",
  "102:21": "PI torch feature that lets you as the",
  "102:24": "name suggests hook into the PI torch",
  "102:26": "machinery itself and run any arbitrary",
  "102:30": "Python code you want to it's a really",
  "102:33": "amazing and nifty thing because you know",
  "102:36": "normally when we do a forward pass",
  "102:39": "through a PI torch module it gives us",
  "102:43": "this set of outputs but we know that in",
  "102:46": "the process it's calculated these",
  "102:49": "so why would I what I would like to do",
  "102:52": "is I would like to hook into that",
  "102:54": "forward pass and tell PI torch hey when",
  "102:58": "you calculate this can you store it for",
  "103:00": "me please okay so what is this this is",
  "103:04": "the output of the convolutional part of",
  "103:07": "the model so the convolutional part of",
  "103:09": "the model which is everything before the",
  "103:11": "average pool is basically all of that",
  "103:16": "but and so thinking back to transfer",
  "103:19": "learning right you remember with",
  "103:25": "transfer learning we actually cut off",
  "103:31": "everything after the convolutional part",
  "103:33": "of the model and replaced it with our",
  "103:35": "own little bit right so with fast AI the",
  "103:39": "original convolutional part of the model",
  "103:40": "is always going to be the first thing in",
  "103:44": "the model and specifically it's always",
  "103:47": "going to be called assuming so in this",
  "103:51": "case I'm taking my model and I'm just",
  "103:54": "going to call it M right so you can see",
  "103:58": "M is this big thing but always at least",
  "104:05": "in first day I always m0 will be the",
  "104:10": "convolutional part of the model so in",
  "104:12": "this case we created a let's go back and",
  "104:16": "see we created a resin at 34 so the the",
  "104:20": "main part of the resin at 34 though the",
  "104:22": "pre-trained bit we hold on to is in m0",
  "104:24": "and so this is basically it this is a",
  "104:26": "printout of the rezident 84 and at the",
  "104:29": "end of it there is the 512 activations",
  "104:32": "so what in other words what we want to",
  "104:34": "do is we want to grab em 0 and we want",
  "104:41": "to hook its output so this is a really",
  "104:45": "useful thing to be able to do so far C",
  "104:46": "is actually created something to do it",
  "104:48": "for you which is literally you say hook",
  "104:50": "output and you pass in the PI torch",
  "104:54": "module that you want to hook the output",
  "104:56": "of and so most of the most likely the",
  "104:58": "thing you want to hook is the",
  "105:00": "convolutional part of the model",
  "105:02": "and that's always going to be M 0 or",
  "105:05": "learn model zero so we give that hawk a",
  "105:08": "name don't worry about this part we'll",
  "105:11": "learn about it next week so having",
  "105:13": "hooked the output we now need to",
  "105:16": "actually do the forward pass all right",
  "105:18": "and so remember in PI torch to actually",
  "105:20": "get it to calculate something which is",
  "105:22": "called doing the forward pass you just",
  "105:24": "act as if the model is a function right",
  "105:27": "so we just pass in our X our X",
  "105:30": "mini-batch so we already had a Maine",
  "105:34": "Coon image called X right but we can't",
  "105:38": "quite pass that into our model it has to",
  "105:42": "be normalized and turned into a mini",
  "105:44": "batch and put on to the GPU so first AI",
  "105:49": "has a thing called a data bunch which we",
  "105:51": "have in data and you can always say data",
  "105:53": "dot one item to create a mini batch with",
  "105:57": "one thing in it ok and as an exercise at",
  "106:00": "home you could try to create a mini",
  "106:02": "batch without using data dot one item so",
  "106:05": "make sure that you kind of learn how to",
  "106:07": "normalize and stuff yourself if you want",
  "106:09": "to but this is how you can create a mini",
  "106:12": "batch with just one thing in it and then",
  "106:15": "I can pop that onto the GPU by saying",
  "106:17": "drop CUDA that's what I passed in my",
  "106:20": "model and so the predictions I get out",
  "106:23": "actually don't care about right because",
  "106:25": "the predictions is the predictions is",
  "106:31": "this thing which is not what I want",
  "106:32": "right so I'm not actually going to do",
  "106:35": "anything with the predictions the thing",
  "106:36": "I care about is the hook that it is",
  "106:39": "created now one thing to be aware of is",
  "106:42": "that when you hook something in playa",
  "106:46": "torch that means every single time you",
  "106:47": "run that model assuming you're hooking",
  "106:50": "outputs it's storing those outputs and",
  "106:53": "so you want to remove the hook when",
  "106:56": "you've got what you want because",
  "106:57": "otherwise if you use the model again",
  "106:58": "it's going to keep hooking more and more",
  "107:00": "outputs which will be slow and memory",
  "107:01": "intensive so we've created this thing",
  "107:05": "Python calls that a context manager",
  "107:07": "you can use any hook as a context",
  "107:09": "manager at the end of that with block",
  "107:11": "it'll remove the hook okay so we've got",
  "107:16": "and so now pi torch walks so fast a",
  "107:21": "eyehooks",
  "107:22": "always give you something called or at",
  "107:24": "least the output hooks always give you",
  "107:26": "something called dot stored which is",
  "107:27": "where it stores away the thing you asked",
  "107:28": "you to hook and so that's where the",
  "107:30": "activations now uh okay so we did a",
  "107:34": "forward pass after hooking the output of",
  "107:37": "the convolutional section of the model",
  "107:38": "we grabbed what it stored we check the",
  "107:42": "shape it was 512 by 11 by 11 as we",
  "107:46": "predicted we then took the mean of the",
  "107:49": "channel axis to get an 11 by 11 tensor",
  "107:54": "and then if we look at that that's our",
  "108:00": "picture so there's a lot to unpack right",
  "108:04": "lot to unpack but if you take your time",
  "108:07": "going through these two sections the",
  "108:09": "convolution kernel section and the",
  "108:12": "heatmap section of this notebook like",
  "108:13": "running those lines of code and changing",
  "108:15": "them around a little bit and remember",
  "108:18": "the most important thing to look at is",
  "108:20": "shape you might have noticed when I'm",
  "108:22": "showing you these notebooks so very",
  "108:24": "often print out the shape and when you",
  "108:26": "look at this shape you want to be",
  "108:27": "looking at how many axes are there",
  "108:30": "that's the rank of the tensor and how",
  "108:32": "many things are there in each axis and",
  "108:34": "try and think why right try going back",
  "108:38": "to the printout of the summary try going",
  "108:41": "back to the actual list of the layers",
  "108:43": "and try and go back and think about the",
  "108:45": "actual picture we drew and think about",
  "108:47": "what's actually going on okay so that's",
  "108:54": "a lot of technical content so what I'm",
  "108:57": "going to do now is switch from technical",
  "108:58": "content to something much more important",
  "109:01": "unless we have some questions first okay",
  "109:05": "because in the next lesson in the next",
  "109:11": "lesson we're going to be looking at",
  "109:14": "generative models both text and image",
  "109:19": "generative models and generative models",
  "109:22": "are where you can create a new piece",
  "109:28": "of text or a new image or a new video or",
  "109:33": "a new sound and as you probably are",
  "109:35": "aware this is the area that deep",
  "109:37": "learning has developed the most in in",
  "109:40": "the last 12 months and we're now at a",
  "109:42": "point where we can generate realistic",
  "109:47": "looking videos images audio and to some",
  "109:54": "extent even text and so there are many",
  "110:00": "things in in this journey which have",
  "110:04": "ethical considerations but perhaps this",
  "110:06": "area of generative modeling is one of",
  "110:08": "the largest ones so before I got into it",
  "110:11": "I wanted to specifically touch on ethics",
  "110:14": "and data science",
  "110:16": "most of the stuff I'm showing you",
  "110:19": "actually comes from Rachel and Rachel",
  "110:23": "has a really cool TEDx San Francisco",
  "110:26": "talk that you can check out on YouTube",
  "110:29": "and a more extensive analysis of ethical",
  "110:33": "principles and bias principles in AI",
  "110:35": "which you can find at this talk here and",
  "110:38": "she has a playlist that you can check",
  "110:40": "out we've already touched on an example",
  "110:44": "of bias which was his gender shades",
  "110:47": "study where if you remember for example",
  "110:51": "lighter male skin people on IBM's main",
  "110:56": "computer vision system 99.7% accurate",
  "111:01": "and darker females are some hundreds of",
  "111:05": "times less accurate in terms of error so",
  "111:08": "like extraordinary differences and so",
  "111:11": "it's interesting to kind of like okay",
  "111:13": "it's it's first more important to be",
  "111:14": "aware that not only can this happen",
  "111:17": "technically that this can happen on a",
  "111:20": "massive companies rolled out publicly",
  "111:24": "available highly marketed system that",
  "111:27": "hundreds of quality control people have",
  "111:29": "studied and lots of people are using it",
  "111:31": "it's it's out there in the world they",
  "111:34": "all look kind of crazy right",
  "111:40": "so it's interesting to think about why",
  "111:41": "and so one of the reasons why is that",
  "111:44": "the data we feed these things but we",
  "111:46": "tend to use be included a lot of these",
  "111:49": "datasets kind of unthinkingly right but",
  "111:53": "like imagenet which is the basis of like",
  "111:54": "a lot of the computer vision stuff we do",
  "111:57": "is over half American and Great Britain",
  "112:01": "right like when it comes to the",
  "112:06": "countries that actually have most of the",
  "112:08": "population in the world I can't even see",
  "112:12": "them here they're somewhere in these",
  "112:13": "impossibly thin lines because remember",
  "112:15": "these datasets are being created almost",
  "112:17": "exclusively by people in u.s. Great",
  "112:22": "Britain and nowadays increasingly also",
  "112:24": "China so there's a lot of bias in the",
  "112:30": "content we're creating because of a bias",
  "112:32": "in the kind of people that are creating",
  "112:34": "that content even when in theory it's",
  "112:37": "being created in a very kind of neutral",
  "112:39": "way but you can't argue with the data",
  "112:41": "right it's it's obviously not neutral at",
  "112:44": "all and so when you have biased data",
  "112:51": "creating biased algorithms you then need",
  "112:54": "to say like or what are we doing with",
  "112:55": "that so we've been spend a lot of time",
  "112:57": "talking about image recognition so a",
  "112:59": "couple of years ago this company deep",
  "113:01": "Lin advertised their image recognition",
  "113:04": "system which can be used to do mass",
  "113:08": "surveillance on large crowds of people",
  "113:11": "find any person passing through who is a",
  "113:15": "person of interest in theory and so",
  "113:19": "putting aside even the question of like",
  "113:21": "is it a good idea to have such a system",
  "113:25": "you kind of think is it a good idea to",
  "113:27": "have such a system where certain kinds",
  "113:30": "of people are 300 times more likely to",
  "113:32": "be misidentified and then thinking about",
  "113:35": "it so this is now starting to happen in",
  "113:39": "America these systems are being rolled",
  "113:41": "out and so there are now systems in",
  "113:44": "America that will identify a person of",
  "113:47": "interest in a video and send a ping to",
  "113:52": "the local police",
  "113:53": "and so these systems are extremely",
  "113:56": "inaccurate and extremely biased and what",
  "113:59": "happens that of course is if you're in a",
  "114:02": "predominantly black neighborhood where",
  "114:05": "the probability of successfully",
  "114:07": "recognizing you is much lower and you're",
  "114:11": "much more likely to be surrounded by",
  "114:12": "black people and so suddenly all of",
  "114:16": "these black people are popping up as",
  "114:17": "persons of interest or in a video of a",
  "114:20": "person of interest all the people in the",
  "114:22": "video are all recognized as in the",
  "114:25": "vicinity as a person of interest you",
  "114:27": "suddenly get all these pings going off",
  "114:28": "the local police department causing the",
  "114:31": "police to run down there and therefore",
  "114:33": "likely to lead to a larger number of",
  "114:36": "arrests which is then likely to feed",
  "114:38": "back into the data being used to develop",
  "114:40": "the systems so this is happening right",
  "114:44": "now",
  "114:44": "and so like thankfully a very small",
  "114:47": "number of people are actually bothering",
  "114:49": "to look into these things I mean",
  "114:50": "ridiculously small but at least it's",
  "114:52": "better than nothing and so for example",
  "114:54": "then one of the best ways that people",
  "114:55": "get publicity is to do kind of funny",
  "114:58": "experiments like let's try the mug shot",
  "115:04": "image recognition system that's being",
  "115:06": "widely used and trade against the",
  "115:08": "members of Congress and find out that",
  "115:10": "there are 28 members of Congress who",
  "115:13": "would have been identified by this",
  "115:15": "system obviously incorrectly oh I didn't",
  "115:20": "know that okay members have black",
  "115:22": "members of Congress not at all surprised",
  "115:24": "to hear that Thank You Rachel we see",
  "115:28": "this kind of bias and a lot of the",
  "115:30": "systems we use I'm not just image",
  "115:32": "recognition but text translation when",
  "115:35": "you convert she as a doctor he is a",
  "115:37": "nurse into Turkish you quite correctly",
  "115:40": "get a gender in specific pronoun because",
  "115:43": "that's what Turkish uses you could then",
  "115:45": "take that and feed it back into Turkish",
  "115:47": "with your gender in specific pronoun and",
  "115:49": "you will now get he as a doctor she is",
  "115:52": "in this so the bias again this is in a",
  "115:56": "massively widely rolled out carefully",
  "115:58": "studied system and it's not like even",
  "116:02": "these kind of things like a little",
  "116:03": "one-off things then get fixed quickly",
  "116:05": "these issues have been identified in",
  "116:07": "Google Translate for a very long time",
  "116:08": "and they're still there and they don't",
  "116:11": "get fixed so the the kind of results of",
  "116:18": "this are in my opinion quite terrifying",
  "116:22": "because what's happening is that in many",
  "116:25": "countries including America where I'm",
  "116:27": "speaking from now algorithms are",
  "116:30": "increasingly being used for all kinds of",
  "116:33": "Public Policy judicial and so forth",
  "116:36": "surfaces for example there's a system",
  "116:38": "called compass which is very widely used",
  "116:40": "to decide who's going to jail and it",
  "116:43": "does that in a couple of ways",
  "116:45": "it tells judges what sentencing",
  "116:47": "guidelines they should use for",
  "116:49": "particular cases and it tells them also",
  "116:52": "which people the system says should be",
  "116:56": "let out on bail but here's the thing",
  "116:59": "white people that keeps on saying let",
  "117:03": "this person out even though they end up",
  "117:05": "reoffending and vice versa it's",
  "117:08": "systematically like out by double",
  "117:10": "compared to what it should be in terms",
  "117:13": "of getting it wrong with white people",
  "117:16": "versus black people so this is like kind",
  "117:23": "of horrifying because I mean amongst",
  "117:26": "other things the data that it's using in",
  "117:28": "this system is literally asking people",
  "117:31": "questions about things like did any of",
  "117:35": "your parents ever go to jail or do any",
  "117:37": "of your friends do drugs like they're",
  "117:40": "asking questions about other people who",
  "117:43": "they have no control over so not only",
  "117:45": "are these systems biased very",
  "117:49": "systematically biased but they're also",
  "117:52": "are being done on the basis of data",
  "117:54": "which is totally out of your control so",
  "117:57": "this is kind of DeJoria it seems that oh",
  "118:00": "yeah are your parents divorced is",
  "118:03": "another question that's being used to",
  "118:04": "decide whether you go to jail or not",
  "118:06": "okay so when we raise these issues kind",
  "118:12": "of on Twitter or in talks or whatever",
  "118:14": "there's always a few people always white",
  "118:17": "men a few people who will always say",
  "118:20": "like",
  "118:21": "that's just the way the world is that's",
  "118:23": "just reflecting what the data shows but",
  "118:26": "when you actually look at it it's not",
  "118:28": "right it's actually systematically",
  "118:32": "erroneous and systematically erroneous",
  "118:36": "against people of color minorities the",
  "118:39": "people who are less involved in creating",
  "118:41": "the systems that these products are",
  "118:44": "based on sometimes this can go a really",
  "118:49": "long way",
  "118:50": "so for example in Myanmar there was a",
  "118:54": "genocide of Thuringia people and that",
  "118:58": "genocide was very heavily created by",
  "119:01": "Facebook not because anybody at Facebook",
  "119:04": "wanted it I mean heavens no I know a lot",
  "119:07": "of people at Facebook I have a lot of",
  "119:08": "friends at Facebook they're really",
  "119:10": "trying to do the right thing right",
  "119:11": "they're really trying to create a",
  "119:13": "product that people like but not in a",
  "119:16": "thought for enough way because when you",
  "119:18": "roll out something we're literally in",
  "119:20": "Myanmar a country that most people",
  "119:23": "didn't have most but maybe half of",
  "119:26": "people didn't have electricity until",
  "119:28": "very recently and you say hey you can",
  "119:31": "all have free internet as long as it's",
  "119:33": "just Facebook I think carefully about",
  "119:36": "what you're doing right and then you use",
  "119:38": "algorithms to feed people the stuff they",
  "119:41": "will click on and of course what people",
  "119:42": "click on is stuff which is controversial",
  "119:45": "stuff that makes their blood boil so",
  "119:48": "when they actually started asking the",
  "119:51": "generals in the Myanmar army that were",
  "119:53": "literally throwing babies onto bonfires",
  "119:56": "they were saying we know that these are",
  "119:59": "not humans we know that they are animals",
  "120:02": "because we read the news we read the",
  "120:05": "internet but and because this is the",
  "120:07": "that this is the stories that the",
  "120:10": "algorithms are pushing but and the",
  "120:12": "algorithms are pushing the stories",
  "120:14": "because the algorithms are good they",
  "120:16": "know how to create eyeballs how to get",
  "120:19": "people watching and how can I get people",
  "120:21": "clicking and again putting it Facebook",
  "120:23": "said let's cause a massive genocide in",
  "120:27": "Myanmar they said let's maximize the",
  "120:30": "engagement of people in this new market",
  "120:32": "on our platform",
  "120:36": "so they very successfully maximized",
  "120:39": "engagement yes please it's just it's",
  "120:46": "important to note people warned",
  "120:48": "executives of Facebook how the platform",
  "120:50": "was being used to incite violence as far",
  "120:52": "back as 2013 2014 2015 and 2015 someone",
  "120:57": "even warned executives that Facebook",
  "121:00": "could be used in Myanmar in the same way",
  "121:01": "that the radio broadcast were used in",
  "121:04": "Rwanda during the Rwandan genocide and",
  "121:07": "as of 2015 Facebook only had four for",
  "121:11": "contractors who spoke Burmese working",
  "121:14": "for them they really did not put many",
  "121:16": "resources into the issue at all even",
  "121:19": "though they were getting very very",
  "121:21": "alarming warnings about it so I mean why",
  "121:25": "does this happen right the part of the",
  "121:28": "issue is that ethics is complicated and",
  "121:32": "you will not find Rachel or I telling",
  "121:36": "you how to do ethics you know how do you",
  "121:38": "fix this we don't know we can just give",
  "121:41": "you kind of things to think about all",
  "121:44": "right another part of a problem we keep",
  "121:46": "hearing is it's not my problem I'm just",
  "121:49": "a researcher I am just a techie I'm just",
  "121:51": "building a data set I'm not part of a",
  "121:54": "problem I'm part of this foundation",
  "121:56": "that's far enough away that I can",
  "121:58": "imagine that I'm not part of this right",
  "122:00": "but you know if you're creating image",
  "122:04": "net and you want it to be successful you",
  "122:07": "want lots of people to use it you want",
  "122:08": "lots of people to build products on it",
  "122:09": "lots people to do research on top of it",
  "122:11": "if you're trying to create something",
  "122:13": "that people are using you want them to",
  "122:16": "use then please try to make it something",
  "122:18": "that won't cause massive amounts of harm",
  "122:21": "and doesn't have massive amounts of bias",
  "122:23": "and it can actually come back and bite",
  "122:25": "you in the ass right",
  "122:27": "the Volkswagen engineer who ended up",
  "122:30": "actually encoding the thing that made",
  "122:33": "them systematically cheat on their",
  "122:35": "diesel emissions tests on their",
  "122:37": "pollution tests ended up in jail not",
  "122:41": "because it was their decision to cheat",
  "122:44": "on the tests but because their manager",
  "122:46": "told them to write their code",
  "122:48": "and they wrote the code and therefore",
  "122:50": "they were at the ones that ended up",
  "122:52": "being criminally responsible and they",
  "122:54": "were the ones that were jailed right so",
  "122:56": "if you do in some way a shitty thing",
  "123:00": "that ends up causing trouble that can",
  "123:03": "absolutely come back around and get you",
  "123:05": "in trouble as well sometimes it can",
  "123:08": "cause huge amounts of trouble",
  "123:10": "so if we go back to World War two right",
  "123:14": "then this was one of the first great",
  "123:17": "opportunities for IBM to show off their",
  "123:19": "amazing amazing tabulating system and",
  "123:22": "they had a huge client in Nazi Germany",
  "123:25": "and Nazi Germany used this amazing new",
  "123:28": "tabulating system to encode all of the",
  "123:31": "different types of Jews that they had in",
  "123:33": "the country and all the different types",
  "123:34": "of problem people so Jews were eight",
  "123:36": "gypsies were 12",
  "123:39": "then different outcomes were coded",
  "123:41": "executions were for death in a gas",
  "123:44": "chamber was six a Swiss judge ruled that",
  "123:50": "IBM was actively involved facilitating",
  "123:56": "the commission of these crimes against",
  "123:58": "humanity right so there are absolutely",
  "124:02": "plenty of examples of people building",
  "124:05": "data processing technology that are",
  "124:08": "directly causing deaths sometimes",
  "124:13": "millions of deaths right so we don't",
  "124:16": "want to be one of those people and so",
  "124:18": "you might have thought oh you know I'm",
  "124:20": "just creating some data processing",
  "124:21": "software and somebody else is thinking",
  "124:23": "I'm just the sales person and somebody",
  "124:24": "else is thinking",
  "124:25": "I'm just the biz dev person opening new",
  "124:27": "markets but it all comes together right",
  "124:29": "so we need to care and so one of the",
  "124:33": "things we need to care about is getting",
  "124:35": "humans back in the loop right and so",
  "124:39": "when we pull humans out of the loop is",
  "124:42": "one of the first times that trouble",
  "124:44": "happens I don't know if you remember I",
  "124:45": "remember this very clearly when I first",
  "124:48": "heard that Facebook was firing the human",
  "124:51": "editors that were responsible for",
  "124:53": "basically curating the news that ended",
  "124:57": "up on the Facebook pages and I got to",
  "125:01": "say",
  "125:01": "a time I thought that's a recipe for",
  "125:04": "disaster because I've seen again and",
  "125:06": "again that humans can be the person in",
  "125:09": "the loop that can realize this isn't",
  "125:12": "right you know it's very hard to create",
  "125:14": "an algorithm that can recognize this",
  "125:17": "isn't right or else humans are very good",
  "125:19": "at that",
  "125:20": "and we saw that's what happened right",
  "125:21": "after Facebook fired two human editors",
  "125:23": "the nature of stories on Facebook",
  "125:26": "dramatically changed that and you",
  "125:28": "started seeing this proliferation of",
  "125:30": "conspiracy theories and the kind of the",
  "125:33": "algorithms went crazy with recommending",
  "125:35": "more and more controversial topics and",
  "125:37": "of course that changed people's",
  "125:39": "consumption behavior causing them to one",
  "125:41": "more and more controversial topics so",
  "125:46": "we're one of the really interesting",
  "125:47": "places this comes in and Cathy O'Neil",
  "125:50": "who's got a great book called reference",
  "125:54": "of math destruction thank you Rachel",
  "125:58": "and many others have pointed out is that",
  "126:00": "what happens to algorithms is that they",
  "126:04": "end up impacting people for example",
  "126:07": "compass sentencing guidelines go to a",
  "126:10": "judge now you can say the algorithm is",
  "126:14": "very good we I mean it in compass this",
  "126:17": "case it isn't it actually turned out to",
  "126:18": "be about as bad as random because it's a",
  "126:21": "black box and all that but even if it",
  "126:24": "was very good",
  "126:25": "you could then say well you know the",
  "126:27": "judge is getting the algorithm otherwise",
  "126:29": "they're just be getting a person people",
  "126:30": "also give bad advice",
  "126:31": "so what humans respond differently to",
  "126:34": "algorithms it's very common particularly",
  "126:37": "for a human that is not very familiar",
  "126:40": "with the technology themselves like a",
  "126:42": "judge just see like oh that's what the",
  "126:45": "computer says the computer looked it up",
  "126:47": "and it figured this out right it's",
  "126:50": "extremely difficult to get a",
  "126:52": "non-technical audience to look at a",
  "126:54": "computer recommendation and come up with",
  "126:57": "a nuanced decision-making process so",
  "127:02": "what we see is that algorithms are often",
  "127:05": "put into place with no appeals process",
  "127:07": "they're often used to massively scale up",
  "127:10": "decision making systems because they're",
  "127:14": "cheap",
  "127:14": "and then the people that are using the",
  "127:17": "Atlas of those algorithms tend to give",
  "127:19": "them more credence than they deserve",
  "127:20": "because very often they're being used by",
  "127:22": "people that don't have the technical",
  "127:24": "competence to judge them themselves so",
  "127:26": "great example right was here's an",
  "127:30": "example of somebody who lost their",
  "127:32": "health care and they lost their health",
  "127:35": "care because of an error in a new",
  "127:37": "algorithm that was systematically",
  "127:40": "failing to recognize that there are many",
  "127:44": "people that need help with was it",
  "127:46": "Alzheimer's cerebral palsy and diabetes",
  "127:50": "thanks Rachel",
  "127:51": "and so this system which had this this",
  "127:55": "era that was later discovered was",
  "127:57": "cutting off these people from the home",
  "127:59": "care that they needed so that cerebal",
  "128:01": "palsey victims loan longer had the care",
  "128:04": "they needed so their life was destroyed",
  "128:07": "basically and so when the person that",
  "128:11": "created that algorithm with the error",
  "128:13": "was asked about this and one",
  "128:15": "specifically said should they have found",
  "128:18": "a better way to communicate the system",
  "128:21": "the strengths the failures and so forth",
  "128:23": "he said yeah I should probably also dust",
  "128:26": "under my bed that was there that was the",
  "128:29": "level of interest they had and this is",
  "128:32": "extremely common I hear this all the",
  "128:35": "time and it's much easier to kind of see",
  "128:37": "it from afar and say okay after the",
  "128:39": "problems happened I can see that that's",
  "128:41": "a really shitty thing to say but it can",
  "128:42": "be very difficult when you're kind of in",
  "128:45": "the middle of it I just want to say one",
  "128:48": "more thing about that example and that's",
  "128:51": "that this was a case where it was",
  "128:53": "separate there was someone who created",
  "128:54": "the algorithm then I think different",
  "128:56": "people implemented the software and this",
  "128:58": "is a note in use in over half of the 50",
  "129:00": "states and then there was also the",
  "129:01": "particular policy decisions made by that",
  "129:04": "state and so there this is one of those",
  "129:06": "situations where nobody felt responsible",
  "129:08": "because the algorithm creators like oh",
  "129:10": "no it's the policy decisions of the",
  "129:11": "state that were bad you know and the",
  "129:13": "state can be like oh no it's the ones",
  "129:15": "who implemented the software and so",
  "129:18": "everyone's just kind of pointing fingers",
  "129:19": "and not taking responsibility and you",
  "129:23": "know in some ways maybe it's unfair but",
  "129:25": "I would argue the person who is",
  "129:28": "creating the data set and the person who",
  "129:30": "is implementing the algorithm is the",
  "129:32": "person best placed to get out there and",
  "129:36": "say hey here are the things you need to",
  "129:38": "be careful of and make sure that they",
  "129:40": "are part of the implementation process",
  "129:43": "so we've also seen this with YouTube",
  "129:46": "right it's kind of similar to what",
  "129:48": "happened with Facebook and we're now",
  "129:49": "seeing with heard examples of students",
  "129:52": "watching the faster I courses who say",
  "129:54": "hey Jeremy and Rachel watching the first",
  "129:56": "day our courses really enjoyed them and",
  "129:58": "at the end of one of them the YouTube",
  "130:01": "autoplay fed me across to a conspiracy",
  "130:03": "theory and what happens is that once the",
  "130:08": "system decides that you like the",
  "130:10": "conspiracy theories it's going to just",
  "130:11": "feed you more and more and then what",
  "130:13": "happens is that please come on just",
  "130:18": "briefly you don't you don't even have to",
  "130:20": "like conspiracy theories the goal is to",
  "130:22": "get as many people hooked on conspiracy",
  "130:24": "theories as possible as what the",
  "130:26": "algorithms trying to do kind of whether",
  "130:28": "or not you've expressed interest right",
  "130:30": "and so the interesting thing again is I",
  "130:32": "know plenty of people involved in",
  "130:33": "YouTube's recommendation systems none of",
  "130:35": "them are wanting to promote conspiracy",
  "130:37": "theories but people click on them right",
  "130:40": "and people share them and what tends to",
  "130:44": "happen is also people that are into",
  "130:47": "conspiracy theories consume a lot more",
  "130:49": "YouTube media so it actually is very",
  "130:52": "good at finding a market that watches a",
  "130:55": "lot of hours of YouTube and then it",
  "130:57": "makes that market watch even more so",
  "130:59": "this is an example of a feedback loop",
  "131:02": "and the New York Times as net is now",
  "131:05": "describing YouTube is perhaps the most",
  "131:06": "powerful radicalizing instrument of the",
  "131:09": "21st century I can tell you my friends",
  "131:12": "that worked on the YouTube",
  "131:13": "recommendation system did not think they",
  "131:16": "were creating the most powerful",
  "131:18": "radicalizing instrument of the 21st",
  "131:20": "century and to be honest most of them",
  "131:23": "today when I talk to them still think",
  "131:26": "they're not they think it's all",
  "131:28": "you know not all of them but a lot of",
  "131:31": "them now are at the point where they",
  "131:33": "just feel like they're the victims here",
  "131:35": "people are unfairly you know they don't",
  "131:37": "get it they don't understand what we're",
  "131:38": "trying to do it's very very difficult",
  "131:41": "right out there in the heart of it so",
  "131:43": "you've got to be thinking from rad at",
  "131:45": "the start what are the possible",
  "131:47": "unintended consequences of what you're",
  "131:50": "working on and as the technical people",
  "131:52": "involved how can you get out in front",
  "131:54": "and make sure that people are aware of",
  "131:56": "them and I just also need to say that in",
  "131:59": "particular many of these conspiracy",
  "132:00": "theories are promoting white supremacy",
  "132:03": "they're you know kind of far-right after",
  "132:05": "no nationalism anti-science and i think",
  "132:08": "you know maybe five or ten years ago I",
  "132:11": "would have thought conspiracy theories",
  "132:12": "are more a more fringe thing but we're",
  "132:14": "seeing the kind of huge societal impact",
  "132:16": "it can have for many people to believe",
  "132:18": "these know and you know partly it's you",
  "132:21": "see them on YouTube all the time it",
  "132:22": "starts to feel a lot more normal right",
  "132:25": "so one of the things that people are",
  "132:26": "doing to try to say like how to fix this",
  "132:29": "problem is to explicitly get involved in",
  "132:32": "talking to the people who might or will",
  "132:34": "be impacted by the kind of decision",
  "132:36": "making processes that you're enabling so",
  "132:38": "for example there was a really cool",
  "132:40": "thing recently where literally",
  "132:43": "statisticians and data scientists got",
  "132:46": "together with people who had been inside",
  "132:50": "the criminal system ie had gone through",
  "132:52": "the the bail and sentencing process of",
  "132:54": "criminals themselves and talking to the",
  "132:56": "lawyers who worked with them and put",
  "132:58": "them together with the data scientists",
  "133:00": "and actually kind of put together a",
  "133:02": "timeline of how exactly does it work and",
  "133:05": "where exactly the other places that",
  "133:07": "there are inputs and how do people",
  "133:08": "respond to them and who's involved this",
  "133:10": "is really cool right this is the only",
  "133:12": "way for you as a kind of a data product",
  "133:16": "developer to actually know how your data",
  "133:18": "products going to be working a really",
  "133:20": "great example of a somebody who did a",
  "133:22": "great job here was Evan s dollar at",
  "133:24": "Meetup who said hey a lot of men are",
  "133:29": "going to our tech meetups and if we use",
  "133:32": "a recommendation system naively it's",
  "133:35": "going to recommend more tech meetups to",
  "133:37": "man which is going to cause more men to",
  "133:40": "go to them and then when women do try to",
  "133:41": "go they'll be like oh my god there's so",
  "133:43": "many men here we're just going to cause",
  "133:45": "more men to go to the tech meetups yeah",
  "133:48": "yeah so showing recommendations to men",
  "133:50": "and therefore not showing them to women",
  "133:52": "yes yeah",
  "133:54": "so so what Evan and made-up decided was",
  "134:00": "to make an explicit product decision",
  "134:01": "that this would not even be representing",
  "134:06": "the actual true preferences of people it",
  "134:08": "would be creating a runaway feedback",
  "134:10": "loop so let's explicitly stop it right",
  "134:12": "before it happens and and not recommend",
  "134:17": "less made ups to women and tech meetups",
  "134:20": "women and more tech meetups",
  "134:21": "come in and so I think that's that's",
  "134:23": "just it's really cool it's like it's",
  "134:25": "saying we don't have to be slaves to the",
  "134:27": "algorithm we actually get to decide",
  "134:30": "another thing that people can do to help",
  "134:34": "is regulation and normally when we kind",
  "134:37": "of talk about regulation there's a",
  "134:39": "natural reaction of like how do you",
  "134:41": "regulate these things that's ridiculous",
  "134:43": "you can't regulate AI but actually when",
  "134:45": "you look at it again and again and this",
  "134:47": "fantastic paper core data sheets for",
  "134:49": "data sets has lots of examples of this",
  "134:52": "there are many many examples of",
  "134:54": "industries where people thought they",
  "134:57": "couldn't be regulated people thought",
  "134:58": "that's just how it was like cars people",
  "135:01": "died in cars all the time because they",
  "135:03": "literally had sharp metal knobs on",
  "135:05": "dashboards steering columns weren't",
  "135:07": "collapsible and all of the discussion in",
  "135:10": "the community was that's just how cars",
  "135:13": "are and when people died in cars it's",
  "135:15": "because of the people but then",
  "135:17": "eventually the regulations did come in",
  "135:19": "and today driving is dramatically safer",
  "135:22": "like dozens and dozens of times safer",
  "135:25": "than it was before",
  "135:27": "right so often there are things we can",
  "135:29": "do through policy so to summarize we are",
  "135:35": "part of the point three to 0.5% of the",
  "135:38": "world that knows how to code all right",
  "135:41": "we have a school that very few other",
  "135:43": "people do not only that we now know how",
  "135:45": "to code deep learning algorithms which",
  "135:47": "is like the most powerful kind of code I",
  "135:49": "know so I'm hoping that we can",
  "135:51": "explicitly think about like at least not",
  "135:55": "making the world worse and perhaps",
  "135:56": "explicitly making it better right and so",
  "136:00": "why is this interesting to you as an",
  "136:02": "audience in particular and that's",
  "136:04": "because fast AI in particular is trying",
  "136:07": "to make it easy for domain experts to use",
  "136:11": "deep learning and so this picture of the",
  "136:13": "goats here is an example of one of our",
  "136:16": "international fellows from a previous",
  "136:18": "course who is a goat dairy farmer and",
  "136:21": "told us that they were going to use deep",
  "136:24": "learning on their remote Canadian Island",
  "136:26": "to help study other disease in goats",
  "136:29": "that and to me this is a great example",
  "136:31": "of like a domain experts problem which",
  "136:34": "nobody else even knows about let alone",
  "136:36": "know that as a computer vision problem",
  "136:38": "that can be solved with deep learning so",
  "136:40": "in your field whatever it is you",
  "136:44": "probably know a lot more now about the",
  "136:48": "opportunities in your field to make it a",
  "136:50": "hell of a lot better than it was before",
  "136:52": "you're probably to come up with all",
  "136:54": "kinds of cool product ideas right maybe",
  "136:57": "be able to startup or create a new",
  "136:59": "product group in your company or",
  "137:00": "whatever but also let us be thinking",
  "137:04": "about what that's going to mean in",
  "137:06": "practice and think about where can you",
  "137:08": "put humans in the loop right where can",
  "137:11": "you put those pressure release valves",
  "137:13": "who are the people you can talk to who",
  "137:15": "could be impacted who could help you",
  "137:17": "understand right and get the kind of",
  "137:19": "humanities folks involved to understand",
  "137:21": "history and psychology and sociology and",
  "137:24": "so forth so that's our plea to you if",
  "137:27": "you've got this far you're definitely at",
  "137:30": "a point now where you're ready to you",
  "137:31": "know make a serious impact on the world",
  "137:34": "so I hope we can make sure that that's a",
  "137:36": "positive impact see you next week"
}
