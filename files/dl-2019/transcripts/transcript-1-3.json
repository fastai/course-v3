{
  "00:00": "welcome back to lesson three so we're",
  "00:05": "going to start with a quick correction",
  "00:06": "which is to let you know that when we",
  "00:09": "referred to this chart is coming from",
  "00:11": "Chora",
  "00:11": "last week we were correct it did come",
  "00:13": "from Chora but actually we realized",
  "00:15": "originally it came from Andrew earns",
  "00:17": "excellent machine learning course on",
  "00:19": "Coursera so apologies for the incorrect",
  "00:21": "citation but in exchange let's talk",
  "00:24": "about Andrew owns excellent machine",
  "00:25": "learning course on Coursera it's it's",
  "00:28": "really great as you can see people gave",
  "00:31": "it four point nine out of five stars in",
  "00:34": "some ways it's a little dated but a lot",
  "00:36": "of the content really is as as",
  "00:40": "appropriate as ever and taught in a more",
  "00:42": "bottom-up style so it can be quite nice",
  "00:45": "to combine andrew's bottom-up style and",
  "00:47": "our top-down style and meet somewhere in",
  "00:49": "the middle also if you're interested in",
  "00:51": "more machine learning foundations you",
  "00:54": "should check out our machine learning",
  "00:55": "course as well if you go to course too",
  "00:57": "fast at AI and click on the machine",
  "00:59": "learning button that will take you to",
  "01:00": "our course which is about twice as long",
  "01:03": "as this deep learning course and kind of",
  "01:06": "takes you much more gradually through",
  "01:07": "some of the foundational stuff around",
  "01:09": "validation sets and model interpretation",
  "01:12": "and our PI torch tensors work and and",
  "01:15": "stuff like that so I think all these",
  "01:18": "courses together if you want to really",
  "01:20": "dig deeply into the material do all of",
  "01:23": "them I know a lot of people who have and",
  "01:25": "end up saying oh I got more out of each",
  "01:27": "one by doing the whole lot or you can",
  "01:29": "skip back within four words see which",
  "01:30": "one works for you so we started talking",
  "01:37": "about deploying your web app last week",
  "01:41": "one thing that's going to make life a",
  "01:43": "lot easier for you is that on the course",
  "01:45": "v3 website there's a production section",
  "01:49": "where right now we have one platform but",
  "01:53": "more will be added by the time this",
  "01:54": "video comes out showing you how to",
  "01:56": "deploy your web app really really easily",
  "01:59": "and when I say easily for example here's",
  "02:03": "the how to deploy on site guide created",
  "02:06": "by San Francisco study group member neph",
  "02:09": "John as you can see it it's just a page",
  "02:11": "there's almost nothing to do",
  "02:13": "and it's free it's not going to serve",
  "02:17": "10,000 simultaneous requests but it'll",
  "02:22": "certainly get you started and I found it",
  "02:24": "works really well it's fast and so",
  "02:27": "deployment you know deploying a model",
  "02:29": "doesn't have to be slow more complicated",
  "02:31": "anymore",
  "02:32": "and the nice thing is you can kind of",
  "02:34": "use this for an MVP and if you do find",
  "02:36": "just started to get a thousand",
  "02:37": "simultaneous requests then you know that",
  "02:40": "things are working out and you can start",
  "02:41": "to you know upgrade your instance types",
  "02:43": "or you know add to a more traditional",
  "02:45": "you know big engineering approach so if",
  "02:49": "you actually use this starter kit it",
  "02:53": "will actually create my teddy bear",
  "02:55": "finder for you and this is an example of",
  "02:58": "my teddy bear fighter so the idea is",
  "02:59": "it's like it's as simple as possible",
  "03:01": "this template so you can fill in your",
  "03:05": "own style sheets your own custom logic",
  "03:07": "and so forth this is kind of designed to",
  "03:09": "be a minimal thing so you can see",
  "03:11": "exactly what's going on the back end is",
  "03:13": "a simple kind of rest style you know",
  "03:17": "interface it sends back JSON and the",
  "03:20": "front end is a super simple little",
  "03:22": "JavaScript thing so yeah it should be a",
  "03:27": "good way to get a sense of how to build",
  "03:29": "a web app which talks to a PI torch",
  "03:33": "model so examples of web apps people",
  "03:38": "have built during the week",
  "03:41": "Edward Ross built the what car is that",
  "03:44": "Apple more specifically the what",
  "03:46": "Australian car is that is that I thought",
  "03:49": "it was kind of interesting that Edward",
  "03:50": "said on the forum that the building of",
  "03:52": "the app was actually a great experience",
  "03:55": "in terms of understanding how dumb how",
  "03:57": "the model works himself better and like",
  "04:04": "it's it's a it's interesting that he's",
  "04:06": "describing like trying it out on his",
  "04:08": "phone lot of people think like oh if I",
  "04:10": "want something on my phone I have to",
  "04:11": "create some kind of mobile tensorflow",
  "04:13": "onn X whatever tricky mobile app you",
  "04:17": "really don't you can run it all in the",
  "04:19": "cloud and make it just a web app or use",
  "04:21": "some kind of simple little GUI front-end",
  "04:25": "that talks to a",
  "04:26": "back end it's not that often that you'll",
  "04:29": "need to actually run stuff on the phone",
  "04:31": "so this is a good example of that",
  "04:35": "see Werner has created a guitar",
  "04:38": "classifier you can decide whether your",
  "04:42": "food is healthy or not apparently this",
  "04:44": "one is healthy that can't be right I",
  "04:46": "would have thought of hamburger is more",
  "04:47": "what we're looking for but there you go",
  "04:51": "apparently Trinidad and Tobago is the",
  "04:53": "home of the hummingbird so if you're",
  "04:55": "visiting you can find out what kind of",
  "04:56": "hummingbirds you're looking at you can",
  "04:59": "decide whether or not to eat a mushroom",
  "05:01": "if you happen to be one of the cousins",
  "05:04": "of Charlie Harrington you can now figure",
  "05:07": "out who is who I believe this was",
  "05:08": "actually designed for his fiancee even",
  "05:11": "will tell you about the interests of",
  "05:13": "this particular cousin so you know",
  "05:15": "fairly niche application but you know",
  "05:17": "apparently there are 36 people who will",
  "05:20": "appreciate this at least I have no",
  "05:24": "cousins that's a lot of cousins this is",
  "05:27": "an example of a a nap which actually",
  "05:30": "takes a video feed and turns it into an",
  "05:32": "emotion classifier that's pretty cool I",
  "05:39": "like it",
  "05:42": "team 26 good job here's a similar one",
  "05:49": "for American Sign Language and so like",
  "05:54": "it's it's not a big step from taking a",
  "05:57": "single image model to taking a video",
  "06:01": "model you can just grab the occasional",
  "06:02": "frame put it through your model and and",
  "06:05": "update the update the UI as the kind of",
  "06:10": "model results come in so it's really",
  "06:12": "cool that you can do this kind of stuff",
  "06:14": "either in plant or in browser nowadays",
  "06:21": "Henri plushie is built your city from",
  "06:26": "space which he describes as creepy how",
  "06:31": "accurate it is so here's why I live",
  "06:34": "which it figured out was in the United",
  "06:35": "States it's interesting he describes",
  "06:37": "here how he actually had to be very",
  "06:40": "thoughtful",
  "06:40": "the validation set he built make sure",
  "06:43": "that the satellite tails were not",
  "06:45": "overlapping or close to each other and",
  "06:47": "doing so he realized he had to download",
  "06:48": "more data but once he did he got this",
  "06:51": "amazingly effective model that can look",
  "06:54": "at satellite imagery and figure out what",
  "06:55": "country it's from I thought this one was",
  "06:58": "pretty interesting which was doing",
  "07:01": "univariate time series analysis by",
  "07:03": "converting it into a picture using",
  "07:07": "something I've never heard of a gradient",
  "07:09": "angular field but he says he's getting",
  "07:12": "closer to say that the results for",
  "07:14": "univariate time series modeling into a",
  "07:17": "picture and so I like this is I like",
  "07:19": "this idea of turning stuff that's not a",
  "07:21": "picture into a picture so something",
  "07:26": "really interesting about this project",
  "07:27": "which was looking at a motion",
  "07:30": "classification from faces was that he",
  "07:33": "was specifically asking the question how",
  "07:35": "well does it go without changing",
  "07:36": "anything just using the default settings",
  "07:38": "which i think is a really interesting",
  "07:39": "experiment because we were all told it's",
  "07:42": "really hard to train models and it takes",
  "07:44": "a lot of you know specific knowledge and",
  "07:47": "actually we're finding that that's often",
  "07:48": "not the case and he looked at this",
  "07:51": "facial expression recognition dataset",
  "07:54": "there was a 20-17 paper that he compared",
  "07:56": "his results to and he got equal more",
  "08:00": "slightly better results than the state",
  "08:02": "of the art paper on face recognition",
  "08:04": "recognition without doing any customer",
  "08:07": "eye perimeter training at all so that",
  "08:09": "was really cool and then Elena Harley",
  "08:12": "who I featured one of her works last",
  "08:16": "week has done another really cool work",
  "08:18": "in the genomic space which is looking at",
  "08:25": "variant analysis looking at false",
  "08:28": "positives in these kinds of pictures and",
  "08:33": "she found she was able to decrease the",
  "08:35": "number of false positives coming out of",
  "08:37": "the kind of industry standard software",
  "08:39": "she was using by 500% by using a deep",
  "08:44": "learning workflow I think this is a nice",
  "08:47": "example of something where if you are",
  "08:48": "going through you know spending hours",
  "08:51": "every day looking at",
  "08:53": "in this case looking at you know it's",
  "08:55": "kind of get rid of the false positives",
  "08:56": "maybe you can make that a lot faster by",
  "08:59": "using deep learning to do a lot of the",
  "09:00": "work for you and again this is an",
  "09:03": "example of a computer vision based",
  "09:05": "approach on something which originally",
  "09:07": "wasn't actually images so that was yeah",
  "09:11": "that's a really cool application so",
  "09:15": "really nice to see what people have been",
  "09:17": "building in terms of both web apps and",
  "09:20": "just classifiers what we're going to do",
  "09:22": "today is look at a whole lot more",
  "09:24": "different types of model that you can",
  "09:26": "build and we're going to kind of zip",
  "09:28": "through them pretty quickly and then",
  "09:29": "we're going to go back and say like oh",
  "09:31": "how did all these things work what's the",
  "09:33": "common denominator but all of these",
  "09:35": "things you can create web apps from",
  "09:38": "these as well but you'll have to think",
  "09:41": "about how to slightly change that",
  "09:43": "template to make it work with these",
  "09:45": "different applications I think that'll",
  "09:47": "be a really good exercise in making sure",
  "09:49": "you understand the material so the first",
  "09:52": "one we're going to look at is a data set",
  "09:54": "of satellite images and satellite",
  "09:57": "imaging is a really fertile area for",
  "10:03": "deep learning it's certainly a lot of",
  "10:05": "people already using deep learning and",
  "10:07": "satellite imaging but only scratching",
  "10:09": "the surface and the data set that we're",
  "10:11": "going to look at looks like this it has",
  "10:15": "satellite tiles and for each one as you",
  "10:19": "can see there's a number of different",
  "10:21": "labels for each tile one of the labels",
  "10:25": "or way always represents the weather",
  "10:27": "that's shown so in this case cloudy or",
  "10:29": "partly cloudy and then all of the other",
  "10:33": "labels tell you any interesting features",
  "10:36": "that are seen there so primary means",
  "10:38": "primary rainforest agriculture means",
  "10:41": "there's some farming road road and so",
  "10:44": "forth so as I'm sure you can tell this",
  "10:47": "is a little different to all the",
  "10:49": "classifiers we've seen so far because",
  "10:51": "there's not just one label is",
  "10:53": "potentially multiple labels so",
  "10:55": "multi-label classification can be done",
  "10:57": "in a very similar way but the first",
  "11:00": "thing we're going to need to do is to",
  "11:01": "download the data now this data comes",
  "11:04": "from cattle cargo is",
  "11:06": "known for being a competitions website",
  "11:08": "and its really great to download data",
  "11:10": "from Kegel when you're learning because",
  "11:13": "you can see how would I have gone in",
  "11:14": "that competition and it's a good way to",
  "11:16": "see whether you kind of know what you're",
  "11:18": "doing I tend to think the goal is to try",
  "11:21": "and get in the top 10% and in my",
  "11:23": "experience all the people in the top 10%",
  "11:25": "of a competition really know what",
  "11:28": "they're doing",
  "11:29": "so if you can get in the top 10% then",
  "11:31": "and that's a really good sign",
  "11:34": "pretty much every Kegel data set is not",
  "11:36": "available for download outside of cattle",
  "11:38": "at least the competition data sets so",
  "11:41": "you have to download it through cattle",
  "11:42": "and the good news is that cowbell",
  "11:44": "provides a python-based download at all",
  "11:47": "which you can use so we've got a quick",
  "11:50": "description here of how to download",
  "11:52": "stuff from cattle so to install stuff to",
  "11:57": "download stuff from cattle you first",
  "11:59": "have to install the the cattle download",
  "12:02": "tool so just pip install cattle and so",
  "12:04": "you can see what we tend to do when",
  "12:06": "there's one-off things to do is we show",
  "12:08": "you the commented out version in the",
  "12:10": "notebook and you can just remove the",
  "12:11": "comment so here's a cool tip for you if",
  "12:13": "you select a few lines and then hit",
  "12:16": "control slash it uncomment them all and",
  "12:19": "then when you're done select them again",
  "12:21": "control slash again and recommence the",
  "12:23": "ball okay so if you run this line it'll",
  "12:27": "install cattle for you depending on your",
  "12:30": "platform you may need sudo you may need",
  "12:34": "slash something else slash pip you may",
  "12:38": "need source activate so have a look on",
  "12:40": "the setup instructions actually the",
  "12:43": "returning to work instructions on the",
  "12:45": "course website to see like when we do",
  "12:48": "condor install you have to do the same",
  "12:51": "basic steps for your pip install so once",
  "12:56": "you've got that module installed you can",
  "13:00": "then go ahead and download the data and",
  "13:02": "basically it's as simple as saying calc",
  "13:05": "or competitions download the competition",
  "13:08": "name and then the files that you want",
  "13:12": "the only other steps before you do that",
  "13:13": "is that you have to authenticate",
  "13:16": "yourself and you'll see there's a little",
  "13:18": "bit of information here on",
  "13:20": "exactly how you can go about downloading",
  "13:21": "from Kegel the the file containing your",
  "13:25": "your API authentication information so I",
  "13:28": "won't bother going through it here but",
  "13:30": "is follow these deaths sometimes stuff",
  "13:34": "on Kegel is not just zipped or tired but",
  "13:38": "it's compressed with a program called",
  "13:40": "7-zip which will have a 7z extension if",
  "13:45": "that's the case you'll need to either",
  "13:47": "app to install P 7-zip or here's",
  "13:51": "something really nice some kind person",
  "13:53": "has actually created a condor",
  "13:54": "installation of 7-zip that works on",
  "13:56": "every platform so you can always just",
  "13:58": "run this condor install doesn't even",
  "14:00": "require a sudo or anything like that and",
  "14:03": "this is actually a good example of where",
  "14:04": "condor is super handy is that you can",
  "14:06": "actually install binaries and libraries",
  "14:08": "and and stuff like that and it's nicely",
  "14:10": "cross-platform so that's a good if you",
  "14:13": "don't have 7-zip installed that's a good",
  "14:15": "way to get get it and so this is how you",
  "14:19": "unzip a 7-zip file in this case it's",
  "14:23": "tired and 7-zip so you can do this all",
  "14:26": "in one step",
  "14:29": "so 7z a is the name of the 7-zip archive",
  "14:32": "a program that you would run okay so",
  "14:34": "that's all basic stuff which if you're",
  "14:37": "not so familiar with the command line",
  "14:39": "and stuff it might take you a little bit",
  "14:40": "of experimenting to get it working feel",
  "14:42": "free to ask on the forum make sure you",
  "14:44": "yes",
  "14:45": "search the forum first to get started",
  "14:49": "okay so once you've got the data",
  "14:51": "downloaded and unzipped you can take a",
  "14:55": "look at it so in this case so in this",
  "15:00": "case because we have multiple labels for",
  "15:04": "each tile we we clearly can't have a",
  "15:08": "different folder for each image telling",
  "15:11": "us what the label is we need some",
  "15:12": "different way to label it and so the way",
  "15:15": "the Cavill did it was they provided a",
  "15:17": "CSV file that had each file name along",
  "15:21": "with a list of all of the labels in",
  "15:25": "order to just take a look at that CSV",
  "15:27": "file we can read it using the pandas",
  "15:29": "library if you haven't used pandas",
  "15:32": "before it's kind of",
  "15:33": "the standard way of dealing with tabular",
  "15:36": "data in in Python pretty much always",
  "15:41": "appears on the PD namespace in this case",
  "15:43": "really well not really doing anything",
  "15:44": "with it other than just showing you the",
  "15:47": "contents of this file so we can read it",
  "15:49": "we can take a look at the first few",
  "15:50": "lines and there it is so we want to turn",
  "15:54": "this into something we can use for",
  "15:58": "modeling so the kind of object that we",
  "16:02": "use for modeling is an object of the",
  "16:04": "data bunch plus so we have to somehow",
  "16:07": "create a data bunch out of this once we",
  "16:10": "have a data bunch we'll be able to go",
  "16:12": "show batch to take a look at it and then",
  "16:15": "we'll be able to go create CNN with it",
  "16:17": "and then we will be the start training",
  "16:18": "okay so really the the trickiest step",
  "16:23": "previously in deep learning has often",
  "16:25": "been getting your data into a form that",
  "16:27": "you can get it into a model so far we've",
  "16:32": "been showing you how to do that using",
  "16:33": "various um factory methods so methods",
  "16:36": "where you basically say I want to create",
  "16:38": "this kind of data from this kind of",
  "16:40": "sauce with these kinds of options the",
  "16:42": "problem is I've been that works fine",
  "16:44": "sometimes when we showed you a few ways",
  "16:46": "of doing it over the last couple of",
  "16:47": "weeks but sometimes you want more",
  "16:52": "flexibility because there's so many",
  "16:53": "choices that you have to make about",
  "16:56": "where do where do the files live and",
  "16:58": "what's the structure they're in and how",
  "16:59": "do the labels appear and how do you spit",
  "17:01": "out the validation set and how do you",
  "17:03": "transform it and so forth so we've got",
  "17:06": "this unique API that I'm really proud of",
  "17:09": "called the data block API and the data",
  "17:12": "block API makes each one of those",
  "17:14": "decisions a separate decision that you",
  "17:16": "make there's separate methods and with",
  "17:18": "their own parameters for every choice",
  "17:20": "that you make around how do I create you",
  "17:22": "know set up my data so for example to",
  "17:27": "grab the planet data we would say we've",
  "17:29": "got a list of image files that are in a",
  "17:32": "folder and they're labeled based on a",
  "17:34": "CSV with this name they have this",
  "17:37": "separator remember I showed you back",
  "17:39": "here that there's a space between them",
  "17:41": "so by passing in separator it's going to",
  "17:43": "create multiple labels the images are in",
  "17:45": "this folder they have",
  "17:46": "Suffolk's we're going to randomly split",
  "17:49": "out a validation set with 20% of the",
  "17:51": "data we're going to create data sets",
  "17:53": "from that which were then going to",
  "17:55": "transform with these transformations and",
  "17:58": "then we're going to create a data bunch",
  "17:59": "out of that which will then normalize",
  "18:01": "using these statistics so there's all",
  "18:04": "these different steps so to give you a",
  "18:07": "sense of what that looks like the first",
  "18:11": "thing I'm going to do is kind of go back",
  "18:13": "and explain what are all of the PI torch",
  "18:16": "and fast they are kind of classes that",
  "18:18": "you need to know about that are going to",
  "18:20": "appear in this process because you're",
  "18:23": "good you're going to see them all the",
  "18:24": "time in the first day I Docs and the PI",
  "18:26": "torch does so the first one you need to",
  "18:31": "know about is a class called a data set",
  "18:33": "and the data set class is part of PI",
  "18:37": "torch and this is the source code for",
  "18:40": "the data set class as you can see it",
  "18:43": "actually does nothing at all so the data",
  "18:52": "set class in PI torch defines two things",
  "18:56": "get item and when in python these",
  "18:59": "special things that are underscore",
  "19:01": "underscore something underscore",
  "19:03": "underscore - Easter's call them dunder",
  "19:06": "some things this would be done to get",
  "19:07": "item dunder lin and they're basically",
  "19:10": "special magical methods that do some",
  "19:14": "special behavior and this particular",
  "19:16": "method you can look them up in the",
  "19:17": "python docs this particular method means",
  "19:20": "that your object if you had an object",
  "19:22": "called o can be indexed with square",
  "19:25": "brackets something like that right so",
  "19:28": "that would call get item with three as",
  "19:31": "the index and then this one called len",
  "19:33": "means that you can go Len o",
  "19:37": "and it will call that method and you can",
  "19:40": "see in this case they're both not",
  "19:42": "implemented so that is to say although",
  "19:44": "pi torch says you tell them to tell",
  "19:49": "piped watch about your data you have to",
  "19:50": "create a data set it doesn't really do",
  "19:52": "anything to help you create the data set",
  "19:55": "it just defines what the data set needs",
  "19:57": "to do so in other words your data this",
  "20:00": "data",
  "20:00": "pure data is something where you can see",
  "20:02": "what is the third item of data in my",
  "20:05": "data set so that's what getitem does and",
  "20:08": "how big is my data set that's what the",
  "20:10": "length does so first AI has lots of data",
  "20:16": "set subclasses that do that for all",
  "20:18": "different kinds of stuff and so so far",
  "20:21": "you've been seeing image classification",
  "20:24": "data sets and so their data sets where",
  "20:26": "getitem will return an image and a",
  "20:30": "single label of what is that image so",
  "20:34": "that's what a data set is now a data set",
  "20:38": "is not enough to train a model the first",
  "20:41": "thing we know we know we have to do if",
  "20:42": "you think back to the gradient descent",
  "20:45": "tutorial last week is we have to have a",
  "20:48": "few images or a few items at a time so",
  "20:52": "that our GPU can work in parallel",
  "20:54": "remember we do this this thing called a",
  "20:56": "mini batch so mini batches a few items",
  "20:58": "that we present to the model at a time",
  "21:00": "that it can train from in parallel so to",
  "21:03": "create a mini batch we use another PI",
  "21:07": "torch another pipe torch plus quite a",
  "21:11": "data loader and so a data loader takes a",
  "21:15": "data set in its constructor so it's now",
  "21:19": "saying oh this is something I can get",
  "21:21": "the third item and the fifth item in the",
  "21:22": "ninth item and it's going to grab items",
  "21:25": "at random and create a batch of whatever",
  "21:29": "size you asked for and passed and pop it",
  "21:32": "on the GPU and send it off to your model",
  "21:35": "for you right so a data loader is",
  "21:36": "something that grabs individual items",
  "21:39": "combines them into a mini batch pops",
  "21:41": "them on the GPU for modeling so that's",
  "21:44": "quite a data loader and that comes from",
  "21:46": "a data set so you can see already",
  "21:49": "there's kind of choices you have to make",
  "21:51": "you know what kind of data set am i",
  "21:52": "creating what is the data for it where",
  "21:54": "it's going to come from and then when I",
  "21:55": "create my data load or what batch size",
  "21:57": "do I want to use right it still isn't",
  "22:00": "enough to train a model not really",
  "22:02": "because we've got no way to validate the",
  "22:05": "model if all we have is a training set",
  "22:07": "then we have no way to know how we're",
  "22:09": "doing because we need a separate set of",
  "22:11": "held out data a validation set",
  "22:14": "see how we're getting along so for that",
  "22:16": "we use a fast a a class called a data",
  "22:20": "bunch and a data bunch is something",
  "22:22": "which as it says here binds together a",
  "22:24": "training data loader and a valid data",
  "22:27": "loader and when you look at the fast AI",
  "22:31": "Docs when you see these kind of mono",
  "22:34": "spaced font things they're always",
  "22:36": "referring to some symbol you can look up",
  "22:38": "elsewhere so in this case you can see",
  "22:39": "train DL is here and there's their point",
  "22:43": "knowing what an act that there's an",
  "22:45": "argument with a certain name with unless",
  "22:47": "you know what that argument is so you",
  "22:50": "should always look after the colon to",
  "22:52": "find out that is a data loader ok so",
  "22:54": "when you create a data Bunch",
  "22:56": "you're basically giving it a training",
  "22:57": "set data loader and a validation set",
  "23:00": "data loader and that's now an object",
  "23:03": "that you can send off to a learner and",
  "23:05": "start that loading so they're the basic",
  "23:10": "pieces so coming back to here this stuff",
  "23:20": "plus this line is all the stuff which",
  "23:23": "create is creating the data set so it's",
  "23:25": "saying read of the images come from",
  "23:27": "because the data set the indexer returns",
  "23:29": "two things it returns the the image and",
  "23:32": "the labels assuming it's an image data",
  "23:34": "set so what are the images come from",
  "23:35": "where do the labels come from and then",
  "23:38": "I'm going to create two separate data",
  "23:40": "sets the training and the validation",
  "23:41": "this is the thing that actually turns",
  "23:43": "them into piped watch data sets this is",
  "23:45": "the thing that transforms them okay and",
  "23:49": "then this is actually going to create",
  "23:50": "the the data loader and the data bunch",
  "23:54": "in one in one go so let's look at some",
  "23:57": "examples of this data block API because",
  "24:00": "once you understand the data block API",
  "24:02": "you'll never be lost for how to convert",
  "24:05": "your data set into something you can",
  "24:07": "start modeling with so here's some",
  "24:11": "examples of using the data block API so",
  "24:13": "for example if you're looking at m mist",
  "24:15": "which remember is the pictures and",
  "24:18": "classes of handwritten numerals you can",
  "24:25": "do something like this",
  "24:27": "this what kind of data set is this going",
  "24:29": "to be it's going to be an it's going to",
  "24:31": "come from a list of image files which",
  "24:34": "are in some folder and they're labeled",
  "24:38": "according to the folder name that",
  "24:41": "they're in and then we're going to split",
  "24:44": "it into trained and validation according",
  "24:47": "to the folder that they're in trainer",
  "24:49": "validation you can optionally add a test",
  "24:52": "set we're going to be talking more about",
  "24:54": "test sets later in the course ok we'll",
  "24:58": "convert those into PI torch data sets",
  "25:00": "now that that's all set up",
  "25:01": "well then transform them using this set",
  "25:06": "of transforms and we're going to",
  "25:09": "transform into something of this size",
  "25:11": "and then we're going to convert them",
  "25:13": "into a data bunch so each of those",
  "25:14": "stages inside these parentheses of",
  "25:16": "various parameters you can pass to",
  "25:20": "customize how that all works right but",
  "25:22": "in the case of something like this M",
  "25:23": "nest data set all the defaults pretty",
  "25:26": "much work so this is all fine",
  "25:29": "so here it is so you can check let's",
  "25:31": "grab something so data dot trained es is",
  "25:34": "the data set not the data load of the",
  "25:36": "data set so I can actually index into it",
  "25:39": "with a particular number so here is the",
  "25:40": "zero indexed item in the training data",
  "25:44": "set it's got an image and a label or you",
  "25:47": "can show batch to see an example of the",
  "25:49": "pictures of it and we could then start",
  "25:51": "training here are the classes that are",
  "25:54": "in that data set and this a little cut",
  "25:56": "down sample of M nest has threes and",
  "25:58": "sevens here's an example using planet",
  "26:04": "this is actually again a sub little",
  "26:06": "subset of planet we use for you know",
  "26:09": "make it easy to try things out so in",
  "26:11": "this case again it's an image file list",
  "26:13": "again we grabbing it from a folder this",
  "26:16": "time we're labeling it based on a CSV",
  "26:17": "file we randomly splitting it by default",
  "26:20": "it's 20%",
  "26:21": "creating data sets transforming it using",
  "26:24": "these transforms we're going to use a",
  "26:28": "smaller size and then create a data",
  "26:30": "bunch there it is and so don't a bunch",
  "26:35": "just know how to draw themselves amongst",
  "26:37": "other things so here's some more",
  "26:39": "examples we're going to be seeing some",
  "26:40": "seeing later today what if we look at",
  "26:43": "this data set called cam vid can vid",
  "26:46": "looks like this",
  "26:48": "it contains pictures and every pixel in",
  "26:51": "the picture is color coded right so in",
  "26:54": "this case we have a list of files in a",
  "26:57": "folder and we're going to label them in",
  "27:00": "this case using a function and so this",
  "27:03": "function is basically the thing we're",
  "27:05": "going to see it later which tells it",
  "27:07": "whereabouts of the color coding for each",
  "27:09": "pixel it's in a different place randomly",
  "27:13": "split it in some way create some",
  "27:15": "datasets in some way we can tell it for",
  "27:19": "a particular list of classes you know",
  "27:21": "how do we know what pixel it'll value 1",
  "27:24": "versus pixel value 2 is and that was",
  "27:26": "something that we can basically read in",
  "27:27": "like so again some transforms create a",
  "27:33": "data bunch you can optionally pass in",
  "27:35": "things like what batch size do you want",
  "27:37": "and again it knows how to draw itself",
  "27:39": "and you can start learning with that or",
  "27:41": "one more example what if we wanted to",
  "27:45": "create something like this it has like",
  "27:46": "bars and chair and remote control and",
  "27:50": "book this is called an object detection",
  "27:52": "data set so again we've got a little",
  "27:54": "minimal cocoa data set cocoa is kind of",
  "27:57": "the most famous academic data set for",
  "27:59": "object detection we can create it using",
  "28:02": "the same process grab a list of files",
  "28:04": "from a folder label them according to",
  "28:07": "this little function randomly split them",
  "28:10": "create an object detection data set",
  "28:12": "create a data bunch in this case as",
  "28:15": "you'll learn when we get to object",
  "28:16": "detection you have to use generally",
  "28:17": "small or batch sizes or your read out of",
  "28:19": "memory and as you'll also learn you have",
  "28:22": "to use something called a collation",
  "28:23": "function and once that's all done we can",
  "28:26": "again show it and here's our object",
  "28:28": "detection data set so you get the idea",
  "28:30": "right so here's a really convenient",
  "28:32": "notebook where will you find this ah",
  "28:35": "this notebook is the documentation",
  "28:38": "remember how I told you that all of the",
  "28:40": "documentation comes from notebooks",
  "28:41": "you'll find them in your faster yo repo",
  "28:44": "in Docs underscore sauce so this which",
  "28:48": "you can play with an experiment with",
  "28:50": "inputs and outputs and try all the",
  "28:51": "different parameters you will find",
  "28:54": "datablock api examples of use if you go",
  "28:56": "to the documentation here it is the data",
  "28:58": "plot API examples of use right so",
  "29:01": "remember everything that you want to use",
  "29:03": "in fast AI you can look it up in the",
  "29:05": "documentation so let's search data block",
  "29:13": "API go straight there and away you go",
  "29:22": "and so once you find some documentation",
  "29:24": "that you actually want to try playing",
  "29:26": "with yourself just look up the name data",
  "29:28": "block and then you can open up a",
  "29:30": "notebook with the same name in the first",
  "29:33": "day I repo and play with it yourself",
  "29:35": "okay so that's a quick overview of this",
  "29:40": "really nice data block API and there's",
  "29:42": "lots of documentation for all of the",
  "29:44": "different ways you can label label",
  "29:46": "inputs and split data and create data",
  "29:49": "sets and so forth and so that's what",
  "29:54": "we're using for planet",
  "29:55": "okay so we're using that API you'll see",
  "29:57": "like in the documentation these these",
  "30:02": "two steps we had all joined up together",
  "30:05": "we can certainly do that here too but",
  "30:07": "you'll learn in a moment why it is that",
  "30:10": "we're actually splitting these up into",
  "30:12": "two separate steps which is also fine as",
  "30:14": "well so a few interesting points about",
  "30:17": "this transforms so transforms by default",
  "30:25": "remember you can hit shift tab to get",
  "30:28": "all the information right transforms by",
  "30:30": "default will flip randomly each image",
  "30:35": "right but they'll actually randomly only",
  "30:38": "flip them horizontally which makes sense",
  "30:41": "right if you're trying to tell if",
  "30:42": "something is a cat or a dog doesn't",
  "30:44": "matter whether it's pointing left or",
  "30:45": "right but it wouldn't expect it to be",
  "30:47": "upside down on the other hand satellite",
  "30:49": "imagery whether something's cloudy or",
  "30:51": "hazy or whether there's a road there or",
  "30:53": "not it could absolutely be flipped",
  "30:55": "upside down there's no such thing as a",
  "30:56": "right way up from space so flip vert",
  "30:59": "which defaults to false we're going to",
  "31:02": "flip over to TRO to say like what",
  "31:04": "randomly you should actually do that and",
  "31:06": "it doesn't just flip it vertically it",
  "31:07": "actually tries also it",
  "31:08": "possible 90-degree rotation so there are",
  "31:11": "eight possible kind of symmetries that",
  "31:13": "it tries out so there's various other",
  "31:17": "things here I've found that these",
  "31:20": "particular settings work pretty well for",
  "31:22": "planet one that's interesting is warp",
  "31:27": "perspective warping is something which",
  "31:29": "very few libraries provide and those",
  "31:31": "that do provide it it tends to be really",
  "31:32": "slow",
  "31:33": "I think fast AI is the first work first",
  "31:35": "one to provide really fast perspective",
  "31:37": "warping and basically the reason this is",
  "31:39": "interesting is if I kind of look at you",
  "31:41": "from below versus look at you from above",
  "31:44": "they're kind of your shape changes right",
  "31:48": "and so when you're taking a photo of a",
  "31:51": "cat or a dog",
  "31:51": "you know sometimes you'll be higher",
  "31:53": "sometimes you'll be lower then that kind",
  "31:56": "of change of shape is certainly",
  "31:58": "something that you would want to include",
  "31:59": "as you're creating your training batches",
  "32:03": "you want to modify it a little bit each",
  "32:05": "time not true for satellite images a",
  "32:09": "satellite always points straight down at",
  "32:12": "the planet so if you added perspective",
  "32:15": "warping you would be making changes that",
  "32:17": "aren't going to be there in real life so",
  "32:19": "I turn that off so this is all something",
  "32:22": "called data augmentation we'll be",
  "32:23": "talking a lot more about it",
  "32:25": "later in the course but you can start to",
  "32:28": "get a feel for the kinds of things that",
  "32:29": "you can do to to augment your data and",
  "32:33": "in general maybe the most important one",
  "32:35": "is if you're looking at astronomical",
  "32:37": "data or kind of pathology you know",
  "32:40": "Digital slide data or satellite data you",
  "32:43": "know data where there isn't really an up",
  "32:45": "or down turning on flip verticals true",
  "32:48": "is generally going to make your models",
  "32:50": "generalize better okay so here's the",
  "32:55": "steps necessary to create our data bunch",
  "32:58": "and so now to create a satellite imagery",
  "33:03": "[Music]",
  "33:04": "classifier multi-label classifier that's",
  "33:07": "going to figure out for each satellite",
  "33:09": "tile what's the weather and what else",
  "33:11": "what can I see in it there's basically",
  "33:13": "nothing else to learn everything else",
  "33:15": "that you've already learnt is going to",
  "33:17": "be exactly nearly the same here it is",
  "33:21": "learn equals create see and",
  "33:22": "in data architecture right and in this",
  "33:27": "case when I first built built this",
  "33:30": "notebook I used resin at 34 as per usual",
  "33:33": "and I found this was a case I tried",
  "33:35": "resin at 50 as I always like to do I",
  "33:36": "found resin at 50 helped a little bit",
  "33:38": "and I had some time to run it so in this",
  "33:40": "case I was using resin at 15 there's one",
  "33:44": "more change I make which is metrics now",
  "33:49": "to remind you a metric has got nothing",
  "33:51": "to do with how the model trains changing",
  "33:55": "your metrics will not change your",
  "33:57": "resulting model at all the only thing",
  "34:00": "that we use metrics for is we print them",
  "34:02": "out during training so here it's",
  "34:04": "printing out accuracy and it's printing",
  "34:06": "out this other metric called F better so",
  "34:08": "if you're trying to figure out how to do",
  "34:11": "a better job with your model changing",
  "34:13": "the metrics will never be something that",
  "34:15": "you need to do they're there just to",
  "34:17": "show you how you're going so that's the",
  "34:21": "first thing to know you can have one",
  "34:23": "metric or no metrics or a list of",
  "34:25": "multiple metrics to be printed out as",
  "34:28": "your models training in this case I want",
  "34:31": "to know two things the first thing I",
  "34:33": "want to know is the accuracy and the",
  "34:36": "second thing I want to know is how would",
  "34:38": "I go on cattle and cattle",
  "34:40": "told me that I'm gonna be judged on a",
  "34:43": "particular metric called the F score so",
  "34:46": "I'm not gonna bother telling you about",
  "34:48": "the F score it's not really interesting",
  "34:49": "enough to be worth spending your time on",
  "34:51": "you can look it up but it's it's",
  "34:53": "basically this when you have a",
  "34:55": "classifier you're going to have some",
  "34:57": "false positives you're going to have",
  "34:59": "some false negatives how do you weigh up",
  "35:01": "those two things to kind of create a",
  "35:03": "single number there's lots of different",
  "35:05": "ways of doing that and something called",
  "35:07": "the F score has is basically a nice way",
  "35:11": "of combining that into a single number",
  "35:13": "and there are various kinds of F scores",
  "35:16": "F 1 F 2 and so forth and Kaggle said in",
  "35:20": "the competition rules we're going to use",
  "35:22": "a metric called",
  "35:23": "F 2 so we have a metric called F beta",
  "35:31": "which in other words it's f with 1 or 2",
  "35:34": "or whatever depending on the value",
  "35:36": "better and we can have a look at its",
  "35:38": "signature and you can see that it's got",
  "35:43": "a threshold in the beta okay so the",
  "35:45": "beater is 2 by default and cackled said",
  "35:48": "that we're going to use f2 so I don't",
  "35:51": "have to change that but there's one",
  "35:53": "other thing that I need to set which is",
  "35:56": "a threshold what does that mean well",
  "36:00": "here's the thing",
  "36:01": "do you remember we had a little look the",
  "36:04": "other day at the source code for the",
  "36:06": "accuracy metric so he put two question",
  "36:09": "marks you get the source code and we",
  "36:11": "found that it used this thing called AG",
  "36:13": "mix and the reason for that if you",
  "36:17": "remember was we we kind of had this you",
  "36:21": "know input image that came in and it",
  "36:24": "went through our model and at the end it",
  "36:28": "came out with a table of ten numbers",
  "36:32": "right this is like if we're doing M&S;",
  "36:34": "digit recognition and the ten numbers",
  "36:35": "were like the probability of each of the",
  "36:40": "possible digits and so then we had to",
  "36:42": "look through all of those and find out",
  "36:45": "which one was the biggest and so that",
  "36:48": "the function in num PI or PI torch or",
  "36:51": "just math notation that finds the",
  "36:53": "biggest in returns its index is called",
  "36:55": "Arg max all right so to get the accuracy",
  "37:01": "for our pet detector we use this",
  "37:03": "accuracy function the called Arg max to",
  "37:06": "find out behind the scenes which Plus ID",
  "37:10": "pet was the one that we're looking at",
  "37:12": "and then it compared that to the actual",
  "37:17": "and then took the average and that was",
  "37:21": "the that was the accuracy we can't do",
  "37:24": "that for satellite recognition in this",
  "37:27": "case because there isn't one label we're",
  "37:30": "looking for",
  "37:31": "there's lots so instead what we do is we",
  "37:35": "look at so in this case",
  "37:44": "so I don't know if you remember but a",
  "37:47": "data bunch has a special attribute",
  "37:48": "called C and C is going to be basically",
  "37:51": "how many outputs do we want our model to",
  "37:54": "create and so for any kind of classifier",
  "37:56": "we want one probability for each",
  "37:59": "possible class so in other words dated C",
  "38:02": "for classifiers is always going to be",
  "38:04": "equal to the length of data type classes",
  "38:08": "right so data dot classes there they all",
  "38:12": "are there's the 17 possibilities right",
  "38:14": "so there they're the we're going to have",
  "38:15": "one probability for each of those but",
  "38:18": "then we're not just going to pick out",
  "38:19": "one of those 17 we're going to pick out",
  "38:22": "any of those 17 and so what we do is we",
  "38:25": "compare each probability to some",
  "38:27": "threshold and then we say anything",
  "38:29": "that's higher than that threshold we're",
  "38:31": "going to assume that the models saying",
  "38:33": "it does have that feature and so we can",
  "38:36": "pick that threshold I found that for",
  "38:41": "this particular data set a threshold of",
  "38:43": "0.2 seems to generally work pretty well",
  "38:46": "this is the kind of thing you can easily",
  "38:47": "just experiment to find a good threshold",
  "38:49": "so I decided I want to print out the",
  "38:52": "accuracy at a threshold of 0.2 so the",
  "38:57": "normal accuracy function doesn't work",
  "38:59": "that way it doesn't Arg max we have to",
  "39:01": "use a different accuracy function called",
  "39:03": "accuracy underscore Thresh and that's",
  "39:05": "the one that's going to compare every",
  "39:07": "probability to a threshold and return",
  "39:09": "all the things higher than that",
  "39:10": "threshold and compare accuracy that way",
  "39:12": "and so one of the things we had passed",
  "39:14": "in is Thresh now of course our metric is",
  "39:20": "going to be calling our function for us",
  "39:22": "so we don't get to tell it every time",
  "39:24": "every time it calls back what threshold",
  "39:27": "do we want so we really want to create a",
  "39:29": "special version of this function that",
  "39:32": "always uses an accuracy of a threshold",
  "39:35": "of point two so one way to do that would",
  "39:37": "be could go define something called",
  "39:39": "accuracy o2 that takes some input and",
  "39:43": "some target and returns accuracy",
  "39:48": "threshold with that input and that",
  "39:51": "target and a threshold of 0.2",
  "39:56": "do it that way okay but it's so common",
  "40:00": "that you want to kind of say create a",
  "40:02": "new function that's just like that other",
  "40:05": "function that we're always going to call",
  "40:07": "it with a particular parameter that",
  "40:08": "computer science has a term for that",
  "40:10": "it's called a partial that's what a",
  "40:12": "partial function application and so",
  "40:13": "Python three has something called",
  "40:16": "partial that takes some function and",
  "40:19": "some lists of keywords and values and",
  "40:23": "creates a new function that is exactly",
  "40:26": "the same as this function that is always",
  "40:28": "going to call it with that keyword",
  "40:30": "argument so yeah this is exactly the",
  "40:33": "same thing as a thing I just typed in a",
  "40:35": "co2 is now a new function that calls",
  "40:38": "accuracy Thresh with a threshold 0.2 and",
  "40:40": "so this is a really common thing to do",
  "40:43": "particularly with the FASTA a library",
  "40:45": "because there's lots of places where you",
  "40:47": "have to pass in functions and you very",
  "40:50": "often want to pass in a slightly",
  "40:51": "customized version of a function so that",
  "40:53": "here's how you do it so here I've got an",
  "40:55": "accuracy threshold point - I've got a F",
  "40:59": "beta threshold point - I can pass them",
  "41:02": "both in his metrics and I can then go",
  "41:05": "ahead and do all the normal stuff LR",
  "41:07": "find recorded up plot find the thing",
  "41:11": "with the steepest slope so I don't know",
  "41:14": "somewhere around money Nick - so we'll",
  "41:17": "make that our learning rate and then fit",
  "41:19": "for awhile with five comma slice LR and",
  "41:22": "see how we go okay and so we've got an",
  "41:25": "accuracy of about 96% and an F beta of",
  "41:29": "about 0.9 to 6 and so you could then go",
  "41:33": "and have a look at Planet leaderboard",
  "41:38": "private leaderboard okay and so the top",
  "41:42": "fiftieth is about 0.93 so we kind of say",
  "41:46": "like oh we're on the right track okay",
  "41:48": "with some something we're doing we're",
  "41:50": "doing fine so as you can see like once",
  "41:52": "you get to a point that the data is",
  "41:54": "there it's very little extra - most of",
  "41:59": "the time so when your model makes an",
  "42:04": "incorrect prediction in a deployed app",
  "42:06": "is there a good way to record that air",
  "42:08": "and use that learning",
  "42:09": "improve the model in a more targeted way",
  "42:11": "oh yeah",
  "42:14": "that's a great question so the first bit",
  "42:16": "is there a way to record that couse",
  "42:18": "there is you record it that's up to you",
  "42:20": "right so maybe some of you can try it",
  "42:21": "this week have you you need to have your",
  "42:25": "user tell you you were wrong this",
  "42:28": "Australian car you said it was a holder",
  "42:30": "and actually it's a falcon so first of",
  "42:33": "all you'll need to collect that feedback",
  "42:34": "and the only way to do that is to ask",
  "42:36": "the user to tell you when it's wrong so",
  "42:39": "you an app need to record in some log",
  "42:40": "somewhere something saying you know this",
  "42:42": "was the file I've stored it here",
  "42:45": "this was the prediction I made this was",
  "42:47": "the extra life of you know this is the",
  "42:49": "actual that they told me and then at the",
  "42:52": "end of the day or at the end of the week",
  "42:54": "you could set up a little job to run",
  "42:55": "something or you can manually run",
  "42:58": "something and what are you going to do",
  "43:00": "you're going to do some fine-tuning",
  "43:02": "what does fine-tuning look like good",
  "43:04": "segue Rachel it looks like this",
  "43:06": "alright so let's pretend here's your",
  "43:09": "safe model right and so then we unfreeze",
  "43:13": "right and then we fit a little bit more",
  "43:17": "right now in this case I'm fitting with",
  "43:19": "my original data set but you could",
  "43:21": "create a new data bunch with just the",
  "43:25": "misclassified instances and go ahead and",
  "43:28": "fit right and the misclassified ones are",
  "43:32": "likely to be particularly interesting so",
  "43:34": "you might want to fit at a slightly",
  "43:35": "higher learning rate you know to make",
  "43:37": "them kind of really mean more or you",
  "43:39": "might want to run them through a few",
  "43:40": "more epochs but it's exactly the same",
  "43:42": "thing right you just call fit with your",
  "43:46": "misclassified examples and passing in",
  "43:48": "the correct classification and that",
  "43:50": "should really help your model quite a",
  "43:53": "lot there there are various other tweaks",
  "43:55": "you can do to this but that's the basic",
  "43:58": "idea next question could someone talk a",
  "44:02": "bit more about the data block ideology",
  "44:04": "I'm not not quite sure how the blocks",
  "44:06": "are meant to be used do they have to be",
  "44:08": "in a certain order is there any other",
  "44:10": "library that uses this type of",
  "44:11": "programming that I could look at yes",
  "44:17": "they do have to be in a certain order",
  "44:23": "they do have to be in a certain order",
  "44:25": "and it's basically the order that you",
  "44:26": "see in the example of use right it's",
  "44:28": "it's what kind of data do you have where",
  "44:35": "does it come from how do you label it",
  "44:37": "how do you split it what kind of data",
  "44:40": "sets do you want optionally how do I",
  "44:42": "transform it and then how do I create a",
  "44:44": "data bunch from it so they're the steps",
  "44:49": "I mean we invented this API I don't know",
  "44:56": "if other people have independently",
  "44:57": "invented it the basic idea of kind of a",
  "45:00": "a pipeline of things that dot into each",
  "45:04": "other is is pretty common in a number of",
  "45:09": "places not so much in Python but you see",
  "45:13": "it more in JavaScript although this kind",
  "45:15": "of approach of like each stage produces",
  "45:19": "something slightly different you don't",
  "45:21": "you tend to see it more in like ETL",
  "45:24": "software like extraction extraction",
  "45:25": "transformation and loading software",
  "45:27": "where there's kind of particular stages",
  "45:29": "in a pipeline so yeah I mean it's been",
  "45:31": "inspired by a bunch of things but yeah",
  "45:34": "oh all you need to know is to kind of",
  "45:36": "use this example to guide you and then",
  "45:41": "look up the documentation to see you",
  "45:44": "know which particular kind of thing you",
  "45:45": "want and in this case the image file",
  "45:49": "list you're actually not going to find",
  "45:51": "the documentation of image file list in",
  "45:53": "data blocks documentation because this",
  "45:55": "is specific to the vision application so",
  "45:58": "to then go and actually find out how to",
  "46:00": "do something for your particular",
  "46:01": "application you would then go you know",
  "46:04": "to look at text and vision and so forth",
  "46:06": "and that's where you can find out what",
  "46:08": "are the data block API pieces available",
  "46:10": "for that application and of course you",
  "46:13": "can then look at the source code if",
  "46:14": "you've got some totally new application",
  "46:16": "you could create your own part of any of",
  "46:20": "these stages like pretty much all of",
  "46:22": "these functions are you know",
  "46:25": "very few lines of code maybe we could",
  "46:29": "look an example of one",
  "46:33": "image list from folder so let's just put",
  "46:37": "that somewhere temporary and then we're",
  "46:40": "gonna go t dot label from CSD and you",
  "46:47": "can look at the documentation to see",
  "46:48": "exactly what that does and that's gonna",
  "46:50": "call label from date of data frame so I",
  "46:54": "mean this is already like useful like if",
  "46:56": "you you know wanted to create a data",
  "46:58": "frame a panda's data frame from",
  "46:59": "something other than the CSV you now",
  "47:01": "know that you could actually just call",
  "47:03": "label from data frame you can look up to",
  "47:05": "find what that does and as you can see",
  "47:07": "like most fast AI functions are no more",
  "47:11": "than you know a few lines of code",
  "47:13": "they're normally pretty pretty",
  "47:15": "straightforward to see what are all the",
  "47:16": "pieces there and how can you use them",
  "47:21": "it's probably one of these things that",
  "47:23": "as you play around with it you'll get a",
  "47:25": "good sense of how it all gets put",
  "47:28": "together but if during the week there",
  "47:29": "are particular things where you're",
  "47:30": "thinking I don't understand how to do",
  "47:32": "this please let us know and we'll try to",
  "47:34": "help you sure what resources do you",
  "47:40": "recommend for getting started with video",
  "47:42": "for example being able to pull frames",
  "47:44": "and submit them to your model",
  "47:50": "I guess it's I mean the answer is it",
  "47:56": "depends if you're using if you're using",
  "48:00": "the web which I guess probably most of",
  "48:02": "you will be then there's there's web api",
  "48:05": "s-- that basically do that for you so",
  "48:08": "you can grab the frames with with the",
  "48:10": "web api and then they're just images",
  "48:13": "which you can pass along if you're doing",
  "48:16": "it client-side i guess most people tend",
  "48:18": "to use OpenCV for that but maybe people",
  "48:22": "during the week could who are doing",
  "48:25": "these video apps can tell us what if",
  "48:26": "what have you used and found useful and",
  "48:28": "we can start to prepare something in the",
  "48:30": "lesson wiki with a list of video",
  "48:32": "resources since it sounds like some",
  "48:33": "people are interested okay so just like",
  "48:41": "usual we unfreeze our model and then we",
  "48:44": "fit some more and we get",
  "48:46": "down to nine to nine ish so one thing to",
  "48:53": "notice here is that wet before we",
  "48:57": "unfreeze your temp to get this shape",
  "48:59": "pretty much all the time if you do your",
  "49:01": "learning rate find it before you",
  "49:02": "unfreeze it's pretty easy you know find",
  "49:04": "the steepest slope not the bottom right",
  "49:07": "remember we're trying to find the bit",
  "49:08": "where we can like slide down it quickly",
  "49:10": "so if you start at the bottom it's just",
  "49:12": "going to send you straight off to the",
  "49:13": "end here so somewhere around here and",
  "49:16": "then we can call it again after you",
  "49:21": "unfreeze",
  "49:22": "i George only get a very different shape",
  "49:24": "right and this is a little bit harder to",
  "49:27": "say what to look for because it tends to",
  "49:29": "be this kind of shape where you get a",
  "49:31": "little bit of upward and then a kind of",
  "49:32": "very gradual downward and then up here",
  "49:34": "so you know I tend to kind of look for",
  "49:37": "just before it shoots up and go back",
  "49:40": "about 10x bad is a kind of a rule of",
  "49:43": "thumb so one a neg five right and that",
  "49:46": "is what I do for the first half of my",
  "49:48": "slice and then for the second half of my",
  "49:51": "slice I normally do whatever learning",
  "49:54": "rate are used for the the frozen part so",
  "49:58": "L R which was 0.01 kind of divided by 5",
  "50:03": "or divided by 10 somewhere around that",
  "50:06": "so that's kind of my role of thumb right",
  "50:08": "look for the bit kind of at the bottom",
  "50:10": "find about 10x smaller that's the number",
  "50:13": "that I put here and then Li over 5 or Li",
  "50:16": "over 10 is kind of what I put there",
  "50:18": "seems to work most of the time we'll be",
  "50:22": "talking more about exactly what's going",
  "50:23": "on here is called discriminative",
  "50:25": "learning rates as the course continues",
  "50:29": "so how am I going to get this better",
  "50:31": "than 9 to 9 because you know there are",
  "50:37": "how many people in this competition",
  "50:39": "about a thousand teams right so we want",
  "50:43": "to get into the top 10% so the top five",
  "50:49": "percent would be 0.93 one ish the top",
  "50:52": "10% is going to be about nine to nine",
  "50:55": "ish so we're not",
  "51:00": "and so um here's a trick right I don't",
  "51:04": "know if you remember but I when I",
  "51:06": "created my data set I put size equals",
  "51:10": "128 and actually the images that Carol",
  "51:14": "gave us are 256 so I used the size of",
  "51:17": "128 partially because I wanted to",
  "51:19": "experiment quickly it's it's much",
  "51:22": "quicker and easier to use small images",
  "51:24": "to experiment but there's a second",
  "51:26": "reason I now have a model that's pretty",
  "51:30": "good at recognizing the contents of 128",
  "51:34": "by 128 satellite images so what am I",
  "51:38": "going to do if I now want to create a",
  "51:39": "model that's pretty good at 256 by 256",
  "51:42": "satellite images well why don't I use",
  "51:45": "transfer learning why don't I start with",
  "51:47": "the model that's good at 128 by 128",
  "51:49": "images and fine-tune that so don't start",
  "51:53": "again right and that's actually going to",
  "51:55": "be really interesting because if I'm",
  "51:59": "trained quite a lot if I'm on the verge",
  "52:01": "of overfitting which I don't want to do",
  "52:03": "right then I'm basically creating a",
  "52:07": "whole new dataset effectively one where",
  "52:09": "my images are twice the size on each",
  "52:12": "axis right so four times bigger so it's",
  "52:14": "really a totally different data set as",
  "52:16": "far as my convolutional neural networks",
  "52:17": "concerned so I kind of got to lose all",
  "52:21": "that overfitting I get to start again so",
  "52:23": "let's create a new learner right well",
  "52:27": "let's let's keep our same liner but use",
  "52:30": "a new data bunch where the data bunch is",
  "52:32": "256 by 256 so that's why I actually",
  "52:36": "stopped here right before I created my",
  "52:39": "data sets because I'm going to now take",
  "52:41": "this this data source and I'm going to",
  "52:45": "create a new data bunch with 256 instead",
  "52:49": "so let's have a look at how we do that",
  "52:51": "so here it is take that source right",
  "52:56": "take that source transform it with the",
  "52:59": "same transforms as before but this time",
  "53:01": "use size 256 now that should be better",
  "53:05": "anyway because this is going to be you",
  "53:07": "know higher resolution images but also",
  "53:09": "I'm going to start with I haven't got",
  "53:11": "rid of my learner it's the same",
  "53:12": "I had before so I'm going to start with",
  "53:14": "this kind of pre trade model and so I'm",
  "53:17": "going to replace the data inside by",
  "53:20": "learner with this new data bunch and",
  "53:22": "then I will freeze again so that means",
  "53:25": "I'm going back to just training the last",
  "53:27": "few layers and I will do a new LR find",
  "53:32": "and because I actually now have a pretty",
  "53:36": "good model like it's pretty good for 128",
  "53:38": "by 128 so it's probably going to be like",
  "53:40": "at least okay for 256 by 256 I don't get",
  "53:44": "that same sharp shape that I did before",
  "53:46": "but I can certainly see where it's way",
  "53:48": "too high right so I'm gonna pick",
  "53:52": "something well before where it's way too",
  "53:54": "high again maybe 10x smaller so here I'm",
  "53:57": "gonna go 1e neg 2 over 2 that's you know",
  "54:00": "seems well before it shoots up and so",
  "54:03": "let's fit a little bit more okay so we",
  "54:07": "frozen again so we're just training the",
  "54:08": "last few layers and fit a little bit",
  "54:10": "more and as you can see I very quickly",
  "54:13": "remember kind of mine to weight was",
  "54:15": "where we got to before after quite a few",
  "54:17": "epochs we're straight up there and",
  "54:18": "suddenly we've passed point 9 3 all",
  "54:22": "right so we're now already kind of into",
  "54:26": "the top 10% so we've hit our first goal",
  "54:30": "right we're doing we're at the very",
  "54:32": "least pretty competent at the problem of",
  "54:35": "understeer cognizing satellite imagery",
  "54:36": "but of course now we can do the same",
  "54:39": "thing before we can unfreeze and train a",
  "54:42": "little more ok again using the same kind",
  "54:45": "of approach I described before lr over 5",
  "54:47": "here and even smaller one here trained a",
  "54:50": "little bit more 0.9 3 1 4 so that's",
  "54:58": "actually pretty good point 9 3 1 well",
  "55:05": "somewhere around top 20 ish so you can",
  "55:11": "see actually when my friend Brendan and",
  "55:13": "I entered this competition we came 22nd",
  "55:15": "with 0.9 31 5 and we spent this was a",
  "55:18": "year or two ago months trying to get",
  "55:21": "here so using kind of pretty much you",
  "55:25": "know defaults with",
  "55:26": "tweaks and one trick which is the",
  "55:28": "resizing tweak you can kind of get right",
  "55:33": "up into the top of the leaderboard of",
  "55:34": "this very challenging competition now I",
  "55:36": "should say we we don't really know where",
  "55:41": "we'd be we'd actually have to check it",
  "55:42": "on the test set that Cable gave us and",
  "55:44": "actually submit to the competition but",
  "55:46": "you can do you can do a late submission",
  "55:47": "and so later on in the course we'll",
  "55:51": "learn how to do that but we certainly",
  "55:53": "know we're we're doing well you know",
  "55:56": "we're doing we're doing very well so",
  "55:58": "that's great news and so you can see",
  "56:03": "also as I kind of go along I tend to",
  "56:05": "save things I just you can name your",
  "56:07": "models but ever you like but I just want",
  "56:09": "to basically know you know is it kind of",
  "56:10": "before or after the unfreeze so I kind",
  "56:13": "of had stage one or two what size were",
  "56:15": "though training on what architecture was",
  "56:17": "a training on so that we could have",
  "56:19": "always go back and experiment pretty",
  "56:22": "easily so that's that's planet",
  "56:26": "multi-label classification",
  "56:30": "let's look another example so another",
  "56:34": "the other example next we're gonna look",
  "56:36": "at is this data set called km vid and",
  "56:39": "it's going to be doing something called",
  "56:41": "segmentation we're going to start with a",
  "56:43": "picture like this and we're going to try",
  "56:45": "and create a color-coded picture like",
  "56:47": "this where all of the bicycle pixels are",
  "56:50": "the same color all of the road line",
  "56:53": "pixels are the same color all of the",
  "56:55": "tree pixels of the same color all of the",
  "56:57": "building pixels are same color the sky",
  "56:59": "the same color and so forth okay now",
  "57:01": "we're not actually going to make them",
  "57:03": "colors we're actually going to do it",
  "57:05": "where each of those pixels has a unique",
  "57:09": "number so in this case the top of left",
  "57:11": "is building so I guess building this",
  "57:13": "number for the top right is tree so tree",
  "57:16": "is 26 and so forth all right so in other",
  "57:20": "words this single top left pixel we're",
  "57:26": "basically committing this we're going to",
  "57:27": "do a classification problem just like",
  "57:29": "the pet's classification for the very",
  "57:31": "top left pixel we're going to say what",
  "57:33": "is that top left pixel is it bicycle",
  "57:37": "Road lines sidewalk",
  "57:40": "what is the very top left pixel and then",
  "57:42": "what is the next pixel along what is the",
  "57:45": "next pixel long so we're going to do a",
  "57:46": "little classification problem for every",
  "57:49": "single pixel in every single image so",
  "57:54": "that's called segmentation all right in",
  "57:59": "order to build a segmentation model you",
  "58:02": "actually need to download or create a",
  "58:06": "dataset where someone has actually",
  "58:10": "labeled every pixel so as you can",
  "58:13": "imagine that's a lot of work okay so",
  "58:16": "this is so that's going to be a lot of",
  "58:18": "work you're probably not going to create",
  "58:20": "your own segmentation datasets but",
  "58:23": "you're probably going to download or",
  "58:24": "find them from somewhere else this is",
  "58:25": "very common in medicine life sciences",
  "58:29": "you know if you're looking through",
  "58:31": "slides at nuclei it's very likely you",
  "58:35": "already have a whole bunch of segmented",
  "58:37": "cells and segmented nuclei in radiology",
  "58:41": "you probably already have lots of",
  "58:43": "examples of segmented lesions and so",
  "58:45": "forth so there's a lot of you know kind",
  "58:50": "of different domain areas where there",
  "58:53": "are domain-specific tools for creating",
  "58:55": "these segmented images as you could",
  "58:58": "guess from this example it's also very",
  "59:00": "common in kind of self-driving cars and",
  "59:03": "stuff like that where you need to see",
  "59:05": "you know what what objects are around",
  "59:07": "and where are they so in this case",
  "59:10": "there's a nice data set called cambered",
  "59:14": "which we can download and they have",
  "59:17": "already got a whole bunch of images and",
  "59:20": "segment masks prepared for us which is",
  "59:24": "pretty cool and remember pretty much all",
  "59:29": "of the data sets that we have provided",
  "59:31": "kind of inbuilt URLs for you can see",
  "59:36": "their details at coarse top faster day I",
  "59:39": "slash data sets and nearly all of them",
  "59:43": "are academic data sets where some very",
  "59:46": "kind people have gone to all of this",
  "59:48": "trouble for us",
  "59:49": "so that we can use this data set and",
  "59:51": "made it available for us to",
  "59:53": "so if you do use it one of these",
  "59:56": "datasets for any kind of project it",
  "59:58": "would be very very nice if you were to",
  "60:00": "go and find the citation and say you",
  "60:03": "know thanks to these people for this",
  "60:05": "data set okay because they've they've",
  "60:08": "provided it and all they're asking in",
  "60:10": "return is is for us to give them that",
  "60:12": "credit okay so here is the canva data",
  "60:14": "set here is the citation and on our data",
  "60:17": "sets page that will link to the academic",
  "60:19": "paper where it came from",
  "60:21": "okay Rachel now is a good time for a",
  "60:23": "question is there a way to use learn",
  "60:30": "Dodd LR find and have it return a",
  "60:33": "suggested number directly rather than",
  "60:35": "having to plot it as a graph and then",
  "60:37": "pick a learning rate by visually",
  "60:38": "inspecting that graph there are a few",
  "60:41": "other questions I think around more",
  "60:42": "guidance on reading the learning rate",
  "60:44": "finder graph yeah I mean it's a great",
  "60:48": "question yeah I mean the short answer is",
  "60:49": "no and the reason the answer is no is",
  "60:53": "because this is still a bit more",
  "60:56": "artisinal than I would like you know as",
  "60:58": "you can kind of see I've been kind of",
  "60:59": "saying how I read this learning rate",
  "61:01": "graph depends a bit on what stage I'm at",
  "61:03": "and kind of what the shape of it is I",
  "61:08": "guess like the when you're just training",
  "61:12": "the head",
  "61:13": "so before you unfreeze it pretty much",
  "61:15": "always looks like this and you can",
  "61:18": "certainly create something that kind of",
  "61:19": "creates a slightly you know creates a",
  "61:21": "smooth version of this finds the",
  "61:23": "sharpest negative slope and picked that",
  "61:26": "you would probably be fine nearly all",
  "61:29": "the time but then for you know these",
  "61:32": "kinds of ones you know it requires a",
  "61:36": "certain amount of experimentation but",
  "61:39": "the good news is you can experiment",
  "61:40": "right you can like you can try obviously",
  "61:43": "if the lines going up you don't monitor",
  "61:46": "almost certainly at the very bottom",
  "61:48": "point you don't want it right because",
  "61:51": "you needed to be going downwards but if",
  "61:53": "you kind of start with somewhere around",
  "61:54": "10x smaller than that and then also you",
  "61:57": "could try another 10x more than that try",
  "61:59": "a few numbers and find out which ones",
  "62:01": "which ones worked best and within a",
  "62:04": "small number of weeks",
  "62:06": "you will find that you're picking the",
  "62:09": "best learning rate most of the time all",
  "62:12": "right so I don't know it's kind of so at",
  "62:14": "this stage it still requires a bit of",
  "62:16": "playing around to get a sense of the",
  "62:18": "different kinds of shapes that you see",
  "62:19": "and how to respond to them maybe by the",
  "62:22": "time this video comes out someone will",
  "62:24": "have a pretty reliable auto learning",
  "62:27": "rate finder we're not there yet it's",
  "62:30": "probably not a massively difficult job",
  "62:34": "to do be an interesting project collect",
  "62:37": "a whole bunch of different data sets",
  "62:39": "maybe grab all the data sets from our",
  "62:41": "data sets page try and come up with some",
  "62:44": "simple heuristic compare it to all the",
  "62:48": "different lessons I've shown but it'd be",
  "62:50": "a really fun project to do but at the",
  "62:53": "moment we we don't have that I'm sure",
  "62:59": "it's possible that we haven't got there",
  "63:04": "okay so how do we do image segmentation",
  "63:10": "same way we do everything else and so",
  "63:14": "basically we're going to start with some",
  "63:15": "path we've just got some information in",
  "63:18": "it of some sort so I always start by you",
  "63:20": "know untiring my data do an LS see what",
  "63:24": "I was given in this case there's a live",
  "63:26": "photo record labels and the photo record",
  "63:28": "images so I'll create paths for each of",
  "63:31": "those we'll take a look inside each of",
  "63:34": "those and you know at this point like",
  "63:37": "you can see there's some kind of coded",
  "63:40": "file names for the images and some kind",
  "63:42": "of coded file names for the segment",
  "63:45": "masks and then you kind of have to",
  "63:47": "figure out how to map from one to the",
  "63:48": "other you know normally these kind of",
  "63:51": "data sets will come with a readme you",
  "63:52": "can look at or you can look at their",
  "63:53": "website often it's kind of obvious in",
  "63:56": "this case I can see like these ones",
  "63:59": "always have this kind of particular",
  "64:00": "format these ones always have exactly",
  "64:03": "the same format with an underscore PE so",
  "64:05": "I kind of but I did this honestly I just",
  "64:07": "guessed I thought oh it's probably the",
  "64:09": "same thing underscore P and so I created",
  "64:12": "a little function that basically took",
  "64:16": "the file name and added the underscore P",
  "64:18": "and put it in the different place",
  "64:20": "and I tried opening it and it I noticed",
  "64:22": "it worked so you know so I've created",
  "64:24": "this little function that converts from",
  "64:27": "the image file names to the equivalent",
  "64:30": "label file names I opened up that to",
  "64:33": "make sure it works normally we use open",
  "64:37": "image to open the file and then you can",
  "64:40": "go touch show to take a look at it but",
  "64:44": "this as we described this is not a usual",
  "64:46": "image file that contains integers so you",
  "64:51": "have to use open masks rather than open",
  "64:54": "image because we want to return integers",
  "64:56": "not floats and fast AI knows how to deal",
  "65:00": "with masks so if you go mask show it",
  "65:03": "will automatically color code it for you",
  "65:05": "in some appropriate way that's why we",
  "65:07": "said open masks so you know we can kind",
  "65:09": "of have a look inside look at the data",
  "65:11": "see what the size is",
  "65:12": "so there's 720 by 960 we can take a look",
  "65:16": "at the data inside and so forth the",
  "65:22": "other thing you might have noticed is",
  "65:23": "that they gave us a file called codes",
  "65:25": "text and a file called valid text so",
  "65:28": "codes dot txt we can load it up and have",
  "65:31": "a look inside and not surprisingly it's",
  "65:33": "got a list telling us that for example",
  "65:35": "number four is zero one two three four",
  "65:39": "it's building top left is building there",
  "65:42": "you go okay so just like we had you know",
  "65:44": "Grizzlies black bears and Teddy's here",
  "65:46": "we've got the coding for what each one",
  "65:49": "of these pixels means so we need to",
  "65:54": "create a databank so to create a data",
  "65:56": "bunch we can go through the data block",
  "65:59": "API and say okay we've got a list of",
  "66:01": "image files that are in a folder we need",
  "66:04": "to create labels which we can use with",
  "66:06": "that get Y file name function we just",
  "66:09": "created we then need to split into",
  "66:11": "training and validation in this case I",
  "66:14": "don't do it randomly why not",
  "66:16": "because actually the pictures they've",
  "66:18": "given us frames from videos so if I did",
  "66:21": "them randomly I would be having like two",
  "66:23": "frames next to each other one in the",
  "66:25": "validation set one in the training set",
  "66:27": "that would be far too easy that's",
  "66:28": "treating right so the people that",
  "66:31": "created this data set actually gave us",
  "66:33": "a data set saying here is the list of",
  "66:35": "file names that are meant to be in your",
  "66:37": "validation set and their non contiguous",
  "66:39": "parts of the video so here's how you can",
  "66:44": "let your validation and training using a",
  "66:47": "file name fail so from that I can create",
  "66:51": "my data sets and so I actually have a",
  "66:54": "list of plus names so like often with",
  "66:59": "stuff like the planet data set or the",
  "67:00": "pets data set we actually have a string",
  "67:03": "saying you know this is a this is a pug",
  "67:05": "or this is a ragdoll or this is a bur",
  "67:08": "man or this is cloudy or whatever in",
  "67:11": "this case you don't have every single",
  "67:13": "pixel labeled with an entire string that",
  "67:15": "would be incredibly inefficient they're",
  "67:17": "each labeled with just a number and then",
  "67:19": "there's a separate file telling you what",
  "67:21": "those numbers mean so here's where we",
  "67:23": "get to tell it and the data block API",
  "67:26": "this is the list of what the numbers",
  "67:28": "mean okay so these are the kind of",
  "67:29": "parameters that the data block API gives",
  "67:31": "you here's our transformations and so",
  "67:36": "here's an interesting point remember I",
  "67:38": "told you that for example sometimes we",
  "67:40": "randomly flip an image right what if we",
  "67:43": "randomly flip the independent variable",
  "67:48": "image but we don't also randomly flip",
  "67:51": "this one there now not matching anymore",
  "67:53": "right so we need to tell fast AI that I",
  "67:58": "want to transform the Y so what so X is",
  "68:01": "our independent variable Y is that a",
  "68:03": "pendant I want to transform the Y as",
  "68:04": "well so whatever you do to the X they",
  "68:07": "also want you to do to the way so",
  "68:08": "there's all these little parameters that",
  "68:10": "we can play with and I can create a data",
  "68:13": "bunch I'm using a smaller batch size",
  "68:15": "because as you can imagine because I'm",
  "68:17": "creating a classifier for every pixel",
  "68:19": "that's going to take a lot more GPU",
  "68:21": "that's why I found a batch size of eight",
  "68:23": "is all I could handle and then normalize",
  "68:26": "in the usual way and this is quite nice",
  "68:29": "fast AI because it knows that you've",
  "68:33": "given it a segmentation problem when you",
  "68:35": "call show batch it actually combines the",
  "68:38": "two pieces for you and it will color",
  "68:39": "code the photo isn't that nice right so",
  "68:42": "you can see here the green on the trees",
  "68:45": "and the red on the line",
  "68:47": "and this kind of color on the walls and",
  "68:50": "so forth alright so you can see here",
  "68:52": "here are the pedestrians this is the",
  "68:55": "pedestrians backpack so this is what the",
  "68:57": "ground truth data looks like so once",
  "69:00": "we've got that we can go ahead and",
  "69:08": "create a learner I'll show you some more",
  "69:10": "details in a moment",
  "69:12": "call allow find find the sharpest bit",
  "69:15": "which looks about one a neg to call fit",
  "69:18": "passing in slice ela and see the",
  "69:21": "accuracy and save the model and unfreeze",
  "69:25": "and train a little bit more so that's",
  "69:30": "the basic idea",
  "69:31": "okay and so we're going to have a break",
  "69:33": "and when we come back I'm going to show",
  "69:35": "you some little tweaks that we can do",
  "69:38": "and I'm also going to explain this",
  "69:41": "custom metric that we've created and",
  "69:43": "then we'll be able to go on and look at",
  "69:45": "some other cool things so let's all come",
  "69:47": "back at eight o'clock six minutes okay",
  "69:55": "welcome back everybody and we're going",
  "69:57": "to start off with a question we got",
  "69:58": "during the break could you use",
  "70:04": "unsupervised learning here pixel",
  "70:06": "classification with the bike example to",
  "70:08": "avoid needing a human to label a heap of",
  "70:11": "images well not exactly",
  "70:15": "unsupervised learning but you can",
  "70:17": "certainly get a sense of where things",
  "70:19": "are without needing these kind of labels",
  "70:23": "and time permitting well we'll try and",
  "70:27": "see some examples of how to do that it's",
  "70:30": "you're certainly not going to get as",
  "70:32": "such a quality in such a specific",
  "70:35": "example as what you see here though if",
  "70:38": "you want to get this level of",
  "70:39": "segmentation mask you need a pretty good",
  "70:43": "segmentation mask ground truth to work",
  "70:45": "with",
  "70:51": "and is there a reason we shouldn't",
  "70:53": "deliberately make a lot of smaller data",
  "70:55": "set up sets to step up from in tuning",
  "70:58": "let's say 64 by 64 128 by 128 256 by 256",
  "71:03": "and so on yes you should totally do that",
  "71:08": "it works great try it I found this idea",
  "71:14": "is something that I first came up with",
  "71:18": "in the course a couple of years ago and",
  "71:21": "I kind of thought it seemed obvious and",
  "71:24": "just presented it as a good idea and",
  "71:26": "then I later discovered that nobody had",
  "71:27": "really published this before and then we",
  "71:29": "started experimenting with it and it was",
  "71:32": "basically the main tricks that we use to",
  "71:34": "to to win the imagenet competition the",
  "71:37": "dawn Banshee imagenet training",
  "71:38": "competition and we're like wow people",
  "71:41": "this wasn't only not not only was this",
  "71:45": "not standard nobody had heard of it",
  "71:46": "before there's been now a few papers",
  "71:50": "that use this trick for various specific",
  "71:52": "purposes but it's still largely unknown",
  "71:54": "and it means that you can train much",
  "71:57": "faster it generalizes better there's",
  "72:00": "still a lot of unknowns about exactly",
  "72:02": "like how how small and how big and how",
  "72:06": "much at each level and so forth but I",
  "72:12": "guess in as much as it has a name now it",
  "72:14": "probably does and I guess we call it",
  "72:15": "progressive resizing I found that going",
  "72:18": "much under 64 by 64 tends not to help",
  "72:22": "very much but yeah it's it's a it's a",
  "72:28": "great technique and I definitely try a",
  "72:29": "few a few different sizes what does",
  "72:36": "accuracy mean for pix pixel wise",
  "72:38": "segmentation is it correctly classified",
  "72:41": "pixels divided by the total number of",
  "72:43": "pixels yep that's it so if you mentioned",
  "72:47": "each pixel was a separate you know",
  "72:50": "object you're classifying it's exactly",
  "72:53": "the same accuracy and so you actually",
  "72:56": "can just pass the inaccuracy as",
  "73:02": "geometric",
  "73:03": "but in this case we actually don't we've",
  "73:06": "created a new metric called accuracy cam",
  "73:10": "vid and the reason for that is that when",
  "73:13": "they labeled the images sometimes they",
  "73:17": "labeled a pixel as void I'm not quite",
  "73:20": "sure why maybe it's some that they",
  "73:23": "didn't know or somebody felt it they'd",
  "73:25": "made a mistake or whatever but some of",
  "73:27": "the pixels avoid and in the canvas paper",
  "73:30": "they say when you're reporting accuracy",
  "73:33": "you should remove the void pixels so",
  "73:38": "we've created a accuracy camford so all",
  "73:41": "metrics take the actual output of the",
  "73:46": "neural net that's the input to the actor",
  "73:48": "this is what they called the inputs is",
  "73:49": "the input to the metric and the target",
  "73:51": "ie the labels we're trying to predict so",
  "73:54": "we then basically create a mask so we",
  "73:57": "look for the places where the target is",
  "73:59": "not equal to Boyd and then we just take",
  "74:04": "the input do the Arg max as per usual",
  "74:09": "just the standard accuracy Arg max but",
  "74:11": "then we just grab those that are not",
  "74:13": "equal to the void code and we do the",
  "74:15": "same for the target and we take the mean",
  "74:17": "okay so it's it's just a standard",
  "74:20": "accuracy it's almost exactly the same as",
  "74:22": "the accuracy source code we saw before",
  "74:24": "with the addition of this mask so this",
  "74:28": "quite often happens that the particular",
  "74:32": "kaggle competition metric you're using",
  "74:36": "or the particular way your organization",
  "74:38": "you know scores things or whatever",
  "74:40": "there's often like little tweaks you",
  "74:42": "have to do and this is how easy it is",
  "74:45": "right and so as you'll see to do this",
  "74:48": "stuff the main thing you need to know",
  "74:50": "pretty well is how to do basic",
  "74:54": "mathematical operations in pi torch so",
  "74:57": "that's just something you kind of need",
  "74:59": "to practice I've noticed that most of",
  "75:05": "the examples and most of my models",
  "75:06": "result in a training loss greater than",
  "75:08": "the validation loss what are the best",
  "75:10": "ways to correct that I should add that",
  "75:13": "this still happens after trying many",
  "75:14": "variations on number of",
  "75:16": "and learning rate okay good question so",
  "75:21": "remember from last week if you're",
  "75:22": "training loss is higher than your",
  "75:24": "validation loss than you're underfitting",
  "75:26": "okay it definitely means that your",
  "75:28": "underfitting you want your training loss",
  "75:31": "to be lower than your validation loss if",
  "75:35": "your underfitting",
  "75:37": "you can train for longer you can train a",
  "75:42": "train the last bit at a lower learning",
  "75:44": "rate but if you're still under fitting",
  "75:49": "then you're going to have to decrease",
  "75:51": "regularization and we haven't talked",
  "75:53": "about that yet so in the second half of",
  "75:57": "this part of the course we're going to",
  "75:59": "be talking quite a lot about",
  "76:00": "regularization and specifically how to",
  "76:04": "avoid overfitting or underfitting by",
  "76:07": "using regularization if you want to skip",
  "76:09": "ahead we're going to be learning about",
  "76:11": "weight decay dropout and data",
  "76:14": "augmentation will be the key things that",
  "76:16": "are we talking about okay for",
  "76:25": "segmentation we don't just create a",
  "76:29": "convolutional neural network we can but",
  "76:34": "actually a architecture called unit",
  "76:37": "turns out to be better and actually the",
  "76:41": "let's find it",
  "76:49": "okay so this is what a unit looks like",
  "76:52": "and this is from the University website",
  "76:56": "where they talk about the unit and so",
  "76:59": "we'll be learning about this both in",
  "77:00": "this part of the course and in part two",
  "77:02": "if you do it but basically this bit down",
  "77:07": "on the left hand side is what a normal",
  "77:09": "convolutional neural network looks like",
  "77:11": "it's something which starts with a",
  "77:13": "bigger big image and gradually makes it",
  "77:14": "smaller and smaller and smaller and",
  "77:16": "smaller until eventually you just have",
  "77:17": "one prediction what a unit does is it",
  "77:20": "then takes that and makes it bigger and",
  "77:22": "bigger and bigger again and then it",
  "77:24": "takes every stage of the downward path",
  "77:27": "and kind of copies it across and it",
  "77:29": "creates this new shape",
  "77:30": "it's was originally actually created or",
  "77:34": "published as a biomechanical image",
  "77:37": "segmentation method but it turns out to",
  "77:40": "be useful for far more than just",
  "77:41": "biomedical image segmentation so it was",
  "77:43": "presented at Mick I which is the main",
  "77:47": "medical imaging conference and as of",
  "77:50": "just yesterday it actually just became",
  "77:52": "the most cited paper of all time from",
  "77:56": "that conference so it's been incredibly",
  "77:58": "useful over 3,000 citations you don't",
  "78:01": "really need to know any details at this",
  "78:03": "stage all you need to know is if you",
  "78:05": "want to create a segmentation model you",
  "78:10": "want to be saying learn add or create",
  "78:11": "unit rather than create CNN but you pass",
  "78:16": "at the normal stuff their data bunch and",
  "78:19": "architecture and some metrics ok so",
  "78:24": "having done that everything else works",
  "78:26": "the same you can do the yelow finder",
  "78:28": "find the slope train it for a while",
  "78:32": "what's the accuracy go up save it from",
  "78:35": "time to time",
  "78:36": "unfreeze probably want to go about 10",
  "78:40": "lists we're still going up so probably",
  "78:43": "10 less than that so one enoch 5 comma",
  "78:46": "lr over 5 train a bit more and there we",
  "78:51": "go right now here's something",
  "78:55": "interesting you can learn dot recorder",
  "78:58": "is where we keep track of what's going",
  "79:00": "on during training and it's got a number",
  "79:02": "nice methods one of which is plot losses",
  "79:04": "and this plots your training loss and",
  "79:07": "your validation loss and you'll see",
  "79:11": "quite often they actually go up a bit",
  "79:14": "before they go down why is that that's",
  "79:18": "because you can also plot your learning",
  "79:21": "rate over time and you'll see that the",
  "79:24": "old learning rate goes up and then it",
  "79:27": "goes down why is that because we said",
  "79:31": "fit one cycle and that's what fit one",
  "79:33": "cycle does it actually makes the",
  "79:35": "learning rate start low go up and then",
  "79:38": "go down again why is that a good idea",
  "79:41": "well to find out why that's a good idea",
  "79:44": "let's first of all look at a really cool",
  "79:48": "project done by Jose Fernandez Patil",
  "79:53": "during the week he took our gradient",
  "79:55": "descent demo notebook and actually",
  "80:00": "plotted the weights over time not just",
  "80:05": "the ground truth and model over time and",
  "80:08": "he did it for a few different learning",
  "80:10": "rates and so remember we had two weights",
  "80:13": "we were doing basically y equals ax plus",
  "80:15": "B or in his nomenclature here y equals W",
  "80:20": "naught X plus W 1 and so we can actually",
  "80:23": "look and see over time what happens to",
  "80:27": "those weights and we know this is the",
  "80:28": "correct answer",
  "80:29": "Yeah right so what a learning rate of",
  "80:32": "point one they're kind of like slides on",
  "80:34": "in here and you can see that it takes a",
  "80:36": "little bit of time to get to the right",
  "80:38": "point and you can see the loss improving",
  "80:42": "at a higher learning rate of 0.7 you can",
  "80:45": "see that the ground truth the model",
  "80:48": "jumps to the ground truth really quickly",
  "80:50": "and you can see that the weights jump",
  "80:53": "straight to the right place really",
  "80:54": "quickly and what if we have a learning",
  "80:58": "rate that's really too high you can see",
  "81:00": "it takes a very very very long time to",
  "81:03": "get to the right point or if it's really",
  "81:05": "too high it diverges okay so you can see",
  "81:10": "here why getting the right learning rate",
  "81:12": "is important when you get the right",
  "81:14": "learning rate it",
  "81:15": "zooms into the best but very quickly now",
  "81:20": "as you get closer to the final spot",
  "81:27": "something interesting happens which is",
  "81:30": "that you really want your learning rate",
  "81:33": "to decrease right because you're kind of",
  "81:35": "you're getting close to the right spot",
  "81:37": "right and what actually happens so what",
  "81:45": "actually happens is I can only draw 2d",
  "81:49": "sorry you don't generally actually have",
  "81:52": "some kind of loss function surface that",
  "81:55": "looks like that and remember there's",
  "81:57": "lots of dimensions but it actually tends",
  "81:59": "to kind of look like bumpy like that",
  "82:02": "right and so you kind of want a learning",
  "82:07": "rate that's like high enough to jump",
  "82:10": "over the bumps right but then once you",
  "82:13": "get close to the middle you know once",
  "82:15": "you get close to the the best answer you",
  "82:18": "don't want to be just jumping backwards",
  "82:19": "and forwards between bumps so you really",
  "82:21": "want your learning rate to go down so",
  "82:23": "that as you get closer you take smaller",
  "82:26": "and smaller steps so that's why it is",
  "82:30": "that we want our learning rate to go",
  "82:32": "down at the end now this idea of",
  "82:37": "decreasing the learning rate during",
  "82:38": "training has been around forever and",
  "82:41": "it's just called learning rate annealing",
  "82:44": "but the idea of gradually increasing it",
  "82:46": "at the start is much more recent and it",
  "82:49": "mainly comes from a guy called Leslie",
  "82:51": "Smith if you're in San Francisco next",
  "82:53": "week actually you can come and join me",
  "82:55": "and Leslie Smith we're having a meet-up",
  "82:57": "where we'll be talking about this stuff",
  "82:59": "so come along to that what Leslie",
  "83:03": "discovered is that if you gradually",
  "83:07": "increase your learning rate what tends",
  "83:10": "to happen is that actually actually what",
  "83:17": "tends to happen is that loss function",
  "83:19": "surfaces tend to kind of look something",
  "83:21": "like this bumpy bumpy bumpy bumpy bumpy",
  "83:24": "bumpy bumpy bumpy bumpy bumpy something",
  "83:27": "like this right they have flat areas",
  "83:29": "and bumpy areas and if you end up in the",
  "83:33": "bottom of a bumpy area that that",
  "83:36": "solution will tend not to generalize",
  "83:37": "very well because you've found a",
  "83:39": "solution that's it's good in that one",
  "83:41": "place but it's not very good",
  "83:43": "in other places where else if you found",
  "83:46": "one in the flat area it probably will",
  "83:48": "generalize well because it's not only",
  "83:50": "good in that one spot but it's good to",
  "83:52": "kind of around it as well if you have a",
  "83:55": "really small learning rate it'll tend to",
  "83:57": "kind of plug down and stick in these",
  "84:03": "places right but if you gradually",
  "84:06": "increase the learning rate then it'll",
  "84:08": "kind of like jump down and then as the",
  "84:11": "learning rate goes up it's going to",
  "84:12": "start kind of going up again like this",
  "84:15": "right and then the learning rate now",
  "84:18": "going to be up here it's going to be",
  "84:19": "bumping backwards and forwards and",
  "84:20": "eventually the learning rate starts to",
  "84:22": "come down again and so it'll tend to",
  "84:26": "find its way to these flat areas so it",
  "84:29": "turns out that gradually increasing the",
  "84:32": "learning rate is a really good way of",
  "84:33": "helping the model to explore the whole",
  "84:37": "function surface and try and find areas",
  "84:40": "where both the loss is is low and also",
  "84:44": "it's it's not bumpy because if it was",
  "84:47": "bumpy it would get kicked out again and",
  "84:49": "so this allows us to train at really",
  "84:52": "high learning rates so it tends to mean",
  "84:54": "that we solve our problem much more",
  "84:55": "quickly and we tend to end up with much",
  "84:58": "more generalizable solutions so if you",
  "85:01": "call plot losses and find that it's just",
  "85:04": "getting a little bit worse and then it",
  "85:07": "gets a lot better you've found a really",
  "85:09": "good maximum learning rate so when you",
  "85:11": "actually call fit one cycle you're not",
  "85:15": "actually passing in a learning rate",
  "85:16": "you're actually passing in a maximum",
  "85:19": "learning rate and if it's kind of always",
  "85:23": "going down particularly after you",
  "85:25": "unfreeze that suggests you could",
  "85:28": "probably bump your your learning rates",
  "85:29": "up a little bit because you really want",
  "85:31": "to see this kind of shape it's going to",
  "85:34": "train faster and generalize better just",
  "85:37": "just a little bit right and return to",
  "85:39": "particularly see it in the validation",
  "85:41": "set the orange is the validation set",
  "85:43": "right and again the difference between",
  "85:45": "kind of knowing this theory and being",
  "85:48": "able to do it is looking at lots of",
  "85:51": "these pictures right so like after you",
  "85:53": "train stuff type learn dot recorder dot",
  "85:56": "and hit tab and see what's in there but",
  "86:01": "and particularly the things that start",
  "86:02": "with plot and start getting a sense of",
  "86:04": "like what are these pictures looking",
  "86:06": "like when you're getting good results",
  "86:07": "and then try making the learning rate",
  "86:09": "much higher try making it much lower",
  "86:11": "more epochs lessee paths and get a sense",
  "86:14": "for that it's not like so in this case",
  "86:21": "we use the size and our transforms of",
  "86:28": "the original image size over to these",
  "86:31": "two slashes in Python means integer",
  "86:33": "divide okay because obviously we can't",
  "86:35": "have half pixel amounts in ell sizes so",
  "86:39": "integer divide divided by two and we use",
  "86:41": "the batch size of eight now I found that",
  "86:43": "fits on my GPU it might not fit on yours",
  "86:46": "if it doesn't you can just decrease the",
  "86:48": "batch size down to four and this isn't",
  "86:52": "really solving the problem because the",
  "86:53": "problem is to segment all of the pixels",
  "86:56": "not half of the pixels so I'm going to",
  "86:58": "use the same trick that I did last time",
  "87:01": "which is I'm now going to put the size",
  "87:03": "up to the full size of the source images",
  "87:06": "which means I now have to have my batch",
  "87:09": "size otherwise I ran out of GPU memory",
  "87:11": "and I'm then going to set my learner I",
  "87:17": "can either say loan dot data equals my",
  "87:19": "new data well I actually found us had a",
  "87:21": "lot of trouble with kind of GPU memory",
  "87:23": "so I generally restarted my kernel came",
  "87:25": "back here created a new learner and",
  "87:27": "loaded up the weights that I saved last",
  "87:30": "time but the key thing here being that",
  "87:33": "this learner now has the same weights",
  "87:35": "that I had here but the data is now the",
  "87:38": "full image size so I can now do an LR",
  "87:42": "find again find an area where it's kind",
  "87:45": "of you know well before it goes up so",
  "87:47": "we're going to use one a Nick three and",
  "87:49": "fit some more and then unfreeze and fit",
  "87:54": "some more",
  "87:56": "and you could go to loan dot show",
  "87:59": "results to see how your predictions",
  "88:01": "compare to the ground truth and you're",
  "88:04": "gonna see they really look pretty good",
  "88:07": "not bad huh",
  "88:09": "so how good is pretty good an accuracy",
  "88:14": "of point of ninety two point one five",
  "88:18": "the best paper I know of for",
  "88:21": "segmentation was a paper called the",
  "88:24": "hundred layers tiramisu which developed",
  "88:27": "a convolutional dense net came out about",
  "88:31": "two years ago so after I trained this",
  "88:33": "today I went back and looked at the",
  "88:35": "paper to find their state-of-the-art",
  "88:39": "accuracy here it is and I looked it up",
  "88:47": "and their best was ninety one point five",
  "88:52": "and we got ninety two point one so I got",
  "88:57": "to say where this happened today I was",
  "88:59": "like wow III don't know if better",
  "89:02": "results have come out since this paper",
  "89:04": "but I remember when this paper came out",
  "89:06": "and it was a really big deal I was like",
  "89:08": "wow this this is an exceptionally good",
  "89:11": "segmentation result like when you",
  "89:12": "compare it to the previous bests that",
  "89:14": "they compared it to it was a big step up",
  "89:16": "and so like in last year's course we",
  "89:20": "spent a lot of time in the course",
  "89:22": "re-implementing the hundred layers",
  "89:23": "tiramisu and now with our totally",
  "89:27": "default fast AI + and easily beating",
  "89:33": "this and I also remember this I had to",
  "89:35": "train for hours and hours and hours",
  "89:37": "where else today's I trained in minutes",
  "89:41": "so we've this is a super strong",
  "89:45": "architecture for segmentation so yeah",
  "89:49": "I'm not going to promise that this is",
  "89:51": "the definite state of the art today",
  "89:52": "because I haven't done a complete",
  "89:54": "literature search to see what's happened",
  "89:56": "in the last two years but it's certainly",
  "89:58": "beating the world's best approach the",
  "90:02": "last time I looked into this which was",
  "90:05": "in last year's course basically and so",
  "90:08": "these are kind of just all the little",
  "90:10": "tricks I guess we've picked up along the",
  "90:12": "way",
  "90:13": "in terms of like how to train things",
  "90:15": "well things like using the pre train",
  "90:17": "model and things like you know using the",
  "90:19": "one cycle convergence and all these",
  "90:21": "little tricks they work extraordinarily",
  "90:25": "well and it's really nice to be able to",
  "90:28": "like show something in class where we",
  "90:29": "can say you know I we actually haven't",
  "90:32": "published the paper on the the exact",
  "90:34": "details of how this variation of the",
  "90:37": "unit works there's a few little tweaks",
  "90:38": "we do but if you come back for part two",
  "90:41": "we'll be going into all of the details",
  "90:43": "about how we make this work so well but",
  "90:47": "for you or you have to know at this",
  "90:49": "stage is that you can say learner doctor",
  "90:51": "yet unit and you should get great",
  "90:53": "results also there's another trick you",
  "91:01": "can use if you're running out of memory",
  "91:06": "a lot which is you can actually do",
  "91:09": "something called mixed precision",
  "91:12": "training and mixed precision training",
  "91:15": "means that instead of using for those of",
  "91:17": "you that have done a little bit of",
  "91:18": "computer science instead of using single",
  "91:20": "precision floating point numbers you can",
  "91:23": "do all the calculations in your model",
  "91:25": "with half precision floating point",
  "91:27": "numbers so 16 bits instead of 32 bits",
  "91:30": "tradition I mean the very idea of this",
  "91:33": "has only been around really for the last",
  "91:36": "couple of years in terms of like",
  "91:38": "hardware that actually does this",
  "91:39": "reasonably quickly and then faster a",
  "91:43": "library I think is the first and",
  "91:45": "probably still the only that makes it",
  "91:47": "actually easy to use this if you add",
  "91:49": "through FP 16 on the end of any learner",
  "91:52": "call you're actually going to get a",
  "91:54": "model that trains in 16-bit precision",
  "91:59": "because it's so new you'll need to have",
  "92:03": "kind of the most recent CUDA drivers and",
  "92:06": "all that stuff for this even to work",
  "92:07": "when I tried it this morning on some of",
  "92:10": "the platforms it just killed the colonel",
  "92:12": "so you need to make sure you've got the",
  "92:14": "most recent drivers but if you've got a",
  "92:18": "really recent GPU like a 20 atti",
  "92:21": "not only will it work",
  "92:23": "but it'll work about twice as fast as",
  "92:27": "otherwise now the reason I'm mentioning",
  "92:28": "it is that it's going to use less GPU",
  "92:32": "Ram so even if you don't have like a 28",
  "92:35": "ETA you might find or you'll probably",
  "92:38": "find that things that didn't fit into",
  "92:40": "your GPU without this then do fit in",
  "92:44": "with this now I actually have never seen",
  "92:48": "people use 16 the mixed precision",
  "92:51": "floating point for segmentation before",
  "92:53": "just for a bit of a laugh I tried it and",
  "92:57": "actually discovered that I got even",
  "93:00": "better resolved so I only found this",
  "93:05": "this morning so I don't have anything",
  "93:06": "more to add here rather than quite often",
  "93:09": "when you make things a little bit less",
  "93:11": "precise in deep learning it generalizes",
  "93:13": "a little bit better and I you know I've",
  "93:16": "never seen a 92.5 accuracy on camford",
  "93:21": "before so yeah this not only will this",
  "93:24": "be faster you'll be able to use bigger",
  "93:25": "batch sizes but you might even find like",
  "93:28": "I did that you get an even better result",
  "93:31": "so that's a cool little trick now you",
  "93:34": "just need to make sure that every time",
  "93:35": "you create a learner you're at this 2fp",
  "93:37": "16 if your kernel dies it probably means",
  "93:39": "you have slightly out of date CUDA",
  "93:42": "drivers or maybe even an old to old",
  "93:46": "graphics card I'm not sure exactly which",
  "93:49": "cards support FP 16 okay so one more",
  "93:58": "before we kind of rewind sorry two more",
  "94:03": "the first one I'm going to show you is",
  "94:05": "an interesting data set called the be.we",
  "94:08": "hippos data set and gabrielle finale was",
  "94:13": "kind enough to give us permission to use",
  "94:15": "this in the class his team created this",
  "94:19": "this cool data set here's what the data",
  "94:21": "set looks like it's pictures it's",
  "94:24": "actually got a few things in it we're",
  "94:25": "just going to do a simplified version",
  "94:26": "and one of the things they do is they",
  "94:28": "have a dot saying this is the center of",
  "94:32": "the face and so we're going to try and",
  "94:35": "create a model that can find this",
  "94:37": "ever faced so um for this data set",
  "94:43": "there's a few data set specific things",
  "94:46": "we have to do which I don't really even",
  "94:48": "understand but I just know from the",
  "94:50": "readme that you have to they use some",
  "94:52": "kind of depth sensing camera I think",
  "94:54": "they actually use to connect you know",
  "94:56": "Xbox Kinect there's some kind of",
  "94:58": "calibration numbers that they provide in",
  "94:59": "a little file which I had to read in and",
  "95:01": "then they provided a little function",
  "95:03": "that you have to use to take their",
  "95:06": "coordinates to change it from this this",
  "95:09": "depth sensor calibration thing to end up",
  "95:12": "with actual coordinates so when you when",
  "95:15": "you open this and you see these at all",
  "95:16": "conversion routines that's just you know",
  "95:20": "I'm just doing what they told us to do",
  "95:22": "basically it's about nothing",
  "95:23": "particularly to do with deep learning to",
  "95:25": "end up with this dot the interesting bit",
  "95:28": "really is where we create something",
  "95:32": "which is not an image or an image",
  "95:34": "segment put an image points and we'll",
  "95:38": "mainly learn about this later in the",
  "95:40": "course but basically image points use",
  "95:45": "this idea of kind of their coordinates",
  "95:48": "right they're not pixel values they're",
  "95:51": "XY coordinates there's just two numbers",
  "95:53": "as you can see let me see",
  "96:07": "so here's an example for a particular",
  "96:10": "image file name this particular image",
  "96:12": "file and here it is the coordinates of",
  "96:16": "the centre of the face are at 263 , 428",
  "96:20": "and here it is so there's just two",
  "96:24": "numbers which represent whereabouts on",
  "96:26": "this picture as the centre of the face",
  "96:27": "so if we're going to create a model that",
  "96:30": "can find the center of a face we need a",
  "96:32": "neural network that spits out two",
  "96:34": "numbers but note this is not a",
  "96:38": "classification model these are not two",
  "96:40": "numbers that you look up in a list to",
  "96:42": "find out that they're Road or building",
  "96:43": "or ragdoll cat or whatever their actual",
  "96:47": "locations so so far everything we've",
  "96:53": "done has been a classification model",
  "96:54": "something that's created labels or",
  "96:56": "classes this for the first time is what",
  "96:59": "we call a regression model a lot of",
  "97:01": "people think regression means linear",
  "97:03": "regression it doesn't regression just",
  "97:05": "means any kind of model where your",
  "97:07": "output is some continuous number or set",
  "97:10": "of numbers so this is we need to create",
  "97:12": "an image regression model something that",
  "97:15": "can predict these two numbers so how do",
  "97:19": "you do that same way as always right so",
  "97:23": "we can actually just say I've got a list",
  "97:26": "of image files it's in a folder and I",
  "97:29": "want to label them using this function",
  "97:32": "that we wrote that basically does the",
  "97:34": "stuff that the readme says to grab the",
  "97:36": "coordinates out of their text files so",
  "97:39": "that's going to give me the two numbers",
  "97:40": "for everyone and then I'm going to split",
  "97:43": "it according to some function and so in",
  "97:45": "this case that the files they gave us",
  "97:50": "again they're from videos and so I",
  "97:52": "picked just one folder to be my",
  "97:55": "validation set in other words a",
  "97:57": "different person so again I was trying",
  "97:59": "to think about like how do I validate",
  "98:01": "this fairly so I said well the the fair",
  "98:03": "validation would be to make sure that it",
  "98:05": "works well on a person that it's never",
  "98:07": "seen before",
  "98:08": "so my validation set is all going to be",
  "98:10": "a particular person create a data set",
  "98:13": "and so this data set I just tell it what",
  "98:15": "kind of data set is it well they're",
  "98:17": "going to be a set of point",
  "98:18": "two points means you know specific",
  "98:20": "coordinates do some transforms again I",
  "98:24": "have to say transform y equals true",
  "98:26": "because that red dot needs to move if I",
  "98:28": "flip or rotate or warp okay pick some",
  "98:32": "size I just picked a size that's going",
  "98:34": "to work pretty quickly create a data",
  "98:35": "bunch normalize it and again show batch",
  "98:38": "there it is okay I noticed that there",
  "98:41": "are red dots don't always seem to be",
  "98:43": "quite in the middle of the face I don't",
  "98:44": "know exactly what they're kind of",
  "98:47": "internal algorithm for putting dots on",
  "98:50": "they kind of sometimes looks like it's",
  "98:52": "meant to be the nose but sometimes it's",
  "98:53": "not quite the nose anyway you get the",
  "98:56": "reps it's somewhere around the center of",
  "98:57": "the face or the nose so how do we create",
  "99:00": "a model we create a CNN but we're going",
  "99:07": "to be learning a lot about loss",
  "99:09": "functions in the next few lessons but",
  "99:12": "generally that basically the loss",
  "99:14": "function is that that that number that",
  "99:16": "says how good is the model and so for",
  "99:19": "classification we use this loss function",
  "99:22": "called cross-entropy loss which says",
  "99:24": "basically remember this from earlier",
  "99:27": "lessons did you predict the correct",
  "99:30": "class and were you confident of that",
  "99:32": "prediction now we can't use that for",
  "99:35": "regression so instead we use something",
  "99:37": "called mean squared error and if you",
  "99:40": "remember from last lesson we actually",
  "99:43": "implemented being squared error from",
  "99:44": "scratch it's just the difference between",
  "99:45": "the two squared and added up together",
  "99:49": "okay so we need to tell it this is not",
  "99:52": "classification so we use mean squared",
  "99:53": "error shown all these so this is not",
  "100:04": "classification so we have to use mean",
  "100:06": "squared error and then once we've",
  "100:08": "created the learner we've taught it what",
  "100:09": "loss function to use we can go ahead and",
  "100:11": "do Ella find we can then fit and you can",
  "100:15": "see here within a minute and a half",
  "100:18": "our mean squared error is 0.0004 now the",
  "100:23": "nice thing is about like mean squared",
  "100:24": "error that's very easy to interpret",
  "100:26": "right so we're trying to predict",
  "100:28": "something which is somewhere around",
  "100:31": "a few hundred and we're getting a",
  "100:34": "squared error on average of 0.0004 so we",
  "100:38": "can feel pretty confident that this is a",
  "100:39": "really good model and then we can look",
  "100:41": "at the results by learner results and we",
  "100:43": "can see predictions ground truth it's",
  "100:47": "doing nearly perfect job okay so that's",
  "100:52": "how you can do image regression models",
  "100:56": "so anytime you've got something you're",
  "100:57": "trying to predict which is some",
  "100:59": "continuous value you use an approach",
  "101:01": "that's something like this so last",
  "101:08": "example before we look at some kind of",
  "101:09": "more foundational theory stuff NLP and",
  "101:13": "next week we're going to be looking at a",
  "101:15": "lot more NLP but let's now do the same",
  "101:19": "thing but rather than creating a",
  "101:21": "classification of pictures let's try and",
  "101:24": "classify documents and so we're going to",
  "101:29": "go through this in a lot more detail",
  "101:30": "next week but let's do the quick version",
  "101:32": "rather than importing from faster I",
  "101:35": "Division are now import for the first",
  "101:37": "time from faster I dot text that's where",
  "101:39": "you'll find all the application specific",
  "101:41": "stuff for analyzing text documents and",
  "101:44": "in this case we're going to use a data",
  "101:45": "set called IMDB and IMDB has lots of",
  "101:50": "movie reviews they're generally about a",
  "101:54": "couple of thousand words and each movie",
  "101:57": "review has been classified as either",
  "102:00": "negative or positive so it's just in a",
  "102:04": "CSV file so we can use pandas to read it",
  "102:06": "we can take a little look we can take a",
  "102:08": "look at a review and basically as per",
  "102:13": "usual we can either use factory methods",
  "102:17": "or the data block API to create a",
  "102:20": "databank so here's the quick way to",
  "102:22": "create a data bunch from a CSV of texts",
  "102:25": "data bunch from CSV and that's that and",
  "102:32": "yeah at this point I could create a",
  "102:35": "learner and start training it but we're",
  "102:38": "going to show you a little bit more",
  "102:39": "detail which remain going to look at",
  "102:41": "next week the steps that actually happen",
  "102:43": "when you create these data buns",
  "102:45": "there's a few steps the first is it does",
  "102:48": "something called tokenization or does it",
  "102:51": "takes those words and it converts them",
  "102:54": "into a standard form of tokens where",
  "102:57": "there's basically each token represents",
  "103:00": "a word but it does things like see here",
  "103:02": "see how didn't has been turned here into",
  "103:05": "two separate words and you see how",
  "103:07": "everything's been lowercased see how",
  "103:10": "your has been turned into two separate",
  "103:12": "words so tokenization is trying to make",
  "103:15": "sure that each each token each each",
  "103:19": "thing that we've got with spaces around",
  "103:21": "it here represents a single you know",
  "103:24": "linguistic concept okay",
  "103:28": "also it finds words that are really rare",
  "103:32": "like really rare names and stuff like",
  "103:35": "that and replaces them with a special",
  "103:37": "token called unknown so anything's",
  "103:40": "starting with XX in fast AI is some",
  "103:42": "special token so this is tokenization so",
  "103:46": "we end up with something where we've got",
  "103:48": "a list of tokenized words you'll also",
  "103:51": "see that things like punctuation end up",
  "103:53": "with spaces around them to make sure",
  "103:55": "that they're separate tokens the next",
  "103:59": "thing we do is we take a complete unique",
  "104:03": "list of all of the possible tokens",
  "104:05": "that's called the vocab and that gets",
  "104:07": "created for us and so here's the first",
  "104:10": "ten items of the vocab so here is every",
  "104:13": "possible token the first ten of them",
  "104:15": "that appear in our all of the movie",
  "104:17": "reviews and we then replace every movie",
  "104:21": "review with a list of numbers and the",
  "104:24": "list of numbers simply says what",
  "104:27": "numbered thing in the vocab is in this",
  "104:30": "place so here 6 is 0 1 2 3 4 5 6 so this",
  "104:35": "is the word ah and this is 3 0 1 2 3",
  "104:39": "this was a comma and so forth right so",
  "104:42": "through",
  "104:43": "organization and numerical ization this",
  "104:46": "is the standard way in NLP of turning a",
  "104:48": "document into a list of numbers we can",
  "104:53": "do that with the data block API right so",
  "104:56": "this time it's not image files list",
  "104:59": "it's text spit data from a CSB convert",
  "105:04": "them to datasets tokenize the numerical",
  "105:08": "eyes them create a data bunch and at",
  "105:12": "that point we can start to create a",
  "105:17": "model as we learn about next week when",
  "105:22": "we do NLP classification we actually",
  "105:24": "create two models the first model is",
  "105:27": "something called a language model which",
  "105:31": "as you can see we train in a kind of a",
  "105:34": "usual way we say we want to create a",
  "105:36": "language model learner we train it we",
  "105:40": "can save it and we unfreeze we train",
  "105:42": "some more and then after we've created a",
  "105:44": "language model we fine-tune it to create",
  "105:47": "the classifier so here's the thing where",
  "105:49": "we create the data bunch of the",
  "105:50": "classifier we created learner train it",
  "105:58": "and we end up with some accuracy so",
  "106:02": "that's the really quick version we're",
  "106:04": "going to go through it in more detail",
  "106:05": "next week but you can see the basic idea",
  "106:07": "of training and NLP classifier is very",
  "106:11": "very very similar to creating every",
  "106:13": "other model we've seen so far and this",
  "106:17": "accuracy so the current state of the art",
  "106:19": "for IMDB classification is actually the",
  "106:24": "algorithm that we built and published",
  "106:26": "with colleague called as named Sebastian",
  "106:29": "Reuter and this basically what I just",
  "106:32": "showed you is pretty much the state of",
  "106:34": "the art algorithm with some minor tweaks",
  "106:35": "you can get this up to about 95% I'm if",
  "106:39": "you try really hard so this is very",
  "106:40": "close to the state of the art accuracy",
  "106:42": "that we developed the question okay",
  "106:48": "that's a great time for question for a",
  "106:54": "dataset very different than imagenet",
  "106:55": "like the satellite images or genomic",
  "106:57": "images shown in lesson two we should use",
  "107:00": "our own stats Jeremy once said if you're",
  "107:03": "using a pre trained model you need to",
  "107:04": "use the same stats it was trained with",
  "107:06": "why is that isn't it that normalized",
  "107:09": "data with its own stats will have",
  "107:11": "roughly the same distribution",
  "107:12": "like imagenet the only thing I can think",
  "107:15": "of which may differ is skewness is it",
  "107:18": "the possibility of skewness or something",
  "107:19": "else the reason of your statement and",
  "107:22": "does that mean you don't recommend using",
  "107:23": "pre train models with very different",
  "107:25": "data sets like the one point mutation",
  "107:28": "that you mentioned in lesson two nope",
  "107:34": "as you can see I've used pre trade",
  "107:36": "models for all of those things",
  "107:38": "every time I've used an image Nate train",
  "107:39": "pre train model and every time I've used",
  "107:41": "image net stats why is that because that",
  "107:45": "model was trained with those stats so",
  "107:48": "for example imagine you're trying to",
  "107:51": "classify different types of green frogs",
  "107:55": "so if you were to use your own per",
  "107:58": "channel means from your data set you",
  "108:00": "would end up converting them to a mean",
  "108:02": "of zero a standard deviation of one for",
  "108:05": "each of your red green and blue channels",
  "108:07": "which means they don't look like green",
  "108:09": "frogs anymore they now look like grey",
  "108:11": "frogs right that imagenet expects frogs",
  "108:14": "to be green okay so you need to",
  "108:17": "normalize with the same stats that the",
  "108:19": "imagenet training people normalized with",
  "108:21": "otherwise the unique characteristics of",
  "108:24": "your data set won't appear anymore",
  "108:25": "you've actually normalized them out in",
  "108:27": "terms of the per channel statistics so",
  "108:29": "you should always use the same stats",
  "108:31": "that the model was trained with okay so",
  "108:40": "in every case what we're doing here is",
  "108:44": "we're using gradient descent with mini",
  "108:48": "batches so stochastic gradient descent",
  "108:50": "to fit some parameters of a model and",
  "108:53": "those parameters are parameters to",
  "108:56": "basically make fixed multiplications and",
  "108:59": "the second half of this part we're",
  "109:01": "actually going to learn about a little",
  "109:02": "tweak called convolutions but it's a",
  "109:04": "basically a type of matrix",
  "109:06": "multiplication",
  "109:07": "the thing is though no amount of matrix",
  "109:11": "multiplications is possibly going to",
  "109:13": "create something that can read IMDB",
  "109:18": "movie reviews and decide if it's",
  "109:19": "positive or negative or look at",
  "109:21": "satellite imagery and decide whether",
  "109:23": "it's got a road in it that's far more",
  "109:26": "and linear classifier can do now we know",
  "109:28": "these are deep neural networks and deep",
  "109:31": "neural networks period contain lots of",
  "109:33": "these matrix multiplications but every",
  "109:35": "matrix multiplication is just a linear",
  "109:39": "model and a lot a linear function on top",
  "109:42": "of a linear function is just another",
  "109:45": "linear function if you remember back to",
  "109:48": "your you know high school math you might",
  "109:51": "remember that if you you know have a y",
  "109:54": "equals ax plus B and then you stick",
  "109:56": "another you know C y plus D on top of",
  "110:01": "that it's still just another slope and",
  "110:04": "another intercept so no amount of",
  "110:06": "stacking matrix multiplications is going",
  "110:09": "to help in the slightest so what are",
  "110:13": "these models actually what are we",
  "110:14": "actually doing and here's the",
  "110:18": "interesting thing",
  "110:19": "all we're actually doing is we literally",
  "110:24": "do have a matrix multiplication or a",
  "110:26": "slight variation like a convolution that",
  "110:28": "we'll learn about and but after each one",
  "110:30": "we do something called a non linearity",
  "110:34": "or an activation function an activation",
  "110:38": "function is something that takes the",
  "110:39": "result of that matrix multiplication and",
  "110:42": "sticks it through some function and",
  "110:46": "these are some of the functions that we",
  "110:50": "use in the old days the most common",
  "110:55": "function that we used to use was",
  "110:58": "basically this shape these shapes are",
  "111:02": "called sigmoid and they have you know",
  "111:09": "particular mathematical definitions",
  "111:12": "nowadays we almost never use those for",
  "111:16": "these between H matrix multiply nowadays",
  "111:21": "we nearly always use this one it's",
  "111:25": "called a rectified linear unit it's very",
  "111:28": "important when you're doing deep",
  "111:29": "learning to use big long words that",
  "111:31": "sound impressive otherwise normal people",
  "111:33": "might think they can do it too but just",
  "111:37": "between you and me a rectified linear",
  "111:39": "unit",
  "111:39": "is to find using the following function",
  "111:46": "that's it",
  "111:48": "okay so and if you want to be really",
  "111:51": "exclusive of course you then shorten the",
  "111:54": "long version and you call it a RAL you",
  "111:56": "to show that you're really in the",
  "111:57": "exclusive in the exclusive team so this",
  "112:00": "is a value activation right so here's",
  "112:04": "the crazy thing if you take your red",
  "112:07": "green blue pixel inputs and you chuck",
  "112:10": "them through a matrix modification and",
  "112:11": "then you replace the negatives with zero",
  "112:15": "and you put it through another matrix",
  "112:17": "modification place the negatives at zero",
  "112:19": "and you keep doing that again and again",
  "112:21": "and again you have a deep learning",
  "112:23": "neural network that's it right so how",
  "112:28": "the hell does that work so extremely",
  "112:32": "cool guy called Michael Nielsen showed",
  "112:34": "how this works he has a very nice",
  "112:38": "website affecting more than a website",
  "112:40": "it's a book neural networks and deep",
  "112:43": "learning calm and he has these beautiful",
  "112:45": "little JavaScript things where you can",
  "112:48": "get to play around because this was back",
  "112:50": "in the old days this was back when we",
  "112:52": "used to use sigmoids right and what he",
  "112:54": "shows is that if you have enough little",
  "112:58": "these shows these little matrix",
  "113:00": "multiplications if you have enough",
  "113:01": "little matrix multiplications followed",
  "113:03": "by sigmoids and there's exactly the same",
  "113:05": "thing works for a matrix multiplication",
  "113:07": "followed by a value you can actually",
  "113:09": "create arbitrary shapes right and so",
  "113:15": "this this this idea that these",
  "113:17": "combinations of of linear functions and",
  "113:22": "nonlinearities can create arbitrary",
  "113:25": "shapes actually has a name and this name",
  "113:27": "is the universal approximation theorem",
  "113:30": "and what it says is that if you have",
  "113:33": "stacks of linear functions and",
  "113:36": "nonlinearities the thing you end up with",
  "113:38": "can approximate any function arbitrarily",
  "113:43": "closely so you just need to make sure",
  "113:46": "that you have a big enough matrix to",
  "113:48": "multiply by or enough of them so if you",
  "113:52": "have",
  "113:53": "you know now this this this dysfunction",
  "113:56": "which is just a sequence of matrix",
  "113:58": "multiplies and nonlinearities where the",
  "114:00": "nonlinearities can be you know basically",
  "114:02": "any of these things we normally use this",
  "114:04": "one if that can approximate anything",
  "114:07": "then all you need is some way to find",
  "114:09": "the particular values of the of the",
  "114:12": "weight matrices in your matrix model",
  "114:14": "players that solve the problem you want",
  "114:15": "to solve and we already know how to find",
  "114:18": "the values of parameters we can use",
  "114:20": "gradient descent and so that's actually",
  "114:23": "it right and this is the bit I find the",
  "114:28": "hardest thing normally to explain to",
  "114:30": "students is that we're actually done",
  "114:33": "male people often come up to me after",
  "114:35": "this lesson and they say what's the rest",
  "114:39": "please explain to me the rest of deep",
  "114:41": "learning but like no there's no rest",
  "114:43": "like we have a function where we take",
  "114:46": "our input pixels or whatever we multiply",
  "114:48": "them by some weight matrix we replace",
  "114:50": "the negatives with zeros we multiply it",
  "114:52": "by another weight matrix replace the",
  "114:53": "negative zeros we do that a few times we",
  "114:56": "see how close it is to our target and",
  "114:58": "then we use gradient descent to update",
  "115:01": "our weight matrices using the",
  "115:02": "derivatives and we do that a few times",
  "115:05": "and eventually we end up with something",
  "115:07": "that can classify movie reviews or can",
  "115:11": "recognize pictures of reptile cats that",
  "115:15": "that's actually it okay so it's it's the",
  "115:18": "reason it's hard to understand",
  "115:22": "intuitively is because we're talking",
  "115:26": "about weight matrices that have you know",
  "115:28": "once you read them all up something like",
  "115:30": "a hundred million parameters they're",
  "115:33": "very big weight matrices all right so",
  "115:35": "your intuition about what multiplying",
  "115:39": "something by a linear model and",
  "115:41": "replacing the negative zeros a bunch of",
  "115:43": "times can do your intuition doesn't hold",
  "115:46": "right you just have to accept",
  "115:49": "empirically the truth is doing that",
  "115:52": "works really well so in part two of the",
  "115:56": "course we're actually going to build",
  "115:58": "these from scratch right but I mean just",
  "116:02": "to skip ahead you know basically we'll",
  "116:05": "find that you know it's going to be",
  "116:07": "kind of five lines of code right it's",
  "116:09": "going to be a little for loop that goes",
  "116:10": "you know T equals you know X at weight",
  "116:16": "matrix one t2 equals max of T comma zero",
  "116:23": "stick that in a for loop that goes",
  "116:25": "through which weight matrix and at the",
  "116:27": "end calculate my loss function and of",
  "116:31": "course we're not going to calculate the",
  "116:32": "gradients ourselves because pi torch",
  "116:34": "does that for us and that's about it so",
  "116:42": "okay Kristin there's a question about",
  "116:46": "tokenization I'm curious about how",
  "116:48": "tokenizing words works when they depend",
  "116:50": "on each other such as San Francisco yeah",
  "116:56": "okay okay tokenization how do you",
  "117:05": "tokenize something like san francisco",
  "117:09": "san francisco contains two tokens San",
  "117:13": "Francisco that's it that's how you",
  "117:16": "tokenize San Francisco the Christian may",
  "117:18": "be coming from people who have done like",
  "117:22": "traditional NLP often need to kind of",
  "117:26": "use these things called engrams and",
  "117:28": "engrams are kind of this idea of like a",
  "117:30": "lot of NLP in the old days was all built",
  "117:34": "on top of linear models where you",
  "117:36": "basically counted how many times",
  "117:38": "particular strings of text appeared like",
  "117:41": "the phrase San Francisco that would be a",
  "117:44": "bigram",
  "117:45": "for an Engram with an N of 2 the cool",
  "117:49": "thing is that we're deep learning we",
  "117:50": "don't have to worry about that like like",
  "117:52": "with many things a lot of the complex",
  "117:55": "feature engineering disappears when you",
  "117:56": "do deep learning so with deep learning",
  "117:58": "each token is literally just a word or",
  "118:03": "in the case that the word really",
  "118:05": "consists of two words like you're you",
  "118:07": "split it into two words and then what",
  "118:10": "we're going to do is we're going to then",
  "118:13": "let the deep learning model figure out",
  "118:16": "how best to combine words together",
  "118:20": "now when we see like let the beep",
  "118:21": "learning model figure it out of course",
  "118:22": "all we really mean is find the weight",
  "118:26": "matrices using gradient descent that",
  "118:28": "gives the right answer like there's not",
  "118:30": "really much more to it than that again",
  "118:34": "there's some minor tweaks right in the",
  "118:36": "second half of the course we're going to",
  "118:37": "be learning about the particular tweak",
  "118:39": "for image models which is using a",
  "118:41": "convolution there'll be a CNN for",
  "118:44": "language there's a particular tweak we",
  "118:46": "do called using recurrent models or an",
  "118:49": "RNN but they're very minor tweaks on on",
  "118:53": "what we've just described so basically",
  "118:54": "it turns out with an R and n that it it",
  "118:58": "can learn that sound plus Francisco has",
  "119:03": "a different meaning when those two",
  "119:05": "things are together some satellite",
  "119:10": "images have four channels how can we",
  "119:12": "deal with data that has four channels or",
  "119:14": "two channels when using pre-trained",
  "119:16": "bottles yeah that's a good question I",
  "119:22": "think that's something that we're going",
  "119:23": "to try and incorporate into fast AI so",
  "119:28": "hopefully by the time you watch this",
  "119:29": "video they'll be easier ways to do this",
  "119:31": "but the basic idea is a pre trained",
  "119:36": "imagenet model expects a red green and",
  "119:39": "blue pixels so if you've only got two",
  "119:44": "channels there's a few things you can do",
  "119:46": "but basically you'll want to create a",
  "119:49": "third Channel and so you can create the",
  "119:52": "third channel as either being all zeros",
  "119:54": "or it could be the average of the other",
  "119:57": "two channels and so you can just use you",
  "120:01": "know normal hi torch arithmetic to",
  "120:05": "create that third channel you could",
  "120:06": "either do that ahead of time in a little",
  "120:09": "loop and save your three Channel",
  "120:11": "versions or you could create a custom",
  "120:13": "data set class that does that on demand",
  "120:18": "for a full channel you probably don't",
  "120:23": "want to get rid of the fourth channel so",
  "120:25": "instead what you'd have to do is to",
  "120:26": "actually modify the model itself so to",
  "120:30": "know how to do that we'll only know how",
  "120:32": "to do",
  "120:33": "in a couple more lessons time but",
  "120:35": "basically the idea is that the initial",
  "120:37": "weight matrix weight matrix is really",
  "120:41": "the wrong term they're not waiting",
  "120:42": "matrices their weight tensors so they",
  "120:45": "can have more than just two dimensions",
  "120:47": "so that weight that initial weight",
  "120:49": "matrix in the neural net it's going to",
  "120:52": "have it's actually a tensor and one of",
  "120:54": "its axes is going to have three whatever",
  "120:58": "three slices so you would just have to",
  "121:02": "change that to add an extra slice which",
  "121:05": "I would generally just initialize to",
  "121:07": "zero or to some random numbers so that's",
  "121:11": "the short version but really to answer",
  "121:13": "this to understand exactly what I meant",
  "121:15": "by that we're going to need a couple",
  "121:16": "more lessons to get there okay",
  "121:20": "so wrapping up what if we looked at",
  "121:24": "today basically we started out by saying",
  "121:34": "hey it's really easy now to create web",
  "121:39": "apps we've got starter kits for you that",
  "121:43": "show you how to create web apps and",
  "121:45": "people have created some really cool web",
  "121:47": "apps using what we've learned so far",
  "121:48": "which is single label classification but",
  "121:54": "the cool thing is the exact same steps",
  "121:57": "we use to do single label classification",
  "122:00": "you can also do to do multi-label",
  "122:04": "classification such as in the planet or",
  "122:12": "you could use to do segmentation or you",
  "122:19": "could use to do or you could use to do",
  "122:26": "any kind of image regression or this is",
  "122:30": "probably a bit earlier if you try this",
  "122:31": "yet you could do for an LP",
  "122:33": "classification and a lot more so and in",
  "122:37": "each case all we're actually doing is",
  "122:42": "we're doing gradient descent on not just",
  "122:45": "two",
  "122:46": "parameters but on maybe 100 million",
  "122:49": "parameters but still just plain gradient",
  "122:51": "descent along with a non-linearity which",
  "122:58": "is normally this one which it turns out",
  "123:01": "the universal approximation theorem",
  "123:03": "tells us lets us arbitrarily accurately",
  "123:06": "approximate any given function including",
  "123:09": "functions such as converting a spoken--",
  "123:13": "waveform into the thing the person was",
  "123:15": "saying while converting a sentence in",
  "123:17": "Japanese to a sentence in English while",
  "123:20": "converting a picture of a dog into the",
  "123:22": "word dog these are all mathematical",
  "123:25": "functions that we can learn using this",
  "123:27": "approach so this week see if you can",
  "123:33": "come up with an interesting idea of a",
  "123:35": "problem that you would like to solve",
  "123:37": "which is either multi-label",
  "123:39": "classification or image regression or",
  "123:43": "image segmentation something like that",
  "123:46": "and see if you can try to solve that",
  "123:51": "problem you will probably find the",
  "123:53": "hardest part of solving that problem is",
  "123:56": "coming up creating the data Bunch and so",
  "123:58": "then you'll need to dig into the data",
  "124:00": "block API to try to figure out how to",
  "124:02": "create the data Bunch from the data you",
  "124:04": "have and with some practice you will",
  "124:09": "start to get pretty good at that it's",
  "124:10": "not a huge API there's a small number of",
  "124:12": "pieces it's also very easy to add your",
  "124:15": "own but for now you know ask on the",
  "124:18": "forum if you try something and you get",
  "124:21": "stuck ok great so um next week we're",
  "124:27": "going to come back and we're going to",
  "124:29": "look at some more NLP we're going to",
  "124:31": "learn some more about some details about",
  "124:35": "how we actually train with SGD quickly",
  "124:37": "we're going to learn about things like",
  "124:38": "Adam and rmsprop and so forth and",
  "124:42": "hopefully we're also going to show off",
  "124:44": "lots of really cool web apps and models",
  "124:47": "that you've all built during the week so",
  "124:49": "I'll see you then Thanks"
}
