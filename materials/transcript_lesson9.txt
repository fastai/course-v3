welcome back to lesson 9 part 2 how to train your model.
before we talk about training our model though I wanted to revisit a couple of things that came up last week and the the reason I really wanted to revisit them is because I wanted to kind of give you an insight into how I do research I mean a lot of this course really will be me showing you how I do research and how I do software development in the hope that that is somewhat helpful to you so one of the questions that came up last week was we we looked at as the size of that okay we looked at now we look inside the NN com 2d that comes with play torch to see how it goes about initializing parameters and we found that inside inside here conven d dot reset parameters we found the way that it does initialization and we've found this math dot square root 5 without any commentary which was quite mysterious so I decided to do some research into you know kind of Joule research one is like what's the impact of this math dot square root 5 and then at the same time trying to get in touch with the PI torch team about asking them where this math dot square root of 5 comes from so let me show you how I went about doing that research I so I loaded up just what we had from from last week which was the ability to download the amnesty door and open it up and and then the function to normalize it which I thought weird we export if we haven't already and then we'd grab the data and we'd normalize it and I because we're going to be talking a lot about convolutions towards the end of today's lesson and particularly next lesson I suspect so I'll skip over some of the details about convolutions for now but basically to do a convolution as you know we need a you know a square or rectangular input and our amnesty input remember was just a single vector per image 768 long so every sized them all to 28 by 28 one channel images so that we could test out the impact of this kampf 2d in it in play torch and set up the various variables that we wanted to have and then I created a calm 2d layer so we have one input because it's just one channel NH which is number hidden which is 32 outputs and let's do a 5x5 kernel now we're talking more about why 5x5 might be suitable and just for testing let's just grab the first hundred elements of the validation set so we've now got a tensor of 100 by 1 by 28 by 28 so it's a really good idea when you're playing with with anything in software development but but including notebooks to refactor things so I'm going to be wanting to look at the mean and standard deviation of a bunch of things so let's create a little function called stats to do that and I never plan ahead what I got to do what when you see this in a notebook it always means that I've written out that by hand and then I copied it and then I'm like ok I'm using it twice I'll check it in a function so then I go back and create the function so here I've got the mean and standard deviation of my l1 which is a Khan 2d layer and so a kanji layer contains a weight tensor perimeter and a bias tensor prouder okay so just to remind you l1 weight dot shape is 32 output filters because that's what number hidden was one input filter we only have one channel and then 5x5 okay so that's the size of our tensor and if you've forgotten why that's the size of a tensor you can go back to the Excel directory for example from part one where you can find the convict sample spreadsheet and in the convict sample spreadsheet you can see what each of those parameters does okay so we basically had a filter for each input channel and for each output Channel so that's kind of what it looked like and so cjz for the next layer we now have a four dimensional tensor or rank four tensor at three feather three by three we've got it for each input and for each output okay so that's the 32 by one by five by five so the mean and standard deviation of the weights zero and point 1 1 and this is because we know there behind the scenes it's called this function to initialize so the bias is initialized with a uniform random number between negative of this and positive of this and then the weights are initialized with comiing uniform with this odd math dot square root five thing so that's fine that's not particularly interesting what's more interesting is to take our input tensor of M nest and put it through this layer which we called l1 which remember is a comma 2d layer so layer 1 and let's create an output T and let's look at the stats of T so this is the stats of the output of this layer and we would like it to be a mean of zero and it's to end a standard deviation or variance of one the mean of zero is there the no deviation of one is not there so that looks like a problem let's compare this to the normal climbing in it so the normal climbing in it remember is designed to be used after a value layer or more generally a leaky value layer and recovered a leaky rally layer has the y equals x here and here the gradient of this is called a or leak or whatever right and now in our case we're just looking at a conflict it's straight here as well so effectively we have like a leak if you like of one or an a of one all right so to use climbing in it with no real you we can just put a equals one and if we do that then we get a mean of 0 and a variance of 1 so climbing in it seems to be working nicely okay so let's now try it with real you so let's now define a function which is the function for layer 1 which is to pass it through our layer 1 con and then to a rail you with some a there's some leak amount which were all set to 0 by default so this will be just a regular value and you can see that if we now run that if we now run that with climbing initialization we get a variance of 1 which is good and the main is no longer 0 as we discussed last week it's about 1/2 but if we go back and and reinitialize the klom to D with this default player torch this is not looking good at all with rel you it's even worse because remember they don't have anything kind of handling that rel you case in the d4 Khanh so this looks like a problem so a variance of 0.35 it may not sound a lot lower than one but let's look take a look at what that means so I forgot to mention where we are this is the zero to a why square root of five notebook so zero to a notebook so in order to explore this I decided that I would try and write my own climbing init function and so normally with the climbing init function if we were working with just a regular fully connected matrix multiplication we would basically be saying how many output filters are there so what's the if this is the weight matrix then what's the what's the width of the weight matrix for a convolutional layer it's a little bit different it's a little bit different right because what we actually want to know is each time like in this case we're basically multiplying all these together with some set of inputs and then adding them all up right that's basically what a single step of a matrix multiplication is in a convolution we're also multiplying a bunch of things together and adding them up but what we're actually adding together is if it was 3 by 3 is we're multiplying together each of the 3 by 3 elements right and also the channel dimension right we actually multiply all of those together and add them all up so because convolution and matrix multiplication are kind of one in the same thing as we know with some weight tying and with some with some zeros so in order to calculate the total number of multiplications and additions going on for a a convolutional layer we need to basically take the kernel size which in this case is five by five and multiply it by the number of filters okay so the general way to get that five by five peace is we can just grab any one piece of this weight tensor and that will return a 5x5 kernel and then say how many elements are in that part of the weight tensor and that's going to be the receptive field size so the receptive field size for just the immediate layer before is you know how many how many elements are in that kernel so for this it's 25 it's 5x5 all right and so if we then say okay let's grab the shape of the weight matrix and it gives us the number of filters out 32 and then the number of filters in 1 and then I'll skip the rest because they're the only two things I want so now for the climbing her in it we can calculate fan-in is the number of input filters times the receptive field size so that's 1 times 25 fan out is 32 by 25 so there you can see this is how we calculate the effective fan-in and fan-out for a convolutional layer so we can do all that by hand and then the the climbing init formula you need to then for leaky value you need to multiply by root 2 or if there's a leaky part in it so if the a is not equal to 0 then it's actually root 2 divided by 1 plus a squared so that's just the formula for the climbing in it and that's often called the gain for the unit and so there's the formula for the gain so you can see that if the gain is 1 right then that's just linear there's no non-linearity at all so there's no change to the calculation of how you do the initialization on the other hand if it's a standard value then you've got the root 2 which we saw last week from the from the climbing paper with a gain of 0.01 it's about root 2 as well it's pretty close and this is a kind of a common leak l√º amount but what about in the case of the PI torch in it and the case of the play torch in it it's root 5 which is 0.577 which sounds like an odd number it's a long way away from what we were expecting to see so that's a bit concerning but one thing we have to account for here is that the initialization that they use for pi torch is not coming normal it's climbing uniform right and so normally distributed random numbers look like that but uniform random numbers look like that right and so the uniform random numbers they were using as they're kind of starting point were between minus 1 and 1 and so the standard deviation of that obviously is not one right the standard deviation is obviously less than one and so you can Google for the standard deviation of a uniform distribution or you could jump into excel or Python and just grab a bunch of random numbers and find out what the standard deviation is and you'll find that you can I've got it here actually I've grabbed 10,000 random numbers in that uniform distribution and asked for their standard deviation and it turns out that it's 1 over root 3 ok so part of the reason for this difference actually is that they need a gain to handle uniform random numbers rather than just normal random numbers but it still doesn't quite account for the difference so let's take a look so here's here's my version of climbing in which I've just grabbed all of the previous lines of code and merge them together and then I've just added this thing to multiply it by root three because of the uniform rental number and so then if I run this climbing to on my weights and get the stats of that nice I again get a variance of about one and again confirming that if I well this is interesting if I do it with a equals method square root five I would expect to get the same result as the PI torch default which I do it's about 0.4 which is what we found back here 0.35 so it seems like we've successfully you know re implemented what they had so at this point I was like okay well what is this what does this do what does this mean so to see kind of what this looks like I threw together a quick confident and I grabbed the first hundred dependent variables and so then I took my input and I ran it through the whole confident to get the stats out of the results so this is now telling me what happens when I use the default pi torch in it and put it through a four layer confident and the answer is I end up with the variance of 0.006 and that sounds likely to be a really big problem right because there's there's so little variation going on that last layer and also there's a huge difference between the first layer and the last layer that's the really big issue the first layer had a standard deviation of 0.4 and the last layer had us down to deviate well the input layer is is 1 the the the first hidden layer is 0.4 and the last layer is 0.06 so these are all going at like totally different rates and then what we could do is we could grab that prediction and put it through a mean squared error this is the function we created last week run backward and get the stat stats on the gradients for the first layer weights so this is now gone all the way forward and all the way back again and again standard deviation is nowhere near one so that sounds like big problem so let's try using climbing uniform instead and if you look at the climbing uniform source code you'll see that it's got this it's got the steps that we saw gained over route of the fan and here is the square root of three because it's uniform okay and so we can confirm let's go through and go through every layer and if it's a convolutional layer then let's call climbing uniform on the weights and set the biases to zero so we'll initialize it ourselves and then we'll grab T and it's not 1 but it's a lot better than 0.008 so this is pretty encouraging that we can get through four layers we wouldn't want to probably have a 40 layer neural network which is losing this much variance but it should be fine plenty good enough for a 4 layer Network and then let's also confirm on the backward and the backward the first layer is gradient is 0.5 so that was my kind of starting point for the research here and at the end of the S I kind of thought this is you know pretty concerning and why did I think it was concerning we'll be seeing a lot more about why it's concerning but let's quickly look at to be initializing so silver and put this together today and he called this why you need a good in it and he's just he's pointed out here that if you grab two as we grab a random vector X and a random matrix a which is random normally distributed mean 0 and standard deviation of 1 then a hundred times you basically go X is a times X and then you go so you're basically multiplying again and again and again after a hundred iterations your standard deviation and main are not a number so basically the issue is that when you multiplied by a matrix lots and lots of times you explode out to the point that your computer can't even keep track so what silver did next was he actually put something in a loop to check whether it's not a number and he found it was 20 what 20 only 28 iterations before before it died so it didn't take very long to to explode now in the other hand what if we take the you know random numbers for the standard deviation of 0.01 instead of 1 and we do that 100 times then it disappears to zero so you can see like you know if you've got a hundred layer neural net because that's what it's doing it's doing 100 matrix multiplies on itself right on the on the output of each previous one you've got to be super careful to find some set of weights that because because if this is your starting set of weights if it's 0.01 or if it's one standard deviation you can't ever learn anything because there are no gradients the gradients are either zero or Nan right so you actually have to have a reasonable starting point and this is really why for decades people weren't able to train deep neural networks because people hadn't figured out how to initialize them so instead we have to use some better in it ok and we'll talk about that in a moment for those who are interested still fans think gone on to describe why it is that you have to divide by the square root of the fan and so feel free to keep reading that if you're interested it's it's cool but we don't need to know it for now it's just some derivation and further discussion so in parallel I also asked the pipe torch team about this you know sent these results to them and I said what's going on and so sumif finally appeared and he said it was a historical accident because 15 years ago or for 15 years for Plato watch appeared there was a product called torch a neural network product in Lua and they did it that way and so then on Google+ in 2014 he started talking to so on a diliman who's now at deep mind and about at this time maybe a bit before he was in town actually and so under said this is a teen lytic hmm and so under said this this root five thing looks weird and sumit said no no go look at the paper and so and I said no that's not what the paper said and sumit said oh it's a bug but it's a good bug because somebody at somebody went and checked it out and they thought that they were getting better results with this thing so so then I dropped to tusu myth and he was already aware of this issue to some extent and within a couple of hours pi torch team had created an issue saying they're gonna update their their init's so this is super cool like it so this is like apparently to say well this is a awesome team super responsive and this is why PI torch works so well is that they see issues and they fix them but it's also to say like when you see something in a library don't assume it's it's right or that it makes sense you know when it comes to deep learning none of us know what we're doing and you can see it doesn't take too much to kind of dig into something you know and then you can you know raise an issue and say here's his analysis that I did there's a fantastic extension called gist it G is t just it so Jupiter notebooks that lets you take your little research notebook press a single button and it turns it into a shareable gist that you can then put a link to say here's the analysis as I did and so yeah that's that's a little bit of fun a little bit of research I did into answering this question from last week there are lots of interesting initialization approaches you can use we've already talked about the fluoro and benzio paper we've already talked about the climbing who are paper there's an interesting paper called all you need is a good which describes how you can kind of iteratively go through your network and set one layer of weights at a time to like literally like kind of do a little optimize to find out which set of parameters gets you a unit variance at every point there's another core paper which talks about something called orthogonal initialization if you've done some linear algebra particularly if you've done Rachel's computational linear algebra course you'll know about the idea of orthogonal matrices and they make good init's we talked briefly last week about fix-up initialization and then there's also something called self normalizing neural networks fix-up and self normalizing neural networks are both interesting papers because they describe how to try to set a combination of kind of activation functions and in it such that you're guaranteed a unit variance as deep as you like and both of those two papers went to a something like a thousand layers deep and trained them successfully in both cases the fix-ups much more recent but in both cases people have kind of hailed them as reasons we can get rid of batch norm I think that's very unlikely to be true very very few people use this cell you think now because in both cases they're incredibly fiddly you know so for example in this in the self normalizing neural networks case if you put in dropout you need to put a correction if you you know if you do anything different unit in a correction because as soon as you as you've seen as soon as something changes like the amount of leakiness in your activation function or whatever all you know all of your assumptions about what your variance will be in the next layer disappear and for this cellular paper it was a particular problem because it relied on two specific numbers that were calculated in a famous 96 page long appendix of math in the celje paper and so if you wanted to do a slightly different you know architecture in any way until they only showed this a fully connected network so even if you want to do convolutions what you got to do you know redo that 96 pages of meth so that 96 pages of meth is now so famous that has its own Twitter handle the cell you appendix which has the pin tweet why does nobody want to read me and this is like literally what the entire snotty six pages of the appendix looks like I will mention that this in my opinion this is kind of a dumb way of finding those two numbers the all you need is a good inert paper is a much better approach to kind of doing these things in my opinion which is like if you've got a couple of parameters you need to set then why not kind of set them using a quick little loop or something you know so if you if you need those if you want to find to kind of sell you parameters that work for your architecture you can find them empirically pretty quickly and pretty easily okay so that's a little bit about in it we'll come back to more of that very shortly there was one other question from last week which was we noticed that the shape of the kind of manual linear layer we created and the shape of the plate which one were transposed and the question was why and so again I did some digging into this until eventually Sumer from the high touch team pointed out to me this commit from seven years ago in the old Lua torch code where this actually happened and that basically it's because that old lower library couldn't handle batch matrix multiplication without doing it in this transposed way and that's why it's jool to this day PI torch does it and it upside down which is fine like it's not slower it's not a problem but again it's kind of an interesting case of like I find this happens all the time like in in deep learning something's done a particular way forever and then everybody does it that way forever and nobody goes back and says why now this particular case it really doesn't matter I don't think but often it does right so like things like how do we initialize neural networks and how many layers should they have and stuff like that they kind of nobody really thought of like nobody really change challenged the normal practices for years so I'm hoping that with this you know really ground-up approach you can see what the assumptions we're making are and see how to question them and see that you know even to me play torch is the best library around at the moment and even play torch has these weird kind of archaic edges to it okay so that was a little diversion to start with but a fun diversion because that's you know something I spend a couple of days this week on and I think it's pretty interesting so to go back to how do we implement a basic modern CNN model we got to this point so we've done a matrix modification so that's our f-fine function we've done real you so that's our non-linearity and so a fully connected Network forward is simply layering together those two things as how we did that and then we did the backward pass and we kind of reflected that nicely and it turned out that it looked pretty similar to PI torches way of doing things and so now we're ready to train our model and that's where we're up to so here we are oh three mini-batch training and we're going to train our model so we can start by grabbing our emne stata so again we're just importing the stuff that we just exported from a little previous class here's the model we created in the previous class and so gets get some predictions from that model and we'll call them pred okay and so now to train our model the first thing we need to do is we need a loss function because without a loss function we can't train it now previously we used mean squared error which I said was a total cheap now that we've decided to trust play torches Auto grad we can use many more things because you don't have to write our own gradients and I'm too lazy to do that so let's go ahead and use cross entropy because cross entropy makes a lot more sense to remind you from the last class there is an entropy example notebook where we learnt first of all that cross entropy requires doing two things first of all softmax well in the case it's multi multi class a categorical cross entropy first through soft Max and then you do the negative log likelihood so the soft max was if we have a bunch of different possible predictions and we've got some output for each one from our model then we take e to the power of that output we sum them all up and then we take the e to the power of divided by the sum of e to the power of and that was our soft max so there it is in math form there it is in summation math form and here it is in code form okay so e to the X divided by X X sum and then the whole thing we do a dot log and that's because in PI Torche negative log likelihood expects a log softmax not just a soft Max and we'll see why in a moment I'm sorry pop a log in the end so here's our loft log of softmax function so now we can go ahead and create our soft max to predictions by passing Preds to log soft max now that we've done that we can calculate cross-entropy loss and cross-entropy loss is generally expressed in this form which is this form sum of actual times the log of the probability of that actual so in other words if we have is Katun is dog then here's our actuals so it's one hot encoded is cat yes is dog no we have our predictions from our from our model from our soft max we can then say well what's the log of the probability it's a cat so log of this what's the log of the probability it's a dog so log of one minus that and so then our negative log likelihood is simply B times e plus C times F and then take the negative of all that that's negative log likelihood which is what this is but remember and I know I keep saying this because people keep forgetting not you guys but people out in the world keep forgetting that when you're multiplying by stuff which is mainly zero and one hot encoded multi you know categorical classification most of your categories are zero every time you multiply by zero you're doing nothing at all but you're doing it very slowly so rather than multiplying by zero and then adding up the one one that you have a much faster way as we know to do to multiply by a 100 coded thing is to first of all simply say what's the location of the one here so in this case it's location 2 in this case just location 1 if we indexed from 1 and then we just look up into our array of probabilities directly offset by this amount or to put it in math terms for one Hutton coded X's the above is simply log of P I where I is the index of our prediction sorry not a prediction of the actual so the index into here of the actual so how do we write this in pi torch and I'll show you a really cool trick this is that this is what we're going to end up with this is our negative log likelihood implementation and it's incredibly fast and it's incredibly concise and I'll show you how we do it let's look at our dependent variable so let's just look at the first three values there 5:04 ok so that's the first three elements of the dependent variable and so what we want to do is we want to find what is the probability associated with five in our predictions and with zero and with four right so our predictions our softmax predictions remember fifty thousand by ten okay and so if we take the very first of those delay Ola right and so it said that the the actual answer should be five so if we go into this zero one two three four five that's the answer that we're going to want right okay so here's how we can grab all three of those at once we can index into our array with the whole thing five zero four and then for the first bit we pass in just the contiguous integers zero one two why does this work this works because pi torch supports all of the advanced indexing support from numpy and so if you click on this link one of the many things that types of indexing that numpy and therefore plate or supports is integer array indexing and what this is is that you pass a list for each dimension so in this case we have two dimensions so we need to pass two lists and the first is the list of all of the row indexes you want and the second is the list of all of the column indexes you want so this is going to end up returning 0 comma 5 1 comma 0 and 2 comma 4 which is the exact numbers that we wanted so example 0 5 is minus 2 point 4 9 right so to grab the entire list of the exact things that we want for our negative log-likelihood then we basically say okay let's look in our predictor let's look in our predictions and then for our row indexes it's every single row index so a range of target shape 0 so target doctor shape 0 is the number of rows so range of that is all of the numbers from zero to the number of rows so zero one two three blah blah blah fifty thousand four forty nine thousand ninety nine and then which columns do we want for each of those rows well whatever our target is whatever the actual value so in this case five zero four etc so that returns all of the values we need we then take - because it's negative log-likelihood and take the mean so that's all it takes to do negative log-likelihood in height watch which is super wonderfully easy so now we can calculate our loss which is the negative log likelihood if the softmax predictions that's what we had up here compared to our actual Y trading and so there it is now this was our softmax formula which is e to the x over sum of e to the x's so we have a and then it's all logged so we've got a log of a over B and remember I keep telling you that like one thing you want to remember from high school math is how logs work so I do want you to try to recall that log of a over B is log of a minus log of B and so we can rewrite this as log of a to the X minus log of all that and of course e to the something and log are opposites of each other so a log of e to the X is just X so that ends up being X minus X dot X dot some log okay so this is useful and let's just check that that actually works so as I kind of keep refactoring these things as even as I'd like to me these mathematical manipulations are just refactoring right so just refactoring the math so you keep checking along so we created tests near last time so let's use it to make sure that it's a similar the same as our loss now you'll see here this is taking the log of the some of the exper and there's a trick called log some X now the reason we need this trick is that when you go e to the power of something you can get ridiculously big numbers and if you've done Rachel's new computational linear algebra course then you'll know that very big numbers in floating point on a computer are really inaccurate basically the further you get away from zero the less kind of fine-grained they are you know gets to the point where like two numbers the thousand apart the computer thinks they're the same number so you don't want big numbers particularly when you're calculating gradients so anywhere you see an e to the X we get nervous we don't want X to be big but it turns out that if you do this at all mathematical substitution you can actually subtract a number from your X's and add them back at the front and you get the same answer so what you could do is you can find the maximum of all of your X's you can subtract it from all of your X's and then add it back afterwards outside the XP and you get exactly the same answer so in other words let's find the maximum let's subtract it from all of our X's and then let's do log some X and then at the end we'll add it back again and that gives you exactly the same number that without this numerical problem all right so when people talk about like numerical stability tricks they're talking about stuff like this and this is a really helpful numerical stability trick so this is how you do log some X in real life we can check that this one here is the same as and look in fact log some X is already a method in Python it's such a important and useful thing you can just actually use plant torches and you'll get the same result as the one we just wrote so now we can use it so log softmax is now just X minus X dot log some X and let's check yep still the same so now that that's all working we may as well just use player torches log softmax and PI tortures and LLL loss but actually NL our loss of LOC softmax is called cross entropy so finally we get tests near F dot cross entropy is the same as loss and it is ok so we've now recreated five torches cross entropy so we're allowed to use it according to our rules ok so now that we have a loss function where you can use it to train and we may as well also define a metric because it's nice to see accuracy to see how we're going it's just much more interpretable and remember from part one that the accuracy is simply grabbed the Arg max ok to find out which which which of the numbers in our softmax is the highest and the index of that is our prediction and then check whether that's equal to the actual and then we want to take the mean but in plaid torch you can't take the mean of intz you have to take the mean of floats which makes some sense so turn it into a flow first so there's our accuracy so let's just check let's grab a batch size of 64 and let's grab our first x batch this is our first playing around with mini batches right so our first x batch is going to be our training set from 0 up to batch size so our predictions is we're just going to run our model and remember our model was linear value linear first you're using a super simple model so let's calculate some predictions and let's have a look at them and here's some predictions and it's 64 by 10 as you'd expect batch size 64 and ten possible probabilities right so now we can grab our first batch of dependent variables and calculate our loss okay and it's 2.3 and calculate our accuracy and as you'd expect it's about 10% because we haven't trained our model ok so we've got a model that's giving basically random answers so let's train it so we need a learning rate we need to pick a number of epochs and we need a training loop so our training loop if you remember from part one remember lesson two SGD our training loop looks like this calculate your predictions calculate your loss through backward subtract learning rate times gradients and zero the gradients okay so let's do exactly the same thing so we're gonna go through each epoch and go through I up until n which is 50,000 that's the number of rows but integer divided by batch size because we're going to do a batch at a time and so then we'll grab everything starting at I times batch size and ending at that plus batch size so this is going to be our first this is going to be our eighth mini batch and so let's grab one X mini batch one Y mini batch and pass that through the model and our loss function and then do backward and then we're going to do our update which remember we have to do with no grad because this is not part of the gradient calculation and this is the result of it but now we can't just go a dot subtract learning rate times gradient we have to do that for every single one of our parameters so our model has three layers there really has no parameters in it so the linear layer has weight and bias and this linear layer has weight and bias so it basically got four tensors to deal with so we're going to go through all of our layers and let's just check whether that layer has an attribute called weight or not that's a bit kind of more flexible than hard coding things and if it does then let's update the weight to minus equals the gradient of that by the learning rate the bias to the bias gradient by the learning rate and then zero those gradients when we're done so let's run it and then let's check the loss function and the accuracy and the loss has gone down from 2.3 to 0.05 and the accuracy has gone up from point 1 2 to 1 notice that this accuracy is for only a single mini batch and it's a mini batch from the training set so it doesn't mean too much but obviously our model there's learning something so this is good so this is this is the you know we're we're now well we haven't really done comm I guess we've got a basic training we're now here we have a basic training loop which is great so we kind of got all the pieces so let's try to make this simpler because this is too much code right and it's too hard to fiddle around with so the first bit we'll do is we're going to try and get rid of this mess and we're going to replace it with this and then so the difference here is rather than manually going through weight and bias for each one we're going to loop through something called model parameters so we're not even going to look through the layers we're just going to loop directly through model parameters and for each parameter will say that parameter minus equals gradient times learning rate so somehow we need to be able to get all of the parameters of our models if we could do that we could greatly simplify this part of the loop and also make it much more flexible right so to do that we could create something like this and it's calling this dummy module right and in dummy module what I'm going to do is I'm going to say every time I set an attribute like l1 or l2 to a you know in this case to linear I want to update a list called underscore modules with a list of all of the modules I have so in other words after I create this dummy module I want to be able to print out and here's my representation I want to be able to print out the list of those modules and see the modules that are there because then I can define a method called parameters that will go through everything in my underscore modules list and then go through all of their parameters and that's what I'll be able to do see I could do here model dot parameters so how did I create this you see it's not inheriting from something right this is all written in pure Python how did I make it so that as soon as I said here's an attribute in my in my inert that somehow it magically appeared in this underscore modules list so that I could then create these parameters so that I could then do this refactoring and the trick is that Python has a special dunder set atra method and every time you assigned to anything inside self inside python it will call this method if you've got one and so this method just checks that my the key so in other words the attribute name doesn't start with underscore because if it does it might be underscore modules and then it's going to be like a recursive loop and also pythons got all kinds of internal stuff that starts with underscore so as long as it's not some internal private stuff put that value inside my modules dictionary and call it K that's it all right then after you've done that do whatever the superclass does when it sets attributes and in this case the superclass is object if you don't say what it is that it's just the Python highest level object so now we have something that has all of the stuff we need to to do this refactoring ma'am but the good news is ply torch also has something that does that and it's called an end up module so we can do the exact same thing rather than implementing that set attribute stuff ourselves we can just call just inherit from an end up module and it does it for us right and so this is now you know why you have to call super dunder init first right because it has to set up its equivalent of this underscore modules dictionary right so that's why you have to call super init first and then after you've done that in ply torch it's exactly the same as what I just showed you it now creates something which you can access through named children and you can see here if I printed out the name and the layer there is the name and the layer alright so this is how play torch does the exact same thing just like I created a dunder repre pipe which also has a dunder repre so if you just print out model it prints it out like so you can grab the attributes just in the normal pythonic waves it's just a normal Python class it has a bit of bit of this extra behavior so now we can run it with this refactoring make sure everything works and there we go okay so this is doing exactly the same thing as before but a little bit more conveniently not convenient enough for my liking so one thing we could try to do is to get rid of the need to write every layer separately maybe go back to having it as a list again so if we made it a list of layers right and then we want to be able to pass that to some model class pass in the layers this is not enough to make them available as parameters right because the only thing that actually that play torch is going to make available as parameters or things that that it knows are proper and end up modules so but here's the cool thing you can just go through all of those layers and call self dot add module that's just the equivalent of what I did here when I said self don't understand my drills blah blah right so in play torch you can just call self to add module and just like I did you gave it a name and then you pass in the layer and so if you do that if you do that then you end up with the same thing okay so that's one that's one thing you can do but this is kind of clunky so it'd be nice if played torch would do it for you and it does that's what any end modulus does so if you if you create if you use an end module list then it just basically calls that line of code for you so you can see us doing it here if we've got to create something called sequential model which just set self dot layers to that module list and then when we call it it just goes through each layer x equals that layer of X and returns it and there's that okay even this is a little bit on the clunky side why would we have to write it ourselves we don't apply torch has that code already it's called an n dot sequential okay so we've now recreated and n dot sequential and there it is doing the same thing so again we're not creating like dumbed down versions if you look at n n dot sequential and you look at the source code and you look it forward it's just it's even the same name itself go through each module in self to underscore modules to at values input equals module import return input right so that's their version and remember our version you know was basically the same right and we could even put it in something called underscore modules so yeah that's what that's all in in dot sequential is doing for you okay so we're making some progress it's less ugly than it used to be still more ugly than we would like this is this is where we got our v function up to so let's try and simplify it a bit more let's replace all this torch no grade for P and module or parameters blah blah blah with something where we could just write those two lines of code that would be nice so let's create a class cord optimizer we're going to pass in some parameters and store them away and we're going to pass in the learning rate and we're going to store that away and so if we're going to be able to go up step up step has to do this so here is step with swatch not know grad go through each parameter and do that okay so it's just factor that out and zero grad we probably shouldn't actually go model dot zero grad because it's actually possible for the user as you know to say I don't want to include certain parameters in my optimizer so when we're doing like gradual and freezing and stuff so really zero grad should actually do this it should go through the list of parameters that you asked to optimize and zero those gradients so here we've now created something called optimizer and we can now grab our model and so we remember that the model now we've created something called dot parameters so we can pass that to our optimizer and then we can now just go up step up 0 grad and let's test it and it works okay now of course luckily for us pipe torture already has these lines of code it's called up Kim STD now optimist GD does do a few more things weight decay momentum stuff like that so let's have a look he's up to him Don SGD and here's a step function so it's got weight decay momentum dampening this trough we're gonna see all these things very shortly but basically all it does is it goes through each layer group and it does the exact thing that we just see okay so once you remove the momentum and stuff and we're going to be implementing this in a much better way than pi torch in very soon so once you remove all that they're up team dot SGD is exactly the same as our optimizer so let's go ahead and use that instead when so it's kind of nice then if we're going to use all those parameters of the model let's just create a gap model which creates our model and returns it as well as a SGD optimizer with all the parameters and okay there's our training loop and seems to be working it's to put tests in from time to time and I like to put these tests in like hey my accuracy should be significantly better than 50% you know note that these kind of stochastic tests are highly imperfect in many ways it's theoretically possible it could fail all because you got really unlucky I know though that this is really it's vanishingly unlikely to happen it's always much more than 90% it's also possible that your code could be failing in a way that causes the accuracy to be a bit lower than it should be but not this low but I still think it's a great idea to have these kinds of tests when you're doing machine learning because they give you a hint when something's going wrong and you'll notice I don't set a random seed at any point this is very intentional I really like it that that if there's variation going on when I run my model at different times I want to see it I don't want it to be hidden away behind a fixed seed so there's a there's a big push in science for like reproducible science which is which is great for many reasons but it's not how you should develop your models when you're developing your models you want to have a kind of good intuitive sense of what bits are stable and what bits are unstable and how much variation do you expect and so if you have a test which you know fails one every out of a one every 100 times it's it's good to know that you know and so like in the first day I code there's lots of tests like that and so then sometimes you know there'll be a test that fails it's nothing particularly to do with a push that just happened but it's it's really helpful for us because then we can look at it and be like oh this thing with short should pretty much always be true sometimes isn't true and then we'll go back and we'll all deeply study why that is and figure out how to make it more stable and how to make it reliably pass that test so this is a kind of a controversial kind of test to have that's something that I found in practice is very very very helpful it's not complete and it's not totally automated and it's imperfect in many ways but it's none less helpful okay let's get rid of these two lines of code these were the lines of codes that grabbed our X mini-batch from the training set and the y mini-batch from the training set let's do them both in one line of code so be nice to have one line of code we have some kind of object where we can pass in the index as we want and get back both x and y and that's quite a data set as you know so here's our dataset class again not inheriting from anything it's all from scratch claw python we initialize it by passing in the X and the y you'll store them away it's very handy to have a length hopefully you know by now if you don't then now's a good time to realize that done delenn is the thing that lets you go Len of something in Python and have it work that's what Len will fall so now we've got the length of our data set and dunder get item is a thing that when you index into it it will return that and so we just returned the tupple of X I and Y I so let's go ahead and create a data set for our training set and a validation set check that the lengths are right check the first few values make sure they all seem sane now we'll grab our model and as I said we will replace those two lines of code with one and so at this point our training loop is getting quite neat it's not as neat as it could be but it's getting quite neat okay so the next thing we're going to do so that's the data set next thing we're going to do is create a data loader this is what the start of our training loop looked like before and let's replace it with this single line of code okay so to do that we're going to have a class we're going to have to have a class that takes a data set and a batch size and stores them away and when you go for blah in blah behind-the-scenes in Python it calls dunder you know and so what we're going to do is we're going to loop through range from 0 up to the size of the data set jumping up batch size at a time so 0 64 128 etc up to 50,000 and each time we go through we will yield our data set at an index starting at I and ending up ending at I plus self-taught batch size probably quite a lot of you haven't seen yield before it's an incredibly useful concept it's if you're really interested it's something quite a co routine it's basically this really interesting idea that you can have a function that doesn't return just one thing once that can return lots of things and you can kind of ask for it lots of times so the way these iterators work in python is that you when you when you call this it basically returns something which you can then call next on lots of times and each time you call next it will return the next thing from that that is yielded so it's not I don't have time to explain co-routines in detail here but it's it's really worth looking up and learning about we'll be using them Lots they're a super valuable thing and it's not just for data science they're really handy for things like network programming web apps stuff like that as well so well worth being familiar with yield in Python and nowadays most programming languages have something like this so you'll be able to take it to wherever you go so now we have a data loader we can create a training one and a validation one and we can this is how we do it it's a valid DL is the thing that basically kind of generates our Co routine for us and then next is the thing that grabs the next thing yielded out of that Co routine so this is a very common thing you'll be doing lots next a table you'd probably did it a whole lot of times in part one because we kind of did it without diving in very deeply into what's going on and that returns one thing from our data set and the data set returns two things because that's what we put in it so we expect to get two things back and we can check that those two things are the right size so that's outdated loda and so let's double check there it is good stuff so now there's our fitness function let's call the fitness function looking good so this is about as neat as we're going to get that's that's quite beautiful right it's kind of all the steps you can think of if you said it in English there go through each epoch go through each batch grabbing the independent independent variable calculate the predictions calculate the losses calculate the gradients update with the learning rate reset the the gradients so that's you know that's kind of where you want to get is to a point where you can read your code in a very kind of intuitive way to it to mine expert and until you get to that point it's very hard really I find to really maintain the code and understand the code and this is the trick for doing research as well as it's not just for you know hardcore software engineering a research that can't do those things to their code can't do research properly right because if you think of something you want to try you know you don't know how to do it or it takes weeks or if there are bugs in it you don't know so you know you want your code to be quite beautiful and I think this is beautiful code and this is at this point you know you know these this data set and this data loader are the same abstractions that PI torch uses so let's dig into this a little bit more we do have a problem which is that we're always looping through our training set in order and that's very problematic because we lose the randomness of kind of shuffling it each time particularly if our training set was already like ordered by a dependent variable then every batch is going to be exactly the same dependent variable so we really want to shuffle it so let's try random sampling so for random sampling I'm going to create a sampler class and we're going to pass into it a data set to sample and a batch size and something that says with it a shuffle or not right and as per usual we just store those away I don't actually store away the data set I just store away the length of the data set so that we know how much how many items to sample okay and then here's that here's our dunder era right so remember this is the thing that we can call next on lots of times and so if we are shuffling then let's grab a random permutation of the numbers from naught to N minus 1 and if we're not shuffling then let's grab all of the integers in order from 0 to n minus 1 and then this is the same we had before go through that range and yield the indexes so what does that look like here's a sampler with shuffle equals false and a batch size of 3 Oh 1 2 3 4 5 6 7 8 9 and here it is with shuffle equals true five four three seven six two eight nine oh one so now that we've got these we can now replace our data loader with something where we pass it a sampler and we then loop through 4s in sampler so it's going to loop through each of these right and the cool thing is that because we're used yield these are only going to be calculated when we ask for them they're not all calculated upfront so we can use these on really big data sets no problem and so it's kind of this is a common thing is where you're actually looping through something which is itself for co-routine and then yielding something which does other things to that so this is like a really nice way of doing streaming computations it's being done lazily you're not gonna run out of memory it's it's really neat way to do things and so then we're going to grab all of the indexes in that sample and we're going to grab the data set at that index so now we've got a list of tenses and then we need some way to callate them all together into a single tenses and so we've created a function called kholate which just grabs the XS and the Y's and stacks them up so torch stack just grabs a bunch of tensors and glues them together on a new axis you might want to do different things like add some padding or you know stuff like that so you can pass in a different collection if you want to and it will store it away and use it right so now we can create our two samplers we can create our two data loaders with those samplers so the training one is shuffling the valid ones not shuffling so let's check as the validation data loader and the training data loader if we call it twice with exactly the same index we get different things in this case we've got two eights but they're different eights call it another two times we're getting different numbers okay so it's it is shuffling as we hoped and so again we can train our model and that's fine so the PI torch data loader does exactly that so let's import the PI torch data loader and you can see it takes exactly the same arguments okay and we can even pass in the exact collate function that we just wrote it's it doesn't have a single sampler that you pass shuffle equals true or false true it has to set sample as one called random one called sequential so slightly different to the API we just wrote but does exactly the same thing and so you can create those data loaders and works exactly the same so that's what a ply torch data loader does most of the time you don't need the flexibility of writing your own sampler and your own collation function so you can just pass in shuffle and it will use the default sampler and collation function that work the way we just showed something that we did not implement in PI torches data loader is that implant registered loader you can pass in an extra parameter called enum workers and that will fire off that many processes and each one will separately grab stuff out of your data set and or collect them together afterwards and so if your datasets doing things like you know opening big JPEG files and doing all kinds of image transformations that's a really good idea so we won't implement that all right so finally for this section we should add validation so to know if we're overfitting we need to have a separate validation set so here's the same loop that we had before and here's and here's the same loop pretty much again but with torch no Grad going through the validation set so for this we grab the predictions and the loss as before but we don't call backward and we don't step the optimizer because just the validation instead we just keep track of the loss and we also keep track of the accuracy okay the only other difference is that we've added here model train and here model dot eval what does that do well actually all it does is it sets a internal attribute called dot training to true or false so let's try it if I put print model training after each one and train this it's a true false true false true false okay and so why does it set this thing called model dot training to true or false because some kinds of layers need to have different behavior depending on whether it's training or evaluation or validation for example batch norm only updates its running statistics if it's training dropout only does randomize dropout if it's training okay they're the two main ones so that's why you always want to have trained an eval and if you forget to put something into a vowel mode when you're done training you'll often be surprised because you'll be getting worst results than you expected okay so that's that's our fit loop one thing to note these validation results correct if the batch size vary spell that correctly if if the batch size varies because what we're doing here is we're adding up the loss and we're adding up the accuracy and then at the end we see how big is our data loader how many batches are there and we divide but if you think about it if you had one mini batch of size a thousand and one mini batch of size one you can't actually just do that right you can't you actually need to a weighted average weighted by the size of the mini batch so this in correct way is how nearly every library does it first day I does it the proper way and next time we do this we're going to do it the proper way okay but for now here's what most people do and it does not work correctly when your batch size varies so it it's handy to have something that we can basically pass in a training data set and a validation data set in a batch size too and just grab the data loaders the training data set will be shuffled validation won't be shuffled also the validation data set we don't need to do the backward pass so we don't need to store the gradients so that means that we have twice as much room so we can make it twice this size twice the batch size so it's you know another nice thing to refactor out you don't have to tape it anymore and also it means you won't accidentally make a mistake and so now we can go ahead and fit and it's do five epochs and so now these are actual validation accuracies okay great so we've successfully built a training loop let's have a six minute break come back at 7:55 and talk about callbacks before we continue our ritual any questions okay so why do we have to zero out our gradients in pi torch why do you have to zero at your gradients in pi torch so yeah the way we let's go sure so it is a here's our optimizer right or let's go back even further here's here's our first version so this is just with no additional help from pi torch at all if we didn't go grab zero here then what's gonna happen the next time we go through and say lost our backward is it's gonna add the new gradients to those existing gradients now why does that happen well that happens because we often have kind of lots of sources of gradients you know there's lots of kind of different modules all connected together and so they're getting their gradients from lots of different places and they all have to be added up so so when we call backward we wouldn't want backward to zero the gradients because then we would lose this ability to kind of plug in lots of things together and just have them have them work so that's why we need the grad zero here so then you know that's part that's part one of the answer part two of the answer is why did we write our optimizer so that was one thing called step and one thing called zero grad because what we could have done is we could have removed these lines and pushed this up here and so that step could have done both and then since we've actually got this kind of twice now we could put it all inside the for loop so we could certainly have written our optimizer like this as I go through each parameter and does the update and sets the gradient to zero and then we would be able to remove this line so the problem with that is that we then remove the ability to not zero the gradients here and that means anytime that we don't want to zero the gradients now can't use the optimizer so for example what if you working with some pretty big objects so like if you're doing super resolution and you try to create a 2k output you know your batch size you can only fit two images on the GPU at a time and the stability of the gradients that you get from a batch size of two is so poor that you need to use a larger batch size so well that would be really easy to do if you did it like this right because we could say if I percent two then right and so this is now going to only run these things every two iterations and so that means that it better our effective batch size is now double so that's handy right that's called gradient accumulation the gradient accumulation is where you change your training loop so that you're your optimizer step and your zero grads only happen occasionally so that's really the reason is it is that there might be times you don't want to zero the gradients every time you do a step and if you or if there's nowhere to do that that's a problem there you could argue that I can't think of a reason that this isn't a good idea we could make our optimizer we could say kind of like Auto zero equals true say and then we could have something in here which kind of says like if self dot Auto zero then self dot zero grad right something like that and then that could even be the default and then you wouldn't have to worry about it unless you explicitly wanted to do great into accumulation think that would be really be a better API design maybe but that's not what they've done but it's so easy to write your own optimizers you could totally do that but I mean do you know the upside is removing a single line of code which isn't a huge upside anyway so yeah any other questions Rachel nope okay okay so that's our training loop but it's not quite where we want it to be and I'm stealing some slides here from Sylvia who had a really cool talk recently called an infinitely customizable training loop so I was deal with her slides before I all do I would like to do a big THANK YOU to silver he has been working full-time with fast AI for well over a year now I guess and a huge amount of what you see in the FASTA a library and research and courses is is him so massive thank you to silver who's the most awesome person I've worked with in my whole life so that's pretty cool but also thank you to lots of other people huge thanks to stairs who a lot of you will have come across in the forum and he's he's done a lot of the stuff that makes faster I work well and he's entirely a volunteer so like super grateful to him you know the stuff that lets you check whether your installation works properly that lets you quickly check whether your performance is what it should be also like organizing lots of helpful projects through the forums he's been fantastic lots of other folks as well Andrew Shaw wrote a lot of the original kind of documentation stuff that we have Fred Munro has been helpful in thousands of ways and is just incredibly generous Jason a lot of you will already be aware of who helped a lot with the final lesson of the last course and is hard at work now on taking it even further to doing some stuff that's going to blow you away I particularly would point out Radek because this is the list of the I can't quite count as a 20 most helpful people on the forum as ranked by a number of likes you know when somebody clicks that like button that means they're saying you know you've you've helped me and more people have said that about Reddick than anybody else and it's not surprising because Reddick is just not just incredibly helpful person but extremely thoughtful and he's now a I mean he gosh you know when he started with as a first day I student he considered himself F remember correctly basically a failed ml student he had tried a number of times to learn ml and hadn't succeeded but he's just applied himself so well for the last couple of years and he's now a Kaggle winner you know a world recognized deep learning practitioner and so thank you to all of these people and everybody else who's contributed in so many ways and of course rachel who's sitting right next to me so this is the fit function that we just wrote or the one this the the slightly more elegant one before we added validation to it okay so go through each epoch go through which sort of mini bet to go through each mini batch get the prediction the loss backward pass update your parameters and then 0 the gradients so that's basically what we're doing okay model predictions loss gradients step okay and each time we grab a bit more training data but that's not really all we want to do in a training loop we might want to add the beautiful fast progress progress bars and animations that silver created in his class progress library or tensor board or whatever and thanks to Jason actually we now have tensor board integration in fast AI so be sure to check that out if you want extra pretty graphs like these hyper parameter scheduling you might want to add all kinds of different regularization techniques these are all examples of regularization techniques that we support in fast AI and many more mixed precision training you know so take advantage of the tensor cause you know volta GPU to train much faster there's more tweaks you might want to do the training loop then then we could possibly think of and even if we did think of all of the ones that exist now somebody will come up with a new one tomorrow so the so you've got some possible ways you could solve this problem and you know some some of the things we're talking about are even things like how do you how do you add ganz more complex stuff so one approach is write a training loop for every possible way you want to train and this is particularly problematic when you start to like when a combine multiple different tweaks right as you like cutting and pasting or whatever so that's certainly not going to work for a fast AI there's what I tried for fast AI 0.7 this is my training loop the last time I tried this which is like throw in every damn thing and it and it just got you know so every time somebody would say like oh well new papers come out can you please implement and I'll just be like no I couldn't bear it so now we have something better callbacks and callbacks or something which like every library has callbacks but nobody else have callbacks anything like our callbacks and you'll see what I mean our callbacks let you not only look at but fully customized every one of these steps right and so here's our starting training loop here's the first AI version 1 training loop it's the same right there's the exact same lines of code plus a bunch of calls to callbacks and so each one basically says you know before I do a step on step again after I do a step on step end after I do a batch on batch end after I do an epoch on epoch end after finish training on training end right and they have the ability to also change things or even they have the ability to say please skip the next step by returning a boolean so with this we can create and have created all kinds of things in faster I like learning rate schedulers and early stopping and parallel trainer this is literally when I wrote parallel trainer this is the entire callback I wrote this is the entire gradient clipping clawback right after you do the backward pass clip the gradients so you can do a lot with a little and then you can mix them all together right because all of the callbacks work with all of the other callbacks all right so these are some of the callbacks that we have in fast AI right now so for example how did we do games last course so what we did behind the scenes was we created a gain module it was ridiculously simple we created again module that had a forward method that just said what's your generator mode is it sorry are you in generator mode or not and we're not means discriminator mode if you're in generator mode called the generator otherwise called the critic and then there's a function called switch that just changed generator mode backwards and forwards between generator and discriminator same thing if we created a loss function where there was a generator loss and a critic loss and so then we created a callback right which had a switch that just switched the generator mode on and off and passed that along to the model I just showed you and the loss function I just showed you and then it would set requires grad to the generator or discriminator as appropriate and then would have untrained begin on train and on that repeater blah blah blah callbacks to do the right thing at the right time so most importantly at the start of an epoch set your generator mode and at the end of training set your generator mode alright so yeah if you look at kind of other libraries implementation of Gans they're basically kind of a whole new training loop whole new data loaders whole new everything and it was really cool in fast AI we were able to create a gain in this you know incredibly small amount of code for such a complex task so let's let's do that ourselves right because we've got a training loop if we add callbacks we should now then be able to do everything so let's start out by grabbing our data as before so we've got the number of hidden is 50 batch size 64 loss function is cross-entropy this is the signature of our fit function before and I got very nervous when I see functions with lots of things being passed to it and it makes me think that we really need to pass all those things to it or can some of them be packaged up together there's a lot of benefits to packaging up things together when you can package up things together where they're kind of like things you can pass them around to everything that needs them together you can create them using kind of factory methods that create them together and you can do smart things like look at the combination of them and make smart decisions for your users rather than having to have them set everything themselves so there's lots of reasons that I would prefer to keep epochs right but I'd like to put all these other things into a single object and specifically we can do that in two steps first of all let's take this data and say training and valid data conceptually should be one thing it's my data but maybe there's test data there as well so let's create a class called data bunch that we're going to pass in training data and validation data and we'll store them away and that's the entirety there's no logic here but for convenience let's make it easy to grab the data set out of them as well hey and remember we're now using you can either use the that the hand made data loader that we built in the last one or you can use the apply torch data loader they're both providing exactly the same API at this point except for the num workers issue so they remember that we passed these data load as a data set that you can access and then it would be nice if we could create a get model function which could create our model but automatically set the last layer to have the correct number of activations because the data knows how many activations it needs so let's also optionally make it that you can pass in C which is going to get stored away so that then when we create our data we can pass in C which remember we set to our maximum Y value and so that way we never have to think about that again so that's our so that's our data bunch class so there's our get model so it's just going to create a model with the number of inputs is the size of the input data a number of hidden is whatever we had earlier if we pass in then a value and then a linear from here into dated C and we'll turn the model and an optimizer and we all know all about dot parameters now so then the other rest of the stuff model loss func opt and data let's store them in something model applause plant data and we'll just store them away and that thing will call a learner so notice our learner class has no logic at all okay it's just a storage device for these four things so now we can create a learner passing in the model and the optimizer since they're returned in this order from get model we can just say star get model so that's going to pass in the model and the optimizer and we've got our loss function already at the top here we set it to cross entropy and we've got our data because it's that data bunch we just created right so this there's nothing magic going on with data bunches and learners so just like wrappers for the information that we need so now we'll take the fit function we had before and I just pasted it here but every time I had model I replaced it with learned up model every time I had data I replaced it with learned data and so forth okay so there's the exact same thing that we had before still working fine and so now let's add call backs so our fit function before basically said for epoch in range epochs for batch in train DL and then it had these contents write predictions lost backwards step 0 grad I factored out the contents into something called one batch okay and then I added all these callbacks all right CB dot after backward CD dot after step I did one other refactoring which is that the training loop has to loop through every batch and the validation loop has to loop through every batch so I just created something called all batches okay so this is my Fit loop right begin fit the epoch in epochs begin epoch or batches with the training set begin validate no gred or batches with the validation set after epoch after pit okay so that's that so here's a callback right which has all the stuff and so then we need a callback handler and that's going to be something which you just say here's all my callbacks and basically it's just going to go through each thing and say go through every callback and call it and keep track of whether we've received a false yet or not false means don't keep going anymore and then return it so we do that for beginning fit after fit begin epoch begin validate after epoch begin batch after loss after backward after step so here's an example of a little callback we could create and it's one that's going to at the start of the fit it'll set number of iterations to zero and then after every step it'll say number of iterations plus equals one and print that out and if we get past ten iterations then it'll tell the learner to stop because we have this little thing called do stop that gets checked at the end so let's test it there we go and so it called fit and it only did 10 batches and this is actually a really handy callback because quite often you want to like just run a few batches to make sure things seem to be working you don't want to run a whole epoch so here's a quick way you can do something like that this is basically what fast AI v1 looks like right now it does have a little bit of extra stuff that lets you pass back and different lofts and different data but it's nearly exactly the same but I really like rewriting stuff because when I rewrite stuff it lets me kind of look and see what I've written and when I looked back at this I saw CB CB CB CB e CB it's like it it's there's this object this is the CP is the callback handler that's being passed everywhere and that's a code smell that code signal says something should have that state and specifically these three functions should be the methods of something that has this state so after I kind of wrote this part of the lesson I suddenly realized oh fast AI is doing at the dumb way so let's fix it so I've and this is likely to appear in a future version of fast AI I created a new thing called Rena and so runner is a new class runner is a new class that contains the three things I just said one batch all batches and fit right and the runner so here's his fit right it's incredibly simple we've got a keep track of how many epochs we're doing we've got a kick track of the learner that we're running and remember the learner has no logic in it just stores four things okay and then we tell each of our callbacks what Runner they're currently working with and then we call begin fit and then we go through each epoch set the epoch we call begin epoch we call all batches and then with no grad we call begin validate and then we call all batches and then we call after epoch and then we call after fit that's it now this self string might look a bit weird but look at what we had before again horrible code smell is lots of duplicate code res equals true for callback blah blah blah blah blah begin epoch res equals true for callback blah blah blah blah begin validate so that's bad right code duplication means cognitive overhead to understand what's going on lots of opportunities to accidentally one or instead of an end lots of places you have to change if you need to edit something so basically I took that out and I factored it out into dunder call so dunder call is the thing that we've seen it before it's the thing that lets you treat an object as if it was a function so I could have called this lots of things I could have called it self dot run callback or whatever right but it's the thing that happens absolutely everywhere and so my kind of rule of thumb is if you do something lots of times make it small so dander call is the smallest possible way you can call something you don't have to give it a name at all when you call it so we say call the callback called after epoch it also makes sense right we're calling a callback so why not use dunder call or to call or call back so after epoch I got to go through all of my callbacks I talked about this sorted in a moment and then the other thing I didn't like before is that all of my callbacks had to inherit from this callback superclass because if they didn't then they would have been missing and one of these methods and so then when it tried to call the method they would have made an exception and I don't like forcing people to have to inherit from something they should be able to do whatever they like so what we did here so what we did here was we used get attribute which is the Python thing which says look inside this object and try to find something of this name eg begin validate and default to none if you can't find it right so it tries to find that callback and that'll be none if the callback doesn't exist and if you find it then you can call it alright so this is a nice way to call any callback but when you implement a callback as you can see look how much easier our test call back is now right it's just super simple just just implement what you need and we inherit from a new callback Plus but we don't have to anymore alright the main reason why is that our core back class now has an underscore order which we can use to choose what order callbacks running we'll talk about that after we handle this question what is the difference between hooks and pi torch and callbacks and fast AI we're going to do hooks very shortly but if you think about it if I want to kind of add a call back after I calculate the forward pass of the second layer of my model there's no way for me to do that right because the point at which I do the forward pass looks like this self dot model right or if I want to hook in to the point at which I've just called the backward pass if my penultimate layer I can't do that either because the whole thing appears here is self but lost or backward okay so Hawks plight watch Hawks callbacks that you can add to specific PI torch modules and we're going to see them in very shortly well it might be next plus we'll see how we go okay so very often you want to be able to inject behavior into something but the different things can influence each other for example transformations we're going to be seeing this when we do data augmentation so quite often you'll need things to run in a particular order so when I add this kind of injectable behavior like callbacks I like to just add something which is what order should it run in you don't have to put this here you might have noticed that what I do when I call this is i/o this currently does sorry actually when we look at transformations it won't require order this one does require an order so yeah okay so your callbacks need to be something that her an underscore order attribute in them and this way we can make sure that some things run after other things so for example you might have noticed that our runner in the fit function never calls model dot a vowel never cause model doctrine so like it literally doesn't do anything you know it just says these are the steps I have to run in the callbacks do the running so I created a train eval callback that at the beginning of an epoch calls model train and the beginning of validation cause model travel and I also added stuff to keep track of how many epochs has it done and this is quite nice it actually does it as a floating point not just as an int so you could be like two point three epochs in at also keeps track of how many iterations do you want so now we have this thing keeping track of iterations our test callback that should stop training after ten iterations rather than keeping track of n it is itself it should just use the ennahdha that was defined in this callback so what we can do is we could say all right well train eval callback has an order of zero with and inherits so what we can just do here is make sure that this is later underscore order equals one okay and so that way we can now refer to stuff that's inside the Train eval callback like a knitter sorry it'll actually we don't even need to do that because it's putting in hitter inside self dot run so we can just go self dot Anita if our or if this ran before trained eval callback that would be a problem because n it o might not have been updated yet so that's what the orders for another nice thing about runner sorry a nice thing about class callback is that I have to find dunder get Etra and I have to find it to say return get atra self dot run come okay an important thing to know about done Durga tetra is that it is only called by Python if it can't find the attribute that you've asked for right so if something asks for self name well I have self dot name so it's never going to get to here okay so if you get to here it means python look for this attribute and it couldn't find it and so very very often the thing you actually want in the callback is actually inside the runner which restore away is self dot run so this means that in all of our call backs let's look at one you can basically just use self dot pretty much everything and it will grab what you want even though most of the stuff you want is inside the runner so you'll see this pattern in fast AI a lot is that when one object contains another object or composes another object we very often delegate get attribute to the other object so for example if you're looking at a data set then I think we delegate to X if you're looking at a stuff in the data blocks API it'll often delegate to stuff lower in the data box API and so forth so I find this pretty handy okay so we have a callback that as you see there's very little to it one interesting thing you might notice is that a callback has a name property and the name property works like this if you have a property called trained eval callback then we've got a function called camel to snake this is called camel case means you've got uppercase and lowercase letters like a camel and snake case looks like this so camel does snake turns this into a snake and then what we do here is we remove call back from the end and that's its name so train eval callback has a name which is just train evil there's an underscore and then in the runner any callback functions that you pass in which it uses to create new callbacks it actually assigns them to an attribute with that name so we now have something called Rana dot train evil for example so we do this in the first do library when you say learned recorder we didn't actually add an attribute called recorder to learner it just automatically sets that because there's a learner callback so so let's see how to use this there's a question okay let's do that in a moment so let's use this to add metrics because it's no fun having a training loop where we can't actually see how we're going and part of the whole point of this is that our actual training loop is now so incredibly tight and neat and easy but we actually want to do all the stuff we want to do so what if we create a little callback called average debts callback right where we're going to stick into it a couple of objects to keep track of our loss and metrics one for training one for valid and at the start of an epoch will reset the statistics at the end of an epoch we'll print out the statistics and after we've got the loss calculated we will accumulate the statistics so then all we need is an object that has an accumulate method so let's create a class that does that and here's our accumulate method it's going to add up the total loss and for each metric it'll add up the total metrics and then we'll give it a property called average stats that will go through all of those losses and metrics and return the average and you might notice here I've fixed the problem of having different batch sizes in the average we're actually being lost times the size of the batch and count plus the size of the batch and metrics times the size of the batch and so then we're dividing here by the total batch size so this is going to keep track of our stats we'll add add under repre so that it prints out those statistics in a nice way and so now we can create our learner add our average stats call back and when we call fit it prints up now we're going and so that's that's the entirety of what it took to add metrics and loss tracking to our minimal training loop yes Rachel runner dunder call exits early when the first callback returns true why is that so one of the things I noticed was really annoying in the first way I wrote the callback handler was I had it so that something had to return something had to return true to mean keep going so basically false meant stop and that was really awkward because if you don't add a return in in Python then it actually returns none and none is false and I thought oh if I forget to return something that should mean keep going that should be like the default so the first thing to point out is that the basic loped now actually says if not rather than if right so if not begin Apoc so in other words if if your callback handler returns false then keep going and so that means that basically none of my callbacks need to return anything most of the time except for test callback which returns true so true means cancel it means stop so if one of my core backs says stop then I mean I could I could certainly imagine an argument in either way that but the way I thought it if it says stop let's just stop right now you know why do we need to run the other callbacks so if it says stop then it returns stop it says we don't want to go anymore and then we can depending on where you are so if it's after a POC returns stop then it's actually going to stop the loop entirely so yeah that's why yeah so this is a little awkward we had to like construct our average stats callback and then we had to pass that to run and then later on we can refer to stats valid stats average stats because remember average stats was where we grabbed this so that's okay but it's a little awkward so instead what I do is I create a accuracy callback function so that is the average stats callback constructor passing in accuracy that with partial so partial returns is a function that returns a function okay and so this is now a function which can create a callback and so I can pass this to C B funks and now I don't have to store it away because the runner this is what we saw before the runner will go through each CB funks it will call that function to create the callback and then it will stick that callback inside the runner giving it this name as the attribute so this way we can say this is our callback function this is our runner fit and now it's automatically available inside run average stats so so this is what fast hiv-1 does except it puts them in side learner because we don't have a runner concept so I think that's pretty handy it's kind of like it looks a little bit awkward the first time you do it but you can kind of create a standard set of callback functions that you want to use for particular types of models and then you can just store them away in a list and you don't have to think about them again which is what you'll see we'll do lots of times so how like a lot of things in this part two of the course you can choose how deep to go on different things I think our approach to callbacks is super interesting and if you do too you might want to go deep here and really look into like you know what kind of callbacks you can build and what things you can do with them that we haven't done yet but you know then a lot of these details around exactly how I do this if you're not as interested in the details of software engineering this might be something you care less about which is fine the main thing that everybody should take away is that that's our training loop okay so you know the other stuff about like exactly how did we create our average stats callback and exactly what does dunder call drew fairly minor details but you should recognize that the fit function stores how many epochs were doing what learner we're working with calls each of the different callbacks at each time right and and like I never remember which ones are at which place if you go to doc stop fast at AI the callbacks documentation will show you personally I just always look at the source code because it's just so easy to see exactly what happens at each time and exactly what's available at each time so let's use this and let's use this to do one cycle training because it's pretty hard when you have to have a constant learning rate all the time particularly because as really wanting to show you like a deep dive which are about to see using hooks a deep dive into how the mechanics or kind of how the dynamics of training models looks like and what we learn is that the first batches everything if you can get the first batches working well then things will tend to be things will begin to be good and this is how you can get super convergence so if you want your first batches to be good it turns out that good annealing is critical so let's do that right away let's set up good and kneeling because we have the mechanics we need because we have callbacks so we're inside o 5 anneal it'll get our data this is all the same as before here's something to create a loaner with one line so let's create a loaner with that same little model we had before and loss function our data and we will create a runner with our average stats callback this defaulted to a learning rate of 0.5 maybe we could try it with learning rate of 0.3 it's pretty handy being able to like quickly create things with different learning rates so let's create a function that's just going to be partial get model with a learning rate and so now we can just call get model funk and pass the learning rate in and will immediately have something with a different learning rate yes tell me the question so what is your typical debugging process my debugging process is to use the debugger so if I got an an exception while I was running a cell then I just go into the next cell and type % debug and that pops up in the debugger if things aren't working the way I expected but it wasn't an exception then I'll just add setting underscore trace somewhere around the point I care about that's about it yeah I find that's that works pretty well most of the time then it's just a case of looking at what's it do what's the shape of everything and what is everything contained like a couple of you know a couple of objects in the batch I normally find something's got Nan's or zeros or whatever yeah it's really rare that using that the bugger that I find debugging is that difficult if it is then it's just a you know case of stepping away and questioning your assumptions but with the help of a debugger that's you know all of the states right there in front of you which is one of the great things about PI torch is that it supports this kind of development okay all right so we're going to create a callback that's going to do hyper parameter scheduling and so for this notebook we're just going to do learning rate as a hyper parameter but it's in the last 12 months one of the really successful areas of research have been people pointing out that you can you can and should schedule everything your drop out amount what kind of data augmentation you do wait okay learning rate momentum everything which makes sense right because the other thing that we've been learning about a lot about in the last 12 months is how as you train a model it kind of goes through this different phases of like the the the the the kind of white landscapes the sorry the lost function the lost landscapes of neural nets look very different at the start in the middle and at the end and so it's very unlikely that you would want the same hyper parameters throughout so being able to schedule anything is super handy so we'll create a parameter schedule a callback and you're just going to pass in a function right and a parameter the schedule so we're going to be passing in L R because L R is what PI torch calls learning right and then this function will be something we takes a single argument which is number of epochs divided by total epochs and remember I told you that that train eval callback we added is going to set this to be a float so this will be the number this will be like 80 pluck number two point three five out of six so this will be a float of exactly how far through training are we and we'll pass that to some function that we're going to write and the result of that function will be used to set the hyper parameter in this case and learning rate as you know from plot one you don't necessarily want to have the same value of a hyper parameter for all of your layers so PI torch has something called parameter groups which we use an abstraction we call layer groups in fast AI but they're basically the same thing and so a PI torch optimizer contains a number of parameter groups unless you explicitly create more than one it'll all be in one that anytime we do stuff with hyper parameters you have to loop through PG in self dot optional parameter groups so then parameter group so a learning rate for this parameter group this layer group is equal to the result of this function and then every time we started your batch if we're training and we'll run our scheduler pretty hard to know if our schedule is working if we can't actually see what's happening to the learning rate as we go so let's create another callback cord recorder that at the start of fit fitting sets the L ours and losses are raised to being empty and then after each batch as long as you're training it depends the current learning rate and the current loss now there's actually lots of learning rates potentially because there's lots of layer groups so in fast AI we tend to use the final layer group as the learning rate we actually print out but you don't have to do it that way and then we're add something to plot the learning rate so I had something to plot the losses so hopefully this looks pretty familiar compared to the recorder in fast AOV one so with that in place we now need to create a function that takes the percentage through the the learning which we're going to call pause for position and returns the value of learning rate and so let's create one for linear schedules so what we want to be able to pass this is a starting learning rate and an ending learning rate so we might pass it's ten and one and it was started the learning rate of ten and go down to one that would be pretty curly high but whatever but we need a function that just takes position so this is a function that's going to return a function so here's a function that takes a start learning rate and an end learning rate and a position and returns the learning rate so to start plus position times the difference right so to convert that function into one which only takes position we do partial right passing in that function and the start and the end we were given so now this function just takes position because that's the only thing from inner that we haven't set so that's going to work fine but it's inconvenient because we're going to create lots of different schedulers and I don't want to have to write all this every time so we can simplify the way that you can create these by using a decorator here's the version with a decorator with a decorator you create linear scheduler in the natural way it's something that takes a start learning rate and end learning rate in a position and returns this and then we add an annealer decorator and the annealer decorator is the thing that does all this inner partial nonsense what's a decorator a decorator is a function that returns a function and what Python does is if it sees the name of a function here with an @ sign before it that it takes this function passes it into this function and replaces the definition of this function with whatever this returns so it's going to take this it's going to pass it over here and then it's going to say return inner where inner is partial as we described before so let's see that so now shed Lyn we wrote it as taking start and end and pause but if I hit shift tab this says it only takes start and end why is that because we've replaced this function with this function and this function just takes start and end right and this is where Jupiter is going to give you a lot more happy times and pretty much any IDE because this kind of dynamic code generation it's pretty hard for an IDE to do that for you where else in Drupada it's actually running the code in an actual Python process so it knows exactly what shed Linh means okay so this has now created a function that takes start and end and returns a function which takes pause which is what we need for our scheduler so let's try it let's say F equals shed Lin 1 comma 2 so this is scheduler that starts at learning rate 1 ends at learning rate 2 and then we'll say hey what should that be 30% of the way through training right and again if I hit shift tab here it knows that F is something that takes putts right so it's it's really nice in Jupiter you can you can take advantage of pythons dynamic nature and like there's no point using a dynamic language if you're not taking advantage of its dynamic nature right so things like decorators are super convenient way to do this stuff there are other languages like Julia that can do similar things with macros like it's is this is not the only way to get this kind of nice a very expressive ability but it's it's one good way to do it so now we can just go ahead and define all of our different schedule errs by passing in each is start and pause so for example no scheduler is something which always returns start or cosign scheduling exponential scheduling so let's define those and then let's try to plot them and it doesn't work why doesn't it work because you can't plot plight or chances but it turns out the only reason you can't plot plate or chances is because sensors don't have an end M attribute which tells matplotlib how many dimensions there are so watch this Torche 10cm dim equals a property that is the length of the shape this is now replaced the definition again using the dynamic features of Python replace the definitely replace or actually insert into the definition of tensor a new property called n dim and now we can plot tensors alright so like the nice thing about Python is you never have to be like oh this isn't supported because you can change everything you can insert things you can replace things whatever so here we've now got a nice printout of our four different schedulers which isn't really enough because if you want to do one cycle scheduling then in fact you know most of the time nowadays you want some kind of warm-up and some kind of cooldown or if you're doing something like SJ dr you've got like multiple cooldowns so we really need to be able to placed some of these schedulers together so let's create another function called combine schedulers and it's going to look like this we're going to pass in we're going to pass in the and of the phases we want so phase one will be a cosine schedule from a learning rate of 0.3 to 0.6 phase 2 will be a learning rate as cosine schedule with the learning rate going from point 6 to point 2 and phase 1 will take up 30% of our batches and phase 2 will take up 70% so that's what we're going to pass in how long is each phase and what's the schedule in each phase so here's how we do that I don't think I need to go through the code it's there's nothing interesting about it but what we do once we have that is that we can then plot that schedule and you can kind of see why we're very fond of these cosine 1 cycle schedules I don't think this has ever been published anywhere but it's what fast AI uses by default nowadays is you kind of get a nice gentle warm-up at the start this is the time when things are just super sensitive and fall apart really quickly but it doesn't take long as you'll see in next week's lesson when we do a deep dive into into stuff using hooks it doesn't take long for it to get into a decent part of the lost landscape and so you can quite quickly increase the learning rate and then something that people have and will start looking at papers next week for this something that people have realized in the last 4 months or so although Leslie Smith really kind of showed us this two years ago but it's only been the last 4 months or so that people have really understood this and the wider academic literature you need to train at a high learning rate for a long time and so with this kind of coached cosine schedule we keep it up high for a long time but then you also need to fine-tune at a very low learning rate for a long time so this has all of the kind of nice features that we want so cosine one cycle schedules are terrific and we now can build them from scratch so let's try trading like this so let's create a list of callback functions it has a recorder in it and average stats callback with accuracy in it and a parameter scheduler that shed the learning rate using this schedule and then fit and that's looking pretty good we're getting up towards 94% pretty quickly and we can now go plot LR and it's the shape that we hoped for and we can even say plot loss okay so we now have really all of the pieces we need to to kind of try out lots of different ways of of training neural nets we still haven't looked at convolutions really we'll do that next week and a lot more but you you kind of have the ability now to hopefully think of lots of things that you might want to try and and try them out so so next week we're going to be starting with clump Nets we're going to be kind of and we're going to be finally using a GPU because once we because once we start creating confidence of this size it starts taking a little bit too long but just to read ahead a little bit how what's it going to take to put stuff on the GPU this is the entirety of the callback alright so we've now got the mechanics we need to do things unbelievably quickly right and then we'll be able to oh and also we'll be wanting to add some transformations this is the entirety of what it takes to do batch wise transformations without callback as we discussed though we can't add callbacks between layers so we will add callbacks between layers initially manually and then using PI torch hooks and that way we're going to be able to plot and see exactly what's going on inside our models as they train and we'll find ways to train them much much more nicely so that by the end of next by the end of the next notebook we will be up over 98% accuracy and that's going to be super cool and then we're going to do a deep dive into batch norm data blocks API optimizes and transforms and at that point I think we'll have basically all the mechanics we need to go into some more advanced architectures and training methods and see how we did some of the cool stuff that we did in plat one so I'll see you next week [Applause]