{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Super resolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "*** Experiment started with the Pytorch backend\n",
      "Device: ID 0, GeForce GTX 1070 Ti (8119 RAM)\n",
      "\n",
      "\n",
      "*** Current state:\n",
      "RAM:  Used  Free  Total      Util\n",
      "CPU:  1901 20119  31588 MB   6.02% \n",
      "GPU:   427  7692   8119 MB   5.26% \n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f5e0f3f0470>"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "･ RAM: △Consumed △Peaked  Used Total | Exec time 0:00:00.002\n",
      "･ CPU:         0       0     1901 MB |\n",
      "･ GPU:         0       0      427 MB |\n"
     ]
    }
   ],
   "source": [
    "import fastai\n",
    "from fastai.vision import *\n",
    "from fastai.callbacks import *\n",
    "from fastai.utils.mem import *\n",
    "\n",
    "from torchvision.models import vgg16_bn\n",
    "\n",
    "from ipyexperiments import *\n",
    "exp1 = IPyExperimentsPytorch()\n",
    "import objgraph\n",
    "\n",
    "\n",
    "\n",
    "# w/o fixing random memory usage patterns change wildly and it's hard to tune things up this way\n",
    "if True:\n",
    "    import torch\n",
    "    torch.manual_seed(42)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.cuda.manual_seed_all(42)\n",
    "    random.seed(42)\n",
    "    np.random.seed(42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "･ RAM: △Consumed △Peaked  Used Total | Exec time 0:00:00.003\n",
      "･ CPU:         0       1     1901 MB |\n",
      "･ GPU:         0       0      427 MB |\n"
     ]
    }
   ],
   "source": [
    "path = untar_data(URLs.PETS)\n",
    "path_hr = path/'images'\n",
    "path_lr = path/'small-96'\n",
    "path_mr = path/'small-256'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "･ RAM: △Consumed △Peaked  Used Total | Exec time 0:00:00.064\n",
      "･ CPU:         2       0     1901 MB |\n",
      "･ GPU:         0       0      427 MB |\n"
     ]
    }
   ],
   "source": [
    "il = ImageItemList.from_folder(path_hr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "･ RAM: △Consumed △Peaked  Used Total | Exec time 0:00:00.001\n",
      "･ CPU:         0       0     1901 MB |\n",
      "･ GPU:         0       0      427 MB |\n"
     ]
    }
   ],
   "source": [
    "def resize_one(fn, i, path, size):\n",
    "    dest = path/fn.relative_to(path_hr)\n",
    "    dest.parent.mkdir(parents=True, exist_ok=True)\n",
    "    img = PIL.Image.open(fn)\n",
    "    targ_sz = resize_to(img, size, use_min=True)\n",
    "    img = img.resize(targ_sz, resample=PIL.Image.BILINEAR).convert('RGB')\n",
    "    img.save(dest, quality=60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "･ RAM: △Consumed △Peaked  Used Total | Exec time 0:00:00.037\n",
      "･ CPU:         0       0     1901 MB |\n",
      "･ GPU:         0       0      427 MB |\n"
     ]
    }
   ],
   "source": [
    "# create smaller image sets the first time this nb is run\n",
    "sets = [(path_lr, 96), (path_mr, 256)]\n",
    "for p,size in sets:\n",
    "    if not p.exists(): \n",
    "        print(f\"resizing to {size} into {p}\")\n",
    "        parallel(partial(resize_one, path=p, size=size), il.items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "･ RAM: △Consumed △Peaked  Used Total | Exec time 0:00:00.099\n",
      "･ CPU:         1       0     1902 MB |\n",
      "･ GPU:         0       0      427 MB |\n"
     ]
    }
   ],
   "source": [
    "bs,size=32,128\n",
    "arch = models.resnet34\n",
    "\n",
    "src = ImageImageList.from_folder(path_lr).random_split_by_pct(0.1, seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "･ RAM: △Consumed △Peaked  Used Total | Exec time 0:00:00.001\n",
      "･ CPU:         0       0     1902 MB |\n",
      "･ GPU:         0       0      427 MB |\n"
     ]
    }
   ],
   "source": [
    "def get_data(bs,size):\n",
    "    data = (src.label_from_func(lambda x: path_hr/x.name)\n",
    "           .transform(get_transforms(max_zoom=2.), size=size, tfm_y=True)\n",
    "           .databunch(bs=bs).normalize(imagenet_stats, do_y=True))\n",
    "\n",
    "    data.c = 3\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "･ RAM: △Consumed △Peaked  Used Total | Exec time 0:00:00.352\n",
      "･ CPU:         1       3     1904 MB |\n",
      "･ GPU:         0       0      427 MB |\n"
     ]
    }
   ],
   "source": [
    "data = get_data(bs,size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data.show_batch(ds_type=DatasetType.Valid, rows=2, figsize=(9,9))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = data.valid_ds[0][1].data\n",
    "t = torch.stack([t,t])\n",
    "\n",
    "def gram_matrix(x):\n",
    "    n,c,h,w = x.size()\n",
    "    x = x.view(n, c, -1)\n",
    "    return (x @ x.transpose(1,2))/(c*h*w)\n",
    "\n",
    "gram_matrix(t)\n",
    "\n",
    "base_loss = F.l1_loss\n",
    "\n",
    "vgg_m = vgg16_bn(True).features.cuda().eval()\n",
    "requires_grad(vgg_m, False)\n",
    "\n",
    "blocks = [i-1 for i,o in enumerate(children(vgg_m)) if isinstance(o,nn.MaxPool2d)]\n",
    "blocks, [vgg_m[i] for i in blocks]\n",
    "\n",
    "class FeatureLoss(nn.Module):\n",
    "    def __init__(self, m_feat, layer_ids, layer_wgts):\n",
    "        super().__init__()\n",
    "        self.m_feat = m_feat\n",
    "        self.loss_features = [self.m_feat[i] for i in layer_ids]\n",
    "        self.hooks = hook_outputs(self.loss_features, detach=False)\n",
    "        self.wgts = layer_wgts\n",
    "        self.metric_names = ['pixel',] + [f'feat_{i}' for i in range(len(layer_ids))\n",
    "              ] + [f'gram_{i}' for i in range(len(layer_ids))]\n",
    "\n",
    "    def make_features(self, x, clone=False):\n",
    "        self.m_feat(x)\n",
    "        return [(o.clone() if clone else o) for o in self.hooks.stored]\n",
    "    \n",
    "    def forward(self, input, target):\n",
    "        out_feat = self.make_features(target, clone=True)\n",
    "        in_feat = self.make_features(input)\n",
    "        self.feat_losses = [base_loss(input,target)]\n",
    "        self.feat_losses += [base_loss(f_in, f_out)*w\n",
    "                             for f_in, f_out, w in zip(in_feat, out_feat, self.wgts)]\n",
    "        self.feat_losses += [base_loss(gram_matrix(f_in), gram_matrix(f_out))*w**2 * 5e3\n",
    "                             for f_in, f_out, w in zip(in_feat, out_feat, self.wgts)]\n",
    "        self.metrics = dict(zip(self.metric_names, self.feat_losses))\n",
    "        return sum(self.feat_losses)\n",
    "    \n",
    "    def __del__(self): print(\"hook remove!!!\"); self.hooks.remove()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_loss = FeatureLoss(vgg_m, blocks[2:5], [5,15,2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wd = 1e-3\n",
    "#loss_func=feat_loss\n",
    "#loss_func=F.l1_loss \n",
    "learn = unet_learner(data, arch, wd=wd, \n",
    "                     #loss_func=F.l1_loss,\n",
    "                     loss_func=feat_loss, callback_fns=LossMetrics,\n",
    "                     blur=True, norm_type=NormType.Weight)\n",
    "del feat_loss # very important memory saving down the road"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#_=learn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#gc.collect()\n",
    "#sys.getrefcount(learn.loss_func)\n",
    "#sys.getrefcount(feat_loss)\n",
    "#len(gc.get_referrers(learn.loss_func))\n",
    "#del learn.loss_func\n",
    "#for x in gc.get_referrers(feat_loss):\n",
    "#    print(x.keys())\n",
    "    \n",
    "\n",
    "#del feat_loss\n",
    "#len(gc.get_referrers(learn.loss_func))\n",
    "#len(gc.get_referrers(learn.loss_func))\n",
    "#len(gc.get_referrers(feat_loss))\n",
    "#feat_loss.hooks.remove()\n",
    "#gc.get_referrers(feat_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#objgraph.show_refs(feat_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#feat_loss.hooks.remove()\n",
    "#objgraph.show_refs(feat_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_=learn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#learn.purge()\n",
    "#learn.destroy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#die\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.lr_find()\n",
    "learn.recorder.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#del learn.loss_func\n",
    "#del feat_loss\n",
    "#del loss_func\n",
    "#learn.destroy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_=learn.purge(clear_opt=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#del vgg_m\n",
    "#del learn\n",
    "#gc.collect()\n",
    "#torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 1e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_fit(save_name, lrs=slice(lr), pct_start=0.9):\n",
    "    # XXX:\n",
    "    cycles = 1\n",
    "    learn.fit_one_cycle(cycles, lrs, pct_start=pct_start)\n",
    "    learn.save(save_name)\n",
    "    learn.show_results(rows=1, imgsize=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "do_fit('1a', slice(lr*10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.destroy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "die"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.unfreeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "do_fit('1b', slice(1e-5,lr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = get_data(12,size*2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.data = data\n",
    "learn.freeze()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.load('1b');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "do_fit('2a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.unfreeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "do_fit('2b', slice(1e-6,1e-4), pct_start=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = None\n",
    "gc.collect();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "256/320*1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "256/320*1600"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "free = gpu_mem_get_free_no_cache()\n",
    "# the max size of the test image depends on the available GPU RAM \n",
    "if free > 8000: size=(1280, 1600) # >  8GB RAM\n",
    "else:           size=( 820, 1024) # <= 8GB RAM\n",
    "print(f\"using size={size}, have {free}MB of GPU RAM free\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = unet_learner(data, arch, loss_func=F.l1_loss, blur=True, norm_type=NormType.Weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_mr = (ImageImageList.from_folder(path_mr).random_split_by_pct(0.1, seed=42)\n",
    "          .label_from_func(lambda x: path_hr/x.name)\n",
    "          .transform(get_transforms(), size=size, tfm_y=True)\n",
    "          .databunch(bs=1).normalize(imagenet_stats, do_y=True))\n",
    "data_mr.c = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.load('2b');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.data = data_mr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fn = data_mr.valid_ds.x.items[0]; fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = open_image(fn); img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p,img_hr,b = learn.predict(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_image(img, figsize=(18,15), interpolation='nearest');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image(img_hr).show(figsize=(18,15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
